{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from e2c_train import create_e2c\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Input\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = '/data/cees/zjin/lstm_rom/datasets/9W_BHP/'\n",
    "data_dir = '/data/cees/zjin/lstm_rom/datasets/9W_BHP_RATE/'\n",
    "\n",
    "output_dir = '/data3/Astro/lstm_rom/e2c_larry/saved_models/' # load model data\n",
    "\n",
    "case_name = '9w_bhp_rate'\n",
    "\n",
    "# suffix = '_single_out_rel_2'\n",
    "# suffix = '_fix_wl_rel_1'\n",
    "case_suffix = '_fix_wl_rel_1' # the dataset being evaluated here\n",
    "# model_suffix = '_single_out_rel_3' # the dataset used to train the model\n",
    "model_suffix = '_fix_wl_rel_1'\n",
    "train_suffix = '_with_p'\n",
    "\n",
    "eval_file = case_name + '_e2c_eval' + case_suffix + train_suffix + '_n2200_dt20day_nt22_nrun100.mat'\n",
    "\n",
    "state_file = case_name + '_train_n_400_full'\n",
    "ctrl_file = case_name + '_norm_bhps_n_400'\n",
    "\n",
    "state_data = state_file + case_suffix + '.mat'\n",
    "ctrl_data = ctrl_file + case_suffix + '.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim, u_dim = 50, 9\n",
    "input_shape = (60, 60, 2) # change from _with_p to _no_p\n",
    "encoder, decoder, transition, sampler = create_e2c(latent_dim, u_dim, input_shape)\n",
    "\n",
    "num_train, latent_dim, learning_rate, epoch = 6600, 50, 1e-4, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder.load_weights(output_dir + 'e2c_encoder_'+case_name+model_suffix+train_suffix+'_nt%d_l%d_lr%.0e_ep%d.h5' % (num_train, latent_dim, learning_rate, epoch))\n",
    "decoder.load_weights(output_dir + 'e2c_decoder_'+case_name+model_suffix+train_suffix+'_nt%d_l%d_lr%.0e_ep%d.h5' % (num_train, latent_dim, learning_rate, epoch))\n",
    "transition.load_weights(output_dir + 'e2c_transition_'+case_name+model_suffix+train_suffix+'_nt%d_l%d_lr%.0e_ep%d.h5' % (num_train, latent_dim, learning_rate, epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One step prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_r = h5py.File(data_dir + eval_file, 'r')\n",
    "state_t_eval = np.array(hf_r.get('state_t'))\n",
    "# state_t1_eval = np.array(hf_r.get('state_t1'))\n",
    "# print(list(hf_r.keys()))\n",
    "# state_t_eval = np.array(hf_r.get('sat_t'))\n",
    "# state_t1_eval = np.array(hf_r.get('sat_t1'))\n",
    "# bhp_eval = np.array(hf_r.get('bhp'))\n",
    "hf_r.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_eval = 20 # pick 20 out of 2200 evals\n",
    "state_t_eval = state_t_eval[:num_eval, ...]\n",
    "# state_t1_eval = state_t1_eval[:num_eval, ...]\n",
    "# bhp_eval = bhp_eval[:num_eval, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 60, 60, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_t_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_r = h5py.File(data_dir + state_file + case_suffix + '.mat', 'r')\n",
    "sat_t = np.array(hf_r.get('sat'))\n",
    "pres_t = np.array(hf_r.get('pres'))\n",
    "print(sat_t.shape)\n",
    "print(pres_t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat = sat.T.reshape((400, 100, 3600))\n",
    "pres = pres.T.reshape(400,100,3600)\n",
    "print(\"sat shape:{}\".format(sat.shape))\n",
    "print(\"pres shape:{}\".format(pres.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "[xi_t_eval, _] = encoder.predict(state_t_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 50)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xi_t_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('data/xi_t_eval_2200.txt',xi_t_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as plt\n",
    "%matplotlib inline\n",
    "plt.plot(t_step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
