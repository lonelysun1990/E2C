{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import e2c as e2c_util\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use, usually either \"0\" or \"1\"\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_loss(x, t_decoded):\n",
    "    '''Reconstruction loss for the plain VAE'''\n",
    "    v = 0.1\n",
    "    # return K.mean(K.sum((K.batch_flatten(x) - K.batch_flatten(t_decoded)) ** 2 / (2*v) + 0.5*K.log(2*np.pi*v), axis=-1))\n",
    "    return K.mean(K.sum((K.batch_flatten(x) - K.batch_flatten(t_decoded)) ** 2 / (2*v), axis=-1))\n",
    "    # return K.sum((K.batch_flatten(x) - K.batch_flatten(t_decoded)) ** 2, axis=-1)\n",
    "\n",
    "\n",
    "def kl_normal_loss(qm, q_logv, pm, p_logv):\n",
    "    # 0.5 * (torch.log(pv) - torch.log(qv) + qv / pv + (qm - pm).pow(2) / pv - 1)\n",
    "    # -0.5 * K.sum(1 + t_log_var - K.square(t_mean) - K.exp(t_log_var), axis=-1)\n",
    "    kl = -0.5 * (1 - p_logv + q_logv - K.exp(q_logv) / K.exp(p_logv) - K.square(qm - pm) / K.exp(p_logv))\n",
    "    return K.mean(K.sum(kl, axis=-1))\n",
    "\n",
    "\n",
    "def get_flux_loss(m, state, state_pred):\n",
    "    # state, state_pred shape (batch_size, 60, 60, 2)\n",
    "    # p, p_pred shape (batch_size, 60, 60, 1)\n",
    "    # k shape (batch_size, 60, 60, 1)\n",
    "    \n",
    "    # Only consider discrepancies in total flux, not in phases (saturation not used) \n",
    "    \n",
    "    perm = K.exp(m)\n",
    "#     print(K.int_shape(perm))\n",
    "#     print(K.int_shape(state))\n",
    "#     print(K.int_shape(state_pred))\n",
    "    p = K.expand_dims(state[:, :, :, 1], -1)\n",
    "    p_pred = K.expand_dims(state_pred[:, :, :, 1], -1)\n",
    "#     print(K.int_shape(p))\n",
    "#     print(K.int_shape(p_pred))\n",
    "          \n",
    "    \n",
    "    tran_x = 1./perm[:, 1:, ...] + 1./perm[:, :-1, ...]\n",
    "    tran_y = 1./perm[:, :, 1:, ...] + 1./perm[:, :, :-1, ...]\n",
    "#     print(K.int_shape(tran_x))\n",
    "#     print(K.int_shape(tran_y))\n",
    "    flux_x = (p[:, 1:, ...] - p[:, :-1, ...]) / tran_x\n",
    "    flux_y = (p[:, :, 1:, :] - p[:, :, :-1, :]) / tran_y\n",
    "    flux_x_pred = (p_pred[:, 1:, ...] - p_pred[:, :-1, ...]) / tran_x\n",
    "    flux_y_pred = (p_pred[:, :, 1:, :] - p_pred[:, :, :-1, :]) / tran_y\n",
    "\n",
    "    loss_x = K.sum(K.abs(K.batch_flatten(flux_x) - K.batch_flatten(flux_x_pred)), axis=-1)\n",
    "    loss_y = K.sum(K.abs(K.batch_flatten(flux_y) - K.batch_flatten(flux_y_pred)), axis=-1)\n",
    "\n",
    "    loss_flux = K.mean(loss_x + loss_y)\n",
    "    return loss_flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_e2c(latent_dim, u_dim, input_shape):\n",
    "    '''\n",
    "    Creates a E2C.\n",
    "\n",
    "    Args:\n",
    "        latent_dim: dimensionality of latent space\n",
    "        return_kl_loss_op: whether to return the operation for\n",
    "                           computing the KL divergence loss.\n",
    "\n",
    "    Returns:\n",
    "        The VAE model. If return_kl_loss_op is True, then the\n",
    "        operation for computing the KL divergence loss is\n",
    "        additionally returned.\n",
    "    '''\n",
    "\n",
    "    encoder_ = e2c_util.create_encoder(latent_dim, input_shape)\n",
    "    decoder_ = e2c_util.create_decoder(latent_dim, input_shape)\n",
    "    transition_ = e2c_util.create_trans(latent_dim, u_dim)\n",
    "    sampler_ = e2c_util.create_sampler()\n",
    "\n",
    "    return encoder_, decoder_, transition_, sampler_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m shape is  (60, 60, 1)\n",
      "m_eval shape is  (2200, 60, 60, 1)\n",
      "m shape is  (6600, 60, 60, 1)\n"
     ]
    }
   ],
   "source": [
    "# Create plain E2C model and associated loss operations\n",
    "\n",
    "################### case specification ######################\n",
    "\n",
    "#     data_dir = '/data/cees/zjin/lstm_rom/datasets/9W_BHP/'\n",
    "data_dir = '/data/cees/zjin/lstm_rom/datasets/9W_BHP_RATE/'\n",
    "output_dir = '/data3/Astro/lstm_rom/e2c_larry/saved_models/'\n",
    "\n",
    "#     case_name = '9w_bhp'\n",
    "case_name = '9w_bhp_rate'\n",
    "\n",
    "#     case_suffix = '_single_out_rel_2'\n",
    "case_suffix = '_fix_wl_rel_1'\n",
    "#     case_suffix = '_single_out_rel_3'\n",
    "train_suffix = '_with_p'\n",
    "model_suffix = '_flux_loss'\n",
    "\n",
    "\n",
    "train_file = case_name + '_e2c_train' + case_suffix + train_suffix + '_n6600_dt20day_nt22_nrun300.mat'\n",
    "eval_file = case_name + '_e2c_eval' + case_suffix + train_suffix +'_n2200_dt20day_nt22_nrun100.mat'\n",
    "\n",
    "#################### model specification ##################\n",
    "epoch = 10\n",
    "batch_size = 4\n",
    "learning_rate = 1e-4\n",
    "latent_dim = 50\n",
    "u_dim = 9 # control dimension\n",
    "\n",
    "# load data\n",
    "hf_r = h5py.File(data_dir + train_file, 'r')\n",
    "state_t_train = np.array(hf_r.get('state_t'))\n",
    "state_t1_train = np.array(hf_r.get('state_t1'))\n",
    "bhp_train = np.array(hf_r.get('bhp'))\n",
    "hf_r.close()\n",
    "\n",
    "num_train = state_t_train.shape[0]\n",
    "\n",
    "hf_r = h5py.File(data_dir + eval_file, 'r')\n",
    "state_t_eval = np.array(hf_r.get('state_t'))\n",
    "state_t1_eval = np.array(hf_r.get('state_t1'))\n",
    "bhp_eval = np.array(hf_r.get('bhp'))\n",
    "hf_r.close()\n",
    "\n",
    "m = np.loadtxt(\"/data/cees/zjin/lstm_rom/sim_runs/case4_9w_bhp_rate/template/logk1.dat\")\n",
    "m = m.reshape(60,60,1)\n",
    "print('m shape is ', m.shape)\n",
    "#     m_tf = K.placeholder((batch_size, 60, 60 ,1))\n",
    "m_tf = Input(shape=(60, 60, 1))\n",
    "\n",
    "\n",
    "\n",
    "m_eval = np.repeat(np.expand_dims(m, axis = 0), state_t_eval.shape[0], axis = 0)\n",
    "print(\"m_eval shape is \", m_eval.shape)\n",
    "m = np.repeat(np.expand_dims(m,axis = 0), state_t_train.shape[0], axis = 0)\n",
    "print(\"m shape is \", m.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Construct E2C\n",
    "input_shape = (60, 60, 2)\n",
    "encoder, decoder, transition, sampler = create_e2c(latent_dim, u_dim, input_shape)\n",
    "\n",
    "xt = Input(shape=input_shape)\n",
    "xt1 = Input(shape=input_shape)\n",
    "ut = Input(shape=(u_dim, ))\n",
    "\n",
    "zt_mean, zt_logvar = encoder(xt)\n",
    "zt = sampler([zt_mean, zt_logvar])\n",
    "xt_rec = decoder(zt)\n",
    "\n",
    "zt1_mean, zt1_logvar = encoder(xt1)\n",
    "\n",
    "# zt1_pred, zt1_mean_pred, zt1_logvar_pred = transition([zt, ut])\n",
    "zt1_pred, zt1_mean_pred = transition([zt, zt_mean, ut])\n",
    "xt1_pred = decoder(zt1_pred)\n",
    "\n",
    "# Compute loss\n",
    "loss_rec_t = reconstruction_loss(xt, xt_rec)\n",
    "loss_rec_t1 = reconstruction_loss(xt1, xt1_pred)\n",
    "\n",
    "loss_flux_t = get_flux_loss(m_tf, xt, xt_rec) / 300.\n",
    "loss_flux_t1 = get_flux_loss(m_tf, xt1, xt1_pred) / 300.\n",
    "\n",
    "loss_kl = kl_normal_loss(zt_mean, zt_logvar, 0., 0.)  # log(1.) = 0.\n",
    "loss_bound = loss_rec_t + loss_rec_t1 + loss_kl  + loss_flux_t + loss_flux_t1\n",
    "\n",
    "# loss_trans = kl_normal_loss(zt1_mean_pred, zt1_logvar_pred, zt1_mean, zt1_logvar)\n",
    "\n",
    "# Use zt_logvar to approximate zt1_logvar_pred\n",
    "loss_trans = kl_normal_loss(zt1_mean_pred, zt_logvar, zt1_mean, zt1_logvar)\n",
    "\n",
    "\n",
    "trans_loss_weight = 1.0 # lambda in E2C paper Eq. (11)\n",
    "loss = loss_bound + trans_loss_weight * loss_trans\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Batch 1/1650, Loss 4038.392822, Loss rec 1701.444824, loss rec t1 2089.495361, loss kl 0.031140, loss_trans 0.026130, loss flux 119.678650, loss flux t1 127.716484\n",
      "Epoch 1/10, Batch 11/1650, Loss 2554.875977, Loss rec 741.356750, loss rec t1 853.260620, loss kl 15.125269, loss_trans 12.703239, loss flux 509.874451, loss flux t1 422.555786\n",
      "Epoch 1/10, Batch 21/1650, Loss 1557.361450, Loss rec 484.480804, loss rec t1 536.387817, loss kl 9.275908, loss_trans 6.374589, loss flux 241.584961, loss flux t1 279.257263\n",
      "Epoch 1/10, Batch 31/1650, Loss 1112.858765, Loss rec 366.910950, loss rec t1 406.548187, loss kl 4.336070, loss_trans 3.413725, loss flux 160.765549, loss flux t1 170.884338\n",
      "Epoch 1/10, Batch 41/1650, Loss 985.137329, Loss rec 346.660461, loss rec t1 354.429352, loss kl 3.759231, loss_trans 2.784351, loss flux 136.276382, loss flux t1 141.227524\n",
      "Epoch 1/10, Batch 51/1650, Loss 762.994019, Loss rec 277.553040, loss rec t1 272.489685, loss kl 2.402936, loss_trans 1.947971, loss flux 103.842743, loss flux t1 104.757538\n",
      "Epoch 1/10, Batch 61/1650, Loss 855.934998, Loss rec 309.612335, loss rec t1 299.728760, loss kl 5.344944, loss_trans 3.223079, loss flux 117.824081, loss flux t1 120.201775\n",
      "Epoch 1/10, Batch 71/1650, Loss 803.444031, Loss rec 300.400757, loss rec t1 299.911926, loss kl 4.101171, loss_trans 2.896348, loss flux 97.152428, loss flux t1 98.981369\n",
      "Epoch 1/10, Batch 81/1650, Loss 737.981567, Loss rec 260.005188, loss rec t1 302.706818, loss kl 2.300744, loss_trans 1.582757, loss flux 89.354309, loss flux t1 82.031731\n",
      "Epoch 1/10, Batch 91/1650, Loss 792.274170, Loss rec 299.933655, loss rec t1 300.820862, loss kl 2.459416, loss_trans 1.670296, loss flux 96.311661, loss flux t1 91.078339\n",
      "Epoch 1/10, Batch 101/1650, Loss 741.173706, Loss rec 277.237183, loss rec t1 288.564209, loss kl 2.275321, loss_trans 1.690048, loss flux 89.167747, loss flux t1 82.239189\n",
      "Epoch 1/10, Batch 111/1650, Loss 740.941833, Loss rec 280.073547, loss rec t1 282.450256, loss kl 2.722333, loss_trans 1.802765, loss flux 87.899078, loss flux t1 85.993805\n",
      "Epoch 1/10, Batch 121/1650, Loss 692.966248, Loss rec 265.160919, loss rec t1 252.489777, loss kl 2.729637, loss_trans 1.674045, loss flux 90.135658, loss flux t1 80.776184\n",
      "Epoch 1/10, Batch 131/1650, Loss 532.735107, Loss rec 191.558853, loss rec t1 199.655548, loss kl 1.367619, loss_trans 1.383446, loss flux 72.067101, loss flux t1 66.702515\n",
      "Epoch 1/10, Batch 141/1650, Loss 447.574249, Loss rec 153.048004, loss rec t1 165.844238, loss kl 1.448071, loss_trans 1.120347, loss flux 65.868240, loss flux t1 60.245335\n",
      "Epoch 1/10, Batch 151/1650, Loss 571.288513, Loss rec 199.870697, loss rec t1 200.319061, loss kl 2.879705, loss_trans 1.930659, loss flux 85.292114, loss flux t1 80.996269\n",
      "Epoch 1/10, Batch 161/1650, Loss 598.547119, Loss rec 210.205887, loss rec t1 222.023514, loss kl 2.586469, loss_trans 1.643538, loss flux 86.250038, loss flux t1 75.837677\n",
      "Epoch 1/10, Batch 171/1650, Loss 558.054260, Loss rec 197.201309, loss rec t1 198.854858, loss kl 2.427013, loss_trans 1.708713, loss flux 82.092049, loss flux t1 75.770302\n",
      "Epoch 1/10, Batch 181/1650, Loss 409.696198, Loss rec 137.816284, loss rec t1 161.578140, loss kl 0.758199, loss_trans 0.774427, loss flux 55.673153, loss flux t1 53.095997\n",
      "Epoch 1/10, Batch 191/1650, Loss 557.925781, Loss rec 177.094070, loss rec t1 201.198944, loss kl 2.130612, loss_trans 1.365745, loss flux 89.349365, loss flux t1 86.787071\n",
      "Epoch 1/10, Batch 201/1650, Loss 450.910675, Loss rec 143.014801, loss rec t1 159.961105, loss kl 1.814591, loss_trans 1.138321, loss flux 78.145805, loss flux t1 66.836014\n",
      "Epoch 1/10, Batch 211/1650, Loss 385.072693, Loss rec 126.216255, loss rec t1 139.310776, loss kl 1.183630, loss_trans 0.947308, loss flux 62.486095, loss flux t1 54.928661\n",
      "Epoch 1/10, Batch 221/1650, Loss 419.183716, Loss rec 149.128143, loss rec t1 144.062805, loss kl 1.234811, loss_trans 0.899774, loss flux 64.980339, loss flux t1 58.877838\n",
      "Epoch 1/10, Batch 231/1650, Loss 420.068787, Loss rec 126.980530, loss rec t1 160.466019, loss kl 1.536177, loss_trans 1.166863, loss flux 66.001671, loss flux t1 63.917545\n",
      "Epoch 1/10, Batch 241/1650, Loss 431.124542, Loss rec 136.644653, loss rec t1 146.569351, loss kl 1.254941, loss_trans 0.886980, loss flux 76.340500, loss flux t1 69.428085\n",
      "Epoch 1/10, Batch 251/1650, Loss 481.803223, Loss rec 162.195129, loss rec t1 182.163269, loss kl 1.542247, loss_trans 1.192590, loss flux 70.448334, loss flux t1 64.261665\n",
      "Epoch 1/10, Batch 261/1650, Loss 380.691132, Loss rec 116.552101, loss rec t1 127.176620, loss kl 0.927954, loss_trans 0.766576, loss flux 69.181938, loss flux t1 66.085938\n",
      "Epoch 1/10, Batch 271/1650, Loss 377.276947, Loss rec 115.716431, loss rec t1 123.030342, loss kl 1.485595, loss_trans 1.054732, loss flux 70.154625, loss flux t1 65.835228\n",
      "Epoch 1/10, Batch 281/1650, Loss 341.001953, Loss rec 99.006104, loss rec t1 122.736717, loss kl 1.101590, loss_trans 0.789466, loss flux 61.883831, loss flux t1 55.484241\n",
      "Epoch 1/10, Batch 291/1650, Loss 359.781647, Loss rec 94.955101, loss rec t1 128.846985, loss kl 1.019321, loss_trans 0.729480, loss flux 69.344795, loss flux t1 64.885956\n",
      "Epoch 1/10, Batch 301/1650, Loss 340.625641, Loss rec 97.665894, loss rec t1 130.374268, loss kl 0.777356, loss_trans 0.550433, loss flux 57.550053, loss flux t1 53.707626\n",
      "Epoch 1/10, Batch 311/1650, Loss 317.342499, Loss rec 92.730942, loss rec t1 99.483368, loss kl 0.610019, loss_trans 0.418308, loss flux 63.396076, loss flux t1 60.703789\n",
      "Epoch 1/10, Batch 321/1650, Loss 337.034973, Loss rec 98.282700, loss rec t1 109.567558, loss kl 1.241335, loss_trans 0.839360, loss flux 64.005157, loss flux t1 63.098888\n",
      "Epoch 1/10, Batch 331/1650, Loss 328.878296, Loss rec 100.180016, loss rec t1 111.101990, loss kl 0.917892, loss_trans 0.708406, loss flux 60.429352, loss flux t1 55.540627\n",
      "Epoch 1/10, Batch 341/1650, Loss 425.839478, Loss rec 139.659851, loss rec t1 156.086243, loss kl 0.918627, loss_trans 0.595763, loss flux 66.557747, loss flux t1 62.021240\n",
      "Epoch 1/10, Batch 351/1650, Loss 354.868378, Loss rec 102.614838, loss rec t1 111.236557, loss kl 1.572260, loss_trans 1.034478, loss flux 70.126823, loss flux t1 68.283417\n",
      "Epoch 1/10, Batch 361/1650, Loss 332.831909, Loss rec 93.784187, loss rec t1 113.671730, loss kl 0.877362, loss_trans 0.603811, loss flux 63.507469, loss flux t1 60.387333\n",
      "Epoch 1/10, Batch 371/1650, Loss 370.721375, Loss rec 111.261726, loss rec t1 127.314804, loss kl 1.152085, loss_trans 0.696005, loss flux 70.119080, loss flux t1 60.177643\n",
      "Epoch 1/10, Batch 381/1650, Loss 315.206268, Loss rec 90.227402, loss rec t1 97.936783, loss kl 1.104857, loss_trans 0.656643, loss flux 65.355682, loss flux t1 59.924885\n",
      "Epoch 1/10, Batch 391/1650, Loss 315.067535, Loss rec 88.156265, loss rec t1 109.626068, loss kl 0.976409, loss_trans 0.538374, loss flux 60.912098, loss flux t1 54.858334\n",
      "Epoch 1/10, Batch 401/1650, Loss 304.385864, Loss rec 86.134369, loss rec t1 105.142113, loss kl 0.835593, loss_trans 0.507995, loss flux 57.648399, loss flux t1 54.117409\n",
      "Epoch 1/10, Batch 411/1650, Loss 316.751709, Loss rec 90.636200, loss rec t1 104.918854, loss kl 1.462968, loss_trans 0.998268, loss flux 61.036068, loss flux t1 57.699364\n",
      "Epoch 1/10, Batch 421/1650, Loss 331.699402, Loss rec 101.096001, loss rec t1 109.301117, loss kl 1.283611, loss_trans 0.899814, loss flux 61.254948, loss flux t1 57.863895\n",
      "Epoch 1/10, Batch 431/1650, Loss 249.112457, Loss rec 59.328243, loss rec t1 80.002747, loss kl 0.650540, loss_trans 0.225202, loss flux 58.829651, loss flux t1 50.076069\n",
      "Epoch 1/10, Batch 441/1650, Loss 286.253723, Loss rec 78.139412, loss rec t1 93.591377, loss kl 0.838932, loss_trans 0.407912, loss flux 60.253387, loss flux t1 53.022717\n",
      "Epoch 1/10, Batch 451/1650, Loss 249.618225, Loss rec 69.641739, loss rec t1 82.754578, loss kl 0.710465, loss_trans 0.538882, loss flux 49.316357, loss flux t1 46.656197\n",
      "Epoch 1/10, Batch 461/1650, Loss 258.143494, Loss rec 74.205833, loss rec t1 84.360245, loss kl 0.768001, loss_trans 0.437824, loss flux 51.157726, loss flux t1 47.213844\n",
      "Epoch 1/10, Batch 471/1650, Loss 239.618546, Loss rec 58.868771, loss rec t1 72.790909, loss kl 0.504271, loss_trans 0.192560, loss flux 55.978855, loss flux t1 51.283176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Batch 481/1650, Loss 232.191895, Loss rec 56.723797, loss rec t1 68.685555, loss kl 0.626647, loss_trans 0.249654, loss flux 54.859707, loss flux t1 51.046539\n",
      "Epoch 1/10, Batch 491/1650, Loss 238.631195, Loss rec 62.441269, loss rec t1 74.228638, loss kl 0.437624, loss_trans 0.272431, loss flux 53.431232, loss flux t1 47.820007\n",
      "Epoch 1/10, Batch 501/1650, Loss 269.780975, Loss rec 77.777695, loss rec t1 90.855621, loss kl 0.878233, loss_trans 0.538329, loss flux 52.102959, loss flux t1 47.628132\n",
      "Epoch 1/10, Batch 511/1650, Loss 274.017029, Loss rec 78.837631, loss rec t1 91.634979, loss kl 0.671138, loss_trans 0.272636, loss flux 53.693245, loss flux t1 48.907394\n",
      "Epoch 1/10, Batch 521/1650, Loss 227.295578, Loss rec 55.506752, loss rec t1 64.365829, loss kl 0.825911, loss_trans 0.386308, loss flux 53.951725, loss flux t1 52.259045\n",
      "Epoch 1/10, Batch 531/1650, Loss 211.640305, Loss rec 53.571312, loss rec t1 62.653252, loss kl 0.455716, loss_trans 0.227345, loss flux 49.570488, loss flux t1 45.162201\n",
      "Epoch 1/10, Batch 541/1650, Loss 232.590729, Loss rec 53.695053, loss rec t1 64.378326, loss kl 0.365483, loss_trans 0.153198, loss flux 59.954884, loss flux t1 54.043785\n",
      "Epoch 1/10, Batch 551/1650, Loss 241.861008, Loss rec 51.561371, loss rec t1 70.735672, loss kl 0.622225, loss_trans 0.326674, loss flux 61.617397, loss flux t1 56.997658\n",
      "Epoch 1/10, Batch 561/1650, Loss 251.669037, Loss rec 69.790627, loss rec t1 77.932304, loss kl 0.591223, loss_trans 0.286242, loss flux 52.554287, loss flux t1 50.514359\n",
      "Epoch 1/10, Batch 571/1650, Loss 236.794693, Loss rec 57.534142, loss rec t1 76.703445, loss kl 0.598860, loss_trans 0.222265, loss flux 52.656921, loss flux t1 49.079071\n",
      "Epoch 1/10, Batch 581/1650, Loss 248.483246, Loss rec 71.660416, loss rec t1 75.924690, loss kl 0.630464, loss_trans 0.283275, loss flux 52.282024, loss flux t1 47.702366\n",
      "Epoch 1/10, Batch 591/1650, Loss 216.511841, Loss rec 56.099251, loss rec t1 67.501175, loss kl 0.396059, loss_trans 0.161752, loss flux 48.277321, loss flux t1 44.076279\n",
      "Epoch 1/10, Batch 601/1650, Loss 262.367249, Loss rec 76.270615, loss rec t1 86.092224, loss kl 0.661431, loss_trans 0.444625, loss flux 52.692802, loss flux t1 46.205563\n",
      "Epoch 1/10, Batch 611/1650, Loss 239.701691, Loss rec 72.250198, loss rec t1 75.704193, loss kl 0.693747, loss_trans 0.428357, loss flux 46.752319, loss flux t1 43.872883\n",
      "Epoch 1/10, Batch 621/1650, Loss 215.518082, Loss rec 55.178246, loss rec t1 63.419518, loss kl 0.703776, loss_trans 0.359468, loss flux 49.111519, loss flux t1 46.745556\n",
      "Epoch 1/10, Batch 631/1650, Loss 256.448334, Loss rec 68.747025, loss rec t1 83.948822, loss kl 0.577394, loss_trans 0.276139, loss flux 54.185944, loss flux t1 48.713001\n",
      "Epoch 1/10, Batch 641/1650, Loss 240.718246, Loss rec 68.224686, loss rec t1 78.322388, loss kl 0.626639, loss_trans 0.379063, loss flux 48.141258, loss flux t1 45.024220\n",
      "Epoch 1/10, Batch 651/1650, Loss 250.323563, Loss rec 72.457520, loss rec t1 80.787735, loss kl 0.581719, loss_trans 0.319702, loss flux 50.362736, loss flux t1 45.814148\n",
      "Epoch 1/10, Batch 661/1650, Loss 226.614639, Loss rec 61.599686, loss rec t1 68.008156, loss kl 0.677049, loss_trans 0.334349, loss flux 50.593243, loss flux t1 45.402145\n",
      "Epoch 1/10, Batch 671/1650, Loss 253.232178, Loss rec 69.876266, loss rec t1 84.307861, loss kl 0.521065, loss_trans 0.273313, loss flux 51.121681, loss flux t1 47.131989\n",
      "Epoch 1/10, Batch 681/1650, Loss 226.613312, Loss rec 47.453331, loss rec t1 67.893677, loss kl 0.415955, loss_trans 0.134786, loss flux 56.987789, loss flux t1 53.727779\n",
      "Epoch 1/10, Batch 691/1650, Loss 245.479599, Loss rec 64.791145, loss rec t1 75.036720, loss kl 0.909970, loss_trans 0.540002, loss flux 53.427177, loss flux t1 50.774582\n",
      "Epoch 1/10, Batch 701/1650, Loss 283.726166, Loss rec 86.172417, loss rec t1 87.935593, loss kl 0.968337, loss_trans 0.582021, loss flux 57.539597, loss flux t1 50.528210\n",
      "Epoch 1/10, Batch 711/1650, Loss 271.779999, Loss rec 74.105782, loss rec t1 81.263557, loss kl 1.024156, loss_trans 0.504766, loss flux 59.724056, loss flux t1 55.157684\n",
      "Epoch 1/10, Batch 721/1650, Loss 231.993546, Loss rec 56.484520, loss rec t1 66.789383, loss kl 0.661301, loss_trans 0.297399, loss flux 56.837223, loss flux t1 50.923717\n",
      "Epoch 1/10, Batch 731/1650, Loss 256.867920, Loss rec 77.419434, loss rec t1 85.083649, loss kl 0.539249, loss_trans 0.213590, loss flux 49.763218, loss flux t1 43.848789\n",
      "Epoch 1/10, Batch 741/1650, Loss 209.023972, Loss rec 53.455280, loss rec t1 67.433464, loss kl 0.559266, loss_trans 0.294962, loss flux 44.653191, loss flux t1 42.627815\n",
      "Epoch 1/10, Batch 751/1650, Loss 222.882767, Loss rec 57.931095, loss rec t1 66.054459, loss kl 0.527380, loss_trans 0.227735, loss flux 50.762028, loss flux t1 47.380070\n",
      "Epoch 1/10, Batch 761/1650, Loss 240.193008, Loss rec 63.322273, loss rec t1 71.671410, loss kl 0.646101, loss_trans 0.339858, loss flux 53.034866, loss flux t1 51.178501\n",
      "Epoch 1/10, Batch 771/1650, Loss 196.556183, Loss rec 44.551346, loss rec t1 56.002289, loss kl 0.382685, loss_trans 0.145036, loss flux 50.007607, loss flux t1 45.467220\n",
      "Epoch 1/10, Batch 781/1650, Loss 212.127075, Loss rec 51.896034, loss rec t1 63.709770, loss kl 0.415282, loss_trans 0.145024, loss flux 49.043255, loss flux t1 46.917706\n",
      "Epoch 1/10, Batch 791/1650, Loss 236.689819, Loss rec 64.268944, loss rec t1 76.949265, loss kl 0.427664, loss_trans 0.201735, loss flux 49.170052, loss flux t1 45.672165\n",
      "Epoch 1/10, Batch 801/1650, Loss 206.199631, Loss rec 50.676022, loss rec t1 62.639332, loss kl 0.593835, loss_trans 0.285412, loss flux 47.296730, loss flux t1 44.708302\n",
      "Epoch 1/10, Batch 811/1650, Loss 238.997208, Loss rec 64.793640, loss rec t1 75.727592, loss kl 0.625899, loss_trans 0.197740, loss flux 50.413563, loss flux t1 47.238770\n",
      "Epoch 1/10, Batch 821/1650, Loss 199.907181, Loss rec 49.154339, loss rec t1 61.768501, loss kl 0.481260, loss_trans 0.243178, loss flux 45.124950, loss flux t1 43.134941\n",
      "Epoch 1/10, Batch 831/1650, Loss 180.900070, Loss rec 45.604858, loss rec t1 50.703491, loss kl 0.661811, loss_trans 0.275682, loss flux 43.728447, loss flux t1 39.925777\n",
      "Epoch 1/10, Batch 841/1650, Loss 158.873535, Loss rec 39.887810, loss rec t1 48.853172, loss kl 0.288858, loss_trans 0.091374, loss flux 36.108952, loss flux t1 33.643364\n",
      "Epoch 1/10, Batch 851/1650, Loss 206.513779, Loss rec 49.648205, loss rec t1 65.702194, loss kl 0.452901, loss_trans 0.170785, loss flux 46.689388, loss flux t1 43.850292\n",
      "Epoch 1/10, Batch 861/1650, Loss 203.289993, Loss rec 50.924294, loss rec t1 60.432213, loss kl 0.533705, loss_trans 0.230243, loss flux 47.129761, loss flux t1 44.039780\n",
      "Epoch 1/10, Batch 871/1650, Loss 197.587555, Loss rec 52.849388, loss rec t1 56.869610, loss kl 0.626689, loss_trans 0.241687, loss flux 44.659782, loss flux t1 42.340405\n",
      "Epoch 1/10, Batch 881/1650, Loss 191.967819, Loss rec 45.853291, loss rec t1 55.981491, loss kl 0.381513, loss_trans 0.178308, loss flux 45.330021, loss flux t1 44.243198\n",
      "Epoch 1/10, Batch 891/1650, Loss 178.709869, Loss rec 40.076157, loss rec t1 51.675224, loss kl 0.429295, loss_trans 0.197918, loss flux 43.507336, loss flux t1 42.823940\n",
      "Epoch 1/10, Batch 901/1650, Loss 191.981812, Loss rec 50.538685, loss rec t1 54.141060, loss kl 0.576311, loss_trans 0.203781, loss flux 45.471344, loss flux t1 41.050625\n",
      "Epoch 1/10, Batch 911/1650, Loss 155.336243, Loss rec 33.346542, loss rec t1 43.728645, loss kl 0.368244, loss_trans 0.106712, loss flux 40.501259, loss flux t1 37.284843\n",
      "Epoch 1/10, Batch 921/1650, Loss 173.189941, Loss rec 40.618622, loss rec t1 50.199188, loss kl 0.414102, loss_trans 0.177338, loss flux 40.941765, loss flux t1 40.838928\n",
      "Epoch 1/10, Batch 931/1650, Loss 163.619858, Loss rec 40.215588, loss rec t1 45.471355, loss kl 0.439654, loss_trans 0.167586, loss flux 40.244205, loss flux t1 37.081459\n",
      "Epoch 1/10, Batch 941/1650, Loss 165.752670, Loss rec 35.896503, loss rec t1 42.145493, loss kl 0.498276, loss_trans 0.162610, loss flux 45.444645, loss flux t1 41.605152\n",
      "Epoch 1/10, Batch 951/1650, Loss 161.718033, Loss rec 35.420921, loss rec t1 40.915104, loss kl 0.376084, loss_trans 0.123005, loss flux 42.378368, loss flux t1 42.504539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Batch 961/1650, Loss 146.064194, Loss rec 35.538204, loss rec t1 38.600197, loss kl 0.321387, loss_trans 0.089723, loss flux 37.333828, loss flux t1 34.180859\n",
      "Epoch 1/10, Batch 971/1650, Loss 178.052399, Loss rec 47.816772, loss rec t1 53.721390, loss kl 0.388423, loss_trans 0.146861, loss flux 38.970829, loss flux t1 37.008121\n",
      "Epoch 1/10, Batch 981/1650, Loss 174.705399, Loss rec 45.048820, loss rec t1 55.005657, loss kl 0.314856, loss_trans 0.088113, loss flux 39.183144, loss flux t1 35.064800\n",
      "Epoch 1/10, Batch 991/1650, Loss 184.408203, Loss rec 42.857517, loss rec t1 53.632256, loss kl 0.271332, loss_trans 0.051972, loss flux 45.523632, loss flux t1 42.071480\n",
      "Epoch 1/10, Batch 1001/1650, Loss 281.685455, Loss rec 70.934845, loss rec t1 89.173866, loss kl 0.645596, loss_trans 0.236516, loss flux 60.719219, loss flux t1 59.975430\n",
      "Epoch 1/10, Batch 1011/1650, Loss 223.987015, Loss rec 62.893044, loss rec t1 71.636032, loss kl 0.249625, loss_trans 0.080540, loss flux 47.091129, loss flux t1 42.036655\n",
      "Epoch 1/10, Batch 1021/1650, Loss 165.861404, Loss rec 39.315086, loss rec t1 44.663807, loss kl 0.367492, loss_trans 0.100743, loss flux 41.064358, loss flux t1 40.349915\n",
      "Epoch 1/10, Batch 1031/1650, Loss 171.090332, Loss rec 45.446846, loss rec t1 48.744888, loss kl 0.617501, loss_trans 0.259678, loss flux 38.666862, loss flux t1 37.354553\n",
      "Epoch 1/10, Batch 1041/1650, Loss 148.168625, Loss rec 37.151917, loss rec t1 42.477570, loss kl 0.405947, loss_trans 0.157670, loss flux 35.083981, loss flux t1 32.891537\n",
      "Epoch 1/10, Batch 1051/1650, Loss 158.245941, Loss rec 38.906853, loss rec t1 45.374031, loss kl 0.316328, loss_trans 0.087011, loss flux 37.350914, loss flux t1 36.210800\n",
      "Epoch 1/10, Batch 1061/1650, Loss 179.141174, Loss rec 46.609322, loss rec t1 55.196995, loss kl 0.520980, loss_trans 0.187183, loss flux 39.239674, loss flux t1 37.387020\n",
      "Epoch 1/10, Batch 1071/1650, Loss 153.568329, Loss rec 33.014984, loss rec t1 39.374897, loss kl 0.506716, loss_trans 0.174533, loss flux 40.921642, loss flux t1 39.575562\n",
      "Epoch 1/10, Batch 1081/1650, Loss 162.683426, Loss rec 43.936050, loss rec t1 48.927040, loss kl 0.472684, loss_trans 0.156136, loss flux 35.329391, loss flux t1 33.862122\n",
      "Epoch 1/10, Batch 1091/1650, Loss 143.244797, Loss rec 29.797310, loss rec t1 36.976204, loss kl 0.192099, loss_trans 0.054535, loss flux 39.669052, loss flux t1 36.555592\n",
      "Epoch 1/10, Batch 1101/1650, Loss 145.467804, Loss rec 32.481396, loss rec t1 40.350517, loss kl 0.260096, loss_trans 0.053951, loss flux 38.717072, loss flux t1 33.604774\n",
      "Epoch 1/10, Batch 1111/1650, Loss 127.594398, Loss rec 25.464048, loss rec t1 34.153999, loss kl 0.253139, loss_trans 0.086983, loss flux 34.541965, loss flux t1 33.094257\n",
      "Epoch 1/10, Batch 1121/1650, Loss 158.032700, Loss rec 36.414364, loss rec t1 42.578915, loss kl 0.484069, loss_trans 0.130895, loss flux 41.450699, loss flux t1 36.973763\n",
      "Epoch 1/10, Batch 1131/1650, Loss 171.946686, Loss rec 45.251266, loss rec t1 49.901478, loss kl 0.675941, loss_trans 0.311589, loss flux 38.465729, loss flux t1 37.340706\n",
      "Epoch 1/10, Batch 1141/1650, Loss 148.072052, Loss rec 37.129066, loss rec t1 42.896881, loss kl 0.462049, loss_trans 0.167252, loss flux 33.533810, loss flux t1 33.882996\n",
      "Epoch 1/10, Batch 1151/1650, Loss 147.271194, Loss rec 35.393902, loss rec t1 41.202766, loss kl 0.543042, loss_trans 0.211939, loss flux 34.872864, loss flux t1 35.046673\n",
      "Epoch 1/10, Batch 1161/1650, Loss 162.599686, Loss rec 44.296234, loss rec t1 48.376007, loss kl 0.437402, loss_trans 0.171244, loss flux 35.574791, loss flux t1 33.743999\n",
      "Epoch 1/10, Batch 1171/1650, Loss 141.257980, Loss rec 34.224277, loss rec t1 37.554707, loss kl 0.330228, loss_trans 0.067757, loss flux 35.185562, loss flux t1 33.895432\n",
      "Epoch 1/10, Batch 1181/1650, Loss 166.051620, Loss rec 39.559731, loss rec t1 45.047367, loss kl 0.563661, loss_trans 0.149097, loss flux 40.432453, loss flux t1 40.299313\n",
      "Epoch 1/10, Batch 1191/1650, Loss 158.274506, Loss rec 39.664307, loss rec t1 45.959404, loss kl 0.487874, loss_trans 0.197351, loss flux 37.272087, loss flux t1 34.693470\n",
      "Epoch 1/10, Batch 1201/1650, Loss 135.109283, Loss rec 29.793169, loss rec t1 36.012047, loss kl 0.287185, loss_trans 0.054833, loss flux 37.697437, loss flux t1 31.264605\n",
      "Epoch 1/10, Batch 1211/1650, Loss 155.899033, Loss rec 39.107300, loss rec t1 42.811089, loss kl 0.416827, loss_trans 0.120817, loss flux 36.897930, loss flux t1 36.545071\n",
      "Epoch 1/10, Batch 1221/1650, Loss 131.310349, Loss rec 25.247602, loss rec t1 31.716007, loss kl 0.311232, loss_trans 0.051993, loss flux 37.615833, loss flux t1 36.367695\n",
      "Epoch 1/10, Batch 1231/1650, Loss 123.745277, Loss rec 26.217722, loss rec t1 34.037415, loss kl 0.301035, loss_trans 0.063330, loss flux 31.846706, loss flux t1 31.279070\n",
      "Epoch 1/10, Batch 1241/1650, Loss 121.743050, Loss rec 25.067150, loss rec t1 30.513248, loss kl 0.346150, loss_trans 0.075850, loss flux 35.335415, loss flux t1 30.405235\n",
      "Epoch 1/10, Batch 1251/1650, Loss 149.378250, Loss rec 38.077209, loss rec t1 44.190712, loss kl 0.282961, loss_trans 0.068947, loss flux 34.201084, loss flux t1 32.557323\n",
      "Epoch 1/10, Batch 1261/1650, Loss 166.018494, Loss rec 40.657986, loss rec t1 46.705078, loss kl 0.369059, loss_trans 0.104513, loss flux 41.680984, loss flux t1 36.500866\n",
      "Epoch 1/10, Batch 1271/1650, Loss 155.834991, Loss rec 40.614784, loss rec t1 45.152645, loss kl 0.415177, loss_trans 0.151038, loss flux 36.156269, loss flux t1 33.345085\n",
      "Epoch 1/10, Batch 1281/1650, Loss 128.781326, Loss rec 28.904587, loss rec t1 31.706028, loss kl 0.279073, loss_trans 0.044128, loss flux 35.932667, loss flux t1 31.914839\n",
      "Epoch 1/10, Batch 1291/1650, Loss 114.548653, Loss rec 23.164711, loss rec t1 27.894432, loss kl 0.221165, loss_trans 0.040243, loss flux 33.083897, loss flux t1 30.144203\n",
      "Epoch 1/10, Batch 1301/1650, Loss 119.762993, Loss rec 27.323204, loss rec t1 30.692884, loss kl 0.312083, loss_trans 0.093115, loss flux 32.020496, loss flux t1 29.321205\n",
      "Epoch 1/10, Batch 1311/1650, Loss 134.150589, Loss rec 28.454193, loss rec t1 37.481972, loss kl 0.263952, loss_trans 0.074936, loss flux 35.923203, loss flux t1 31.952337\n",
      "Epoch 1/10, Batch 1321/1650, Loss 149.265427, Loss rec 39.341248, loss rec t1 39.468987, loss kl 0.447707, loss_trans 0.154652, loss flux 36.248508, loss flux t1 33.604332\n",
      "Epoch 1/10, Batch 1331/1650, Loss 144.031494, Loss rec 35.916885, loss rec t1 39.505230, loss kl 0.284467, loss_trans 0.097669, loss flux 35.864986, loss flux t1 32.362240\n",
      "Epoch 1/10, Batch 1341/1650, Loss 108.597832, Loss rec 20.378445, loss rec t1 26.850964, loss kl 0.276866, loss_trans 0.063455, loss flux 31.324591, loss flux t1 29.703516\n",
      "Epoch 1/10, Batch 1351/1650, Loss 109.983673, Loss rec 24.561562, loss rec t1 27.650585, loss kl 0.210489, loss_trans 0.028534, loss flux 29.956772, loss flux t1 27.575729\n",
      "Epoch 1/10, Batch 1361/1650, Loss 141.061371, Loss rec 33.575684, loss rec t1 40.488083, loss kl 0.452291, loss_trans 0.098685, loss flux 35.195019, loss flux t1 31.251621\n",
      "Epoch 1/10, Batch 1371/1650, Loss 120.244568, Loss rec 23.455725, loss rec t1 30.320745, loss kl 0.221176, loss_trans 0.032396, loss flux 35.417961, loss flux t1 30.796570\n",
      "Epoch 1/10, Batch 1381/1650, Loss 132.785736, Loss rec 31.886719, loss rec t1 34.656090, loss kl 0.404803, loss_trans 0.105907, loss flux 32.687626, loss flux t1 33.044582\n",
      "Epoch 1/10, Batch 1391/1650, Loss 131.626709, Loss rec 28.824711, loss rec t1 32.677204, loss kl 0.418959, loss_trans 0.121105, loss flux 35.873047, loss flux t1 33.711674\n",
      "Epoch 1/10, Batch 1401/1650, Loss 123.493576, Loss rec 26.194439, loss rec t1 33.117008, loss kl 0.270805, loss_trans 0.048688, loss flux 32.752068, loss flux t1 31.110567\n",
      "Epoch 1/10, Batch 1411/1650, Loss 138.858047, Loss rec 33.989872, loss rec t1 39.233528, loss kl 0.387424, loss_trans 0.107078, loss flux 34.567047, loss flux t1 30.573112\n",
      "Epoch 1/10, Batch 1421/1650, Loss 139.777588, Loss rec 34.305931, loss rec t1 40.047256, loss kl 0.278176, loss_trans 0.049277, loss flux 33.469139, loss flux t1 31.627813\n",
      "Epoch 1/10, Batch 1431/1650, Loss 118.545250, Loss rec 25.630177, loss rec t1 29.310646, loss kl 0.336611, loss_trans 0.068736, loss flux 32.780529, loss flux t1 30.418556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Batch 1441/1650, Loss 156.319092, Loss rec 34.724789, loss rec t1 46.496399, loss kl 0.434294, loss_trans 0.127593, loss flux 36.658817, loss flux t1 37.877190\n",
      "Epoch 1/10, Batch 1451/1650, Loss 129.998276, Loss rec 33.390976, loss rec t1 37.864182, loss kl 0.340138, loss_trans 0.084459, loss flux 29.798727, loss flux t1 28.519785\n",
      "Epoch 1/10, Batch 1461/1650, Loss 123.025307, Loss rec 28.835087, loss rec t1 31.349075, loss kl 0.247718, loss_trans 0.034680, loss flux 33.105858, loss flux t1 29.452888\n",
      "Epoch 1/10, Batch 1471/1650, Loss 141.009521, Loss rec 36.898380, loss rec t1 39.097115, loss kl 0.369869, loss_trans 0.085198, loss flux 32.308979, loss flux t1 32.249973\n",
      "Epoch 1/10, Batch 1481/1650, Loss 146.943756, Loss rec 36.766670, loss rec t1 44.331429, loss kl 0.302128, loss_trans 0.075139, loss flux 33.076859, loss flux t1 32.391533\n",
      "Epoch 1/10, Batch 1491/1650, Loss 137.574860, Loss rec 33.782700, loss rec t1 36.601387, loss kl 0.511071, loss_trans 0.136174, loss flux 34.281597, loss flux t1 32.261940\n",
      "Epoch 1/10, Batch 1501/1650, Loss 152.141083, Loss rec 39.708221, loss rec t1 43.978889, loss kl 0.471614, loss_trans 0.145987, loss flux 33.675533, loss flux t1 34.160839\n",
      "Epoch 1/10, Batch 1511/1650, Loss 144.856934, Loss rec 37.404289, loss rec t1 43.247860, loss kl 0.257664, loss_trans 0.055714, loss flux 33.035606, loss flux t1 30.855808\n",
      "Epoch 1/10, Batch 1521/1650, Loss 118.677269, Loss rec 23.952797, loss rec t1 29.884054, loss kl 0.282655, loss_trans 0.051301, loss flux 32.836094, loss flux t1 31.670372\n",
      "Epoch 1/10, Batch 1531/1650, Loss 132.731659, Loss rec 31.104412, loss rec t1 35.980377, loss kl 0.327060, loss_trans 0.090864, loss flux 33.528778, loss flux t1 31.700171\n",
      "Epoch 1/10, Batch 1541/1650, Loss 135.337723, Loss rec 29.408520, loss rec t1 37.131218, loss kl 0.330820, loss_trans 0.039813, loss flux 35.344078, loss flux t1 33.083282\n",
      "Epoch 1/10, Batch 1551/1650, Loss 118.909042, Loss rec 27.296192, loss rec t1 31.550259, loss kl 0.205470, loss_trans 0.045165, loss flux 30.790932, loss flux t1 29.021023\n",
      "Epoch 1/10, Batch 1561/1650, Loss 139.416534, Loss rec 33.886032, loss rec t1 37.036079, loss kl 0.411725, loss_trans 0.079617, loss flux 34.895248, loss flux t1 33.107834\n",
      "Epoch 1/10, Batch 1571/1650, Loss 111.861107, Loss rec 22.386068, loss rec t1 24.900494, loss kl 0.356407, loss_trans 0.083248, loss flux 32.534550, loss flux t1 31.600340\n",
      "Epoch 1/10, Batch 1581/1650, Loss 98.152573, Loss rec 20.938187, loss rec t1 23.929192, loss kl 0.192917, loss_trans 0.019163, loss flux 27.741276, loss flux t1 25.331833\n",
      "Epoch 1/10, Batch 1591/1650, Loss 118.431297, Loss rec 25.347450, loss rec t1 27.534275, loss kl 0.347689, loss_trans 0.110237, loss flux 34.360210, loss flux t1 30.731426\n",
      "Epoch 1/10, Batch 1601/1650, Loss 112.162651, Loss rec 27.989826, loss rec t1 34.722137, loss kl 0.127844, loss_trans 0.028708, loss flux 25.877680, loss flux t1 23.416458\n",
      "Epoch 1/10, Batch 1611/1650, Loss 101.164505, Loss rec 18.515491, loss rec t1 21.417099, loss kl 0.153487, loss_trans 0.013744, loss flux 32.332363, loss flux t1 28.732319\n",
      "Epoch 1/10, Batch 1621/1650, Loss 95.833672, Loss rec 17.564140, loss rec t1 21.104691, loss kl 0.282187, loss_trans 0.033178, loss flux 31.440525, loss flux t1 25.408949\n",
      "Epoch 1/10, Batch 1631/1650, Loss 122.974686, Loss rec 30.483856, loss rec t1 36.802879, loss kl 0.232579, loss_trans 0.061962, loss flux 28.757502, loss flux t1 26.635902\n",
      "Epoch 1/10, Batch 1641/1650, Loss 114.332047, Loss rec 23.306850, loss rec t1 29.303501, loss kl 0.301716, loss_trans 0.032811, loss flux 32.367168, loss flux t1 29.019995\n",
      "Epoch 1/10, Train loss 104.132828, Eval loss 123.331146\n",
      "Epoch 2/10, Batch 1/1650, Loss 109.726700, Loss rec 19.216599, loss rec t1 25.410683, loss kl 0.280181, loss_trans 0.021423, loss flux 34.259830, loss flux t1 30.537975\n",
      "Epoch 2/10, Batch 11/1650, Loss 118.211716, Loss rec 23.266758, loss rec t1 30.309795, loss kl 0.320662, loss_trans 0.046947, loss flux 33.232761, loss flux t1 31.034800\n",
      "Epoch 2/10, Batch 21/1650, Loss 127.707054, Loss rec 32.672989, loss rec t1 36.212147, loss kl 0.244662, loss_trans 0.076704, loss flux 29.927263, loss flux t1 28.573298\n",
      "Epoch 2/10, Batch 31/1650, Loss 113.816925, Loss rec 25.445070, loss rec t1 30.695164, loss kl 0.195436, loss_trans 0.025274, loss flux 29.040470, loss flux t1 28.415503\n",
      "Epoch 2/10, Batch 41/1650, Loss 112.272835, Loss rec 23.118391, loss rec t1 27.211336, loss kl 0.239379, loss_trans 0.039431, loss flux 32.776264, loss flux t1 28.888041\n",
      "Epoch 2/10, Batch 51/1650, Loss 99.062164, Loss rec 19.869556, loss rec t1 24.516586, loss kl 0.177753, loss_trans 0.020740, loss flux 27.512712, loss flux t1 26.964821\n",
      "Epoch 2/10, Batch 61/1650, Loss 186.366486, Loss rec 44.805550, loss rec t1 52.286079, loss kl 0.385122, loss_trans 0.103049, loss flux 46.747169, loss flux t1 42.039524\n",
      "Epoch 2/10, Batch 71/1650, Loss 217.752213, Loss rec 57.075905, loss rec t1 65.691177, loss kl 0.332940, loss_trans 0.071395, loss flux 46.571709, loss flux t1 48.009090\n",
      "Epoch 2/10, Batch 81/1650, Loss 137.839447, Loss rec 34.304955, loss rec t1 40.161564, loss kl 0.188959, loss_trans 0.046968, loss flux 33.152180, loss flux t1 29.984818\n",
      "Epoch 2/10, Batch 91/1650, Loss 151.439209, Loss rec 40.639698, loss rec t1 41.039612, loss kl 0.252920, loss_trans 0.054726, loss flux 35.483738, loss flux t1 33.968502\n",
      "Epoch 2/10, Batch 101/1650, Loss 128.627075, Loss rec 29.920631, loss rec t1 36.267044, loss kl 0.221901, loss_trans 0.049494, loss flux 32.027489, loss flux t1 30.140518\n",
      "Epoch 2/10, Batch 111/1650, Loss 142.386078, Loss rec 33.509026, loss rec t1 37.783176, loss kl 0.417525, loss_trans 0.100402, loss flux 36.209896, loss flux t1 34.366039\n",
      "Epoch 2/10, Batch 121/1650, Loss 134.529358, Loss rec 31.411560, loss rec t1 39.409245, loss kl 0.338893, loss_trans 0.053538, loss flux 32.621212, loss flux t1 30.694916\n",
      "Epoch 2/10, Batch 131/1650, Loss 103.383995, Loss rec 22.129766, loss rec t1 24.114725, loss kl 0.156663, loss_trans 0.020861, loss flux 30.321381, loss flux t1 26.640604\n",
      "Epoch 2/10, Batch 141/1650, Loss 91.053062, Loss rec 18.555695, loss rec t1 21.629740, loss kl 0.200736, loss_trans 0.032694, loss flux 27.131088, loss flux t1 23.503109\n",
      "Epoch 2/10, Batch 151/1650, Loss 113.088455, Loss rec 25.420620, loss rec t1 28.226534, loss kl 0.406559, loss_trans 0.115640, loss flux 29.864630, loss flux t1 29.054476\n",
      "Epoch 2/10, Batch 161/1650, Loss 137.557892, Loss rec 32.002419, loss rec t1 37.463669, loss kl 0.400075, loss_trans 0.086971, loss flux 35.668530, loss flux t1 31.936213\n",
      "Epoch 2/10, Batch 171/1650, Loss 138.063858, Loss rec 33.689224, loss rec t1 37.833256, loss kl 0.375009, loss_trans 0.088270, loss flux 34.296867, loss flux t1 31.781239\n",
      "Epoch 2/10, Batch 181/1650, Loss 92.169891, Loss rec 19.604431, loss rec t1 25.495010, loss kl 0.168414, loss_trans 0.014470, loss flux 24.366776, loss flux t1 22.520790\n",
      "Epoch 2/10, Batch 191/1650, Loss 123.585007, Loss rec 28.451473, loss rec t1 30.669994, loss kl 0.349554, loss_trans 0.088166, loss flux 32.992649, loss flux t1 31.033175\n",
      "Epoch 2/10, Batch 201/1650, Loss 114.642883, Loss rec 27.495403, loss rec t1 28.247770, loss kl 0.269723, loss_trans 0.042743, loss flux 30.487349, loss flux t1 28.099897\n",
      "Epoch 2/10, Batch 211/1650, Loss 98.725121, Loss rec 24.679276, loss rec t1 24.810070, loss kl 0.163939, loss_trans 0.018399, loss flux 26.076193, loss flux t1 22.977243\n",
      "Epoch 2/10, Batch 221/1650, Loss 90.888802, Loss rec 18.650850, loss rec t1 21.305706, loss kl 0.246984, loss_trans 0.022115, loss flux 26.471281, loss flux t1 24.191862\n",
      "Epoch 2/10, Batch 231/1650, Loss 103.537056, Loss rec 21.891125, loss rec t1 26.645144, loss kl 0.321928, loss_trans 0.072196, loss flux 27.523966, loss flux t1 27.082693\n",
      "Epoch 2/10, Batch 241/1650, Loss 107.719452, Loss rec 24.105320, loss rec t1 28.173410, loss kl 0.225778, loss_trans 0.026119, loss flux 29.442953, loss flux t1 25.745871\n",
      "Epoch 2/10, Batch 251/1650, Loss 115.409012, Loss rec 28.607452, loss rec t1 32.502888, loss kl 0.301826, loss_trans 0.091774, loss flux 27.817162, loss flux t1 26.087915\n",
      "Epoch 2/10, Batch 261/1650, Loss 106.065224, Loss rec 24.312397, loss rec t1 28.476269, loss kl 0.179927, loss_trans 0.017053, loss flux 27.098448, loss flux t1 25.981131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Batch 271/1650, Loss 116.362480, Loss rec 27.855495, loss rec t1 29.871208, loss kl 0.283315, loss_trans 0.056684, loss flux 29.786160, loss flux t1 28.509623\n",
      "Epoch 2/10, Batch 281/1650, Loss 160.937546, Loss rec 48.069954, loss rec t1 54.782158, loss kl 0.235743, loss_trans 0.034059, loss flux 30.407257, loss flux t1 27.408367\n",
      "Epoch 2/10, Batch 291/1650, Loss 117.535835, Loss rec 27.711464, loss rec t1 30.340364, loss kl 0.273659, loss_trans 0.045421, loss flux 31.168400, loss flux t1 27.996536\n",
      "Epoch 2/10, Batch 301/1650, Loss 100.412651, Loss rec 25.282467, loss rec t1 26.629313, loss kl 0.177873, loss_trans 0.023204, loss flux 25.179243, loss flux t1 23.120548\n",
      "Epoch 2/10, Batch 311/1650, Loss 91.624306, Loss rec 16.366505, loss rec t1 20.777315, loss kl 0.175471, loss_trans 0.007878, loss flux 28.194656, loss flux t1 26.102478\n",
      "Epoch 2/10, Batch 321/1650, Loss 107.653397, Loss rec 23.887150, loss rec t1 25.759708, loss kl 0.266612, loss_trans 0.054308, loss flux 30.105822, loss flux t1 27.579792\n",
      "Epoch 2/10, Batch 331/1650, Loss 111.969673, Loss rec 27.860588, loss rec t1 32.615078, loss kl 0.169773, loss_trans 0.029961, loss flux 26.505407, loss flux t1 24.788864\n",
      "Epoch 2/10, Batch 341/1650, Loss 130.242340, Loss rec 33.286545, loss rec t1 39.903950, loss kl 0.253172, loss_trans 0.028998, loss flux 28.983652, loss flux t1 27.786032\n",
      "Epoch 2/10, Batch 351/1650, Loss 118.166061, Loss rec 28.393030, loss rec t1 28.074722, loss kl 0.344289, loss_trans 0.068695, loss flux 31.533051, loss flux t1 29.752275\n",
      "Epoch 2/10, Batch 361/1650, Loss 103.634880, Loss rec 22.513414, loss rec t1 25.509825, loss kl 0.228483, loss_trans 0.043493, loss flux 28.981329, loss flux t1 26.358332\n",
      "Epoch 2/10, Batch 371/1650, Loss 104.814842, Loss rec 20.652443, loss rec t1 24.291100, loss kl 0.312969, loss_trans 0.076715, loss flux 31.267246, loss flux t1 28.214373\n",
      "Epoch 2/10, Batch 381/1650, Loss 107.252556, Loss rec 25.239471, loss rec t1 30.497742, loss kl 0.250540, loss_trans 0.032567, loss flux 26.639112, loss flux t1 24.593117\n",
      "Epoch 2/10, Batch 391/1650, Loss 91.174294, Loss rec 19.360720, loss rec t1 21.913864, loss kl 0.250885, loss_trans 0.034953, loss flux 25.332354, loss flux t1 24.281527\n",
      "Epoch 2/10, Batch 401/1650, Loss 93.100395, Loss rec 19.974895, loss rec t1 23.078262, loss kl 0.194704, loss_trans 0.030635, loss flux 26.058994, loss flux t1 23.762913\n",
      "Epoch 2/10, Batch 411/1650, Loss 107.157440, Loss rec 24.629169, loss rec t1 29.021418, loss kl 0.352064, loss_trans 0.090999, loss flux 27.317904, loss flux t1 25.745890\n",
      "Epoch 2/10, Batch 421/1650, Loss 110.299057, Loss rec 27.108665, loss rec t1 28.354916, loss kl 0.338270, loss_trans 0.087126, loss flux 28.031185, loss flux t1 26.378891\n",
      "Epoch 2/10, Batch 431/1650, Loss 80.893417, Loss rec 14.099604, loss rec t1 16.688263, loss kl 0.230231, loss_trans 0.009443, loss flux 26.982189, loss flux t1 22.883682\n",
      "Epoch 2/10, Batch 441/1650, Loss 119.547455, Loss rec 29.075436, loss rec t1 31.719852, loss kl 0.253958, loss_trans 0.023210, loss flux 31.217772, loss flux t1 27.257229\n",
      "Epoch 2/10, Batch 451/1650, Loss 92.968132, Loss rec 20.156094, loss rec t1 23.154354, loss kl 0.193838, loss_trans 0.047417, loss flux 25.225756, loss flux t1 24.190672\n",
      "Epoch 2/10, Batch 461/1650, Loss 113.623795, Loss rec 28.790314, loss rec t1 33.869061, loss kl 0.195028, loss_trans 0.031063, loss flux 26.272585, loss flux t1 24.465752\n",
      "Epoch 2/10, Batch 471/1650, Loss 82.851913, Loss rec 14.883381, loss rec t1 17.403080, loss kl 0.183487, loss_trans 0.010760, loss flux 26.965414, loss flux t1 23.405796\n",
      "Epoch 2/10, Batch 481/1650, Loss 85.241280, Loss rec 17.903431, loss rec t1 19.294945, loss kl 0.181969, loss_trans 0.012652, loss flux 25.015127, loss flux t1 22.833158\n",
      "Epoch 2/10, Batch 491/1650, Loss 93.740936, Loss rec 19.630627, loss rec t1 23.212324, loss kl 0.128870, loss_trans 0.013594, loss flux 25.845182, loss flux t1 24.910341\n",
      "Epoch 2/10, Batch 501/1650, Loss 100.004036, Loss rec 23.264000, loss rec t1 25.532597, loss kl 0.274942, loss_trans 0.034994, loss flux 25.295160, loss flux t1 25.602345\n",
      "Epoch 2/10, Batch 511/1650, Loss 105.915886, Loss rec 25.258530, loss rec t1 26.000343, loss kl 0.211733, loss_trans 0.020321, loss flux 29.078197, loss flux t1 25.346754\n",
      "Epoch 2/10, Batch 521/1650, Loss 99.008690, Loss rec 19.446173, loss rec t1 21.700924, loss kl 0.287958, loss_trans 0.055826, loss flux 29.831284, loss flux t1 27.686531\n",
      "Epoch 2/10, Batch 531/1650, Loss 88.429344, Loss rec 17.459045, loss rec t1 21.990709, loss kl 0.141263, loss_trans 0.016334, loss flux 25.681475, loss flux t1 23.140522\n",
      "Epoch 2/10, Batch 541/1650, Loss 82.236862, Loss rec 12.756994, loss rec t1 17.781424, loss kl 0.160394, loss_trans 0.010815, loss flux 26.969299, loss flux t1 24.557928\n",
      "Epoch 2/10, Batch 551/1650, Loss 83.516068, Loss rec 13.179319, loss rec t1 17.935238, loss kl 0.220601, loss_trans 0.043151, loss flux 27.080025, loss flux t1 25.057732\n",
      "Epoch 2/10, Batch 561/1650, Loss 87.158646, Loss rec 19.679033, loss rec t1 21.974995, loss kl 0.201317, loss_trans 0.024901, loss flux 22.836784, loss flux t1 22.441612\n",
      "Epoch 2/10, Batch 571/1650, Loss 84.781212, Loss rec 17.212246, loss rec t1 19.737921, loss kl 0.217853, loss_trans 0.012513, loss flux 25.135332, loss flux t1 22.465345\n",
      "Epoch 2/10, Batch 581/1650, Loss 100.105179, Loss rec 21.215086, loss rec t1 24.875298, loss kl 0.208804, loss_trans 0.018768, loss flux 28.510710, loss flux t1 25.276516\n",
      "Epoch 2/10, Batch 591/1650, Loss 88.748344, Loss rec 18.860477, loss rec t1 24.087029, loss kl 0.139086, loss_trans 0.007566, loss flux 23.738138, loss flux t1 21.916046\n",
      "Epoch 2/10, Batch 601/1650, Loss 117.078957, Loss rec 30.075865, loss rec t1 32.640137, loss kl 0.219743, loss_trans 0.049435, loss flux 27.749142, loss flux t1 26.344629\n",
      "Epoch 2/10, Batch 611/1650, Loss 97.493088, Loss rec 23.524738, loss rec t1 25.005388, loss kl 0.229554, loss_trans 0.040406, loss flux 24.869431, loss flux t1 23.823574\n",
      "Epoch 2/10, Batch 621/1650, Loss 108.271805, Loss rec 24.611469, loss rec t1 29.658096, loss kl 0.259491, loss_trans 0.035678, loss flux 26.596176, loss flux t1 27.110903\n",
      "Epoch 2/10, Batch 631/1650, Loss 118.336823, Loss rec 28.802937, loss rec t1 32.716156, loss kl 0.244445, loss_trans 0.038318, loss flux 30.621111, loss flux t1 25.913855\n",
      "Epoch 2/10, Batch 641/1650, Loss 177.130539, Loss rec 55.717407, loss rec t1 57.968250, loss kl 0.197790, loss_trans 0.034748, loss flux 31.276329, loss flux t1 31.936020\n",
      "Epoch 2/10, Batch 651/1650, Loss 110.890984, Loss rec 24.831606, loss rec t1 29.669918, loss kl 0.228117, loss_trans 0.035328, loss flux 27.353569, loss flux t1 28.772446\n",
      "Epoch 2/10, Batch 661/1650, Loss 103.789909, Loss rec 23.414562, loss rec t1 25.918060, loss kl 0.270772, loss_trans 0.051814, loss flux 27.992540, loss flux t1 26.142162\n",
      "Epoch 2/10, Batch 671/1650, Loss 100.383080, Loss rec 23.872444, loss rec t1 26.775642, loss kl 0.190858, loss_trans 0.031807, loss flux 25.546024, loss flux t1 23.966307\n",
      "Epoch 2/10, Batch 681/1650, Loss 99.135651, Loss rec 15.355711, loss rec t1 20.044559, loss kl 0.178916, loss_trans 0.012561, loss flux 34.062878, loss flux t1 29.481030\n",
      "Epoch 2/10, Batch 691/1650, Loss 106.451637, Loss rec 23.458408, loss rec t1 25.892422, loss kl 0.346280, loss_trans 0.061033, loss flux 28.501375, loss flux t1 28.192114\n",
      "Epoch 2/10, Batch 701/1650, Loss 103.790428, Loss rec 24.805513, loss rec t1 25.687538, loss kl 0.351612, loss_trans 0.079324, loss flux 27.846052, loss flux t1 25.020395\n",
      "Epoch 2/10, Batch 711/1650, Loss 118.847717, Loss rec 27.681347, loss rec t1 28.839975, loss kl 0.407799, loss_trans 0.050524, loss flux 31.225285, loss flux t1 30.642788\n",
      "Epoch 2/10, Batch 721/1650, Loss 106.237427, Loss rec 22.369236, loss rec t1 26.041494, loss kl 0.275115, loss_trans 0.026385, loss flux 30.258526, loss flux t1 27.266680\n",
      "Epoch 2/10, Batch 731/1650, Loss 123.356186, Loss rec 31.684689, loss rec t1 35.564323, loss kl 0.222068, loss_trans 0.025120, loss flux 28.856855, loss flux t1 27.003132\n",
      "Epoch 2/10, Batch 741/1650, Loss 108.011681, Loss rec 23.912880, loss rec t1 26.495565, loss kl 0.207431, loss_trans 0.038556, loss flux 29.624590, loss flux t1 27.732651\n",
      "Epoch 2/10, Batch 751/1650, Loss 134.100189, Loss rec 32.922447, loss rec t1 41.140202, loss kl 0.252536, loss_trans 0.028307, loss flux 31.690157, loss flux t1 28.066540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Batch 761/1650, Loss 149.491013, Loss rec 35.964874, loss rec t1 46.500843, loss kl 0.250381, loss_trans 0.056438, loss flux 33.542747, loss flux t1 33.175732\n",
      "Epoch 2/10, Batch 771/1650, Loss 102.466103, Loss rec 20.876900, loss rec t1 24.746555, loss kl 0.179595, loss_trans 0.019739, loss flux 29.722015, loss flux t1 26.921299\n",
      "Epoch 2/10, Batch 781/1650, Loss 193.548447, Loss rec 54.205246, loss rec t1 74.422462, loss kl 0.168366, loss_trans 0.014459, loss flux 32.276379, loss flux t1 32.461517\n",
      "Epoch 2/10, Batch 791/1650, Loss 133.149734, Loss rec 30.206633, loss rec t1 34.520546, loss kl 0.177787, loss_trans 0.035606, loss flux 35.702164, loss flux t1 32.507004\n",
      "Epoch 2/10, Batch 801/1650, Loss 161.614182, Loss rec 41.368244, loss rec t1 45.305328, loss kl 0.286919, loss_trans 0.054354, loss flux 38.116894, loss flux t1 36.482449\n",
      "Epoch 2/10, Batch 811/1650, Loss 149.559601, Loss rec 35.607086, loss rec t1 45.003937, loss kl 0.329470, loss_trans 0.041202, loss flux 34.229885, loss flux t1 34.348030\n",
      "Epoch 2/10, Batch 821/1650, Loss 115.538872, Loss rec 26.821249, loss rec t1 29.956350, loss kl 0.207812, loss_trans 0.046720, loss flux 31.213705, loss flux t1 27.293032\n",
      "Epoch 2/10, Batch 831/1650, Loss 101.285851, Loss rec 24.607922, loss rec t1 25.581917, loss kl 0.341209, loss_trans 0.069087, loss flux 26.324276, loss flux t1 24.361439\n",
      "Epoch 2/10, Batch 841/1650, Loss 95.639748, Loss rec 23.497276, loss rec t1 25.378506, loss kl 0.150148, loss_trans 0.010209, loss flux 23.650684, loss flux t1 22.952927\n",
      "Epoch 2/10, Batch 851/1650, Loss 113.740242, Loss rec 26.057741, loss rec t1 31.276012, loss kl 0.224713, loss_trans 0.030063, loss flux 28.753458, loss flux t1 27.398256\n",
      "Epoch 2/10, Batch 861/1650, Loss 97.010292, Loss rec 20.738937, loss rec t1 23.343731, loss kl 0.267011, loss_trans 0.053091, loss flux 28.125021, loss flux t1 24.482500\n",
      "Epoch 2/10, Batch 871/1650, Loss 96.496429, Loss rec 21.927166, loss rec t1 22.219231, loss kl 0.273152, loss_trans 0.042598, loss flux 26.524256, loss flux t1 25.510035\n",
      "Epoch 2/10, Batch 881/1650, Loss 88.989220, Loss rec 15.987570, loss rec t1 21.054504, loss kl 0.197981, loss_trans 0.037419, loss flux 25.985605, loss flux t1 25.726133\n",
      "Epoch 2/10, Batch 891/1650, Loss 92.276398, Loss rec 17.435875, loss rec t1 22.953182, loss kl 0.207940, loss_trans 0.038930, loss flux 24.898989, loss flux t1 26.741476\n",
      "Epoch 2/10, Batch 901/1650, Loss 94.037437, Loss rec 20.852242, loss rec t1 24.200098, loss kl 0.303076, loss_trans 0.042453, loss flux 24.843664, loss flux t1 23.795906\n",
      "Epoch 2/10, Batch 911/1650, Loss 71.917114, Loss rec 12.231905, loss rec t1 15.711590, loss kl 0.173010, loss_trans 0.017565, loss flux 22.495729, loss flux t1 21.287313\n",
      "Epoch 2/10, Batch 921/1650, Loss 81.396492, Loss rec 15.741493, loss rec t1 19.700653, loss kl 0.208443, loss_trans 0.039461, loss flux 22.712702, loss flux t1 22.993746\n",
      "Epoch 2/10, Batch 931/1650, Loss 82.868637, Loss rec 16.751842, loss rec t1 18.966902, loss kl 0.222513, loss_trans 0.034077, loss flux 24.422861, loss flux t1 22.470446\n",
      "Epoch 2/10, Batch 941/1650, Loss 80.225861, Loss rec 15.170799, loss rec t1 18.516336, loss kl 0.270399, loss_trans 0.037270, loss flux 24.069487, loss flux t1 22.161570\n",
      "Epoch 2/10, Batch 951/1650, Loss 83.334679, Loss rec 16.288998, loss rec t1 19.496996, loss kl 0.171726, loss_trans 0.015938, loss flux 24.194990, loss flux t1 23.166029\n",
      "Epoch 2/10, Batch 961/1650, Loss 81.286446, Loss rec 16.168873, loss rec t1 18.386398, loss kl 0.149169, loss_trans 0.010219, loss flux 25.369329, loss flux t1 21.202461\n",
      "Epoch 2/10, Batch 971/1650, Loss 92.954071, Loss rec 23.067348, loss rec t1 23.497852, loss kl 0.184993, loss_trans 0.026118, loss flux 24.144821, loss flux t1 22.032934\n",
      "Epoch 2/10, Batch 981/1650, Loss 84.828476, Loss rec 17.978733, loss rec t1 22.268419, loss kl 0.164861, loss_trans 0.012843, loss flux 22.832874, loss flux t1 21.570745\n",
      "Epoch 2/10, Batch 991/1650, Loss 80.594498, Loss rec 15.150003, loss rec t1 16.938927, loss kl 0.157908, loss_trans 0.008912, loss flux 24.968201, loss flux t1 23.370548\n",
      "Epoch 2/10, Batch 1001/1650, Loss 136.543427, Loss rec 38.518639, loss rec t1 41.839184, loss kl 0.308168, loss_trans 0.046850, loss flux 27.972553, loss flux t1 27.858047\n",
      "Epoch 2/10, Batch 1011/1650, Loss 94.966736, Loss rec 19.386124, loss rec t1 22.846125, loss kl 0.183196, loss_trans 0.017350, loss flux 27.415756, loss flux t1 25.118191\n",
      "Epoch 2/10, Batch 1021/1650, Loss 91.233276, Loss rec 16.656414, loss rec t1 21.094913, loss kl 0.198976, loss_trans 0.014790, loss flux 26.882084, loss flux t1 26.386103\n",
      "Epoch 2/10, Batch 1031/1650, Loss 89.712669, Loss rec 21.525581, loss rec t1 21.602886, loss kl 0.321436, loss_trans 0.051142, loss flux 23.933308, loss flux t1 22.278318\n",
      "Epoch 2/10, Batch 1041/1650, Loss 76.459740, Loss rec 16.809509, loss rec t1 19.232409, loss kl 0.209757, loss_trans 0.031324, loss flux 20.889050, loss flux t1 19.287693\n",
      "Epoch 2/10, Batch 1051/1650, Loss 80.758217, Loss rec 17.581558, loss rec t1 20.995605, loss kl 0.163046, loss_trans 0.014461, loss flux 21.083347, loss flux t1 20.920197\n",
      "Epoch 2/10, Batch 1061/1650, Loss 97.412445, Loss rec 22.836636, loss rec t1 26.495646, loss kl 0.265480, loss_trans 0.040022, loss flux 24.012175, loss flux t1 23.762478\n",
      "Epoch 2/10, Batch 1071/1650, Loss 86.733833, Loss rec 15.598734, loss rec t1 18.874794, loss kl 0.290318, loss_trans 0.039836, loss flux 26.088545, loss flux t1 25.841610\n",
      "Epoch 2/10, Batch 1081/1650, Loss 94.024452, Loss rec 23.259020, loss rec t1 26.359592, loss kl 0.242162, loss_trans 0.031554, loss flux 22.599720, loss flux t1 21.532402\n",
      "Epoch 2/10, Batch 1091/1650, Loss 77.831299, Loss rec 14.157101, loss rec t1 16.698219, loss kl 0.112106, loss_trans 0.007660, loss flux 23.822430, loss flux t1 23.033779\n",
      "Epoch 2/10, Batch 1101/1650, Loss 74.877434, Loss rec 12.983753, loss rec t1 16.633493, loss kl 0.169030, loss_trans 0.013491, loss flux 23.318256, loss flux t1 21.759417\n",
      "Epoch 2/10, Batch 1111/1650, Loss 74.113503, Loss rec 12.195058, loss rec t1 15.323731, loss kl 0.157981, loss_trans 0.022213, loss flux 25.383001, loss flux t1 21.031519\n",
      "Epoch 2/10, Batch 1121/1650, Loss 87.375908, Loss rec 18.308636, loss rec t1 21.002926, loss kl 0.267920, loss_trans 0.024562, loss flux 24.442709, loss flux t1 23.329153\n",
      "Epoch 2/10, Batch 1131/1650, Loss 94.669334, Loss rec 21.184736, loss rec t1 23.078491, loss kl 0.376547, loss_trans 0.080372, loss flux 25.260517, loss flux t1 24.688663\n",
      "Epoch 2/10, Batch 1141/1650, Loss 82.991302, Loss rec 18.220327, loss rec t1 20.521164, loss kl 0.247319, loss_trans 0.033511, loss flux 22.068935, loss flux t1 21.900045\n",
      "Epoch 2/10, Batch 1151/1650, Loss 80.538986, Loss rec 16.939270, loss rec t1 19.289650, loss kl 0.287981, loss_trans 0.043382, loss flux 22.076963, loss flux t1 21.901737\n",
      "Epoch 2/10, Batch 1161/1650, Loss 91.107063, Loss rec 20.880159, loss rec t1 23.220638, loss kl 0.222432, loss_trans 0.038766, loss flux 23.741062, loss flux t1 23.004007\n",
      "Epoch 2/10, Batch 1171/1650, Loss 77.631157, Loss rec 15.268860, loss rec t1 17.447943, loss kl 0.186888, loss_trans 0.011002, loss flux 22.998636, loss flux t1 21.717827\n",
      "Epoch 2/10, Batch 1181/1650, Loss 95.938774, Loss rec 21.576340, loss rec t1 23.617252, loss kl 0.318855, loss_trans 0.033404, loss flux 25.573061, loss flux t1 24.819860\n",
      "Epoch 2/10, Batch 1191/1650, Loss 91.539413, Loss rec 19.815359, loss rec t1 22.309624, loss kl 0.268928, loss_trans 0.046939, loss flux 24.906794, loss flux t1 24.191769\n",
      "Epoch 2/10, Batch 1201/1650, Loss 74.333961, Loss rec 14.177125, loss rec t1 16.751562, loss kl 0.174859, loss_trans 0.014333, loss flux 23.329865, loss flux t1 19.886211\n",
      "Epoch 2/10, Batch 1211/1650, Loss 83.633308, Loss rec 18.169321, loss rec t1 19.230068, loss kl 0.256167, loss_trans 0.027808, loss flux 23.322083, loss flux t1 22.627853\n",
      "Epoch 2/10, Batch 1221/1650, Loss 74.497459, Loss rec 12.005445, loss rec t1 15.504021, loss kl 0.196814, loss_trans 0.009043, loss flux 23.564249, loss flux t1 23.217890\n",
      "Epoch 2/10, Batch 1231/1650, Loss 69.350395, Loss rec 12.548485, loss rec t1 15.949971, loss kl 0.180870, loss_trans 0.014544, loss flux 20.642021, loss flux t1 20.014505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Batch 1241/1650, Loss 69.876953, Loss rec 12.233240, loss rec t1 14.699400, loss kl 0.201692, loss_trans 0.020422, loss flux 22.747772, loss flux t1 19.974424\n",
      "Epoch 2/10, Batch 1251/1650, Loss 82.205780, Loss rec 16.967596, loss rec t1 19.134304, loss kl 0.166358, loss_trans 0.014452, loss flux 23.284168, loss flux t1 22.638908\n",
      "Epoch 2/10, Batch 1261/1650, Loss 83.393753, Loss rec 19.356373, loss rec t1 20.962406, loss kl 0.187706, loss_trans 0.022260, loss flux 22.076342, loss flux t1 20.788670\n",
      "Epoch 2/10, Batch 1271/1650, Loss 86.616013, Loss rec 19.961369, loss rec t1 22.368927, loss kl 0.227946, loss_trans 0.036441, loss flux 22.459131, loss flux t1 21.562199\n",
      "Epoch 2/10, Batch 1281/1650, Loss 74.343002, Loss rec 13.079581, loss rec t1 16.052887, loss kl 0.197249, loss_trans 0.012243, loss flux 23.411583, loss flux t1 21.589453\n",
      "Epoch 2/10, Batch 1291/1650, Loss 66.779297, Loss rec 11.562589, loss rec t1 14.320303, loss kl 0.137316, loss_trans 0.010010, loss flux 21.483486, loss flux t1 19.265598\n",
      "Epoch 2/10, Batch 1301/1650, Loss 69.681351, Loss rec 14.074954, loss rec t1 14.966516, loss kl 0.188229, loss_trans 0.025632, loss flux 20.767385, loss flux t1 19.658630\n",
      "Epoch 2/10, Batch 1311/1650, Loss 77.216545, Loss rec 14.118330, loss rec t1 18.045622, loss kl 0.162546, loss_trans 0.018905, loss flux 23.075361, loss flux t1 21.795786\n",
      "Epoch 2/10, Batch 1321/1650, Loss 87.364487, Loss rec 18.939072, loss rec t1 21.182465, loss kl 0.269254, loss_trans 0.040449, loss flux 24.051844, loss flux t1 22.881403\n",
      "Epoch 2/10, Batch 1331/1650, Loss 82.271797, Loss rec 17.287842, loss rec t1 19.331631, loss kl 0.164348, loss_trans 0.025255, loss flux 24.190630, loss flux t1 21.272097\n",
      "Epoch 2/10, Batch 1341/1650, Loss 65.593399, Loss rec 9.715916, loss rec t1 13.491829, loss kl 0.192849, loss_trans 0.020414, loss flux 22.337725, loss flux t1 19.834663\n",
      "Epoch 2/10, Batch 1351/1650, Loss 64.430588, Loss rec 13.011143, loss rec t1 14.301779, loss kl 0.125643, loss_trans 0.005907, loss flux 19.079832, loss flux t1 17.906286\n",
      "Epoch 2/10, Batch 1361/1650, Loss 86.958199, Loss rec 19.159019, loss rec t1 22.151657, loss kl 0.293259, loss_trans 0.029748, loss flux 23.728682, loss flux t1 21.595831\n",
      "Epoch 2/10, Batch 1371/1650, Loss 66.672852, Loss rec 10.487897, loss rec t1 13.391990, loss kl 0.166000, loss_trans 0.011797, loss flux 22.531153, loss flux t1 20.084013\n",
      "Epoch 2/10, Batch 1381/1650, Loss 75.774200, Loss rec 16.486500, loss rec t1 17.839041, loss kl 0.247548, loss_trans 0.022676, loss flux 20.693262, loss flux t1 20.485178\n",
      "Epoch 2/10, Batch 1391/1650, Loss 79.436928, Loss rec 14.990758, loss rec t1 17.542217, loss kl 0.280507, loss_trans 0.034597, loss flux 24.115059, loss flux t1 22.473793\n",
      "Epoch 2/10, Batch 1401/1650, Loss 71.562088, Loss rec 12.823399, loss rec t1 15.762709, loss kl 0.165073, loss_trans 0.011843, loss flux 22.463654, loss flux t1 20.335411\n",
      "Epoch 2/10, Batch 1411/1650, Loss 76.869202, Loss rec 16.543261, loss rec t1 18.157944, loss kl 0.230413, loss_trans 0.026301, loss flux 21.742498, loss flux t1 20.168793\n",
      "Epoch 2/10, Batch 1421/1650, Loss 69.921738, Loss rec 14.346710, loss rec t1 15.965054, loss kl 0.185614, loss_trans 0.013146, loss flux 19.892523, loss flux t1 19.518692\n",
      "Epoch 2/10, Batch 1431/1650, Loss 67.008904, Loss rec 13.811431, loss rec t1 15.089399, loss kl 0.210026, loss_trans 0.016896, loss flux 19.551628, loss flux t1 18.329519\n",
      "Epoch 2/10, Batch 1441/1650, Loss 75.826668, Loss rec 12.797791, loss rec t1 14.957960, loss kl 0.279036, loss_trans 0.033481, loss flux 24.291019, loss flux t1 23.467382\n",
      "Epoch 2/10, Batch 1451/1650, Loss 73.716003, Loss rec 15.848202, loss rec t1 19.171642, loss kl 0.209270, loss_trans 0.022952, loss flux 19.572662, loss flux t1 18.891281\n",
      "Epoch 2/10, Batch 1461/1650, Loss 69.247673, Loss rec 13.497656, loss rec t1 15.219845, loss kl 0.163017, loss_trans 0.006551, loss flux 20.695173, loss flux t1 19.665428\n",
      "Epoch 2/10, Batch 1471/1650, Loss 76.497963, Loss rec 16.134712, loss rec t1 18.375849, loss kl 0.228386, loss_trans 0.023117, loss flux 20.807579, loss flux t1 20.928320\n",
      "Epoch 2/10, Batch 1481/1650, Loss 76.782845, Loss rec 16.078594, loss rec t1 20.432028, loss kl 0.194806, loss_trans 0.017175, loss flux 19.880274, loss flux t1 20.179966\n",
      "Epoch 2/10, Batch 1491/1650, Loss 107.627083, Loss rec 22.593596, loss rec t1 23.778111, loss kl 0.297767, loss_trans 0.032977, loss flux 31.800213, loss flux t1 29.124428\n",
      "Epoch 2/10, Batch 1501/1650, Loss 96.397209, Loss rec 24.590143, loss rec t1 23.504021, loss kl 0.278806, loss_trans 0.036019, loss flux 24.407427, loss flux t1 23.580795\n",
      "Epoch 2/10, Batch 1511/1650, Loss 87.906631, Loss rec 20.792591, loss rec t1 25.359943, loss kl 0.159535, loss_trans 0.014952, loss flux 21.424591, loss flux t1 20.155014\n",
      "Epoch 2/10, Batch 1521/1650, Loss 69.896980, Loss rec 13.081017, loss rec t1 15.260190, loss kl 0.190886, loss_trans 0.011559, loss flux 20.364300, loss flux t1 20.989031\n",
      "Epoch 2/10, Batch 1531/1650, Loss 80.958931, Loss rec 18.185310, loss rec t1 20.429901, loss kl 0.209217, loss_trans 0.023629, loss flux 21.693228, loss flux t1 20.417650\n",
      "Epoch 2/10, Batch 1541/1650, Loss 76.955040, Loss rec 13.767520, loss rec t1 18.065849, loss kl 0.226046, loss_trans 0.012747, loss flux 23.189184, loss flux t1 21.693691\n",
      "Epoch 2/10, Batch 1551/1650, Loss 69.738548, Loss rec 13.761736, loss rec t1 15.781191, loss kl 0.140192, loss_trans 0.010990, loss flux 20.145954, loss flux t1 19.898479\n",
      "Epoch 2/10, Batch 1561/1650, Loss 85.198189, Loss rec 17.497534, loss rec t1 19.718332, loss kl 0.296504, loss_trans 0.024088, loss flux 24.394760, loss flux t1 23.266973\n",
      "Epoch 2/10, Batch 1571/1650, Loss 71.138206, Loss rec 12.256052, loss rec t1 13.563787, loss kl 0.263346, loss_trans 0.024740, loss flux 22.712944, loss flux t1 22.317337\n",
      "Epoch 2/10, Batch 1581/1650, Loss 62.872723, Loss rec 11.850776, loss rec t1 13.013882, loss kl 0.129220, loss_trans 0.004740, loss flux 20.283466, loss flux t1 17.590639\n",
      "Epoch 2/10, Batch 1591/1650, Loss 73.273849, Loss rec 13.865149, loss rec t1 15.174085, loss kl 0.222633, loss_trans 0.029626, loss flux 22.849052, loss flux t1 21.133305\n",
      "Epoch 2/10, Batch 1601/1650, Loss 65.038521, Loss rec 14.350610, loss rec t1 16.163094, loss kl 0.090375, loss_trans 0.009713, loss flux 17.851671, loss flux t1 16.573061\n",
      "Epoch 2/10, Batch 1611/1650, Loss 60.336056, Loss rec 9.691805, loss rec t1 11.687911, loss kl 0.111071, loss_trans 0.005118, loss flux 19.767839, loss flux t1 19.072311\n",
      "Epoch 2/10, Batch 1621/1650, Loss 61.372490, Loss rec 9.686909, loss rec t1 12.111532, loss kl 0.215415, loss_trans 0.011062, loss flux 20.638433, loss flux t1 18.709137\n",
      "Epoch 2/10, Batch 1631/1650, Loss 72.401985, Loss rec 15.973820, loss rec t1 19.351910, loss kl 0.148856, loss_trans 0.021349, loss flux 18.952848, loss flux t1 17.953203\n",
      "Epoch 2/10, Batch 1641/1650, Loss 71.537132, Loss rec 13.327825, loss rec t1 16.441366, loss kl 0.219297, loss_trans 0.010154, loss flux 21.553076, loss flux t1 19.985409\n",
      "Epoch 2/10, Train loss 61.894600, Eval loss 72.719971\n",
      "Epoch 3/10, Batch 1/1650, Loss 63.488968, Loss rec 9.679848, loss rec t1 12.811602, loss kl 0.219162, loss_trans 0.007965, loss flux 21.106384, loss flux t1 19.664011\n",
      "Epoch 3/10, Batch 11/1650, Loss 68.586075, Loss rec 11.571331, loss rec t1 15.209395, loss kl 0.232100, loss_trans 0.011714, loss flux 20.455343, loss flux t1 21.106195\n",
      "Epoch 3/10, Batch 21/1650, Loss 75.881599, Loss rec 17.487522, loss rec t1 19.802313, loss kl 0.170064, loss_trans 0.026065, loss flux 19.627474, loss flux t1 18.768164\n",
      "Epoch 3/10, Batch 31/1650, Loss 66.405350, Loss rec 12.676094, loss rec t1 15.754911, loss kl 0.134766, loss_trans 0.008831, loss flux 19.184923, loss flux t1 18.645817\n",
      "Epoch 3/10, Batch 41/1650, Loss 67.149673, Loss rec 13.098183, loss rec t1 14.899310, loss kl 0.157474, loss_trans 0.012231, loss flux 20.307829, loss flux t1 18.674643\n",
      "Epoch 3/10, Batch 51/1650, Loss 60.056259, Loss rec 11.115391, loss rec t1 13.200699, loss kl 0.130457, loss_trans 0.006257, loss flux 17.819918, loss flux t1 17.783539\n",
      "Epoch 3/10, Batch 61/1650, Loss 94.846733, Loss rec 21.411673, loss rec t1 25.128124, loss kl 0.256759, loss_trans 0.035994, loss flux 24.609575, loss flux t1 23.404612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Batch 71/1650, Loss 80.281883, Loss rec 15.937933, loss rec t1 16.134058, loss kl 0.258117, loss_trans 0.022226, loss flux 25.367413, loss flux t1 22.562140\n",
      "Epoch 3/10, Batch 81/1650, Loss 73.387886, Loss rec 15.505436, loss rec t1 16.830906, loss kl 0.147658, loss_trans 0.015878, loss flux 21.335009, loss flux t1 19.553005\n",
      "Epoch 3/10, Batch 91/1650, Loss 78.573769, Loss rec 18.051933, loss rec t1 20.424980, loss kl 0.173466, loss_trans 0.018284, loss flux 20.220335, loss flux t1 19.684769\n",
      "Epoch 3/10, Batch 101/1650, Loss 78.115829, Loss rec 15.817324, loss rec t1 19.662308, loss kl 0.145875, loss_trans 0.011588, loss flux 22.341309, loss flux t1 20.137428\n",
      "Epoch 3/10, Batch 111/1650, Loss 84.116478, Loss rec 16.985176, loss rec t1 19.707552, loss kl 0.255628, loss_trans 0.027497, loss flux 24.197107, loss flux t1 22.943520\n",
      "Epoch 3/10, Batch 121/1650, Loss 92.088852, Loss rec 20.446438, loss rec t1 23.337219, loss kl 0.237781, loss_trans 0.015196, loss flux 24.308123, loss flux t1 23.744099\n",
      "Epoch 3/10, Batch 131/1650, Loss 71.591057, Loss rec 13.764675, loss rec t1 17.414297, loss kl 0.106138, loss_trans 0.004477, loss flux 21.292553, loss flux t1 19.008917\n",
      "Epoch 3/10, Batch 141/1650, Loss 60.934906, Loss rec 11.854868, loss rec t1 13.432894, loss kl 0.132688, loss_trans 0.009723, loss flux 18.607962, loss flux t1 16.896770\n",
      "Epoch 3/10, Batch 151/1650, Loss 76.419907, Loss rec 15.058947, loss rec t1 16.791302, loss kl 0.276630, loss_trans 0.036850, loss flux 21.841419, loss flux t1 22.414761\n",
      "Epoch 3/10, Batch 161/1650, Loss 86.550262, Loss rec 18.294052, loss rec t1 20.670860, loss kl 0.285374, loss_trans 0.025595, loss flux 24.078377, loss flux t1 23.196003\n",
      "Epoch 3/10, Batch 171/1650, Loss 87.468002, Loss rec 18.002632, loss rec t1 20.100534, loss kl 0.273676, loss_trans 0.025485, loss flux 24.882900, loss flux t1 24.182781\n",
      "Epoch 3/10, Batch 181/1650, Loss 56.183586, Loss rec 9.589696, loss rec t1 12.759777, loss kl 0.122588, loss_trans 0.006131, loss flux 17.704441, loss flux t1 16.000957\n",
      "Epoch 3/10, Batch 191/1650, Loss 80.166641, Loss rec 17.055166, loss rec t1 18.928829, loss kl 0.239301, loss_trans 0.027372, loss flux 22.394571, loss flux t1 21.521404\n",
      "Epoch 3/10, Batch 201/1650, Loss 87.574203, Loss rec 20.433849, loss rec t1 21.119835, loss kl 0.178034, loss_trans 0.013008, loss flux 23.545277, loss flux t1 22.284203\n",
      "Epoch 3/10, Batch 211/1650, Loss 128.173691, Loss rec 42.308624, loss rec t1 43.406990, loss kl 0.113444, loss_trans 0.004942, loss flux 22.247013, loss flux t1 20.092680\n",
      "Epoch 3/10, Batch 221/1650, Loss 92.072136, Loss rec 21.119179, loss rec t1 24.206467, loss kl 0.175848, loss_trans 0.007336, loss flux 24.211582, loss flux t1 22.351727\n",
      "Epoch 3/10, Batch 231/1650, Loss 74.361061, Loss rec 12.978928, loss rec t1 15.155958, loss kl 0.230904, loss_trans 0.024942, loss flux 23.035431, loss flux t1 22.934898\n",
      "Epoch 3/10, Batch 241/1650, Loss 84.286324, Loss rec 17.660851, loss rec t1 21.574339, loss kl 0.159409, loss_trans 0.010841, loss flux 23.632046, loss flux t1 21.248838\n",
      "Epoch 3/10, Batch 251/1650, Loss 82.813370, Loss rec 18.493914, loss rec t1 19.865021, loss kl 0.207784, loss_trans 0.036648, loss flux 22.520437, loss flux t1 21.689564\n",
      "Epoch 3/10, Batch 261/1650, Loss 77.029549, Loss rec 15.459359, loss rec t1 17.185570, loss kl 0.125372, loss_trans 0.007042, loss flux 22.309679, loss flux t1 21.942524\n",
      "Epoch 3/10, Batch 271/1650, Loss 84.925415, Loss rec 18.357061, loss rec t1 18.271603, loss kl 0.210147, loss_trans 0.022551, loss flux 25.273106, loss flux t1 22.790945\n",
      "Epoch 3/10, Batch 281/1650, Loss 91.773865, Loss rec 24.486324, loss rec t1 26.723328, loss kl 0.174900, loss_trans 0.014254, loss flux 21.448481, loss flux t1 18.926584\n",
      "Epoch 3/10, Batch 291/1650, Loss 67.753479, Loss rec 11.400247, loss rec t1 14.233843, loss kl 0.210382, loss_trans 0.018538, loss flux 21.207239, loss flux t1 20.683226\n",
      "Epoch 3/10, Batch 301/1650, Loss 63.872845, Loss rec 12.918931, loss rec t1 14.415956, loss kl 0.133354, loss_trans 0.009406, loss flux 19.072041, loss flux t1 17.323154\n",
      "Epoch 3/10, Batch 311/1650, Loss 56.041431, Loss rec 9.204760, loss rec t1 11.375425, loss kl 0.133084, loss_trans 0.003833, loss flux 18.155226, loss flux t1 17.169106\n",
      "Epoch 3/10, Batch 321/1650, Loss 75.180984, Loss rec 16.162622, loss rec t1 18.234905, loss kl 0.197232, loss_trans 0.019083, loss flux 20.453051, loss flux t1 20.114090\n",
      "Epoch 3/10, Batch 331/1650, Loss 76.267044, Loss rec 16.679916, loss rec t1 19.243217, loss kl 0.121057, loss_trans 0.011173, loss flux 20.730255, loss flux t1 19.481426\n",
      "Epoch 3/10, Batch 341/1650, Loss 96.071526, Loss rec 22.462151, loss rec t1 26.588909, loss kl 0.183933, loss_trans 0.010591, loss flux 24.796593, loss flux t1 22.029350\n",
      "Epoch 3/10, Batch 351/1650, Loss 86.810158, Loss rec 19.551376, loss rec t1 19.016605, loss kl 0.254780, loss_trans 0.023014, loss flux 23.823788, loss flux t1 24.140594\n",
      "Epoch 3/10, Batch 361/1650, Loss 73.325806, Loss rec 14.365982, loss rec t1 16.158867, loss kl 0.168037, loss_trans 0.017596, loss flux 21.755697, loss flux t1 20.859623\n",
      "Epoch 3/10, Batch 371/1650, Loss 72.094795, Loss rec 13.179451, loss rec t1 14.764093, loss kl 0.246394, loss_trans 0.036205, loss flux 22.432058, loss flux t1 21.436596\n",
      "Epoch 3/10, Batch 381/1650, Loss 77.277405, Loss rec 15.468204, loss rec t1 19.031185, loss kl 0.189156, loss_trans 0.014081, loss flux 22.687582, loss flux t1 19.887192\n",
      "Epoch 3/10, Batch 391/1650, Loss 62.947384, Loss rec 12.599859, loss rec t1 13.769785, loss kl 0.183831, loss_trans 0.012813, loss flux 18.810911, loss flux t1 17.570181\n",
      "Epoch 3/10, Batch 401/1650, Loss 67.577614, Loss rec 14.411760, loss rec t1 15.842319, loss kl 0.132971, loss_trans 0.012821, loss flux 18.897188, loss flux t1 18.280556\n",
      "Epoch 3/10, Batch 411/1650, Loss 79.132080, Loss rec 17.279425, loss rec t1 20.114388, loss kl 0.267145, loss_trans 0.039588, loss flux 21.245358, loss flux t1 20.186176\n",
      "Epoch 3/10, Batch 421/1650, Loss 76.765472, Loss rec 17.023733, loss rec t1 17.988693, loss kl 0.256669, loss_trans 0.040073, loss flux 20.958988, loss flux t1 20.497322\n",
      "Epoch 3/10, Batch 431/1650, Loss 54.578072, Loss rec 8.392433, loss rec t1 10.248350, loss kl 0.179725, loss_trans 0.004639, loss flux 18.988787, loss flux t1 16.764137\n",
      "Epoch 3/10, Batch 441/1650, Loss 68.692520, Loss rec 13.082846, loss rec t1 15.347324, loss kl 0.199745, loss_trans 0.009633, loss flux 21.021263, loss flux t1 19.031710\n",
      "Epoch 3/10, Batch 451/1650, Loss 60.093124, Loss rec 11.743365, loss rec t1 12.521442, loss kl 0.143774, loss_trans 0.018923, loss flux 18.647413, loss flux t1 17.018204\n",
      "Epoch 3/10, Batch 461/1650, Loss 65.469696, Loss rec 13.542262, loss rec t1 15.150265, loss kl 0.156756, loss_trans 0.013501, loss flux 18.782074, loss flux t1 17.824833\n",
      "Epoch 3/10, Batch 471/1650, Loss 57.884342, Loss rec 9.303973, loss rec t1 10.663825, loss kl 0.149547, loss_trans 0.005129, loss flux 19.969919, loss flux t1 17.791945\n",
      "Epoch 3/10, Batch 481/1650, Loss 55.678860, Loss rec 9.813209, loss rec t1 11.545266, loss kl 0.144629, loss_trans 0.005492, loss flux 17.690508, loss flux t1 16.479755\n",
      "Epoch 3/10, Batch 491/1650, Loss 60.159309, Loss rec 10.749149, loss rec t1 12.802124, loss kl 0.103100, loss_trans 0.005005, loss flux 18.743778, loss flux t1 17.756151\n",
      "Epoch 3/10, Batch 501/1650, Loss 70.856155, Loss rec 14.283619, loss rec t1 15.642083, loss kl 0.189199, loss_trans 0.012152, loss flux 20.401453, loss flux t1 20.327646\n",
      "Epoch 3/10, Batch 511/1650, Loss 69.094254, Loss rec 13.767086, loss rec t1 15.776255, loss kl 0.170801, loss_trans 0.008703, loss flux 20.584459, loss flux t1 18.786951\n",
      "Epoch 3/10, Batch 521/1650, Loss 72.992920, Loss rec 13.340088, loss rec t1 14.732446, loss kl 0.230885, loss_trans 0.024076, loss flux 23.095146, loss flux t1 21.570278\n",
      "Epoch 3/10, Batch 531/1650, Loss 64.728561, Loss rec 10.618515, loss rec t1 13.525840, loss kl 0.113024, loss_trans 0.008163, loss flux 20.986429, loss flux t1 19.476585\n",
      "Epoch 3/10, Batch 541/1650, Loss 56.291603, Loss rec 7.965537, loss rec t1 10.970627, loss kl 0.129809, loss_trans 0.005551, loss flux 19.244915, loss flux t1 17.975163\n",
      "Epoch 3/10, Batch 551/1650, Loss 59.404053, Loss rec 8.571119, loss rec t1 11.694021, loss kl 0.180614, loss_trans 0.019730, loss flux 20.025467, loss flux t1 18.913101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Batch 561/1650, Loss 62.838112, Loss rec 12.844818, loss rec t1 14.747274, loss kl 0.141165, loss_trans 0.009869, loss flux 17.397051, loss flux t1 17.697933\n",
      "Epoch 3/10, Batch 571/1650, Loss 63.006817, Loss rec 12.349564, loss rec t1 13.836174, loss kl 0.169129, loss_trans 0.005512, loss flux 18.825682, loss flux t1 17.820757\n",
      "Epoch 3/10, Batch 581/1650, Loss 66.551697, Loss rec 13.741898, loss rec t1 14.818191, loss kl 0.145860, loss_trans 0.007824, loss flux 19.317888, loss flux t1 18.520029\n",
      "Epoch 3/10, Batch 591/1650, Loss 90.718994, Loss rec 24.069763, loss rec t1 27.847919, loss kl 0.108052, loss_trans 0.003799, loss flux 18.876385, loss flux t1 19.813084\n",
      "Epoch 3/10, Batch 601/1650, Loss 96.419434, Loss rec 26.045269, loss rec t1 25.981350, loss kl 0.172059, loss_trans 0.025966, loss flux 22.677135, loss flux t1 21.517664\n",
      "Epoch 3/10, Batch 611/1650, Loss 74.844528, Loss rec 16.238844, loss rec t1 16.960966, loss kl 0.171533, loss_trans 0.018672, loss flux 21.227549, loss flux t1 20.226967\n",
      "Epoch 3/10, Batch 621/1650, Loss 70.432152, Loss rec 13.317352, loss rec t1 14.807898, loss kl 0.191144, loss_trans 0.016040, loss flux 20.755167, loss flux t1 21.344551\n",
      "Epoch 3/10, Batch 631/1650, Loss 74.849854, Loss rec 13.863092, loss rec t1 18.018188, loss kl 0.196728, loss_trans 0.017659, loss flux 22.566996, loss flux t1 20.187185\n",
      "Epoch 3/10, Batch 641/1650, Loss 108.978905, Loss rec 29.418579, loss rec t1 33.157753, loss kl 0.161301, loss_trans 0.017467, loss flux 22.572334, loss flux t1 23.651472\n",
      "Epoch 3/10, Batch 651/1650, Loss 84.496086, Loss rec 17.639215, loss rec t1 20.191959, loss kl 0.182607, loss_trans 0.017052, loss flux 22.906290, loss flux t1 23.558956\n",
      "Epoch 3/10, Batch 661/1650, Loss 91.588318, Loss rec 18.232605, loss rec t1 20.465595, loss kl 0.217791, loss_trans 0.026594, loss flux 26.937399, loss flux t1 25.708330\n",
      "Epoch 3/10, Batch 671/1650, Loss 81.571693, Loss rec 18.605104, loss rec t1 18.645054, loss kl 0.156592, loss_trans 0.015589, loss flux 22.773148, loss flux t1 21.376204\n",
      "Epoch 3/10, Batch 681/1650, Loss 68.744377, Loss rec 10.658987, loss rec t1 14.081646, loss kl 0.147009, loss_trans 0.006853, loss flux 22.464298, loss flux t1 21.385584\n",
      "Epoch 3/10, Batch 691/1650, Loss 84.164566, Loss rec 19.609003, loss rec t1 20.360481, loss kl 0.256929, loss_trans 0.026009, loss flux 22.433691, loss flux t1 21.478456\n",
      "Epoch 3/10, Batch 701/1650, Loss 78.517914, Loss rec 17.758263, loss rec t1 18.564194, loss kl 0.264188, loss_trans 0.035400, loss flux 22.115927, loss flux t1 19.779949\n",
      "Epoch 3/10, Batch 711/1650, Loss 93.424973, Loss rec 19.388702, loss rec t1 19.995693, loss kl 0.323283, loss_trans 0.024485, loss flux 28.052633, loss flux t1 25.640173\n",
      "Epoch 3/10, Batch 721/1650, Loss 76.055603, Loss rec 14.959843, loss rec t1 16.771343, loss kl 0.229266, loss_trans 0.011540, loss flux 22.478546, loss flux t1 21.605061\n",
      "Epoch 3/10, Batch 731/1650, Loss 82.433968, Loss rec 21.097519, loss rec t1 22.630547, loss kl 0.177004, loss_trans 0.013234, loss flux 19.683002, loss flux t1 18.832663\n",
      "Epoch 3/10, Batch 741/1650, Loss 71.274406, Loss rec 15.105396, loss rec t1 17.186180, loss kl 0.165402, loss_trans 0.018214, loss flux 19.836830, loss flux t1 18.962383\n",
      "Epoch 3/10, Batch 751/1650, Loss 72.325195, Loss rec 14.345591, loss rec t1 16.071972, loss kl 0.196662, loss_trans 0.013878, loss flux 22.223503, loss flux t1 19.473587\n",
      "Epoch 3/10, Batch 761/1650, Loss 76.228004, Loss rec 14.185588, loss rec t1 17.688049, loss kl 0.228302, loss_trans 0.032843, loss flux 22.875336, loss flux t1 21.217882\n",
      "Epoch 3/10, Batch 771/1650, Loss 57.590172, Loss rec 9.363392, loss rec t1 11.391449, loss kl 0.145480, loss_trans 0.009757, loss flux 19.356449, loss flux t1 17.323641\n",
      "Epoch 3/10, Batch 781/1650, Loss 59.159637, Loss rec 10.706952, loss rec t1 12.135151, loss kl 0.146828, loss_trans 0.005563, loss flux 18.135118, loss flux t1 18.030031\n",
      "Epoch 3/10, Batch 791/1650, Loss 65.535942, Loss rec 12.352756, loss rec t1 14.462406, loss kl 0.138758, loss_trans 0.014444, loss flux 19.779793, loss flux t1 18.787790\n",
      "Epoch 3/10, Batch 801/1650, Loss 65.668480, Loss rec 12.589118, loss rec t1 14.783366, loss kl 0.204534, loss_trans 0.016073, loss flux 19.377678, loss flux t1 18.697706\n",
      "Epoch 3/10, Batch 811/1650, Loss 68.846771, Loss rec 13.312792, loss rec t1 16.214787, loss kl 0.249500, loss_trans 0.012469, loss flux 20.242458, loss flux t1 18.814766\n",
      "Epoch 3/10, Batch 821/1650, Loss 58.031334, Loss rec 10.829437, loss rec t1 12.412670, loss kl 0.168726, loss_trans 0.017671, loss flux 17.891205, loss flux t1 16.711622\n",
      "Epoch 3/10, Batch 831/1650, Loss 59.305035, Loss rec 10.099000, loss rec t1 12.891481, loss kl 0.265831, loss_trans 0.020231, loss flux 18.696587, loss flux t1 17.331902\n",
      "Epoch 3/10, Batch 841/1650, Loss 51.001217, Loss rec 9.658407, loss rec t1 11.683216, loss kl 0.105142, loss_trans 0.004539, loss flux 14.989561, loss flux t1 14.560352\n",
      "Epoch 3/10, Batch 851/1650, Loss 64.083710, Loss rec 12.146424, loss rec t1 13.537561, loss kl 0.172938, loss_trans 0.011346, loss flux 19.360737, loss flux t1 18.854708\n",
      "Epoch 3/10, Batch 861/1650, Loss 62.384068, Loss rec 11.200466, loss rec t1 12.765023, loss kl 0.224595, loss_trans 0.021270, loss flux 19.921585, loss flux t1 18.251125\n",
      "Epoch 3/10, Batch 871/1650, Loss 69.125961, Loss rec 14.164001, loss rec t1 14.352469, loss kl 0.202312, loss_trans 0.012605, loss flux 20.277142, loss flux t1 20.117435\n",
      "Epoch 3/10, Batch 881/1650, Loss 62.178673, Loss rec 11.241327, loss rec t1 13.713751, loss kl 0.158772, loss_trans 0.014492, loss flux 18.999451, loss flux t1 18.050880\n",
      "Epoch 3/10, Batch 891/1650, Loss 58.953396, Loss rec 9.442769, loss rec t1 12.709518, loss kl 0.160644, loss_trans 0.014036, loss flux 18.063259, loss flux t1 18.563171\n",
      "Epoch 3/10, Batch 901/1650, Loss 62.188862, Loss rec 12.599340, loss rec t1 14.865487, loss kl 0.224311, loss_trans 0.012324, loss flux 17.626781, loss flux t1 16.860619\n",
      "Epoch 3/10, Batch 911/1650, Loss 49.741814, Loss rec 7.555222, loss rec t1 9.750134, loss kl 0.137010, loss_trans 0.006120, loss flux 16.849724, loss flux t1 15.443607\n",
      "Epoch 3/10, Batch 921/1650, Loss 57.658749, Loss rec 10.039021, loss rec t1 12.319593, loss kl 0.164102, loss_trans 0.013935, loss flux 17.621302, loss flux t1 17.500795\n",
      "Epoch 3/10, Batch 931/1650, Loss 63.653645, Loss rec 12.085701, loss rec t1 13.264604, loss kl 0.162138, loss_trans 0.011814, loss flux 19.483849, loss flux t1 18.645540\n",
      "Epoch 3/10, Batch 941/1650, Loss 62.050415, Loss rec 10.043709, loss rec t1 11.140327, loss kl 0.212459, loss_trans 0.014450, loss flux 21.328373, loss flux t1 19.311094\n",
      "Epoch 3/10, Batch 951/1650, Loss 58.172447, Loss rec 10.340127, loss rec t1 11.602553, loss kl 0.140492, loss_trans 0.005776, loss flux 17.925900, loss flux t1 18.157600\n",
      "Epoch 3/10, Batch 961/1650, Loss 55.571529, Loss rec 10.009003, loss rec t1 11.629862, loss kl 0.104051, loss_trans 0.003726, loss flux 16.757788, loss flux t1 17.067101\n",
      "Epoch 3/10, Batch 971/1650, Loss 64.469505, Loss rec 13.911150, loss rec t1 15.520254, loss kl 0.140067, loss_trans 0.011562, loss flux 17.964783, loss flux t1 16.921694\n",
      "Epoch 3/10, Batch 981/1650, Loss 60.196182, Loss rec 12.609421, loss rec t1 14.815145, loss kl 0.124764, loss_trans 0.005729, loss flux 16.880341, loss flux t1 15.760780\n",
      "Epoch 3/10, Batch 991/1650, Loss 61.720951, Loss rec 10.640085, loss rec t1 11.738405, loss kl 0.122639, loss_trans 0.004419, loss flux 20.623499, loss flux t1 18.591902\n",
      "Epoch 3/10, Batch 1001/1650, Loss 72.370003, Loss rec 15.353420, loss rec t1 16.421961, loss kl 0.220630, loss_trans 0.015617, loss flux 19.911036, loss flux t1 20.447334\n",
      "Epoch 3/10, Batch 1011/1650, Loss 63.119267, Loss rec 12.163201, loss rec t1 13.173841, loss kl 0.133404, loss_trans 0.007573, loss flux 19.474773, loss flux t1 18.166471\n",
      "Epoch 3/10, Batch 1021/1650, Loss 59.436043, Loss rec 11.082037, loss rec t1 12.780059, loss kl 0.136636, loss_trans 0.005406, loss flux 17.839796, loss flux t1 17.592113\n",
      "Epoch 3/10, Batch 1031/1650, Loss 69.623558, Loss rec 16.564537, loss rec t1 16.191294, loss kl 0.233718, loss_trans 0.017118, loss flux 18.542015, loss flux t1 18.074877\n",
      "Epoch 3/10, Batch 1041/1650, Loss 54.438519, Loss rec 11.090245, loss rec t1 12.558069, loss kl 0.144296, loss_trans 0.011189, loss flux 16.072643, loss flux t1 14.562071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Batch 1051/1650, Loss 58.162273, Loss rec 11.600777, loss rec t1 13.132486, loss kl 0.122626, loss_trans 0.006380, loss flux 16.916475, loss flux t1 16.383532\n",
      "Epoch 3/10, Batch 1061/1650, Loss 67.688080, Loss rec 13.517035, loss rec t1 15.619224, loss kl 0.198473, loss_trans 0.016713, loss flux 19.019739, loss flux t1 19.316895\n",
      "Epoch 3/10, Batch 1071/1650, Loss 63.051277, Loss rec 10.354125, loss rec t1 11.805414, loss kl 0.220315, loss_trans 0.014610, loss flux 21.088854, loss flux t1 19.567957\n",
      "Epoch 3/10, Batch 1081/1650, Loss 64.888329, Loss rec 14.204144, loss rec t1 15.545400, loss kl 0.181276, loss_trans 0.012644, loss flux 17.517052, loss flux t1 17.427816\n",
      "Epoch 3/10, Batch 1091/1650, Loss 56.512623, Loss rec 8.701746, loss rec t1 10.761461, loss kl 0.101136, loss_trans 0.004138, loss flux 18.513470, loss flux t1 18.430672\n",
      "Epoch 3/10, Batch 1101/1650, Loss 58.898617, Loss rec 10.732245, loss rec t1 14.212499, loss kl 0.132563, loss_trans 0.006756, loss flux 18.394794, loss flux t1 15.419760\n",
      "Epoch 3/10, Batch 1111/1650, Loss 50.876846, Loss rec 7.314738, loss rec t1 9.918323, loss kl 0.135098, loss_trans 0.010385, loss flux 17.388680, loss flux t1 16.109623\n",
      "Epoch 3/10, Batch 1121/1650, Loss 63.485355, Loss rec 12.283266, loss rec t1 12.743320, loss kl 0.206044, loss_trans 0.009541, loss flux 19.569279, loss flux t1 18.673903\n",
      "Epoch 3/10, Batch 1131/1650, Loss 71.670723, Loss rec 15.680431, loss rec t1 16.802223, loss kl 0.277539, loss_trans 0.032998, loss flux 19.632645, loss flux t1 19.244884\n",
      "Epoch 3/10, Batch 1141/1650, Loss 72.036858, Loss rec 14.176294, loss rec t1 15.385168, loss kl 0.181485, loss_trans 0.012549, loss flux 21.311794, loss flux t1 20.969568\n",
      "Epoch 3/10, Batch 1151/1650, Loss 68.642975, Loss rec 14.340178, loss rec t1 15.475985, loss kl 0.220806, loss_trans 0.014352, loss flux 20.318445, loss flux t1 18.273211\n",
      "Epoch 3/10, Batch 1161/1650, Loss 76.511147, Loss rec 17.021225, loss rec t1 19.368822, loss kl 0.172356, loss_trans 0.017183, loss flux 20.234049, loss flux t1 19.697517\n",
      "Epoch 3/10, Batch 1171/1650, Loss 71.899963, Loss rec 13.727379, loss rec t1 15.915935, loss kl 0.143308, loss_trans 0.004580, loss flux 23.003181, loss flux t1 19.105583\n",
      "Epoch 3/10, Batch 1181/1650, Loss 105.813644, Loss rec 30.029053, loss rec t1 33.752064, loss kl 0.239200, loss_trans 0.013039, loss flux 20.799339, loss flux t1 20.980951\n",
      "Epoch 3/10, Batch 1191/1650, Loss 108.520859, Loss rec 30.612629, loss rec t1 34.356674, loss kl 0.210588, loss_trans 0.018962, loss flux 21.471313, loss flux t1 21.850700\n",
      "Epoch 3/10, Batch 1201/1650, Loss 67.644363, Loss rec 14.457500, loss rec t1 15.190576, loss kl 0.152535, loss_trans 0.008467, loss flux 20.256998, loss flux t1 17.578289\n",
      "Epoch 3/10, Batch 1211/1650, Loss 67.651917, Loss rec 13.704870, loss rec t1 15.533694, loss kl 0.185658, loss_trans 0.011492, loss flux 19.139467, loss flux t1 19.076735\n",
      "Epoch 3/10, Batch 1221/1650, Loss 72.094917, Loss rec 13.343975, loss rec t1 16.581064, loss kl 0.165687, loss_trans 0.005432, loss flux 21.406691, loss flux t1 20.592068\n",
      "Epoch 3/10, Batch 1231/1650, Loss 64.432899, Loss rec 12.838629, loss rec t1 14.894402, loss kl 0.152313, loss_trans 0.008613, loss flux 18.470953, loss flux t1 18.067991\n",
      "Epoch 3/10, Batch 1241/1650, Loss 67.331131, Loss rec 13.401973, loss rec t1 16.038836, loss kl 0.152920, loss_trans 0.009737, loss flux 19.802029, loss flux t1 17.925638\n",
      "Epoch 3/10, Batch 1251/1650, Loss 63.003948, Loss rec 12.486872, loss rec t1 13.307188, loss kl 0.142424, loss_trans 0.007358, loss flux 18.683044, loss flux t1 18.377062\n",
      "Epoch 3/10, Batch 1261/1650, Loss 64.192665, Loss rec 14.462473, loss rec t1 15.769182, loss kl 0.144861, loss_trans 0.013295, loss flux 17.236328, loss flux t1 16.566525\n",
      "Epoch 3/10, Batch 1271/1650, Loss 68.531181, Loss rec 14.925689, loss rec t1 16.354416, loss kl 0.171036, loss_trans 0.020599, loss flux 19.174744, loss flux t1 17.884695\n",
      "Epoch 3/10, Batch 1281/1650, Loss 62.757832, Loss rec 10.910690, loss rec t1 12.918941, loss kl 0.167895, loss_trans 0.007860, loss flux 20.293289, loss flux t1 18.459152\n",
      "Epoch 3/10, Batch 1291/1650, Loss 50.593391, Loss rec 8.612503, loss rec t1 10.076128, loss kl 0.117074, loss_trans 0.006355, loss flux 16.536774, loss flux t1 15.244556\n",
      "Epoch 3/10, Batch 1301/1650, Loss 53.897728, Loss rec 10.987528, loss rec t1 11.598083, loss kl 0.156801, loss_trans 0.013176, loss flux 16.318871, loss flux t1 14.823269\n",
      "Epoch 3/10, Batch 1311/1650, Loss 56.157055, Loss rec 9.747366, loss rec t1 12.257385, loss kl 0.133599, loss_trans 0.010852, loss flux 17.632696, loss flux t1 16.375156\n",
      "Epoch 3/10, Batch 1321/1650, Loss 63.519371, Loss rec 12.740786, loss rec t1 14.777468, loss kl 0.219158, loss_trans 0.020593, loss flux 18.427277, loss flux t1 17.334089\n",
      "Epoch 3/10, Batch 1331/1650, Loss 73.435043, Loss rec 16.105064, loss rec t1 18.734486, loss kl 0.127006, loss_trans 0.013700, loss flux 20.272795, loss flux t1 18.181993\n",
      "Epoch 3/10, Batch 1341/1650, Loss 49.820412, Loss rec 6.993066, loss rec t1 9.039591, loss kl 0.163909, loss_trans 0.012084, loss flux 18.145039, loss flux t1 15.466719\n",
      "Epoch 3/10, Batch 1351/1650, Loss 55.022190, Loss rec 10.645889, loss rec t1 11.630541, loss kl 0.102166, loss_trans 0.003612, loss flux 16.631371, loss flux t1 16.008608\n",
      "Epoch 3/10, Batch 1361/1650, Loss 68.993080, Loss rec 15.602867, loss rec t1 18.047228, loss kl 0.237832, loss_trans 0.017255, loss flux 18.104811, loss flux t1 16.983086\n",
      "Epoch 3/10, Batch 1371/1650, Loss 53.685528, Loss rec 7.849741, loss rec t1 9.577787, loss kl 0.146836, loss_trans 0.007734, loss flux 18.767265, loss flux t1 17.336168\n",
      "Epoch 3/10, Batch 1381/1650, Loss 62.346493, Loss rec 14.109303, loss rec t1 15.280207, loss kl 0.189787, loss_trans 0.011540, loss flux 16.564882, loss flux t1 16.190771\n",
      "Epoch 3/10, Batch 1391/1650, Loss 58.818813, Loss rec 9.758703, loss rec t1 12.100164, loss kl 0.238782, loss_trans 0.018634, loss flux 18.265860, loss flux t1 18.436670\n",
      "Epoch 3/10, Batch 1401/1650, Loss 61.364899, Loss rec 11.581425, loss rec t1 13.176983, loss kl 0.136091, loss_trans 0.006460, loss flux 19.085506, loss flux t1 17.378437\n",
      "Epoch 3/10, Batch 1411/1650, Loss 70.488937, Loss rec 15.374985, loss rec t1 17.700275, loss kl 0.175413, loss_trans 0.014607, loss flux 19.686171, loss flux t1 17.537483\n",
      "Epoch 3/10, Batch 1421/1650, Loss 61.003632, Loss rec 11.409479, loss rec t1 12.815880, loss kl 0.154424, loss_trans 0.008178, loss flux 18.612013, loss flux t1 18.003656\n",
      "Epoch 3/10, Batch 1431/1650, Loss 53.281925, Loss rec 10.306477, loss rec t1 10.873812, loss kl 0.167807, loss_trans 0.009064, loss flux 16.526041, loss flux t1 15.398725\n",
      "Epoch 3/10, Batch 1441/1650, Loss 77.550415, Loss rec 16.765694, loss rec t1 20.779188, loss kl 0.239822, loss_trans 0.019119, loss flux 19.704865, loss flux t1 20.041729\n",
      "Epoch 3/10, Batch 1451/1650, Loss 59.436974, Loss rec 12.476343, loss rec t1 14.770184, loss kl 0.166246, loss_trans 0.014356, loss flux 16.424637, loss flux t1 15.585209\n",
      "Epoch 3/10, Batch 1461/1650, Loss 55.948223, Loss rec 9.422650, loss rec t1 10.879074, loss kl 0.141707, loss_trans 0.004707, loss flux 18.715500, loss flux t1 16.784588\n",
      "Epoch 3/10, Batch 1471/1650, Loss 62.317577, Loss rec 11.929397, loss rec t1 13.571480, loss kl 0.185452, loss_trans 0.011335, loss flux 18.148785, loss flux t1 18.471132\n",
      "Epoch 3/10, Batch 1481/1650, Loss 55.925640, Loss rec 10.679186, loss rec t1 12.093191, loss kl 0.164246, loss_trans 0.009089, loss flux 16.769678, loss flux t1 16.210251\n",
      "Epoch 3/10, Batch 1491/1650, Loss 67.395119, Loss rec 12.756090, loss rec t1 13.248944, loss kl 0.242899, loss_trans 0.016597, loss flux 20.481703, loss flux t1 20.648884\n",
      "Epoch 3/10, Batch 1501/1650, Loss 71.935410, Loss rec 16.156120, loss rec t1 16.175737, loss kl 0.225151, loss_trans 0.019562, loss flux 20.004301, loss flux t1 19.354542\n",
      "Epoch 3/10, Batch 1511/1650, Loss 63.309502, Loss rec 14.036858, loss rec t1 17.101471, loss kl 0.123068, loss_trans 0.009624, loss flux 16.176435, loss flux t1 15.862044\n",
      "Epoch 3/10, Batch 1521/1650, Loss 54.441479, Loss rec 10.046996, loss rec t1 11.328024, loss kl 0.153303, loss_trans 0.005901, loss flux 16.710743, loss flux t1 16.196512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Batch 1531/1650, Loss 58.997150, Loss rec 12.935094, loss rec t1 13.927261, loss kl 0.163081, loss_trans 0.013087, loss flux 15.926547, loss flux t1 16.032080\n",
      "Epoch 3/10, Batch 1541/1650, Loss 57.488518, Loss rec 9.987795, loss rec t1 12.957706, loss kl 0.186172, loss_trans 0.008117, loss flux 17.857281, loss flux t1 16.491447\n",
      "Epoch 3/10, Batch 1551/1650, Loss 53.339714, Loss rec 9.960972, loss rec t1 11.171694, loss kl 0.115468, loss_trans 0.006036, loss flux 16.051371, loss flux t1 16.034176\n",
      "Epoch 3/10, Batch 1561/1650, Loss 68.768974, Loss rec 14.045444, loss rec t1 15.861267, loss kl 0.238677, loss_trans 0.013737, loss flux 19.110527, loss flux t1 19.499321\n",
      "Epoch 3/10, Batch 1571/1650, Loss 64.049309, Loss rec 11.233292, loss rec t1 12.996814, loss kl 0.225822, loss_trans 0.014309, loss flux 20.072306, loss flux t1 19.506765\n",
      "Epoch 3/10, Batch 1581/1650, Loss 47.800625, Loss rec 8.375036, loss rec t1 9.920639, loss kl 0.113285, loss_trans 0.003239, loss flux 15.457696, loss flux t1 13.930728\n",
      "Epoch 3/10, Batch 1591/1650, Loss 55.926914, Loss rec 9.773070, loss rec t1 11.158240, loss kl 0.189228, loss_trans 0.016257, loss flux 17.954473, loss flux t1 16.835644\n",
      "Epoch 3/10, Batch 1601/1650, Loss 53.416294, Loss rec 12.215433, loss rec t1 13.356270, loss kl 0.075128, loss_trans 0.006391, loss flux 14.196424, loss flux t1 13.566652\n",
      "Epoch 3/10, Batch 1611/1650, Loss 45.632999, Loss rec 6.847365, loss rec t1 8.448756, loss kl 0.094275, loss_trans 0.003823, loss flux 15.347948, loss flux t1 14.890834\n",
      "Epoch 3/10, Batch 1621/1650, Loss 46.231022, Loss rec 6.922206, loss rec t1 8.226039, loss kl 0.183367, loss_trans 0.007451, loss flux 16.377640, loss flux t1 14.514320\n",
      "Epoch 3/10, Batch 1631/1650, Loss 55.936768, Loss rec 11.742382, loss rec t1 14.001424, loss kl 0.117988, loss_trans 0.012968, loss flux 15.419417, loss flux t1 14.642591\n",
      "Epoch 3/10, Batch 1641/1650, Loss 57.107056, Loss rec 10.738085, loss rec t1 12.054409, loss kl 0.187965, loss_trans 0.006997, loss flux 17.726604, loss flux t1 16.392998\n",
      "Epoch 3/10, Train loss 49.823917, Eval loss 64.149673\n",
      "Epoch 4/10, Batch 1/1650, Loss 53.896515, Loss rec 8.396947, loss rec t1 10.169529, loss kl 0.200912, loss_trans 0.005424, loss flux 18.622801, loss flux t1 16.500898\n",
      "Epoch 4/10, Batch 11/1650, Loss 63.190891, Loss rec 11.333330, loss rec t1 13.714748, loss kl 0.191267, loss_trans 0.006527, loss flux 18.569956, loss flux t1 19.375061\n",
      "Epoch 4/10, Batch 21/1650, Loss 60.150723, Loss rec 12.917462, loss rec t1 14.580752, loss kl 0.137854, loss_trans 0.015202, loss flux 16.785143, loss flux t1 15.714311\n",
      "Epoch 4/10, Batch 31/1650, Loss 53.959084, Loss rec 10.218571, loss rec t1 11.233797, loss kl 0.115473, loss_trans 0.005398, loss flux 16.303785, loss flux t1 16.082058\n",
      "Epoch 4/10, Batch 41/1650, Loss 56.404102, Loss rec 11.354112, loss rec t1 12.516354, loss kl 0.129333, loss_trans 0.006765, loss flux 17.039680, loss flux t1 15.357862\n",
      "Epoch 4/10, Batch 51/1650, Loss 55.514877, Loss rec 10.475521, loss rec t1 12.199271, loss kl 0.108689, loss_trans 0.004160, loss flux 17.128447, loss flux t1 15.598794\n",
      "Epoch 4/10, Batch 61/1650, Loss 110.914452, Loss rec 28.091965, loss rec t1 33.581234, loss kl 0.191093, loss_trans 0.020647, loss flux 25.440420, loss flux t1 23.589096\n",
      "Epoch 4/10, Batch 71/1650, Loss 84.843071, Loss rec 21.680792, loss rec t1 23.002142, loss kl 0.203863, loss_trans 0.012670, loss flux 20.674133, loss flux t1 19.269474\n",
      "Epoch 4/10, Batch 81/1650, Loss 87.718941, Loss rec 21.418383, loss rec t1 20.487993, loss kl 0.131674, loss_trans 0.010734, loss flux 23.808533, loss flux t1 21.861620\n",
      "Epoch 4/10, Batch 91/1650, Loss 70.212997, Loss rec 14.663583, loss rec t1 15.069220, loss kl 0.140719, loss_trans 0.011116, loss flux 20.400015, loss flux t1 19.928345\n",
      "Epoch 4/10, Batch 101/1650, Loss 65.132721, Loss rec 12.951382, loss rec t1 15.177467, loss kl 0.112170, loss_trans 0.007571, loss flux 18.220749, loss flux t1 18.663383\n",
      "Epoch 4/10, Batch 111/1650, Loss 83.068718, Loss rec 18.968447, loss rec t1 21.605042, loss kl 0.211310, loss_trans 0.015418, loss flux 22.034254, loss flux t1 20.234249\n",
      "Epoch 4/10, Batch 121/1650, Loss 77.552269, Loss rec 16.192390, loss rec t1 19.623768, loss kl 0.204632, loss_trans 0.009605, loss flux 21.004080, loss flux t1 20.517792\n",
      "Epoch 4/10, Batch 131/1650, Loss 66.571281, Loss rec 12.727653, loss rec t1 12.945665, loss kl 0.099527, loss_trans 0.003138, loss flux 22.228374, loss flux t1 18.566925\n",
      "Epoch 4/10, Batch 141/1650, Loss 54.759735, Loss rec 9.825583, loss rec t1 10.318974, loss kl 0.113399, loss_trans 0.007611, loss flux 18.696764, loss flux t1 15.797404\n",
      "Epoch 4/10, Batch 151/1650, Loss 81.715858, Loss rec 19.172550, loss rec t1 17.336819, loss kl 0.258101, loss_trans 0.020089, loss flux 22.533657, loss flux t1 22.394644\n",
      "Epoch 4/10, Batch 161/1650, Loss 95.693115, Loss rec 23.581009, loss rec t1 23.833153, loss kl 0.230437, loss_trans 0.017187, loss flux 24.958097, loss flux t1 23.073229\n",
      "Epoch 4/10, Batch 171/1650, Loss 94.856728, Loss rec 22.916616, loss rec t1 26.902885, loss kl 0.222050, loss_trans 0.014176, loss flux 22.790627, loss flux t1 22.010370\n",
      "Epoch 4/10, Batch 181/1650, Loss 55.589905, Loss rec 11.733068, loss rec t1 12.942915, loss kl 0.109450, loss_trans 0.005357, loss flux 16.344269, loss flux t1 14.454850\n",
      "Epoch 4/10, Batch 191/1650, Loss 72.075775, Loss rec 15.236530, loss rec t1 17.873753, loss kl 0.215923, loss_trans 0.019564, loss flux 19.222927, loss flux t1 19.507080\n",
      "Epoch 4/10, Batch 201/1650, Loss 76.966728, Loss rec 20.416849, loss rec t1 22.655203, loss kl 0.140828, loss_trans 0.007328, loss flux 17.093502, loss flux t1 16.653021\n",
      "Epoch 4/10, Batch 211/1650, Loss 57.311722, Loss rec 12.455591, loss rec t1 12.648299, loss kl 0.087837, loss_trans 0.003661, loss flux 16.260576, loss flux t1 15.855757\n",
      "Epoch 4/10, Batch 221/1650, Loss 59.886913, Loss rec 12.411185, loss rec t1 13.576351, loss kl 0.143309, loss_trans 0.003652, loss flux 18.176399, loss flux t1 15.576017\n",
      "Epoch 4/10, Batch 231/1650, Loss 57.596432, Loss rec 10.356101, loss rec t1 12.463783, loss kl 0.196509, loss_trans 0.014478, loss flux 17.435961, loss flux t1 17.129601\n",
      "Epoch 4/10, Batch 241/1650, Loss 59.752995, Loss rec 11.570679, loss rec t1 12.214391, loss kl 0.135996, loss_trans 0.008157, loss flux 18.785261, loss flux t1 17.038513\n",
      "Epoch 4/10, Batch 251/1650, Loss 61.613049, Loss rec 12.729895, loss rec t1 13.641846, loss kl 0.182136, loss_trans 0.023189, loss flux 17.819229, loss flux t1 17.216749\n",
      "Epoch 4/10, Batch 261/1650, Loss 51.252274, Loss rec 9.341713, loss rec t1 11.012932, loss kl 0.112858, loss_trans 0.004547, loss flux 15.977366, loss flux t1 14.802855\n",
      "Epoch 4/10, Batch 271/1650, Loss 55.904488, Loss rec 10.427732, loss rec t1 11.259565, loss kl 0.181588, loss_trans 0.011533, loss flux 17.431341, loss flux t1 16.592728\n",
      "Epoch 4/10, Batch 281/1650, Loss 61.433636, Loss rec 13.309703, loss rec t1 16.837868, loss kl 0.154050, loss_trans 0.010197, loss flux 16.187300, loss flux t1 14.934515\n",
      "Epoch 4/10, Batch 291/1650, Loss 53.832466, Loss rec 8.533571, loss rec t1 10.463055, loss kl 0.184358, loss_trans 0.011238, loss flux 17.811640, loss flux t1 16.828608\n",
      "Epoch 4/10, Batch 301/1650, Loss 49.551426, Loss rec 9.075054, loss rec t1 10.022243, loss kl 0.114686, loss_trans 0.005640, loss flux 16.119019, loss flux t1 14.214784\n",
      "Epoch 4/10, Batch 311/1650, Loss 50.604343, Loss rec 8.542314, loss rec t1 10.110865, loss kl 0.123196, loss_trans 0.003041, loss flux 16.046303, loss flux t1 15.778626\n",
      "Epoch 4/10, Batch 321/1650, Loss 56.317287, Loss rec 10.761707, loss rec t1 12.158490, loss kl 0.167745, loss_trans 0.010707, loss flux 16.591326, loss flux t1 16.627314\n",
      "Epoch 4/10, Batch 331/1650, Loss 51.701027, Loss rec 9.854635, loss rec t1 11.383376, loss kl 0.102986, loss_trans 0.006807, loss flux 15.722914, loss flux t1 14.630310\n",
      "Epoch 4/10, Batch 341/1650, Loss 77.687737, Loss rec 18.964134, loss rec t1 21.738995, loss kl 0.152370, loss_trans 0.006144, loss flux 18.418924, loss flux t1 18.407177\n",
      "Epoch 4/10, Batch 351/1650, Loss 74.802460, Loss rec 15.102775, loss rec t1 15.605928, loss kl 0.217363, loss_trans 0.013705, loss flux 22.063189, loss flux t1 21.799505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Batch 361/1650, Loss 65.906021, Loss rec 11.553625, loss rec t1 13.403675, loss kl 0.139295, loss_trans 0.009221, loss flux 20.486176, loss flux t1 20.314028\n",
      "Epoch 4/10, Batch 371/1650, Loss 66.215286, Loss rec 12.129955, loss rec t1 13.213679, loss kl 0.222305, loss_trans 0.024333, loss flux 21.640196, loss flux t1 18.984818\n",
      "Epoch 4/10, Batch 381/1650, Loss 60.918007, Loss rec 11.479250, loss rec t1 14.169214, loss kl 0.166661, loss_trans 0.008117, loss flux 17.820528, loss flux t1 17.274239\n",
      "Epoch 4/10, Batch 391/1650, Loss 58.461758, Loss rec 11.857031, loss rec t1 14.159742, loss kl 0.164074, loss_trans 0.007991, loss flux 16.771549, loss flux t1 15.501370\n",
      "Epoch 4/10, Batch 401/1650, Loss 64.154694, Loss rec 13.646650, loss rec t1 14.944698, loss kl 0.106712, loss_trans 0.007877, loss flux 17.173246, loss flux t1 18.275511\n",
      "Epoch 4/10, Batch 411/1650, Loss 64.423943, Loss rec 12.103582, loss rec t1 13.582000, loss kl 0.236916, loss_trans 0.024922, loss flux 20.009205, loss flux t1 18.467316\n",
      "Epoch 4/10, Batch 421/1650, Loss 59.480305, Loss rec 12.671302, loss rec t1 13.488277, loss kl 0.212462, loss_trans 0.023899, loss flux 16.851362, loss flux t1 16.233002\n",
      "Epoch 4/10, Batch 431/1650, Loss 46.855148, Loss rec 6.958903, loss rec t1 8.660706, loss kl 0.155101, loss_trans 0.003225, loss flux 16.167171, loss flux t1 14.910043\n",
      "Epoch 4/10, Batch 441/1650, Loss 68.734581, Loss rec 14.829397, loss rec t1 16.502626, loss kl 0.175533, loss_trans 0.007831, loss flux 19.844145, loss flux t1 17.375051\n",
      "Epoch 4/10, Batch 451/1650, Loss 53.116280, Loss rec 9.934363, loss rec t1 11.406655, loss kl 0.123786, loss_trans 0.013174, loss flux 16.428974, loss flux t1 15.209325\n",
      "Epoch 4/10, Batch 461/1650, Loss 64.946022, Loss rec 14.469688, loss rec t1 18.330193, loss kl 0.125867, loss_trans 0.008601, loss flux 16.277906, loss flux t1 15.733773\n",
      "Epoch 4/10, Batch 471/1650, Loss 54.724663, Loss rec 10.438471, loss rec t1 12.102020, loss kl 0.133752, loss_trans 0.003901, loss flux 16.690859, loss flux t1 15.355659\n",
      "Epoch 4/10, Batch 481/1650, Loss 55.419930, Loss rec 8.991098, loss rec t1 12.364727, loss kl 0.129998, loss_trans 0.003767, loss flux 16.505932, loss flux t1 17.424404\n",
      "Epoch 4/10, Batch 491/1650, Loss 66.929787, Loss rec 12.711827, loss rec t1 16.079874, loss kl 0.096565, loss_trans 0.004280, loss flux 19.951941, loss flux t1 18.085297\n",
      "Epoch 4/10, Batch 501/1650, Loss 66.890327, Loss rec 14.277164, loss rec t1 14.059467, loss kl 0.170136, loss_trans 0.007807, loss flux 20.530172, loss flux t1 17.845583\n",
      "Epoch 4/10, Batch 511/1650, Loss 65.483025, Loss rec 14.587661, loss rec t1 14.887581, loss kl 0.148344, loss_trans 0.006619, loss flux 18.653938, loss flux t1 17.198874\n",
      "Epoch 4/10, Batch 521/1650, Loss 72.633209, Loss rec 15.537480, loss rec t1 15.794198, loss kl 0.225012, loss_trans 0.019564, loss flux 21.236153, loss flux t1 19.820808\n",
      "Epoch 4/10, Batch 531/1650, Loss 56.415192, Loss rec 9.938984, loss rec t1 11.426156, loss kl 0.102756, loss_trans 0.007280, loss flux 18.761824, loss flux t1 16.178194\n",
      "Epoch 4/10, Batch 541/1650, Loss 55.214558, Loss rec 8.952169, loss rec t1 11.801139, loss kl 0.114359, loss_trans 0.004148, loss flux 18.358400, loss flux t1 15.984344\n",
      "Epoch 4/10, Batch 551/1650, Loss 51.530327, Loss rec 8.605166, loss rec t1 8.995968, loss kl 0.174403, loss_trans 0.015236, loss flux 17.587433, loss flux t1 16.152119\n",
      "Epoch 4/10, Batch 561/1650, Loss 53.062820, Loss rec 10.410580, loss rec t1 11.629104, loss kl 0.123179, loss_trans 0.007102, loss flux 15.429473, loss flux t1 15.463383\n",
      "Epoch 4/10, Batch 571/1650, Loss 52.904274, Loss rec 10.667223, loss rec t1 11.659298, loss kl 0.158986, loss_trans 0.004208, loss flux 16.189554, loss flux t1 14.225007\n",
      "Epoch 4/10, Batch 581/1650, Loss 54.164066, Loss rec 10.757053, loss rec t1 11.352205, loss kl 0.127116, loss_trans 0.006154, loss flux 15.950667, loss flux t1 15.970869\n",
      "Epoch 4/10, Batch 591/1650, Loss 49.280144, Loss rec 9.396250, loss rec t1 10.558138, loss kl 0.104288, loss_trans 0.002790, loss flux 15.363451, loss flux t1 13.855228\n",
      "Epoch 4/10, Batch 601/1650, Loss 64.358513, Loss rec 15.867306, loss rec t1 14.684980, loss kl 0.142138, loss_trans 0.015163, loss flux 17.397415, loss flux t1 16.251518\n",
      "Epoch 4/10, Batch 611/1650, Loss 67.050232, Loss rec 15.315998, loss rec t1 15.185120, loss kl 0.138294, loss_trans 0.012075, loss flux 19.394611, loss flux t1 17.004133\n",
      "Epoch 4/10, Batch 621/1650, Loss 85.324036, Loss rec 21.183645, loss rec t1 25.026058, loss kl 0.165295, loss_trans 0.009308, loss flux 18.885138, loss flux t1 20.054592\n",
      "Epoch 4/10, Batch 631/1650, Loss 83.457130, Loss rec 18.302809, loss rec t1 16.515663, loss kl 0.194722, loss_trans 0.014407, loss flux 25.850803, loss flux t1 22.578726\n",
      "Epoch 4/10, Batch 641/1650, Loss 86.337555, Loss rec 20.689671, loss rec t1 22.922476, loss kl 0.160388, loss_trans 0.014222, loss flux 20.542501, loss flux t1 22.008299\n",
      "Epoch 4/10, Batch 651/1650, Loss 84.649307, Loss rec 21.102619, loss rec t1 24.217119, loss kl 0.151472, loss_trans 0.010415, loss flux 20.188042, loss flux t1 18.979635\n",
      "Epoch 4/10, Batch 661/1650, Loss 69.484818, Loss rec 13.506460, loss rec t1 15.674700, loss kl 0.204274, loss_trans 0.018519, loss flux 21.158983, loss flux t1 18.921885\n",
      "Epoch 4/10, Batch 671/1650, Loss 74.519142, Loss rec 13.814075, loss rec t1 17.393337, loss kl 0.121804, loss_trans 0.010095, loss flux 22.358963, loss flux t1 20.820869\n",
      "Epoch 4/10, Batch 681/1650, Loss 70.975060, Loss rec 13.318897, loss rec t1 16.993231, loss kl 0.128349, loss_trans 0.004265, loss flux 20.550772, loss flux t1 19.979544\n",
      "Epoch 4/10, Batch 691/1650, Loss 72.825356, Loss rec 14.702304, loss rec t1 15.091578, loss kl 0.245972, loss_trans 0.017329, loss flux 21.581367, loss flux t1 21.186813\n",
      "Epoch 4/10, Batch 701/1650, Loss 73.919647, Loss rec 19.269894, loss rec t1 18.954418, loss kl 0.219001, loss_trans 0.023893, loss flux 17.992718, loss flux t1 17.459717\n",
      "Epoch 4/10, Batch 711/1650, Loss 71.867790, Loss rec 14.567758, loss rec t1 15.765037, loss kl 0.303610, loss_trans 0.016220, loss flux 20.625004, loss flux t1 20.590164\n",
      "Epoch 4/10, Batch 721/1650, Loss 63.032661, Loss rec 11.292662, loss rec t1 12.549208, loss kl 0.221215, loss_trans 0.008407, loss flux 20.201189, loss flux t1 18.759977\n",
      "Epoch 4/10, Batch 731/1650, Loss 55.191093, Loss rec 10.797573, loss rec t1 12.820400, loss kl 0.151960, loss_trans 0.008474, loss flux 15.698415, loss flux t1 15.714272\n",
      "Epoch 4/10, Batch 741/1650, Loss 51.898899, Loss rec 10.311726, loss rec t1 11.404181, loss kl 0.145766, loss_trans 0.010333, loss flux 14.968955, loss flux t1 15.057940\n",
      "Epoch 4/10, Batch 751/1650, Loss 51.450497, Loss rec 9.516968, loss rec t1 10.898563, loss kl 0.178975, loss_trans 0.008967, loss flux 16.196081, loss flux t1 14.650941\n",
      "Epoch 4/10, Batch 761/1650, Loss 54.360367, Loss rec 10.012163, loss rec t1 11.129490, loss kl 0.207955, loss_trans 0.022314, loss flux 16.927130, loss flux t1 16.061314\n",
      "Epoch 4/10, Batch 771/1650, Loss 43.006424, Loss rec 6.316119, loss rec t1 8.310175, loss kl 0.127839, loss_trans 0.005941, loss flux 14.719399, loss flux t1 13.526954\n",
      "Epoch 4/10, Batch 781/1650, Loss 47.048725, Loss rec 8.831287, loss rec t1 10.036978, loss kl 0.124841, loss_trans 0.004064, loss flux 14.072881, loss flux t1 13.978676\n",
      "Epoch 4/10, Batch 791/1650, Loss 50.577469, Loss rec 9.228745, loss rec t1 10.480267, loss kl 0.123901, loss_trans 0.009839, loss flux 15.403891, loss flux t1 15.330831\n",
      "Epoch 4/10, Batch 801/1650, Loss 48.804943, Loss rec 8.913567, loss rec t1 10.342461, loss kl 0.182220, loss_trans 0.009933, loss flux 14.853103, loss flux t1 14.503659\n",
      "Epoch 4/10, Batch 811/1650, Loss 54.921947, Loss rec 10.149506, loss rec t1 12.201137, loss kl 0.210051, loss_trans 0.008032, loss flux 17.100039, loss flux t1 15.253184\n",
      "Epoch 4/10, Batch 821/1650, Loss 46.069374, Loss rec 8.201059, loss rec t1 9.409060, loss kl 0.147698, loss_trans 0.011786, loss flux 14.112055, loss flux t1 14.187714\n",
      "Epoch 4/10, Batch 831/1650, Loss 48.553165, Loss rec 8.755177, loss rec t1 10.404315, loss kl 0.232918, loss_trans 0.012582, loss flux 15.198744, loss flux t1 13.949428\n",
      "Epoch 4/10, Batch 841/1650, Loss 40.061584, Loss rec 7.359449, loss rec t1 8.800552, loss kl 0.097455, loss_trans 0.003906, loss flux 12.113380, loss flux t1 11.686841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Batch 851/1650, Loss 54.539825, Loss rec 10.048040, loss rec t1 11.927731, loss kl 0.151804, loss_trans 0.008726, loss flux 16.081354, loss flux t1 16.322165\n",
      "Epoch 4/10, Batch 861/1650, Loss 51.291859, Loss rec 8.563836, loss rec t1 10.204755, loss kl 0.202363, loss_trans 0.014584, loss flux 16.668079, loss flux t1 15.638243\n",
      "Epoch 4/10, Batch 871/1650, Loss 51.472363, Loss rec 10.270391, loss rec t1 10.903357, loss kl 0.172889, loss_trans 0.007842, loss flux 15.136690, loss flux t1 14.981194\n",
      "Epoch 4/10, Batch 881/1650, Loss 50.940895, Loss rec 8.463884, loss rec t1 11.325017, loss kl 0.143239, loss_trans 0.009907, loss flux 15.760347, loss flux t1 15.238500\n",
      "Epoch 4/10, Batch 891/1650, Loss 48.245750, Loss rec 7.352224, loss rec t1 9.877413, loss kl 0.143725, loss_trans 0.008442, loss flux 15.403548, loss flux t1 15.460401\n",
      "Epoch 4/10, Batch 901/1650, Loss 52.486477, Loss rec 10.152514, loss rec t1 11.916719, loss kl 0.201670, loss_trans 0.007942, loss flux 15.418074, loss flux t1 14.789557\n",
      "Epoch 4/10, Batch 911/1650, Loss 40.330547, Loss rec 5.836969, loss rec t1 7.337091, loss kl 0.128334, loss_trans 0.003986, loss flux 14.172810, loss flux t1 12.851356\n",
      "Epoch 4/10, Batch 921/1650, Loss 46.288795, Loss rec 7.715988, loss rec t1 9.448273, loss kl 0.142129, loss_trans 0.008699, loss flux 14.562389, loss flux t1 14.411316\n",
      "Epoch 4/10, Batch 931/1650, Loss 46.501934, Loss rec 8.469814, loss rec t1 9.760168, loss kl 0.146100, loss_trans 0.008219, loss flux 14.429164, loss flux t1 13.688471\n",
      "Epoch 4/10, Batch 941/1650, Loss 55.333344, Loss rec 8.898432, loss rec t1 11.495230, loss kl 0.182468, loss_trans 0.008965, loss flux 18.288166, loss flux t1 16.460085\n",
      "Epoch 4/10, Batch 951/1650, Loss 48.534248, Loss rec 8.043894, loss rec t1 9.050376, loss kl 0.121657, loss_trans 0.004356, loss flux 15.592611, loss flux t1 15.721354\n",
      "Epoch 4/10, Batch 961/1650, Loss 43.229233, Loss rec 7.972999, loss rec t1 8.676414, loss kl 0.096499, loss_trans 0.002880, loss flux 14.143343, loss flux t1 12.337098\n",
      "Epoch 4/10, Batch 971/1650, Loss 52.444984, Loss rec 10.712152, loss rec t1 11.946484, loss kl 0.115504, loss_trans 0.008494, loss flux 16.163773, loss flux t1 13.498577\n",
      "Epoch 4/10, Batch 981/1650, Loss 46.869160, Loss rec 9.151157, loss rec t1 10.744089, loss kl 0.115893, loss_trans 0.004742, loss flux 13.779142, loss flux t1 13.074133\n",
      "Epoch 4/10, Batch 991/1650, Loss 48.795219, Loss rec 8.628395, loss rec t1 9.048768, loss kl 0.109525, loss_trans 0.003332, loss flux 15.566940, loss flux t1 15.438254\n",
      "Epoch 4/10, Batch 1001/1650, Loss 58.953888, Loss rec 10.587465, loss rec t1 11.601027, loss kl 0.193860, loss_trans 0.010657, loss flux 18.205952, loss flux t1 18.354929\n",
      "Epoch 4/10, Batch 1011/1650, Loss 49.826603, Loss rec 8.166954, loss rec t1 10.131322, loss kl 0.118388, loss_trans 0.005637, loss flux 16.122669, loss flux t1 15.281634\n",
      "Epoch 4/10, Batch 1021/1650, Loss 46.977711, Loss rec 8.180688, loss rec t1 9.441902, loss kl 0.121044, loss_trans 0.003787, loss flux 14.562357, loss flux t1 14.667930\n",
      "Epoch 4/10, Batch 1031/1650, Loss 58.653667, Loss rec 12.721467, loss rec t1 12.196721, loss kl 0.205426, loss_trans 0.010517, loss flux 17.365986, loss flux t1 16.153551\n",
      "Epoch 4/10, Batch 1041/1650, Loss 45.542610, Loss rec 9.482424, loss rec t1 10.827523, loss kl 0.129248, loss_trans 0.006704, loss flux 12.860872, loss flux t1 12.235836\n",
      "Epoch 4/10, Batch 1051/1650, Loss 45.717808, Loss rec 8.589885, loss rec t1 9.459894, loss kl 0.111140, loss_trans 0.004615, loss flux 13.871634, loss flux t1 13.680638\n",
      "Epoch 4/10, Batch 1061/1650, Loss 54.957218, Loss rec 10.308067, loss rec t1 11.873378, loss kl 0.177959, loss_trans 0.011012, loss flux 16.201168, loss flux t1 16.385632\n",
      "Epoch 4/10, Batch 1071/1650, Loss 53.727142, Loss rec 9.062446, loss rec t1 9.495771, loss kl 0.192735, loss_trans 0.009622, loss flux 17.576212, loss flux t1 17.390358\n",
      "Epoch 4/10, Batch 1081/1650, Loss 57.688454, Loss rec 12.978830, loss rec t1 14.263270, loss kl 0.156750, loss_trans 0.008328, loss flux 15.213040, loss flux t1 15.068236\n",
      "Epoch 4/10, Batch 1091/1650, Loss 50.141331, Loss rec 8.170449, loss rec t1 10.197090, loss kl 0.092104, loss_trans 0.003093, loss flux 15.790739, loss flux t1 15.887856\n",
      "Epoch 4/10, Batch 1101/1650, Loss 47.434292, Loss rec 7.076418, loss rec t1 9.151634, loss kl 0.123329, loss_trans 0.005572, loss flux 17.299500, loss flux t1 13.777839\n",
      "Epoch 4/10, Batch 1111/1650, Loss 44.708042, Loss rec 6.304111, loss rec t1 7.561297, loss kl 0.124076, loss_trans 0.008046, loss flux 17.008419, loss flux t1 13.702097\n",
      "Epoch 4/10, Batch 1121/1650, Loss 52.682606, Loss rec 10.176378, loss rec t1 10.971817, loss kl 0.178101, loss_trans 0.006941, loss flux 16.140158, loss flux t1 15.209212\n",
      "Epoch 4/10, Batch 1131/1650, Loss 61.220837, Loss rec 13.436884, loss rec t1 13.523228, loss kl 0.244929, loss_trans 0.020587, loss flux 17.345951, loss flux t1 16.649256\n",
      "Epoch 4/10, Batch 1141/1650, Loss 64.411125, Loss rec 13.925376, loss rec t1 16.526941, loss kl 0.167700, loss_trans 0.009727, loss flux 17.175276, loss flux t1 16.606110\n",
      "Epoch 4/10, Batch 1151/1650, Loss 51.173523, Loss rec 10.237715, loss rec t1 11.851261, loss kl 0.198405, loss_trans 0.009543, loss flux 14.597398, loss flux t1 14.279200\n",
      "Epoch 4/10, Batch 1161/1650, Loss 55.410213, Loss rec 11.589503, loss rec t1 12.096119, loss kl 0.146064, loss_trans 0.011370, loss flux 16.189453, loss flux t1 15.377699\n",
      "Epoch 4/10, Batch 1171/1650, Loss 47.007843, Loss rec 7.611420, loss rec t1 9.113607, loss kl 0.130503, loss_trans 0.003742, loss flux 15.491683, loss flux t1 14.656888\n",
      "Epoch 4/10, Batch 1181/1650, Loss 65.409103, Loss rec 12.832932, loss rec t1 14.611248, loss kl 0.231257, loss_trans 0.009267, loss flux 18.738789, loss flux t1 18.985611\n",
      "Epoch 4/10, Batch 1191/1650, Loss 57.874756, Loss rec 11.211000, loss rec t1 12.881576, loss kl 0.176708, loss_trans 0.011315, loss flux 16.962355, loss flux t1 16.631807\n",
      "Epoch 4/10, Batch 1201/1650, Loss 46.312023, Loss rec 7.594728, loss rec t1 9.089571, loss kl 0.132941, loss_trans 0.006066, loss flux 15.986836, loss flux t1 13.501881\n",
      "Epoch 4/10, Batch 1211/1650, Loss 59.932934, Loss rec 12.344028, loss rec t1 14.667175, loss kl 0.175932, loss_trans 0.006980, loss flux 16.216354, loss flux t1 16.522465\n",
      "Epoch 4/10, Batch 1221/1650, Loss 49.513786, Loss rec 7.179002, loss rec t1 8.653126, loss kl 0.148924, loss_trans 0.003981, loss flux 17.355040, loss flux t1 16.173712\n",
      "Epoch 4/10, Batch 1231/1650, Loss 55.965363, Loss rec 12.243889, loss rec t1 13.487309, loss kl 0.134930, loss_trans 0.004528, loss flux 15.439913, loss flux t1 14.654796\n",
      "Epoch 4/10, Batch 1241/1650, Loss 51.587612, Loss rec 9.373985, loss rec t1 11.722998, loss kl 0.138604, loss_trans 0.005932, loss flux 15.947868, loss flux t1 14.398226\n",
      "Epoch 4/10, Batch 1251/1650, Loss 73.098846, Loss rec 18.869530, loss rec t1 21.830635, loss kl 0.113210, loss_trans 0.005037, loss flux 16.206360, loss flux t1 16.074076\n",
      "Epoch 4/10, Batch 1261/1650, Loss 53.213490, Loss rec 11.879066, loss rec t1 12.532698, loss kl 0.120545, loss_trans 0.007746, loss flux 14.986296, loss flux t1 13.687138\n",
      "Epoch 4/10, Batch 1271/1650, Loss 53.929085, Loss rec 11.921576, loss rec t1 12.598619, loss kl 0.143083, loss_trans 0.013328, loss flux 15.310440, loss flux t1 13.942039\n",
      "Epoch 4/10, Batch 1281/1650, Loss 46.302517, Loss rec 7.242924, loss rec t1 7.960736, loss kl 0.151297, loss_trans 0.005288, loss flux 16.601105, loss flux t1 14.341167\n",
      "Epoch 4/10, Batch 1291/1650, Loss 44.554760, Loss rec 7.043428, loss rec t1 8.734316, loss kl 0.104800, loss_trans 0.004508, loss flux 14.616994, loss flux t1 14.050714\n",
      "Epoch 4/10, Batch 1301/1650, Loss 42.225235, Loss rec 7.519931, loss rec t1 8.658411, loss kl 0.133998, loss_trans 0.008531, loss flux 13.448775, loss flux t1 12.455590\n",
      "Epoch 4/10, Batch 1311/1650, Loss 53.630356, Loss rec 9.674694, loss rec t1 11.504798, loss kl 0.122796, loss_trans 0.007071, loss flux 16.587412, loss flux t1 15.733580\n",
      "Epoch 4/10, Batch 1321/1650, Loss 60.530846, Loss rec 13.907013, loss rec t1 15.849133, loss kl 0.188599, loss_trans 0.012741, loss flux 16.065693, loss flux t1 14.507669\n",
      "Epoch 4/10, Batch 1331/1650, Loss 52.884445, Loss rec 10.411124, loss rec t1 11.622748, loss kl 0.120999, loss_trans 0.010386, loss flux 15.284421, loss flux t1 15.434766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Batch 1341/1650, Loss 42.115105, Loss rec 6.004437, loss rec t1 7.671164, loss kl 0.152880, loss_trans 0.008378, loss flux 14.913571, loss flux t1 13.364676\n",
      "Epoch 4/10, Batch 1351/1650, Loss 43.415047, Loss rec 7.738408, loss rec t1 9.050864, loss kl 0.089747, loss_trans 0.002661, loss flux 12.981428, loss flux t1 13.551940\n",
      "Epoch 4/10, Batch 1361/1650, Loss 52.206734, Loss rec 10.614677, loss rec t1 11.704900, loss kl 0.208082, loss_trans 0.011376, loss flux 15.340116, loss flux t1 14.327581\n",
      "Epoch 4/10, Batch 1371/1650, Loss 46.121460, Loss rec 6.372201, loss rec t1 7.839075, loss kl 0.132530, loss_trans 0.006173, loss flux 17.090441, loss flux t1 14.681044\n",
      "Epoch 4/10, Batch 1381/1650, Loss 50.370270, Loss rec 10.196621, loss rec t1 11.118741, loss kl 0.167216, loss_trans 0.006194, loss flux 14.681488, loss flux t1 14.200012\n",
      "Epoch 4/10, Batch 1391/1650, Loss 48.736694, Loss rec 7.710493, loss rec t1 9.882338, loss kl 0.222214, loss_trans 0.012108, loss flux 15.507367, loss flux t1 15.402175\n",
      "Epoch 4/10, Batch 1401/1650, Loss 49.880463, Loss rec 9.383758, loss rec t1 10.584383, loss kl 0.127369, loss_trans 0.004363, loss flux 15.244534, loss flux t1 14.536055\n",
      "Epoch 4/10, Batch 1411/1650, Loss 56.513672, Loss rec 11.862911, loss rec t1 13.070679, loss kl 0.154115, loss_trans 0.009527, loss flux 16.693150, loss flux t1 14.723294\n",
      "Epoch 4/10, Batch 1421/1650, Loss 47.444485, Loss rec 8.207393, loss rec t1 9.493660, loss kl 0.138233, loss_trans 0.005889, loss flux 14.766707, loss flux t1 14.832600\n",
      "Epoch 4/10, Batch 1431/1650, Loss 43.439552, Loss rec 7.989168, loss rec t1 8.702047, loss kl 0.149253, loss_trans 0.006156, loss flux 13.522645, loss flux t1 13.070284\n",
      "Epoch 4/10, Batch 1441/1650, Loss 46.779358, Loss rec 7.570940, loss rec t1 8.803017, loss kl 0.212968, loss_trans 0.011914, loss flux 15.361631, loss flux t1 14.818891\n",
      "Epoch 4/10, Batch 1451/1650, Loss 48.423489, Loss rec 10.142530, loss rec t1 11.965820, loss kl 0.144262, loss_trans 0.009691, loss flux 13.543719, loss flux t1 12.617465\n",
      "Epoch 4/10, Batch 1461/1650, Loss 42.777100, Loss rec 7.135231, loss rec t1 8.074383, loss kl 0.127527, loss_trans 0.003705, loss flux 14.425723, loss flux t1 13.010533\n",
      "Epoch 4/10, Batch 1471/1650, Loss 49.608200, Loss rec 9.747819, loss rec t1 10.742759, loss kl 0.166841, loss_trans 0.007040, loss flux 14.442155, loss flux t1 14.501582\n",
      "Epoch 4/10, Batch 1481/1650, Loss 49.761654, Loss rec 9.923314, loss rec t1 11.246063, loss kl 0.145538, loss_trans 0.005872, loss flux 14.955835, loss flux t1 13.485029\n",
      "Epoch 4/10, Batch 1491/1650, Loss 67.508682, Loss rec 17.100861, loss rec t1 16.823521, loss kl 0.216649, loss_trans 0.011234, loss flux 16.780849, loss flux t1 16.575573\n",
      "Epoch 4/10, Batch 1501/1650, Loss 65.154129, Loss rec 14.468775, loss rec t1 14.597816, loss kl 0.210431, loss_trans 0.013248, loss flux 18.315950, loss flux t1 17.547911\n",
      "Epoch 4/10, Batch 1511/1650, Loss 57.119934, Loss rec 11.757391, loss rec t1 13.602509, loss kl 0.108662, loss_trans 0.007353, loss flux 16.046513, loss flux t1 15.597504\n",
      "Epoch 4/10, Batch 1521/1650, Loss 52.086174, Loss rec 10.623754, loss rec t1 12.780186, loss kl 0.145972, loss_trans 0.004189, loss flux 14.469644, loss flux t1 14.062433\n",
      "Epoch 4/10, Batch 1531/1650, Loss 54.834499, Loss rec 12.068816, loss rec t1 12.791444, loss kl 0.142690, loss_trans 0.008638, loss flux 14.515514, loss flux t1 15.307396\n",
      "Epoch 4/10, Batch 1541/1650, Loss 56.201672, Loss rec 10.986952, loss rec t1 12.417505, loss kl 0.166853, loss_trans 0.006383, loss flux 17.195938, loss flux t1 15.428041\n",
      "Epoch 4/10, Batch 1551/1650, Loss 47.057949, Loss rec 8.198536, loss rec t1 9.080139, loss kl 0.101878, loss_trans 0.004793, loss flux 15.291098, loss flux t1 14.381502\n",
      "Epoch 4/10, Batch 1561/1650, Loss 56.569183, Loss rec 10.421967, loss rec t1 12.187233, loss kl 0.216322, loss_trans 0.009550, loss flux 16.741653, loss flux t1 16.992458\n",
      "Epoch 4/10, Batch 1571/1650, Loss 56.847862, Loss rec 9.091092, loss rec t1 9.911521, loss kl 0.207892, loss_trans 0.009435, loss flux 19.329226, loss flux t1 18.298698\n",
      "Epoch 4/10, Batch 1581/1650, Loss 44.373081, Loss rec 7.925162, loss rec t1 8.769983, loss kl 0.104170, loss_trans 0.002610, loss flux 14.316838, loss flux t1 13.254317\n",
      "Epoch 4/10, Batch 1591/1650, Loss 46.421547, Loss rec 7.585737, loss rec t1 8.621112, loss kl 0.170587, loss_trans 0.010477, loss flux 15.512059, loss flux t1 14.521576\n",
      "Epoch 4/10, Batch 1601/1650, Loss 46.642921, Loss rec 10.215664, loss rec t1 11.523058, loss kl 0.068651, loss_trans 0.005163, loss flux 12.742988, loss flux t1 12.087398\n",
      "Epoch 4/10, Batch 1611/1650, Loss 39.975548, Loss rec 5.689941, loss rec t1 6.966626, loss kl 0.092925, loss_trans 0.003244, loss flux 13.965674, loss flux t1 13.257139\n",
      "Epoch 4/10, Batch 1621/1650, Loss 45.172638, Loss rec 7.018022, loss rec t1 7.459577, loss kl 0.166934, loss_trans 0.005577, loss flux 16.231575, loss flux t1 14.290955\n",
      "Epoch 4/10, Batch 1631/1650, Loss 59.904621, Loss rec 13.373028, loss rec t1 16.025436, loss kl 0.102110, loss_trans 0.009232, loss flux 16.208658, loss flux t1 14.186157\n",
      "Epoch 4/10, Batch 1641/1650, Loss 53.861675, Loss rec 9.387478, loss rec t1 10.343216, loss kl 0.182331, loss_trans 0.005715, loss flux 17.611691, loss flux t1 16.331245\n",
      "Epoch 4/10, Train loss 44.134796, Eval loss 51.980473\n",
      "Epoch 5/10, Batch 1/1650, Loss 45.811794, Loss rec 5.727445, loss rec t1 7.364496, loss kl 0.181159, loss_trans 0.004490, loss flux 16.330925, loss flux t1 16.203281\n",
      "Epoch 5/10, Batch 11/1650, Loss 51.719837, Loss rec 8.351258, loss rec t1 9.858890, loss kl 0.176786, loss_trans 0.004717, loss flux 16.641478, loss flux t1 16.686707\n",
      "Epoch 5/10, Batch 21/1650, Loss 51.521858, Loss rec 10.991264, loss rec t1 12.159159, loss kl 0.124010, loss_trans 0.010424, loss flux 14.036415, loss flux t1 14.200584\n",
      "Epoch 5/10, Batch 31/1650, Loss 44.458618, Loss rec 7.877815, loss rec t1 9.195239, loss kl 0.101301, loss_trans 0.004089, loss flux 13.419242, loss flux t1 13.860929\n",
      "Epoch 5/10, Batch 41/1650, Loss 50.173916, Loss rec 9.972652, loss rec t1 11.889021, loss kl 0.115954, loss_trans 0.005088, loss flux 14.490399, loss flux t1 13.700803\n",
      "Epoch 5/10, Batch 51/1650, Loss 55.651901, Loss rec 10.550600, loss rec t1 13.213970, loss kl 0.099281, loss_trans 0.003587, loss flux 15.328067, loss flux t1 16.456396\n",
      "Epoch 5/10, Batch 61/1650, Loss 104.887962, Loss rec 30.262489, loss rec t1 37.899284, loss kl 0.176162, loss_trans 0.015055, loss flux 18.186375, loss flux t1 18.348602\n",
      "Epoch 5/10, Batch 71/1650, Loss 77.202484, Loss rec 17.276169, loss rec t1 16.805950, loss kl 0.172567, loss_trans 0.009092, loss flux 22.191797, loss flux t1 20.746908\n",
      "Epoch 5/10, Batch 81/1650, Loss 58.323643, Loss rec 11.961258, loss rec t1 12.417393, loss kl 0.113153, loss_trans 0.008695, loss flux 17.378258, loss flux t1 16.444887\n",
      "Epoch 5/10, Batch 91/1650, Loss 67.633263, Loss rec 14.066551, loss rec t1 15.361485, loss kl 0.141059, loss_trans 0.007839, loss flux 19.707836, loss flux t1 18.348492\n",
      "Epoch 5/10, Batch 101/1650, Loss 60.313263, Loss rec 12.792976, loss rec t1 13.752342, loss kl 0.103189, loss_trans 0.006307, loss flux 17.850752, loss flux t1 15.807697\n",
      "Epoch 5/10, Batch 111/1650, Loss 60.035225, Loss rec 12.434172, loss rec t1 13.155939, loss kl 0.195331, loss_trans 0.010520, loss flux 17.605169, loss flux t1 16.634092\n",
      "Epoch 5/10, Batch 121/1650, Loss 56.365841, Loss rec 10.526297, loss rec t1 13.678408, loss kl 0.190620, loss_trans 0.008020, loss flux 15.951506, loss flux t1 16.010990\n",
      "Epoch 5/10, Batch 131/1650, Loss 54.052464, Loss rec 10.122480, loss rec t1 10.555222, loss kl 0.074769, loss_trans 0.002201, loss flux 18.162014, loss flux t1 15.135778\n",
      "Epoch 5/10, Batch 141/1650, Loss 51.218887, Loss rec 10.892248, loss rec t1 12.223482, loss kl 0.106687, loss_trans 0.005715, loss flux 14.594063, loss flux t1 13.396689\n",
      "Epoch 5/10, Batch 151/1650, Loss 51.773335, Loss rec 9.631626, loss rec t1 10.113918, loss kl 0.206129, loss_trans 0.012226, loss flux 15.739685, loss flux t1 16.069750\n",
      "Epoch 5/10, Batch 161/1650, Loss 54.517677, Loss rec 9.989701, loss rec t1 11.761348, loss kl 0.215344, loss_trans 0.010476, loss flux 16.894129, loss flux t1 15.646684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Batch 171/1650, Loss 59.568626, Loss rec 11.087414, loss rec t1 12.564606, loss kl 0.214532, loss_trans 0.009279, loss flux 17.992081, loss flux t1 17.700720\n",
      "Epoch 5/10, Batch 181/1650, Loss 39.959873, Loss rec 6.681352, loss rec t1 8.922965, loss kl 0.105349, loss_trans 0.004170, loss flux 12.535916, loss flux t1 11.710121\n",
      "Epoch 5/10, Batch 191/1650, Loss 52.349487, Loss rec 9.694466, loss rec t1 11.535648, loss kl 0.189166, loss_trans 0.012557, loss flux 15.358617, loss flux t1 15.559031\n",
      "Epoch 5/10, Batch 201/1650, Loss 73.973053, Loss rec 17.652195, loss rec t1 17.695080, loss kl 0.128093, loss_trans 0.005871, loss flux 20.444674, loss flux t1 18.047136\n",
      "Epoch 5/10, Batch 211/1650, Loss 47.294388, Loss rec 9.146420, loss rec t1 9.570841, loss kl 0.079094, loss_trans 0.002529, loss flux 14.205870, loss flux t1 14.289636\n",
      "Epoch 5/10, Batch 221/1650, Loss 48.815975, Loss rec 8.976155, loss rec t1 8.989413, loss kl 0.130875, loss_trans 0.002850, loss flux 16.204079, loss flux t1 14.512605\n",
      "Epoch 5/10, Batch 231/1650, Loss 46.474632, Loss rec 8.381446, loss rec t1 9.951670, loss kl 0.167973, loss_trans 0.007894, loss flux 14.278490, loss flux t1 13.687161\n",
      "Epoch 5/10, Batch 241/1650, Loss 49.211178, Loss rec 9.183238, loss rec t1 10.211952, loss kl 0.123948, loss_trans 0.006067, loss flux 15.357656, loss flux t1 14.328316\n",
      "Epoch 5/10, Batch 251/1650, Loss 48.155621, Loss rec 9.415142, loss rec t1 10.458517, loss kl 0.162026, loss_trans 0.013968, loss flux 14.339919, loss flux t1 13.766048\n",
      "Epoch 5/10, Batch 261/1650, Loss 43.768669, Loss rec 7.028873, loss rec t1 7.905449, loss kl 0.104881, loss_trans 0.003376, loss flux 14.612855, loss flux t1 14.113236\n",
      "Epoch 5/10, Batch 271/1650, Loss 52.849434, Loss rec 10.857123, loss rec t1 11.450190, loss kl 0.159975, loss_trans 0.007035, loss flux 15.937868, loss flux t1 14.437243\n",
      "Epoch 5/10, Batch 281/1650, Loss 49.582714, Loss rec 9.618311, loss rec t1 10.724983, loss kl 0.135635, loss_trans 0.006417, loss flux 15.356622, loss flux t1 13.740745\n",
      "Epoch 5/10, Batch 291/1650, Loss 45.258350, Loss rec 7.312922, loss rec t1 8.418047, loss kl 0.163194, loss_trans 0.006762, loss flux 15.134044, loss flux t1 14.223379\n",
      "Epoch 5/10, Batch 301/1650, Loss 44.398464, Loss rec 8.048129, loss rec t1 9.621548, loss kl 0.101951, loss_trans 0.004320, loss flux 13.762462, loss flux t1 12.860059\n",
      "Epoch 5/10, Batch 311/1650, Loss 38.394741, Loss rec 5.818357, loss rec t1 7.135853, loss kl 0.110593, loss_trans 0.002354, loss flux 12.852071, loss flux t1 12.475512\n",
      "Epoch 5/10, Batch 321/1650, Loss 51.481766, Loss rec 8.986802, loss rec t1 9.629894, loss kl 0.145905, loss_trans 0.006663, loss flux 16.429438, loss flux t1 16.283062\n",
      "Epoch 5/10, Batch 331/1650, Loss 54.169243, Loss rec 12.070265, loss rec t1 12.677252, loss kl 0.091672, loss_trans 0.004720, loss flux 15.151252, loss flux t1 14.174083\n",
      "Epoch 5/10, Batch 341/1650, Loss 59.800545, Loss rec 12.683327, loss rec t1 14.707717, loss kl 0.138905, loss_trans 0.005418, loss flux 16.570335, loss flux t1 15.694842\n",
      "Epoch 5/10, Batch 351/1650, Loss 58.953480, Loss rec 12.022161, loss rec t1 12.275166, loss kl 0.195430, loss_trans 0.007749, loss flux 17.604956, loss flux t1 16.848021\n",
      "Epoch 5/10, Batch 361/1650, Loss 52.535301, Loss rec 9.421905, loss rec t1 10.776536, loss kl 0.124443, loss_trans 0.005970, loss flux 16.219164, loss flux t1 15.987286\n",
      "Epoch 5/10, Batch 371/1650, Loss 53.366596, Loss rec 9.126669, loss rec t1 10.179160, loss kl 0.187256, loss_trans 0.015579, loss flux 16.943792, loss flux t1 16.914143\n",
      "Epoch 5/10, Batch 381/1650, Loss 54.995926, Loss rec 9.249915, loss rec t1 11.371761, loss kl 0.144736, loss_trans 0.007338, loss flux 19.168890, loss flux t1 15.053288\n",
      "Epoch 5/10, Batch 391/1650, Loss 50.521206, Loss rec 9.798691, loss rec t1 12.253122, loss kl 0.144797, loss_trans 0.004746, loss flux 14.604515, loss flux t1 13.715337\n",
      "Epoch 5/10, Batch 401/1650, Loss 47.448608, Loss rec 9.888130, loss rec t1 10.839641, loss kl 0.093687, loss_trans 0.005573, loss flux 13.242870, loss flux t1 13.378705\n",
      "Epoch 5/10, Batch 411/1650, Loss 52.709057, Loss rec 9.962004, loss rec t1 11.182627, loss kl 0.206786, loss_trans 0.015771, loss flux 16.312855, loss flux t1 15.029019\n",
      "Epoch 5/10, Batch 421/1650, Loss 50.250755, Loss rec 10.024474, loss rec t1 10.547577, loss kl 0.192089, loss_trans 0.015689, loss flux 15.240900, loss flux t1 14.230021\n",
      "Epoch 5/10, Batch 431/1650, Loss 37.297626, Loss rec 5.136862, loss rec t1 6.680462, loss kl 0.148739, loss_trans 0.002498, loss flux 13.315499, loss flux t1 12.013566\n",
      "Epoch 5/10, Batch 441/1650, Loss 48.932533, Loss rec 8.254640, loss rec t1 8.982000, loss kl 0.158079, loss_trans 0.005424, loss flux 16.793282, loss flux t1 14.739105\n",
      "Epoch 5/10, Batch 451/1650, Loss 43.286270, Loss rec 7.820587, loss rec t1 8.528833, loss kl 0.111204, loss_trans 0.007839, loss flux 13.921944, loss flux t1 12.895862\n",
      "Epoch 5/10, Batch 461/1650, Loss 44.067646, Loss rec 8.268887, loss rec t1 8.891312, loss kl 0.115715, loss_trans 0.005928, loss flux 13.759177, loss flux t1 13.026627\n",
      "Epoch 5/10, Batch 471/1650, Loss 39.701092, Loss rec 6.030400, loss rec t1 6.801081, loss kl 0.125496, loss_trans 0.002994, loss flux 13.973568, loss flux t1 12.767552\n",
      "Epoch 5/10, Batch 481/1650, Loss 40.007225, Loss rec 6.340746, loss rec t1 7.667200, loss kl 0.115036, loss_trans 0.002730, loss flux 13.403490, loss flux t1 12.478021\n",
      "Epoch 5/10, Batch 491/1650, Loss 42.360790, Loss rec 7.252598, loss rec t1 7.826353, loss kl 0.089872, loss_trans 0.002820, loss flux 13.929157, loss flux t1 13.259991\n",
      "Epoch 5/10, Batch 501/1650, Loss 51.952900, Loss rec 9.448289, loss rec t1 9.955954, loss kl 0.145273, loss_trans 0.004939, loss flux 16.854502, loss flux t1 15.543942\n",
      "Epoch 5/10, Batch 511/1650, Loss 51.560108, Loss rec 10.357656, loss rec t1 12.100731, loss kl 0.134290, loss_trans 0.004963, loss flux 15.279613, loss flux t1 13.682852\n",
      "Epoch 5/10, Batch 521/1650, Loss 73.557739, Loss rec 15.024127, loss rec t1 16.658859, loss kl 0.198597, loss_trans 0.012115, loss flux 20.937897, loss flux t1 20.726139\n",
      "Epoch 5/10, Batch 531/1650, Loss 54.779644, Loss rec 10.412172, loss rec t1 11.068011, loss kl 0.087268, loss_trans 0.005833, loss flux 18.148098, loss flux t1 15.058262\n",
      "Epoch 5/10, Batch 541/1650, Loss 47.290115, Loss rec 6.528053, loss rec t1 8.863413, loss kl 0.112153, loss_trans 0.003677, loss flux 16.542507, loss flux t1 15.240313\n",
      "Epoch 5/10, Batch 551/1650, Loss 64.216248, Loss rec 12.906174, loss rec t1 15.429136, loss kl 0.157409, loss_trans 0.011280, loss flux 18.609375, loss flux t1 17.102880\n",
      "Epoch 5/10, Batch 561/1650, Loss 75.125580, Loss rec 16.572317, loss rec t1 21.058544, loss kl 0.107986, loss_trans 0.005051, loss flux 19.225199, loss flux t1 18.156490\n",
      "Epoch 5/10, Batch 571/1650, Loss 64.076637, Loss rec 14.772315, loss rec t1 14.851851, loss kl 0.145047, loss_trans 0.003772, loss flux 18.130236, loss flux t1 16.173424\n",
      "Epoch 5/10, Batch 581/1650, Loss 73.566238, Loss rec 16.554808, loss rec t1 17.448652, loss kl 0.112351, loss_trans 0.005496, loss flux 20.314615, loss flux t1 19.130320\n",
      "Epoch 5/10, Batch 591/1650, Loss 50.192825, Loss rec 7.812894, loss rec t1 11.157061, loss kl 0.099073, loss_trans 0.002991, loss flux 15.949937, loss flux t1 15.170866\n",
      "Epoch 5/10, Batch 601/1650, Loss 70.236961, Loss rec 16.375164, loss rec t1 16.054810, loss kl 0.139234, loss_trans 0.013803, loss flux 20.785242, loss flux t1 16.868715\n",
      "Epoch 5/10, Batch 611/1650, Loss 84.836746, Loss rec 18.700420, loss rec t1 19.345890, loss kl 0.121439, loss_trans 0.009860, loss flux 25.825985, loss flux t1 20.833158\n",
      "Epoch 5/10, Batch 621/1650, Loss 92.961510, Loss rec 23.893135, loss rec t1 28.752480, loss kl 0.164503, loss_trans 0.007905, loss flux 19.898214, loss flux t1 20.245277\n",
      "Epoch 5/10, Batch 631/1650, Loss 79.044296, Loss rec 17.658876, loss rec t1 20.856274, loss kl 0.160342, loss_trans 0.010379, loss flux 21.134577, loss flux t1 19.223848\n",
      "Epoch 5/10, Batch 641/1650, Loss 62.486950, Loss rec 13.441370, loss rec t1 14.683467, loss kl 0.149396, loss_trans 0.011556, loss flux 17.237082, loss flux t1 16.964081\n",
      "Epoch 5/10, Batch 651/1650, Loss 74.946327, Loss rec 17.473183, loss rec t1 19.345772, loss kl 0.142821, loss_trans 0.011002, loss flux 19.950663, loss flux t1 18.022890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Batch 661/1650, Loss 75.579163, Loss rec 13.901808, loss rec t1 16.584799, loss kl 0.184772, loss_trans 0.014705, loss flux 23.346329, loss flux t1 21.546751\n",
      "Epoch 5/10, Batch 671/1650, Loss 79.451469, Loss rec 16.269600, loss rec t1 19.978500, loss kl 0.113634, loss_trans 0.008519, loss flux 21.917503, loss flux t1 21.163706\n",
      "Epoch 5/10, Batch 681/1650, Loss 55.032242, Loss rec 6.403280, loss rec t1 8.352457, loss kl 0.122444, loss_trans 0.004326, loss flux 21.162584, loss flux t1 18.987152\n",
      "Epoch 5/10, Batch 691/1650, Loss 113.209091, Loss rec 31.368851, loss rec t1 25.262745, loss kl 0.248413, loss_trans 0.014747, loss flux 29.453608, loss flux t1 26.860725\n",
      "Epoch 5/10, Batch 701/1650, Loss 127.089394, Loss rec 41.649635, loss rec t1 33.383148, loss kl 0.193079, loss_trans 0.022157, loss flux 26.702755, loss flux t1 25.138617\n",
      "Epoch 5/10, Batch 711/1650, Loss 86.718414, Loss rec 17.421379, loss rec t1 16.151978, loss kl 0.275279, loss_trans 0.014603, loss flux 26.694487, loss flux t1 26.160686\n",
      "Epoch 5/10, Batch 721/1650, Loss 70.903976, Loss rec 13.214111, loss rec t1 13.084148, loss kl 0.216537, loss_trans 0.009350, loss flux 23.320763, loss flux t1 21.059065\n",
      "Epoch 5/10, Batch 731/1650, Loss 64.642235, Loss rec 15.232671, loss rec t1 14.348087, loss kl 0.140934, loss_trans 0.008386, loss flux 17.856459, loss flux t1 17.055698\n",
      "Epoch 5/10, Batch 741/1650, Loss 54.243980, Loss rec 11.903812, loss rec t1 11.078250, loss kl 0.141479, loss_trans 0.011500, loss flux 15.561212, loss flux t1 15.547725\n",
      "Epoch 5/10, Batch 751/1650, Loss 53.589520, Loss rec 10.017339, loss rec t1 11.271521, loss kl 0.185866, loss_trans 0.008844, loss flux 16.857176, loss flux t1 15.248770\n",
      "Epoch 5/10, Batch 761/1650, Loss 53.513195, Loss rec 10.019440, loss rec t1 10.858632, loss kl 0.197692, loss_trans 0.019555, loss flux 16.676950, loss flux t1 15.740930\n",
      "Epoch 5/10, Batch 771/1650, Loss 44.280804, Loss rec 6.219240, loss rec t1 8.494740, loss kl 0.131752, loss_trans 0.005914, loss flux 14.839564, loss flux t1 14.589595\n",
      "Epoch 5/10, Batch 781/1650, Loss 49.040752, Loss rec 10.533843, loss rec t1 12.141670, loss kl 0.119104, loss_trans 0.004316, loss flux 13.613522, loss flux t1 12.628298\n",
      "Epoch 5/10, Batch 791/1650, Loss 45.759007, Loss rec 7.851906, loss rec t1 9.230843, loss kl 0.118684, loss_trans 0.009813, loss flux 14.316999, loss flux t1 14.230762\n",
      "Epoch 5/10, Batch 801/1650, Loss 49.539776, Loss rec 9.029831, loss rec t1 9.700669, loss kl 0.176522, loss_trans 0.009547, loss flux 15.361745, loss flux t1 15.261462\n",
      "Epoch 5/10, Batch 811/1650, Loss 51.728619, Loss rec 8.935841, loss rec t1 11.360264, loss kl 0.209535, loss_trans 0.007246, loss flux 15.902184, loss flux t1 15.313548\n",
      "Epoch 5/10, Batch 821/1650, Loss 43.524158, Loss rec 6.982634, loss rec t1 8.700935, loss kl 0.140772, loss_trans 0.009640, loss flux 14.374362, loss flux t1 13.315817\n",
      "Epoch 5/10, Batch 831/1650, Loss 45.840252, Loss rec 7.909470, loss rec t1 9.637297, loss kl 0.224636, loss_trans 0.010727, loss flux 14.594249, loss flux t1 13.463874\n",
      "Epoch 5/10, Batch 841/1650, Loss 36.971123, Loss rec 6.445686, loss rec t1 7.957249, loss kl 0.091349, loss_trans 0.003987, loss flux 11.362643, loss flux t1 11.110210\n",
      "Epoch 5/10, Batch 851/1650, Loss 51.921028, Loss rec 10.847063, loss rec t1 11.910172, loss kl 0.144545, loss_trans 0.007870, loss flux 15.033513, loss flux t1 13.977868\n",
      "Epoch 5/10, Batch 861/1650, Loss 47.564468, Loss rec 8.095676, loss rec t1 8.607650, loss kl 0.203295, loss_trans 0.011343, loss flux 16.261564, loss flux t1 14.384942\n",
      "Epoch 5/10, Batch 871/1650, Loss 49.329330, Loss rec 9.700608, loss rec t1 10.359405, loss kl 0.171606, loss_trans 0.006856, loss flux 14.585721, loss flux t1 14.505134\n",
      "Epoch 5/10, Batch 881/1650, Loss 46.881840, Loss rec 8.281024, loss rec t1 10.378795, loss kl 0.140767, loss_trans 0.008657, loss flux 14.228892, loss flux t1 13.843703\n",
      "Epoch 5/10, Batch 891/1650, Loss 46.520908, Loss rec 6.991890, loss rec t1 9.091917, loss kl 0.139740, loss_trans 0.007479, loss flux 15.150284, loss flux t1 15.139597\n",
      "Epoch 5/10, Batch 901/1650, Loss 44.800610, Loss rec 8.220661, loss rec t1 9.435152, loss kl 0.198386, loss_trans 0.007802, loss flux 13.461317, loss flux t1 13.477292\n",
      "Epoch 5/10, Batch 911/1650, Loss 36.722206, Loss rec 5.399445, loss rec t1 6.523397, loss kl 0.127016, loss_trans 0.004087, loss flux 12.963363, loss flux t1 11.704900\n",
      "Epoch 5/10, Batch 921/1650, Loss 39.894764, Loss rec 6.334423, loss rec t1 7.731081, loss kl 0.137642, loss_trans 0.007444, loss flux 13.096747, loss flux t1 12.587430\n",
      "Epoch 5/10, Batch 931/1650, Loss 40.738701, Loss rec 8.089361, loss rec t1 8.825956, loss kl 0.142881, loss_trans 0.006436, loss flux 12.050492, loss flux t1 11.623573\n",
      "Epoch 5/10, Batch 941/1650, Loss 44.630615, Loss rec 6.867262, loss rec t1 8.260375, loss kl 0.178290, loss_trans 0.007657, loss flux 15.400547, loss flux t1 13.916485\n",
      "Epoch 5/10, Batch 951/1650, Loss 41.102798, Loss rec 6.936201, loss rec t1 7.801096, loss kl 0.116315, loss_trans 0.004318, loss flux 12.916722, loss flux t1 13.328145\n",
      "Epoch 5/10, Batch 961/1650, Loss 55.464207, Loss rec 11.076029, loss rec t1 11.396183, loss kl 0.089389, loss_trans 0.002793, loss flux 17.833490, loss flux t1 15.066322\n",
      "Epoch 5/10, Batch 971/1650, Loss 66.422905, Loss rec 15.256390, loss rec t1 14.875417, loss kl 0.102361, loss_trans 0.007435, loss flux 20.229023, loss flux t1 15.952281\n",
      "Epoch 5/10, Batch 981/1650, Loss 55.962635, Loss rec 11.430742, loss rec t1 11.487139, loss kl 0.106173, loss_trans 0.005249, loss flux 17.875374, loss flux t1 15.057956\n",
      "Epoch 5/10, Batch 991/1650, Loss 48.100544, Loss rec 7.941266, loss rec t1 8.593756, loss kl 0.107711, loss_trans 0.003474, loss flux 15.904402, loss flux t1 15.549933\n",
      "Epoch 5/10, Batch 1001/1650, Loss 48.018234, Loss rec 9.085421, loss rec t1 9.777759, loss kl 0.181076, loss_trans 0.008859, loss flux 14.619695, loss flux t1 14.345427\n",
      "Epoch 5/10, Batch 1011/1650, Loss 42.663944, Loss rec 6.869382, loss rec t1 8.601014, loss kl 0.115750, loss_trans 0.005206, loss flux 13.955948, loss flux t1 13.116643\n",
      "Epoch 5/10, Batch 1021/1650, Loss 41.412666, Loss rec 7.094200, loss rec t1 8.067802, loss kl 0.116366, loss_trans 0.003487, loss flux 12.661362, loss flux t1 13.469449\n",
      "Epoch 5/10, Batch 1031/1650, Loss 44.067657, Loss rec 9.027650, loss rec t1 9.758884, loss kl 0.197017, loss_trans 0.009135, loss flux 12.985778, loss flux t1 12.089194\n",
      "Epoch 5/10, Batch 1041/1650, Loss 39.766060, Loss rec 7.217448, loss rec t1 8.397971, loss kl 0.130010, loss_trans 0.006119, loss flux 12.368740, loss flux t1 11.645770\n",
      "Epoch 5/10, Batch 1051/1650, Loss 41.585606, Loss rec 7.981874, loss rec t1 8.042456, loss kl 0.105489, loss_trans 0.003898, loss flux 13.071896, loss flux t1 12.379994\n",
      "Epoch 5/10, Batch 1061/1650, Loss 47.878849, Loss rec 8.602453, loss rec t1 9.526336, loss kl 0.170047, loss_trans 0.009690, loss flux 14.705771, loss flux t1 14.864552\n",
      "Epoch 5/10, Batch 1071/1650, Loss 45.422028, Loss rec 7.563045, loss rec t1 8.514081, loss kl 0.188806, loss_trans 0.007456, loss flux 14.793620, loss flux t1 14.355020\n",
      "Epoch 5/10, Batch 1081/1650, Loss 45.592583, Loss rec 9.792133, loss rec t1 10.561649, loss kl 0.149080, loss_trans 0.007058, loss flux 12.613715, loss flux t1 12.468950\n",
      "Epoch 5/10, Batch 1091/1650, Loss 40.269836, Loss rec 6.478831, loss rec t1 7.341348, loss kl 0.087294, loss_trans 0.002612, loss flux 13.472450, loss flux t1 12.887299\n",
      "Epoch 5/10, Batch 1101/1650, Loss 37.166813, Loss rec 6.182487, loss rec t1 6.985508, loss kl 0.116729, loss_trans 0.004985, loss flux 12.736436, loss flux t1 11.140669\n",
      "Epoch 5/10, Batch 1111/1650, Loss 40.695675, Loss rec 5.963139, loss rec t1 6.778629, loss kl 0.117961, loss_trans 0.007680, loss flux 15.651827, loss flux t1 12.176442\n",
      "Epoch 5/10, Batch 1121/1650, Loss 49.292488, Loss rec 8.317771, loss rec t1 9.773372, loss kl 0.168780, loss_trans 0.005953, loss flux 15.494131, loss flux t1 15.532484\n",
      "Epoch 5/10, Batch 1131/1650, Loss 49.288685, Loss rec 9.970051, loss rec t1 9.928823, loss kl 0.242485, loss_trans 0.017135, loss flux 14.518780, loss flux t1 14.611408\n",
      "Epoch 5/10, Batch 1141/1650, Loss 44.659237, Loss rec 8.319014, loss rec t1 9.397083, loss kl 0.150583, loss_trans 0.007530, loss flux 13.304704, loss flux t1 13.480323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Batch 1151/1650, Loss 44.373978, Loss rec 7.609974, loss rec t1 8.354660, loss kl 0.189870, loss_trans 0.007433, loss flux 14.980682, loss flux t1 13.231359\n",
      "Epoch 5/10, Batch 1161/1650, Loss 48.649521, Loss rec 9.053958, loss rec t1 9.788787, loss kl 0.134729, loss_trans 0.009579, loss flux 15.091874, loss flux t1 14.570596\n",
      "Epoch 5/10, Batch 1171/1650, Loss 48.731735, Loss rec 8.654957, loss rec t1 10.084562, loss kl 0.121743, loss_trans 0.003347, loss flux 16.212811, loss flux t1 13.654315\n",
      "Epoch 5/10, Batch 1181/1650, Loss 50.337959, Loss rec 8.897549, loss rec t1 10.272409, loss kl 0.219471, loss_trans 0.007961, loss flux 15.194375, loss flux t1 15.746194\n",
      "Epoch 5/10, Batch 1191/1650, Loss 49.584518, Loss rec 9.265022, loss rec t1 10.147707, loss kl 0.173489, loss_trans 0.010727, loss flux 15.113972, loss flux t1 14.873602\n",
      "Epoch 5/10, Batch 1201/1650, Loss 42.091747, Loss rec 7.200129, loss rec t1 8.120474, loss kl 0.133803, loss_trans 0.005853, loss flux 13.992037, loss flux t1 12.639455\n",
      "Epoch 5/10, Batch 1211/1650, Loss 44.272736, Loss rec 7.982743, loss rec t1 9.296778, loss kl 0.165772, loss_trans 0.005933, loss flux 13.569751, loss flux t1 13.251763\n",
      "Epoch 5/10, Batch 1221/1650, Loss 40.270905, Loss rec 5.557564, loss rec t1 6.956090, loss kl 0.139784, loss_trans 0.003034, loss flux 13.771097, loss flux t1 13.843337\n",
      "Epoch 5/10, Batch 1231/1650, Loss 39.121471, Loss rec 6.083541, loss rec t1 7.147671, loss kl 0.130744, loss_trans 0.003998, loss flux 13.036435, loss flux t1 12.719081\n",
      "Epoch 5/10, Batch 1241/1650, Loss 41.547638, Loss rec 6.579331, loss rec t1 7.983336, loss kl 0.136868, loss_trans 0.004998, loss flux 14.043874, loss flux t1 12.799232\n",
      "Epoch 5/10, Batch 1251/1650, Loss 49.583260, Loss rec 11.272175, loss rec t1 12.370823, loss kl 0.107080, loss_trans 0.004219, loss flux 13.003333, loss flux t1 12.825629\n",
      "Epoch 5/10, Batch 1261/1650, Loss 41.357445, Loss rec 8.631887, loss rec t1 8.823786, loss kl 0.112638, loss_trans 0.006577, loss flux 12.361555, loss flux t1 11.421003\n",
      "Epoch 5/10, Batch 1271/1650, Loss 44.950859, Loss rec 9.447860, loss rec t1 10.270332, loss kl 0.129439, loss_trans 0.010132, loss flux 12.944034, loss flux t1 12.149063\n",
      "Epoch 5/10, Batch 1281/1650, Loss 37.784798, Loss rec 5.374257, loss rec t1 6.262204, loss kl 0.143796, loss_trans 0.004263, loss flux 13.439795, loss flux t1 12.560483\n",
      "Epoch 5/10, Batch 1291/1650, Loss 35.296944, Loss rec 5.273641, loss rec t1 7.120990, loss kl 0.099397, loss_trans 0.003993, loss flux 11.503428, loss flux t1 11.295493\n",
      "Epoch 5/10, Batch 1301/1650, Loss 37.861729, Loss rec 7.036891, loss rec t1 7.483788, loss kl 0.127883, loss_trans 0.006144, loss flux 11.995667, loss flux t1 11.211354\n",
      "Epoch 5/10, Batch 1311/1650, Loss 45.021248, Loss rec 7.982882, loss rec t1 9.245061, loss kl 0.119686, loss_trans 0.006074, loss flux 14.123809, loss flux t1 13.543736\n",
      "Epoch 5/10, Batch 1321/1650, Loss 50.267609, Loss rec 10.374869, loss rec t1 11.628666, loss kl 0.181943, loss_trans 0.010340, loss flux 15.021000, loss flux t1 13.050795\n",
      "Epoch 5/10, Batch 1331/1650, Loss 59.356331, Loss rec 13.389737, loss rec t1 16.029320, loss kl 0.113245, loss_trans 0.008913, loss flux 14.580891, loss flux t1 15.234227\n",
      "Epoch 5/10, Batch 1341/1650, Loss 39.655094, Loss rec 4.997865, loss rec t1 6.147243, loss kl 0.146488, loss_trans 0.006240, loss flux 14.694852, loss flux t1 13.662406\n",
      "Epoch 5/10, Batch 1351/1650, Loss 38.213966, Loss rec 6.340194, loss rec t1 7.812137, loss kl 0.081429, loss_trans 0.002412, loss flux 12.064351, loss flux t1 11.913445\n",
      "Epoch 5/10, Batch 1361/1650, Loss 47.490479, Loss rec 8.626999, loss rec t1 10.299320, loss kl 0.202477, loss_trans 0.010087, loss flux 14.930079, loss flux t1 13.421515\n",
      "Epoch 5/10, Batch 1371/1650, Loss 41.972408, Loss rec 5.408104, loss rec t1 6.701175, loss kl 0.128416, loss_trans 0.005549, loss flux 15.651823, loss flux t1 14.077341\n",
      "Epoch 5/10, Batch 1381/1650, Loss 44.539307, Loss rec 8.646044, loss rec t1 10.110957, loss kl 0.159585, loss_trans 0.005282, loss flux 13.136139, loss flux t1 12.481299\n",
      "Epoch 5/10, Batch 1391/1650, Loss 44.616211, Loss rec 7.513806, loss rec t1 8.325517, loss kl 0.214700, loss_trans 0.009292, loss flux 14.530107, loss flux t1 14.022790\n",
      "Epoch 5/10, Batch 1401/1650, Loss 41.261082, Loss rec 7.288812, loss rec t1 7.999852, loss kl 0.122272, loss_trans 0.003979, loss flux 13.004663, loss flux t1 12.841504\n",
      "Epoch 5/10, Batch 1411/1650, Loss 44.896309, Loss rec 9.701088, loss rec t1 10.026659, loss kl 0.146856, loss_trans 0.007478, loss flux 12.553161, loss flux t1 12.461067\n",
      "Epoch 5/10, Batch 1421/1650, Loss 40.291332, Loss rec 7.096836, loss rec t1 8.082307, loss kl 0.127938, loss_trans 0.005493, loss flux 12.594293, loss flux t1 12.384466\n",
      "Epoch 5/10, Batch 1431/1650, Loss 38.061634, Loss rec 6.893289, loss rec t1 7.339808, loss kl 0.142134, loss_trans 0.005332, loss flux 11.792047, loss flux t1 11.889023\n",
      "Epoch 5/10, Batch 1441/1650, Loss 44.174541, Loss rec 6.934052, loss rec t1 7.640527, loss kl 0.203096, loss_trans 0.010066, loss flux 15.409163, loss flux t1 13.977638\n",
      "Epoch 5/10, Batch 1451/1650, Loss 41.479050, Loss rec 7.911699, loss rec t1 9.254005, loss kl 0.138942, loss_trans 0.008499, loss flux 12.480615, loss flux t1 11.685288\n",
      "Epoch 5/10, Batch 1461/1650, Loss 37.308060, Loss rec 5.913054, loss rec t1 6.982678, loss kl 0.121179, loss_trans 0.003709, loss flux 12.576773, loss flux t1 11.710665\n",
      "Epoch 5/10, Batch 1471/1650, Loss 41.768391, Loss rec 7.736305, loss rec t1 8.818945, loss kl 0.156437, loss_trans 0.005566, loss flux 12.338006, loss flux t1 12.713130\n",
      "Epoch 5/10, Batch 1481/1650, Loss 41.797550, Loss rec 7.353597, loss rec t1 8.344113, loss kl 0.131461, loss_trans 0.004529, loss flux 13.349086, loss flux t1 12.614766\n",
      "Epoch 5/10, Batch 1491/1650, Loss 43.910454, Loss rec 8.794600, loss rec t1 9.125847, loss kl 0.199573, loss_trans 0.008922, loss flux 12.887816, loss flux t1 12.893697\n",
      "Epoch 5/10, Batch 1501/1650, Loss 46.553543, Loss rec 9.030455, loss rec t1 9.916887, loss kl 0.202581, loss_trans 0.010004, loss flux 13.631447, loss flux t1 13.762167\n",
      "Epoch 5/10, Batch 1511/1650, Loss 54.211662, Loss rec 12.353495, loss rec t1 14.886782, loss kl 0.103816, loss_trans 0.006696, loss flux 13.440973, loss flux t1 13.419903\n",
      "Epoch 5/10, Batch 1521/1650, Loss 46.953857, Loss rec 8.529119, loss rec t1 10.362165, loss kl 0.136650, loss_trans 0.003782, loss flux 14.368767, loss flux t1 13.553376\n",
      "Epoch 5/10, Batch 1531/1650, Loss 52.284637, Loss rec 11.181431, loss rec t1 11.641244, loss kl 0.133417, loss_trans 0.007169, loss flux 14.245872, loss flux t1 15.075505\n",
      "Epoch 5/10, Batch 1541/1650, Loss 47.201820, Loss rec 7.302428, loss rec t1 9.103537, loss kl 0.160968, loss_trans 0.006018, loss flux 16.089323, loss flux t1 14.539543\n",
      "Epoch 5/10, Batch 1551/1650, Loss 43.075302, Loss rec 7.296690, loss rec t1 8.207397, loss kl 0.091328, loss_trans 0.004334, loss flux 13.744018, loss flux t1 13.731539\n",
      "Epoch 5/10, Batch 1561/1650, Loss 52.359409, Loss rec 9.894287, loss rec t1 10.186950, loss kl 0.198053, loss_trans 0.008962, loss flux 16.648712, loss flux t1 15.422445\n",
      "Epoch 5/10, Batch 1571/1650, Loss 42.292068, Loss rec 5.855078, loss rec t1 7.042026, loss kl 0.191995, loss_trans 0.007614, loss flux 14.716340, loss flux t1 14.479014\n",
      "Epoch 5/10, Batch 1581/1650, Loss 34.758568, Loss rec 5.680767, loss rec t1 6.296354, loss kl 0.097454, loss_trans 0.002304, loss flux 11.895123, loss flux t1 10.786566\n",
      "Epoch 5/10, Batch 1591/1650, Loss 39.937580, Loss rec 6.506464, loss rec t1 7.080603, loss kl 0.159682, loss_trans 0.008006, loss flux 13.619037, loss flux t1 12.563785\n",
      "Epoch 5/10, Batch 1601/1650, Loss 36.442635, Loss rec 6.908889, loss rec t1 7.812512, loss kl 0.067703, loss_trans 0.005014, loss flux 10.962790, loss flux t1 10.685729\n",
      "Epoch 5/10, Batch 1611/1650, Loss 33.881149, Loss rec 4.676805, loss rec t1 5.619395, loss kl 0.092447, loss_trans 0.003235, loss flux 12.388377, loss flux t1 11.100889\n",
      "Epoch 5/10, Batch 1621/1650, Loss 39.604969, Loss rec 5.998292, loss rec t1 6.881873, loss kl 0.153169, loss_trans 0.004962, loss flux 14.280983, loss flux t1 12.285688\n",
      "Epoch 5/10, Batch 1631/1650, Loss 55.627628, Loss rec 12.393812, loss rec t1 14.544394, loss kl 0.092254, loss_trans 0.007990, loss flux 15.168122, loss flux t1 13.421060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Batch 1641/1650, Loss 46.180614, Loss rec 8.310261, loss rec t1 8.761320, loss kl 0.170811, loss_trans 0.004890, loss flux 15.209816, loss flux t1 13.723515\n",
      "Epoch 5/10, Train loss 42.030247, Eval loss 50.765331\n",
      "Epoch 6/10, Batch 1/1650, Loss 44.260361, Loss rec 5.321827, loss rec t1 7.198874, loss kl 0.162477, loss_trans 0.003967, loss flux 16.552916, loss flux t1 15.020300\n",
      "Epoch 6/10, Batch 11/1650, Loss 45.105980, Loss rec 6.646914, loss rec t1 8.751802, loss kl 0.166253, loss_trans 0.003821, loss flux 14.747341, loss flux t1 14.789845\n",
      "Epoch 6/10, Batch 21/1650, Loss 41.633621, Loss rec 8.692930, loss rec t1 9.271221, loss kl 0.114313, loss_trans 0.008929, loss flux 11.941171, loss flux t1 11.605056\n",
      "Epoch 6/10, Batch 31/1650, Loss 41.857506, Loss rec 7.344545, loss rec t1 8.620731, loss kl 0.096840, loss_trans 0.003557, loss flux 13.000707, loss flux t1 12.791127\n",
      "Epoch 6/10, Batch 41/1650, Loss 43.779556, Loss rec 7.739183, loss rec t1 8.922212, loss kl 0.111590, loss_trans 0.004234, loss flux 14.199608, loss flux t1 12.802731\n",
      "Epoch 6/10, Batch 51/1650, Loss 41.105064, Loss rec 6.133829, loss rec t1 7.614451, loss kl 0.093716, loss_trans 0.003048, loss flux 13.429919, loss flux t1 13.830101\n",
      "Epoch 6/10, Batch 61/1650, Loss 53.028507, Loss rec 10.466862, loss rec t1 12.098055, loss kl 0.172918, loss_trans 0.011837, loss flux 15.427640, loss flux t1 14.851195\n",
      "Epoch 6/10, Batch 71/1650, Loss 55.718418, Loss rec 9.849997, loss rec t1 10.701048, loss kl 0.164436, loss_trans 0.007094, loss flux 18.082396, loss flux t1 16.913448\n",
      "Epoch 6/10, Batch 81/1650, Loss 43.192505, Loss rec 8.284161, loss rec t1 8.066612, loss kl 0.098091, loss_trans 0.006193, loss flux 13.837041, loss flux t1 12.900407\n",
      "Epoch 6/10, Batch 91/1650, Loss 46.738110, Loss rec 9.155527, loss rec t1 10.529858, loss kl 0.127840, loss_trans 0.006978, loss flux 13.385507, loss flux t1 13.532401\n",
      "Epoch 6/10, Batch 101/1650, Loss 45.603619, Loss rec 8.334148, loss rec t1 10.103065, loss kl 0.098768, loss_trans 0.004264, loss flux 13.859185, loss flux t1 13.204185\n",
      "Epoch 6/10, Batch 111/1650, Loss 47.491592, Loss rec 8.886944, loss rec t1 10.923430, loss kl 0.185962, loss_trans 0.007411, loss flux 14.283686, loss flux t1 13.204159\n",
      "Epoch 6/10, Batch 121/1650, Loss 45.914066, Loss rec 8.854652, loss rec t1 10.171845, loss kl 0.168801, loss_trans 0.007045, loss flux 13.270466, loss flux t1 13.441258\n",
      "Epoch 6/10, Batch 131/1650, Loss 39.377785, Loss rec 7.055577, loss rec t1 7.758815, loss kl 0.077446, loss_trans 0.001884, loss flux 12.335923, loss flux t1 12.148141\n",
      "Epoch 6/10, Batch 141/1650, Loss 34.352837, Loss rec 5.957799, loss rec t1 7.478813, loss kl 0.096818, loss_trans 0.004154, loss flux 10.816195, loss flux t1 9.999057\n",
      "Epoch 6/10, Batch 151/1650, Loss 48.643559, Loss rec 9.937971, loss rec t1 10.375729, loss kl 0.192187, loss_trans 0.008521, loss flux 13.797008, loss flux t1 14.332142\n",
      "Epoch 6/10, Batch 161/1650, Loss 48.819237, Loss rec 9.799088, loss rec t1 11.497287, loss kl 0.199701, loss_trans 0.006812, loss flux 13.900591, loss flux t1 13.415757\n",
      "Epoch 6/10, Batch 171/1650, Loss 51.743549, Loss rec 9.799389, loss rec t1 11.400145, loss kl 0.199912, loss_trans 0.007375, loss flux 15.242813, loss flux t1 15.093916\n",
      "Epoch 6/10, Batch 181/1650, Loss 33.734222, Loss rec 5.759311, loss rec t1 6.988242, loss kl 0.092306, loss_trans 0.003410, loss flux 10.815418, loss flux t1 10.075533\n",
      "Epoch 6/10, Batch 191/1650, Loss 44.401016, Loss rec 7.860621, loss rec t1 9.382580, loss kl 0.174570, loss_trans 0.009745, loss flux 13.326451, loss flux t1 13.647044\n",
      "Epoch 6/10, Batch 201/1650, Loss 40.729961, Loss rec 8.055986, loss rec t1 8.551762, loss kl 0.106197, loss_trans 0.003784, loss flux 11.991432, loss flux t1 12.020801\n",
      "Epoch 6/10, Batch 211/1650, Loss 46.274940, Loss rec 10.428046, loss rec t1 11.650923, loss kl 0.070557, loss_trans 0.002320, loss flux 12.122095, loss flux t1 12.000999\n",
      "Epoch 6/10, Batch 221/1650, Loss 54.042629, Loss rec 10.744154, loss rec t1 14.057970, loss kl 0.129961, loss_trans 0.002448, loss flux 14.790370, loss flux t1 14.317725\n",
      "Epoch 6/10, Batch 231/1650, Loss 55.833389, Loss rec 10.390341, loss rec t1 11.772373, loss kl 0.166085, loss_trans 0.005081, loss flux 17.685698, loss flux t1 15.813810\n",
      "Epoch 6/10, Batch 241/1650, Loss 59.702065, Loss rec 10.673899, loss rec t1 10.720763, loss kl 0.108027, loss_trans 0.005326, loss flux 19.897896, loss flux t1 18.296160\n",
      "Epoch 6/10, Batch 251/1650, Loss 52.603165, Loss rec 10.747393, loss rec t1 11.886092, loss kl 0.142057, loss_trans 0.011902, loss flux 15.446540, loss flux t1 14.369184\n",
      "Epoch 6/10, Batch 261/1650, Loss 38.380550, Loss rec 6.780759, loss rec t1 7.605656, loss kl 0.098269, loss_trans 0.002941, loss flux 11.963816, loss flux t1 11.929111\n",
      "Epoch 6/10, Batch 271/1650, Loss 48.044144, Loss rec 8.673595, loss rec t1 10.567858, loss kl 0.151789, loss_trans 0.005404, loss flux 14.663980, loss flux t1 13.981519\n",
      "Epoch 6/10, Batch 281/1650, Loss 46.566765, Loss rec 9.591120, loss rec t1 10.904709, loss kl 0.128632, loss_trans 0.005868, loss flux 13.660501, loss flux t1 12.275938\n",
      "Epoch 6/10, Batch 291/1650, Loss 54.149094, Loss rec 8.068150, loss rec t1 10.040672, loss kl 0.157603, loss_trans 0.005636, loss flux 18.096090, loss flux t1 17.780945\n",
      "Epoch 6/10, Batch 301/1650, Loss 40.364716, Loss rec 7.431427, loss rec t1 9.019695, loss kl 0.094892, loss_trans 0.003546, loss flux 12.206471, loss flux t1 11.608681\n",
      "Epoch 6/10, Batch 311/1650, Loss 38.324730, Loss rec 5.646639, loss rec t1 6.673217, loss kl 0.106007, loss_trans 0.002724, loss flux 13.157249, loss flux t1 12.738894\n",
      "Epoch 6/10, Batch 321/1650, Loss 49.467186, Loss rec 8.500684, loss rec t1 9.437716, loss kl 0.138961, loss_trans 0.005479, loss flux 15.657139, loss flux t1 15.727206\n",
      "Epoch 6/10, Batch 331/1650, Loss 45.486633, Loss rec 8.975745, loss rec t1 11.151781, loss kl 0.087113, loss_trans 0.003961, loss flux 12.432209, loss flux t1 12.835826\n",
      "Epoch 6/10, Batch 341/1650, Loss 51.627804, Loss rec 10.854597, loss rec t1 11.917538, loss kl 0.136966, loss_trans 0.005348, loss flux 14.571272, loss flux t1 14.142087\n",
      "Epoch 6/10, Batch 351/1650, Loss 52.073944, Loss rec 8.601741, loss rec t1 10.167148, loss kl 0.188577, loss_trans 0.006462, loss flux 16.146156, loss flux t1 16.963861\n",
      "Epoch 6/10, Batch 361/1650, Loss 40.944363, Loss rec 6.890389, loss rec t1 7.868256, loss kl 0.115491, loss_trans 0.005775, loss flux 13.246490, loss flux t1 12.817963\n",
      "Epoch 6/10, Batch 371/1650, Loss 50.981621, Loss rec 10.719850, loss rec t1 10.252032, loss kl 0.179757, loss_trans 0.013283, loss flux 15.741687, loss flux t1 14.075013\n",
      "Epoch 6/10, Batch 381/1650, Loss 46.247753, Loss rec 6.630255, loss rec t1 8.050288, loss kl 0.132701, loss_trans 0.004223, loss flux 16.913887, loss flux t1 14.516401\n",
      "Epoch 6/10, Batch 391/1650, Loss 42.446835, Loss rec 7.443050, loss rec t1 8.387419, loss kl 0.133793, loss_trans 0.003908, loss flux 13.406894, loss flux t1 13.071774\n",
      "Epoch 6/10, Batch 401/1650, Loss 37.117710, Loss rec 6.760093, loss rec t1 7.706816, loss kl 0.087019, loss_trans 0.005100, loss flux 11.276961, loss flux t1 11.281721\n",
      "Epoch 6/10, Batch 411/1650, Loss 46.740704, Loss rec 9.228690, loss rec t1 9.635298, loss kl 0.198756, loss_trans 0.012477, loss flux 14.933052, loss flux t1 12.732430\n",
      "Epoch 6/10, Batch 421/1650, Loss 46.082535, Loss rec 9.440590, loss rec t1 10.103209, loss kl 0.175375, loss_trans 0.011576, loss flux 13.727377, loss flux t1 12.624407\n",
      "Epoch 6/10, Batch 431/1650, Loss 33.617775, Loss rec 4.572353, loss rec t1 5.389286, loss kl 0.143930, loss_trans 0.002441, loss flux 12.417302, loss flux t1 11.092461\n",
      "Epoch 6/10, Batch 441/1650, Loss 50.935589, Loss rec 10.174414, loss rec t1 11.359725, loss kl 0.149392, loss_trans 0.004847, loss flux 15.191834, loss flux t1 14.055378\n",
      "Epoch 6/10, Batch 451/1650, Loss 39.822975, Loss rec 6.942699, loss rec t1 7.453030, loss kl 0.107881, loss_trans 0.006846, loss flux 13.269932, loss flux t1 12.042588\n",
      "Epoch 6/10, Batch 461/1650, Loss 47.297817, Loss rec 9.718859, loss rec t1 10.242243, loss kl 0.108679, loss_trans 0.005241, loss flux 13.838627, loss flux t1 13.384166\n",
      "Epoch 6/10, Batch 471/1650, Loss 37.017490, Loss rec 5.259529, loss rec t1 6.241080, loss kl 0.113188, loss_trans 0.002877, loss flux 13.148519, loss flux t1 12.252297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Batch 481/1650, Loss 36.089367, Loss rec 6.001860, loss rec t1 7.054422, loss kl 0.109942, loss_trans 0.002687, loss flux 11.794328, loss flux t1 11.126128\n",
      "Epoch 6/10, Batch 491/1650, Loss 39.229076, Loss rec 6.388805, loss rec t1 7.860435, loss kl 0.086424, loss_trans 0.002886, loss flux 12.617625, loss flux t1 12.272902\n",
      "Epoch 6/10, Batch 501/1650, Loss 49.320320, Loss rec 10.301505, loss rec t1 10.834621, loss kl 0.135399, loss_trans 0.003993, loss flux 13.972861, loss flux t1 14.071938\n",
      "Epoch 6/10, Batch 511/1650, Loss 52.518856, Loss rec 12.067612, loss rec t1 13.882830, loss kl 0.124028, loss_trans 0.005015, loss flux 14.068997, loss flux t1 12.370373\n",
      "Epoch 6/10, Batch 521/1650, Loss 46.626934, Loss rec 8.340902, loss rec t1 9.997477, loss kl 0.174324, loss_trans 0.008370, loss flux 14.658254, loss flux t1 13.447609\n",
      "Epoch 6/10, Batch 531/1650, Loss 44.132450, Loss rec 7.665610, loss rec t1 10.323768, loss kl 0.090143, loss_trans 0.004537, loss flux 13.287192, loss flux t1 12.761201\n",
      "Epoch 6/10, Batch 541/1650, Loss 42.688812, Loss rec 6.002164, loss rec t1 9.134211, loss kl 0.113815, loss_trans 0.004009, loss flux 13.751737, loss flux t1 13.682878\n",
      "Epoch 6/10, Batch 551/1650, Loss 58.811817, Loss rec 9.802948, loss rec t1 13.887961, loss kl 0.154860, loss_trans 0.008723, loss flux 17.884016, loss flux t1 17.073307\n",
      "Epoch 6/10, Batch 561/1650, Loss 51.952179, Loss rec 9.616843, loss rec t1 10.478050, loss kl 0.096892, loss_trans 0.003912, loss flux 15.888923, loss flux t1 15.867556\n",
      "Epoch 6/10, Batch 571/1650, Loss 54.482677, Loss rec 12.790855, loss rec t1 13.937197, loss kl 0.136523, loss_trans 0.003931, loss flux 14.211020, loss flux t1 13.403156\n",
      "Epoch 6/10, Batch 581/1650, Loss 50.349781, Loss rec 10.139225, loss rec t1 11.695091, loss kl 0.109487, loss_trans 0.005291, loss flux 14.546273, loss flux t1 13.854411\n",
      "Epoch 6/10, Batch 591/1650, Loss 79.952133, Loss rec 21.385429, loss rec t1 24.903246, loss kl 0.095155, loss_trans 0.002473, loss flux 17.360147, loss flux t1 16.205690\n",
      "Epoch 6/10, Batch 601/1650, Loss 68.421944, Loss rec 19.254175, loss rec t1 16.050331, loss kl 0.132564, loss_trans 0.012242, loss flux 17.412550, loss flux t1 15.560081\n",
      "Epoch 6/10, Batch 611/1650, Loss 57.665401, Loss rec 13.263230, loss rec t1 14.467161, loss kl 0.120539, loss_trans 0.006887, loss flux 14.980245, loss flux t1 14.827337\n",
      "Epoch 6/10, Batch 621/1650, Loss 55.583313, Loss rec 10.596206, loss rec t1 10.816159, loss kl 0.139937, loss_trans 0.006331, loss flux 18.733486, loss flux t1 15.291190\n",
      "Epoch 6/10, Batch 631/1650, Loss 60.290771, Loss rec 11.740375, loss rec t1 15.203427, loss kl 0.157252, loss_trans 0.009070, loss flux 17.400816, loss flux t1 15.779829\n",
      "Epoch 6/10, Batch 641/1650, Loss 56.188690, Loss rec 13.693196, loss rec t1 13.717171, loss kl 0.128001, loss_trans 0.007918, loss flux 14.766649, loss flux t1 13.875755\n",
      "Epoch 6/10, Batch 651/1650, Loss 58.072895, Loss rec 13.835375, loss rec t1 15.564106, loss kl 0.136070, loss_trans 0.008533, loss flux 14.658275, loss flux t1 13.870538\n",
      "Epoch 6/10, Batch 661/1650, Loss 58.178955, Loss rec 13.232456, loss rec t1 15.055887, loss kl 0.177620, loss_trans 0.009946, loss flux 15.322758, loss flux t1 14.380290\n",
      "Epoch 6/10, Batch 671/1650, Loss 56.254326, Loss rec 10.886917, loss rec t1 12.729694, loss kl 0.112193, loss_trans 0.007894, loss flux 16.717382, loss flux t1 15.800248\n",
      "Epoch 6/10, Batch 681/1650, Loss 40.815895, Loss rec 4.452459, loss rec t1 6.106356, loss kl 0.127580, loss_trans 0.003906, loss flux 15.316102, loss flux t1 14.809492\n",
      "Epoch 6/10, Batch 691/1650, Loss 53.726871, Loss rec 11.271132, loss rec t1 10.732569, loss kl 0.193574, loss_trans 0.009668, loss flux 16.570976, loss flux t1 14.948956\n",
      "Epoch 6/10, Batch 701/1650, Loss 52.836521, Loss rec 11.942159, loss rec t1 12.987457, loss kl 0.186243, loss_trans 0.013501, loss flux 13.798950, loss flux t1 13.908212\n",
      "Epoch 6/10, Batch 711/1650, Loss 54.870510, Loss rec 10.936201, loss rec t1 11.318618, loss kl 0.245701, loss_trans 0.008892, loss flux 16.406548, loss flux t1 15.954551\n",
      "Epoch 6/10, Batch 721/1650, Loss 48.756523, Loss rec 7.720968, loss rec t1 8.649315, loss kl 0.188344, loss_trans 0.004782, loss flux 17.475443, loss flux t1 14.717668\n",
      "Epoch 6/10, Batch 731/1650, Loss 44.451832, Loss rec 8.217424, loss rec t1 8.979027, loss kl 0.121714, loss_trans 0.006569, loss flux 13.364168, loss flux t1 13.762930\n",
      "Epoch 6/10, Batch 741/1650, Loss 42.253471, Loss rec 8.309237, loss rec t1 8.923366, loss kl 0.120903, loss_trans 0.007795, loss flux 12.512935, loss flux t1 12.379237\n",
      "Epoch 6/10, Batch 751/1650, Loss 44.711666, Loss rec 7.422580, loss rec t1 8.630383, loss kl 0.156993, loss_trans 0.006138, loss flux 14.930922, loss flux t1 13.564650\n",
      "Epoch 6/10, Batch 761/1650, Loss 47.093765, Loss rec 8.002229, loss rec t1 9.722765, loss kl 0.172873, loss_trans 0.014833, loss flux 14.996371, loss flux t1 14.184696\n",
      "Epoch 6/10, Batch 771/1650, Loss 38.175018, Loss rec 5.166296, loss rec t1 7.033388, loss kl 0.115094, loss_trans 0.004120, loss flux 13.757895, loss flux t1 12.098227\n",
      "Epoch 6/10, Batch 781/1650, Loss 41.227264, Loss rec 7.776621, loss rec t1 9.310114, loss kl 0.105402, loss_trans 0.003038, loss flux 11.887119, loss flux t1 12.144973\n",
      "Epoch 6/10, Batch 791/1650, Loss 42.270927, Loss rec 6.765711, loss rec t1 8.121264, loss kl 0.110962, loss_trans 0.007908, loss flux 13.988447, loss flux t1 13.276633\n",
      "Epoch 6/10, Batch 801/1650, Loss 39.226357, Loss rec 6.873781, loss rec t1 7.447956, loss kl 0.154680, loss_trans 0.006144, loss flux 12.211381, loss flux t1 12.532413\n",
      "Epoch 6/10, Batch 811/1650, Loss 43.312241, Loss rec 7.100681, loss rec t1 9.094008, loss kl 0.180142, loss_trans 0.006026, loss flux 14.198041, loss flux t1 12.733340\n",
      "Epoch 6/10, Batch 821/1650, Loss 35.669365, Loss rec 5.982072, loss rec t1 6.887359, loss kl 0.122789, loss_trans 0.006757, loss flux 11.270851, loss flux t1 11.399540\n",
      "Epoch 6/10, Batch 831/1650, Loss 36.990414, Loss rec 5.895181, loss rec t1 7.210357, loss kl 0.198528, loss_trans 0.007374, loss flux 12.495331, loss flux t1 11.183645\n",
      "Epoch 6/10, Batch 841/1650, Loss 31.993101, Loss rec 5.297871, loss rec t1 6.599872, loss kl 0.082618, loss_trans 0.003373, loss flux 10.040757, loss flux t1 9.968611\n",
      "Epoch 6/10, Batch 851/1650, Loss 47.620495, Loss rec 8.164154, loss rec t1 9.915026, loss kl 0.132946, loss_trans 0.007139, loss flux 14.783809, loss flux t1 14.617422\n",
      "Epoch 6/10, Batch 861/1650, Loss 42.337814, Loss rec 6.793095, loss rec t1 7.724644, loss kl 0.174542, loss_trans 0.008513, loss flux 14.271511, loss flux t1 13.365509\n",
      "Epoch 6/10, Batch 871/1650, Loss 44.616520, Loss rec 8.036448, loss rec t1 8.124639, loss kl 0.143602, loss_trans 0.005532, loss flux 14.462862, loss flux t1 13.843438\n",
      "Epoch 6/10, Batch 881/1650, Loss 40.801014, Loss rec 6.222113, loss rec t1 8.711531, loss kl 0.127096, loss_trans 0.006627, loss flux 12.914090, loss flux t1 12.819556\n",
      "Epoch 6/10, Batch 891/1650, Loss 39.586956, Loss rec 6.065876, loss rec t1 7.054971, loss kl 0.123996, loss_trans 0.005056, loss flux 13.456705, loss flux t1 12.880353\n",
      "Epoch 6/10, Batch 901/1650, Loss 40.688251, Loss rec 7.081716, loss rec t1 8.128952, loss kl 0.167407, loss_trans 0.005740, loss flux 12.687569, loss flux t1 12.616865\n",
      "Epoch 6/10, Batch 911/1650, Loss 31.648729, Loss rec 4.238096, loss rec t1 5.565765, loss kl 0.114391, loss_trans 0.003184, loss flux 11.063210, loss flux t1 10.664083\n",
      "Epoch 6/10, Batch 921/1650, Loss 38.160515, Loss rec 5.837841, loss rec t1 7.177461, loss kl 0.123968, loss_trans 0.005722, loss flux 12.458083, loss flux t1 12.557442\n",
      "Epoch 6/10, Batch 931/1650, Loss 36.588745, Loss rec 6.152460, loss rec t1 6.654170, loss kl 0.125205, loss_trans 0.004995, loss flux 11.922831, loss flux t1 11.729088\n",
      "Epoch 6/10, Batch 941/1650, Loss 41.046425, Loss rec 5.565999, loss rec t1 6.352835, loss kl 0.165682, loss_trans 0.005778, loss flux 15.233573, loss flux t1 13.722557\n",
      "Epoch 6/10, Batch 951/1650, Loss 36.375740, Loss rec 5.469704, loss rec t1 6.551409, loss kl 0.109199, loss_trans 0.003534, loss flux 12.115329, loss flux t1 12.126563\n",
      "Epoch 6/10, Batch 961/1650, Loss 32.855389, Loss rec 6.088214, loss rec t1 6.926959, loss kl 0.076623, loss_trans 0.002322, loss flux 10.369357, loss flux t1 9.391912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Batch 971/1650, Loss 43.631302, Loss rec 9.769360, loss rec t1 9.709563, loss kl 0.097613, loss_trans 0.006202, loss flux 12.559489, loss flux t1 11.489074\n",
      "Epoch 6/10, Batch 981/1650, Loss 38.778561, Loss rec 7.830543, loss rec t1 8.222445, loss kl 0.100119, loss_trans 0.004323, loss flux 11.673426, loss flux t1 10.947707\n",
      "Epoch 6/10, Batch 991/1650, Loss 42.338428, Loss rec 7.306812, loss rec t1 8.706506, loss kl 0.097904, loss_trans 0.002880, loss flux 13.055114, loss flux t1 13.169213\n",
      "Epoch 6/10, Batch 1001/1650, Loss 54.596409, Loss rec 11.695963, loss rec t1 11.686237, loss kl 0.154795, loss_trans 0.007513, loss flux 16.157598, loss flux t1 14.894303\n",
      "Epoch 6/10, Batch 1011/1650, Loss 41.686237, Loss rec 7.135437, loss rec t1 7.963954, loss kl 0.103551, loss_trans 0.004849, loss flux 13.896221, loss flux t1 12.582224\n",
      "Epoch 6/10, Batch 1021/1650, Loss 50.980091, Loss rec 8.285500, loss rec t1 10.277540, loss kl 0.109140, loss_trans 0.002974, loss flux 15.488803, loss flux t1 16.816133\n",
      "Epoch 6/10, Batch 1031/1650, Loss 42.565170, Loss rec 8.432304, loss rec t1 8.656712, loss kl 0.172814, loss_trans 0.006867, loss flux 12.915543, loss flux t1 12.380933\n",
      "Epoch 6/10, Batch 1041/1650, Loss 41.342613, Loss rec 9.771076, loss rec t1 10.203581, loss kl 0.115389, loss_trans 0.004811, loss flux 10.849632, loss flux t1 10.398124\n",
      "Epoch 6/10, Batch 1051/1650, Loss 37.119259, Loss rec 7.077857, loss rec t1 7.148916, loss kl 0.099755, loss_trans 0.003779, loss flux 11.724178, loss flux t1 11.064773\n",
      "Epoch 6/10, Batch 1061/1650, Loss 50.617470, Loss rec 9.728073, loss rec t1 10.738650, loss kl 0.150606, loss_trans 0.007937, loss flux 15.232539, loss flux t1 14.759662\n",
      "Epoch 6/10, Batch 1071/1650, Loss 42.755444, Loss rec 6.243859, loss rec t1 7.530398, loss kl 0.169350, loss_trans 0.006089, loss flux 14.342308, loss flux t1 14.463440\n",
      "Epoch 6/10, Batch 1081/1650, Loss 49.179882, Loss rec 12.573200, loss rec t1 13.205496, loss kl 0.134930, loss_trans 0.006054, loss flux 11.463643, loss flux t1 11.796556\n",
      "Epoch 6/10, Batch 1091/1650, Loss 41.989532, Loss rec 7.631087, loss rec t1 8.837656, loss kl 0.087354, loss_trans 0.002638, loss flux 13.026280, loss flux t1 12.404512\n",
      "Epoch 6/10, Batch 1101/1650, Loss 37.017853, Loss rec 6.062486, loss rec t1 7.478466, loss kl 0.115474, loss_trans 0.004605, loss flux 12.535379, loss flux t1 10.821445\n",
      "Epoch 6/10, Batch 1111/1650, Loss 37.601173, Loss rec 6.415045, loss rec t1 7.462848, loss kl 0.109729, loss_trans 0.006136, loss flux 12.892384, loss flux t1 10.715034\n",
      "Epoch 6/10, Batch 1121/1650, Loss 51.099480, Loss rec 10.347673, loss rec t1 10.940948, loss kl 0.153767, loss_trans 0.004897, loss flux 15.318571, loss flux t1 14.333622\n",
      "Epoch 6/10, Batch 1131/1650, Loss 46.951694, Loss rec 9.928035, loss rec t1 10.132349, loss kl 0.216986, loss_trans 0.013836, loss flux 13.147792, loss flux t1 13.512700\n",
      "Epoch 6/10, Batch 1141/1650, Loss 40.434872, Loss rec 7.556709, loss rec t1 8.140704, loss kl 0.140548, loss_trans 0.006479, loss flux 12.536150, loss flux t1 12.054281\n",
      "Epoch 6/10, Batch 1151/1650, Loss 43.579605, Loss rec 7.260664, loss rec t1 7.802937, loss kl 0.174035, loss_trans 0.005803, loss flux 14.790283, loss flux t1 13.545882\n",
      "Epoch 6/10, Batch 1161/1650, Loss 44.286686, Loss rec 8.131557, loss rec t1 9.328846, loss kl 0.128093, loss_trans 0.008178, loss flux 13.389154, loss flux t1 13.300857\n",
      "Epoch 6/10, Batch 1171/1650, Loss 41.081577, Loss rec 6.600976, loss rec t1 7.779835, loss kl 0.107191, loss_trans 0.003059, loss flux 14.279538, loss flux t1 12.310978\n",
      "Epoch 6/10, Batch 1181/1650, Loss 44.572445, Loss rec 7.799173, loss rec t1 8.906607, loss kl 0.198980, loss_trans 0.006614, loss flux 14.003915, loss flux t1 13.657154\n",
      "Epoch 6/10, Batch 1191/1650, Loss 45.907253, Loss rec 8.826487, loss rec t1 9.747545, loss kl 0.155076, loss_trans 0.008595, loss flux 13.610026, loss flux t1 13.559525\n",
      "Epoch 6/10, Batch 1201/1650, Loss 40.969704, Loss rec 6.355098, loss rec t1 8.190333, loss kl 0.124158, loss_trans 0.005494, loss flux 14.416020, loss flux t1 11.878601\n",
      "Epoch 6/10, Batch 1211/1650, Loss 45.863693, Loss rec 8.283165, loss rec t1 8.881361, loss kl 0.153890, loss_trans 0.005456, loss flux 14.626672, loss flux t1 13.913150\n",
      "Epoch 6/10, Batch 1221/1650, Loss 40.724586, Loss rec 5.784377, loss rec t1 7.241596, loss kl 0.135370, loss_trans 0.002782, loss flux 13.742565, loss flux t1 13.817899\n",
      "Epoch 6/10, Batch 1231/1650, Loss 39.367867, Loss rec 6.538639, loss rec t1 7.631676, loss kl 0.119021, loss_trans 0.003867, loss flux 12.625995, loss flux t1 12.448668\n",
      "Epoch 6/10, Batch 1241/1650, Loss 38.122231, Loss rec 5.290618, loss rec t1 6.406526, loss kl 0.130759, loss_trans 0.004152, loss flux 13.551653, loss flux t1 12.738527\n",
      "Epoch 6/10, Batch 1251/1650, Loss 56.138935, Loss rec 14.772080, loss rec t1 16.303829, loss kl 0.102644, loss_trans 0.003993, loss flux 12.249599, loss flux t1 12.706793\n",
      "Epoch 6/10, Batch 1261/1650, Loss 41.775211, Loss rec 9.085318, loss rec t1 8.878905, loss kl 0.102968, loss_trans 0.005917, loss flux 12.260885, loss flux t1 11.441217\n",
      "Epoch 6/10, Batch 1271/1650, Loss 42.396606, Loss rec 9.069613, loss rec t1 9.733236, loss kl 0.118009, loss_trans 0.009017, loss flux 12.114620, loss flux t1 11.352114\n",
      "Epoch 6/10, Batch 1281/1650, Loss 35.197403, Loss rec 5.076771, loss rec t1 5.859948, loss kl 0.131029, loss_trans 0.004028, loss flux 12.407040, loss flux t1 11.718587\n",
      "Epoch 6/10, Batch 1291/1650, Loss 32.933624, Loss rec 4.409824, loss rec t1 5.810268, loss kl 0.091311, loss_trans 0.004209, loss flux 11.346268, loss flux t1 11.271746\n",
      "Epoch 6/10, Batch 1301/1650, Loss 39.072403, Loss rec 7.841770, loss rec t1 7.955733, loss kl 0.113786, loss_trans 0.004822, loss flux 12.007276, loss flux t1 11.149015\n",
      "Epoch 6/10, Batch 1311/1650, Loss 44.799084, Loss rec 8.359509, loss rec t1 9.504458, loss kl 0.112896, loss_trans 0.006194, loss flux 14.097822, loss flux t1 12.718204\n",
      "Epoch 6/10, Batch 1321/1650, Loss 43.808556, Loss rec 8.032572, loss rec t1 8.784810, loss kl 0.165164, loss_trans 0.008600, loss flux 14.371162, loss flux t1 12.446249\n",
      "Epoch 6/10, Batch 1331/1650, Loss 44.486771, Loss rec 8.488973, loss rec t1 9.997330, loss kl 0.105222, loss_trans 0.007852, loss flux 12.731797, loss flux t1 13.155598\n",
      "Epoch 6/10, Batch 1341/1650, Loss 33.639061, Loss rec 4.533279, loss rec t1 5.774377, loss kl 0.138078, loss_trans 0.005493, loss flux 12.073597, loss flux t1 11.114235\n",
      "Epoch 6/10, Batch 1351/1650, Loss 34.034454, Loss rec 5.205781, loss rec t1 6.000179, loss kl 0.077253, loss_trans 0.002310, loss flux 11.083913, loss flux t1 11.665018\n",
      "Epoch 6/10, Batch 1361/1650, Loss 41.176659, Loss rec 7.527007, loss rec t1 8.909227, loss kl 0.186270, loss_trans 0.008842, loss flux 12.901127, loss flux t1 11.644185\n",
      "Epoch 6/10, Batch 1371/1650, Loss 34.787632, Loss rec 4.263146, loss rec t1 5.636021, loss kl 0.124573, loss_trans 0.005300, loss flux 12.798606, loss flux t1 11.959986\n",
      "Epoch 6/10, Batch 1381/1650, Loss 39.584995, Loss rec 7.931793, loss rec t1 8.756838, loss kl 0.143167, loss_trans 0.003710, loss flux 11.413531, loss flux t1 11.335956\n",
      "Epoch 6/10, Batch 1391/1650, Loss 38.996906, Loss rec 5.838350, loss rec t1 6.868674, loss kl 0.196008, loss_trans 0.008040, loss flux 13.587678, loss flux t1 12.498153\n",
      "Epoch 6/10, Batch 1401/1650, Loss 43.614346, Loss rec 9.009793, loss rec t1 10.021525, loss kl 0.112847, loss_trans 0.003431, loss flux 12.870163, loss flux t1 11.596584\n",
      "Epoch 6/10, Batch 1411/1650, Loss 44.783188, Loss rec 8.931562, loss rec t1 9.419806, loss kl 0.130912, loss_trans 0.006760, loss flux 13.693539, loss flux t1 12.600609\n",
      "Epoch 6/10, Batch 1421/1650, Loss 39.274563, Loss rec 6.363826, loss rec t1 7.176583, loss kl 0.119204, loss_trans 0.004690, loss flux 13.013841, loss flux t1 12.596420\n",
      "Epoch 6/10, Batch 1431/1650, Loss 36.089836, Loss rec 6.072317, loss rec t1 6.361849, loss kl 0.131586, loss_trans 0.004644, loss flux 12.101591, loss flux t1 11.417850\n",
      "Epoch 6/10, Batch 1441/1650, Loss 39.789883, Loss rec 6.356983, loss rec t1 7.265942, loss kl 0.188996, loss_trans 0.007812, loss flux 13.439228, loss flux t1 12.530923\n",
      "Epoch 6/10, Batch 1451/1650, Loss 37.687565, Loss rec 7.307285, loss rec t1 8.272805, loss kl 0.127399, loss_trans 0.007617, loss flux 11.512271, loss flux t1 10.460187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Batch 1461/1650, Loss 34.073074, Loss rec 5.289658, loss rec t1 6.405458, loss kl 0.115631, loss_trans 0.003599, loss flux 11.672955, loss flux t1 10.585776\n",
      "Epoch 6/10, Batch 1471/1650, Loss 39.010136, Loss rec 7.359815, loss rec t1 8.446198, loss kl 0.146499, loss_trans 0.004528, loss flux 11.355407, loss flux t1 11.697688\n",
      "Epoch 6/10, Batch 1481/1650, Loss 37.458664, Loss rec 7.082400, loss rec t1 7.933856, loss kl 0.123079, loss_trans 0.003718, loss flux 11.434614, loss flux t1 10.880997\n",
      "Epoch 6/10, Batch 1491/1650, Loss 39.842430, Loss rec 8.127571, loss rec t1 8.091290, loss kl 0.182717, loss_trans 0.006642, loss flux 11.678332, loss flux t1 11.755877\n",
      "Epoch 6/10, Batch 1501/1650, Loss 40.718147, Loss rec 7.606030, loss rec t1 8.351613, loss kl 0.183915, loss_trans 0.008328, loss flux 12.510127, loss flux t1 12.058133\n",
      "Epoch 6/10, Batch 1511/1650, Loss 40.374519, Loss rec 8.118855, loss rec t1 9.768143, loss kl 0.093086, loss_trans 0.005568, loss flux 11.262119, loss flux t1 11.126747\n",
      "Epoch 6/10, Batch 1521/1650, Loss 41.321400, Loss rec 7.916029, loss rec t1 9.409029, loss kl 0.128429, loss_trans 0.003306, loss flux 12.023006, loss flux t1 11.841600\n",
      "Epoch 6/10, Batch 1531/1650, Loss 44.063572, Loss rec 9.005564, loss rec t1 9.797317, loss kl 0.121066, loss_trans 0.005837, loss flux 12.419796, loss flux t1 12.713996\n",
      "Epoch 6/10, Batch 1541/1650, Loss 37.243198, Loss rec 5.652977, loss rec t1 7.131965, loss kl 0.154701, loss_trans 0.005384, loss flux 12.688858, loss flux t1 11.609313\n",
      "Epoch 6/10, Batch 1551/1650, Loss 35.500828, Loss rec 5.647983, loss rec t1 6.392609, loss kl 0.088080, loss_trans 0.003626, loss flux 11.656901, loss flux t1 11.711630\n",
      "Epoch 6/10, Batch 1561/1650, Loss 41.690666, Loss rec 7.746411, loss rec t1 8.000753, loss kl 0.183646, loss_trans 0.006630, loss flux 12.954390, loss flux t1 12.798837\n",
      "Epoch 6/10, Batch 1571/1650, Loss 35.001396, Loss rec 4.873323, loss rec t1 5.974640, loss kl 0.176929, loss_trans 0.005944, loss flux 12.136398, loss flux t1 11.834160\n",
      "Epoch 6/10, Batch 1581/1650, Loss 31.038105, Loss rec 5.104344, loss rec t1 5.767109, loss kl 0.094090, loss_trans 0.002210, loss flux 10.699716, loss flux t1 9.370636\n",
      "Epoch 6/10, Batch 1591/1650, Loss 34.740433, Loss rec 5.594502, loss rec t1 6.389131, loss kl 0.145886, loss_trans 0.006032, loss flux 11.919932, loss flux t1 10.684950\n",
      "Epoch 6/10, Batch 1601/1650, Loss 32.690025, Loss rec 6.186114, loss rec t1 7.107620, loss kl 0.062981, loss_trans 0.004351, loss flux 9.772408, loss flux t1 9.556549\n",
      "Epoch 6/10, Batch 1611/1650, Loss 30.671881, Loss rec 4.483438, loss rec t1 5.407938, loss kl 0.087731, loss_trans 0.003023, loss flux 10.715941, loss flux t1 9.973808\n",
      "Epoch 6/10, Batch 1621/1650, Loss 32.368076, Loss rec 4.677121, loss rec t1 5.101453, loss kl 0.145286, loss_trans 0.004458, loss flux 11.716611, loss flux t1 10.723145\n",
      "Epoch 6/10, Batch 1631/1650, Loss 41.324070, Loss rec 8.980389, loss rec t1 10.621405, loss kl 0.085364, loss_trans 0.007131, loss flux 11.223923, loss flux t1 10.405862\n",
      "Epoch 6/10, Batch 1641/1650, Loss 40.167721, Loss rec 6.416981, loss rec t1 7.029755, loss kl 0.155283, loss_trans 0.004470, loss flux 14.030517, loss flux t1 12.530713\n",
      "Epoch 6/10, Train loss 32.726360, Eval loss 39.043182\n",
      "Epoch 7/10, Batch 1/1650, Loss 35.306957, Loss rec 4.204989, loss rec t1 5.573063, loss kl 0.162477, loss_trans 0.003539, loss flux 12.522657, loss flux t1 12.840232\n",
      "Epoch 7/10, Batch 11/1650, Loss 37.822006, Loss rec 5.733602, loss rec t1 7.604287, loss kl 0.158896, loss_trans 0.003485, loss flux 12.036130, loss flux t1 12.285608\n",
      "Epoch 7/10, Batch 21/1650, Loss 40.095108, Loss rec 8.368416, loss rec t1 8.669619, loss kl 0.105081, loss_trans 0.007827, loss flux 11.607885, loss flux t1 11.336279\n",
      "Epoch 7/10, Batch 31/1650, Loss 35.925819, Loss rec 6.154488, loss rec t1 7.439856, loss kl 0.087129, loss_trans 0.002964, loss flux 11.099109, loss flux t1 11.142274\n",
      "Epoch 7/10, Batch 41/1650, Loss 37.192142, Loss rec 6.540429, loss rec t1 7.519747, loss kl 0.103406, loss_trans 0.003795, loss flux 11.712614, loss flux t1 11.312151\n",
      "Epoch 7/10, Batch 51/1650, Loss 39.559399, Loss rec 5.853058, loss rec t1 7.088336, loss kl 0.089280, loss_trans 0.002908, loss flux 13.310056, loss flux t1 13.215760\n",
      "Epoch 7/10, Batch 61/1650, Loss 48.639553, Loss rec 9.249683, loss rec t1 10.925387, loss kl 0.158513, loss_trans 0.010352, loss flux 14.310956, loss flux t1 13.984657\n",
      "Epoch 7/10, Batch 71/1650, Loss 46.538700, Loss rec 8.127674, loss rec t1 8.761002, loss kl 0.146366, loss_trans 0.004883, loss flux 15.458449, loss flux t1 14.040324\n",
      "Epoch 7/10, Batch 81/1650, Loss 58.323551, Loss rec 15.299538, loss rec t1 16.928598, loss kl 0.094362, loss_trans 0.005015, loss flux 13.228498, loss flux t1 12.767540\n",
      "Epoch 7/10, Batch 91/1650, Loss 45.229404, Loss rec 9.346304, loss rec t1 10.628422, loss kl 0.117003, loss_trans 0.006237, loss flux 12.585704, loss flux t1 12.545736\n",
      "Epoch 7/10, Batch 101/1650, Loss 40.320713, Loss rec 7.616040, loss rec t1 8.972973, loss kl 0.091007, loss_trans 0.003720, loss flux 11.995764, loss flux t1 11.641212\n",
      "Epoch 7/10, Batch 111/1650, Loss 54.676418, Loss rec 10.085624, loss rec t1 12.514020, loss kl 0.165738, loss_trans 0.005641, loss flux 16.229103, loss flux t1 15.676292\n",
      "Epoch 7/10, Batch 121/1650, Loss 49.991825, Loss rec 8.639132, loss rec t1 10.138137, loss kl 0.158636, loss_trans 0.005832, loss flux 15.287355, loss flux t1 15.762732\n",
      "Epoch 7/10, Batch 131/1650, Loss 41.033897, Loss rec 7.473785, loss rec t1 8.723610, loss kl 0.075533, loss_trans 0.001879, loss flux 12.513489, loss flux t1 12.245605\n",
      "Epoch 7/10, Batch 141/1650, Loss 35.411308, Loss rec 6.340816, loss rec t1 7.405512, loss kl 0.089478, loss_trans 0.004158, loss flux 11.502507, loss flux t1 10.068834\n",
      "Epoch 7/10, Batch 151/1650, Loss 44.222786, Loss rec 7.735138, loss rec t1 7.844027, loss kl 0.176700, loss_trans 0.007788, loss flux 14.117595, loss flux t1 14.341540\n",
      "Epoch 7/10, Batch 161/1650, Loss 47.938736, Loss rec 9.841740, loss rec t1 11.055258, loss kl 0.187960, loss_trans 0.006474, loss flux 13.701333, loss flux t1 13.145972\n",
      "Epoch 7/10, Batch 171/1650, Loss 46.245739, Loss rec 7.790469, loss rec t1 8.550528, loss kl 0.182066, loss_trans 0.006394, loss flux 15.092333, loss flux t1 14.623952\n",
      "Epoch 7/10, Batch 181/1650, Loss 30.662504, Loss rec 4.986089, loss rec t1 5.589657, loss kl 0.086678, loss_trans 0.003187, loss flux 10.367364, loss flux t1 9.629528\n",
      "Epoch 7/10, Batch 191/1650, Loss 40.669216, Loss rec 6.970570, loss rec t1 7.696488, loss kl 0.162663, loss_trans 0.007962, loss flux 12.933548, loss flux t1 12.897985\n",
      "Epoch 7/10, Batch 201/1650, Loss 37.739349, Loss rec 8.424149, loss rec t1 8.251610, loss kl 0.099440, loss_trans 0.003744, loss flux 10.411959, loss flux t1 10.548450\n",
      "Epoch 7/10, Batch 211/1650, Loss 42.437183, Loss rec 8.106853, loss rec t1 9.135845, loss kl 0.066570, loss_trans 0.002194, loss flux 12.049412, loss flux t1 13.076311\n",
      "Epoch 7/10, Batch 221/1650, Loss 43.436016, Loss rec 9.082443, loss rec t1 9.235142, loss kl 0.117787, loss_trans 0.002263, loss flux 12.718724, loss flux t1 12.279660\n",
      "Epoch 7/10, Batch 231/1650, Loss 38.985569, Loss rec 6.959098, loss rec t1 8.112074, loss kl 0.145504, loss_trans 0.004719, loss flux 12.098086, loss flux t1 11.666090\n",
      "Epoch 7/10, Batch 241/1650, Loss 55.950657, Loss rec 11.337725, loss rec t1 14.627027, loss kl 0.105373, loss_trans 0.005323, loss flux 15.156835, loss flux t1 14.718374\n",
      "Epoch 7/10, Batch 251/1650, Loss 42.032589, Loss rec 7.620651, loss rec t1 9.933636, loss kl 0.139671, loss_trans 0.009453, loss flux 12.226378, loss flux t1 12.102799\n",
      "Epoch 7/10, Batch 261/1650, Loss 39.166393, Loss rec 6.579142, loss rec t1 7.490562, loss kl 0.091991, loss_trans 0.002791, loss flux 13.059126, loss flux t1 11.942780\n",
      "Epoch 7/10, Batch 271/1650, Loss 46.178482, Loss rec 7.827497, loss rec t1 9.182064, loss kl 0.144710, loss_trans 0.004471, loss flux 14.504558, loss flux t1 14.515182\n",
      "Epoch 7/10, Batch 281/1650, Loss 46.207077, Loss rec 10.303232, loss rec t1 12.061576, loss kl 0.119082, loss_trans 0.005140, loss flux 12.441626, loss flux t1 11.276425\n",
      "Epoch 7/10, Batch 291/1650, Loss 52.876270, Loss rec 9.171108, loss rec t1 11.269243, loss kl 0.151193, loss_trans 0.004752, loss flux 16.420443, loss flux t1 15.859530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Batch 301/1650, Loss 39.890202, Loss rec 7.554976, loss rec t1 8.181085, loss kl 0.090649, loss_trans 0.002990, loss flux 12.670258, loss flux t1 11.390244\n",
      "Epoch 7/10, Batch 311/1650, Loss 32.578526, Loss rec 4.718369, loss rec t1 5.586887, loss kl 0.102994, loss_trans 0.002597, loss flux 11.352781, loss flux t1 10.814894\n",
      "Epoch 7/10, Batch 321/1650, Loss 47.236759, Loss rec 8.945580, loss rec t1 10.319193, loss kl 0.138074, loss_trans 0.005388, loss flux 14.136485, loss flux t1 13.692039\n",
      "Epoch 7/10, Batch 331/1650, Loss 35.165047, Loss rec 6.479840, loss rec t1 7.302894, loss kl 0.086689, loss_trans 0.003850, loss flux 10.979411, loss flux t1 10.312362\n",
      "Epoch 7/10, Batch 341/1650, Loss 54.005817, Loss rec 12.531775, loss rec t1 13.574056, loss kl 0.127467, loss_trans 0.004967, loss flux 13.877853, loss flux t1 13.889698\n",
      "Epoch 7/10, Batch 351/1650, Loss 51.443501, Loss rec 8.391045, loss rec t1 9.495163, loss kl 0.168883, loss_trans 0.005716, loss flux 16.386883, loss flux t1 16.995811\n",
      "Epoch 7/10, Batch 361/1650, Loss 50.242268, Loss rec 9.518570, loss rec t1 10.394364, loss kl 0.115920, loss_trans 0.005060, loss flux 15.067689, loss flux t1 15.140668\n",
      "Epoch 7/10, Batch 371/1650, Loss 47.894928, Loss rec 10.235749, loss rec t1 11.619421, loss kl 0.177712, loss_trans 0.012062, loss flux 13.101435, loss flux t1 12.748546\n",
      "Epoch 7/10, Batch 381/1650, Loss 44.942242, Loss rec 6.557972, loss rec t1 7.403497, loss kl 0.126712, loss_trans 0.004442, loss flux 16.358793, loss flux t1 14.490826\n",
      "Epoch 7/10, Batch 391/1650, Loss 44.077377, Loss rec 8.506618, loss rec t1 10.075724, loss kl 0.135117, loss_trans 0.004088, loss flux 13.177807, loss flux t1 12.178024\n",
      "Epoch 7/10, Batch 401/1650, Loss 40.923820, Loss rec 8.429356, loss rec t1 9.754505, loss kl 0.081840, loss_trans 0.004967, loss flux 11.402436, loss flux t1 11.250718\n",
      "Epoch 7/10, Batch 411/1650, Loss 45.136463, Loss rec 8.749175, loss rec t1 9.408894, loss kl 0.185910, loss_trans 0.011120, loss flux 14.147849, loss flux t1 12.633514\n",
      "Epoch 7/10, Batch 421/1650, Loss 43.931492, Loss rec 8.759197, loss rec t1 9.636724, loss kl 0.167488, loss_trans 0.011127, loss flux 13.140124, loss flux t1 12.216829\n",
      "Epoch 7/10, Batch 431/1650, Loss 32.604469, Loss rec 4.007828, loss rec t1 4.973353, loss kl 0.135605, loss_trans 0.002502, loss flux 12.733451, loss flux t1 10.751730\n",
      "Epoch 7/10, Batch 441/1650, Loss 43.107388, Loss rec 7.542475, loss rec t1 8.520984, loss kl 0.142469, loss_trans 0.005222, loss flux 14.125727, loss flux t1 12.770512\n",
      "Epoch 7/10, Batch 451/1650, Loss 36.694519, Loss rec 6.953994, loss rec t1 7.939007, loss kl 0.104499, loss_trans 0.006609, loss flux 11.004657, loss flux t1 10.685750\n",
      "Epoch 7/10, Batch 461/1650, Loss 52.129051, Loss rec 11.037594, loss rec t1 13.601465, loss kl 0.097679, loss_trans 0.004959, loss flux 14.224567, loss flux t1 13.162789\n",
      "Epoch 7/10, Batch 471/1650, Loss 42.870331, Loss rec 6.605869, loss rec t1 7.663116, loss kl 0.112488, loss_trans 0.003104, loss flux 14.402721, loss flux t1 14.083030\n",
      "Epoch 7/10, Batch 481/1650, Loss 40.605907, Loss rec 6.679889, loss rec t1 7.727061, loss kl 0.107263, loss_trans 0.002437, loss flux 13.300165, loss flux t1 12.789091\n",
      "Epoch 7/10, Batch 491/1650, Loss 55.438698, Loss rec 11.036684, loss rec t1 13.846586, loss kl 0.083528, loss_trans 0.002646, loss flux 15.050880, loss flux t1 15.418373\n",
      "Epoch 7/10, Batch 501/1650, Loss 54.840721, Loss rec 12.393350, loss rec t1 13.301319, loss kl 0.131300, loss_trans 0.003689, loss flux 15.211455, loss flux t1 13.799611\n",
      "Epoch 7/10, Batch 511/1650, Loss 48.524624, Loss rec 9.955293, loss rec t1 10.246120, loss kl 0.132320, loss_trans 0.005413, loss flux 15.067067, loss flux t1 13.118412\n",
      "Epoch 7/10, Batch 521/1650, Loss 60.238834, Loss rec 12.594998, loss rec t1 12.766547, loss kl 0.172579, loss_trans 0.009160, loss flux 18.328867, loss flux t1 16.366686\n",
      "Epoch 7/10, Batch 531/1650, Loss 39.302223, Loss rec 6.521891, loss rec t1 7.025371, loss kl 0.092290, loss_trans 0.005595, loss flux 13.578191, loss flux t1 12.078885\n",
      "Epoch 7/10, Batch 541/1650, Loss 37.025986, Loss rec 4.597609, loss rec t1 7.072995, loss kl 0.115586, loss_trans 0.003608, loss flux 13.152216, loss flux t1 12.083967\n",
      "Epoch 7/10, Batch 551/1650, Loss 42.959232, Loss rec 6.122169, loss rec t1 8.186908, loss kl 0.145992, loss_trans 0.008141, loss flux 14.467690, loss flux t1 14.028334\n",
      "Epoch 7/10, Batch 561/1650, Loss 45.370377, Loss rec 9.735468, loss rec t1 12.268145, loss kl 0.097195, loss_trans 0.003845, loss flux 11.436001, loss flux t1 11.829722\n",
      "Epoch 7/10, Batch 571/1650, Loss 52.579178, Loss rec 13.110552, loss rec t1 14.253810, loss kl 0.125363, loss_trans 0.003782, loss flux 13.082480, loss flux t1 12.003194\n",
      "Epoch 7/10, Batch 581/1650, Loss 49.098503, Loss rec 11.088300, loss rec t1 10.314048, loss kl 0.102592, loss_trans 0.004530, loss flux 14.421485, loss flux t1 13.167547\n",
      "Epoch 7/10, Batch 591/1650, Loss 41.951488, Loss rec 7.218158, loss rec t1 7.375817, loss kl 0.092676, loss_trans 0.001938, loss flux 14.400496, loss flux t1 12.862404\n",
      "Epoch 7/10, Batch 601/1650, Loss 46.652264, Loss rec 9.691111, loss rec t1 10.423185, loss kl 0.113330, loss_trans 0.010002, loss flux 13.663645, loss flux t1 12.750987\n",
      "Epoch 7/10, Batch 611/1650, Loss 39.161507, Loss rec 7.544266, loss rec t1 8.454525, loss kl 0.112014, loss_trans 0.006097, loss flux 12.358135, loss flux t1 10.686468\n",
      "Epoch 7/10, Batch 621/1650, Loss 43.782345, Loss rec 7.975220, loss rec t1 9.437128, loss kl 0.129175, loss_trans 0.005277, loss flux 14.281208, loss flux t1 11.954339\n",
      "Epoch 7/10, Batch 631/1650, Loss 47.156536, Loss rec 7.674784, loss rec t1 9.413311, loss kl 0.147052, loss_trans 0.008386, loss flux 16.555738, loss flux t1 13.357265\n",
      "Epoch 7/10, Batch 641/1650, Loss 44.157410, Loss rec 9.194361, loss rec t1 9.150849, loss kl 0.116457, loss_trans 0.006855, loss flux 12.982483, loss flux t1 12.706404\n",
      "Epoch 7/10, Batch 651/1650, Loss 43.346729, Loss rec 8.757566, loss rec t1 9.680900, loss kl 0.130963, loss_trans 0.007230, loss flux 12.659111, loss flux t1 12.110961\n",
      "Epoch 7/10, Batch 661/1650, Loss 39.428810, Loss rec 7.262895, loss rec t1 7.590605, loss kl 0.163709, loss_trans 0.008081, loss flux 12.810158, loss flux t1 11.593367\n",
      "Epoch 7/10, Batch 671/1650, Loss 36.781475, Loss rec 6.683541, loss rec t1 8.341080, loss kl 0.104660, loss_trans 0.006680, loss flux 10.988825, loss flux t1 10.656689\n",
      "Epoch 7/10, Batch 681/1650, Loss 40.446617, Loss rec 5.858229, loss rec t1 8.606664, loss kl 0.113160, loss_trans 0.002649, loss flux 13.180885, loss flux t1 12.685030\n",
      "Epoch 7/10, Batch 691/1650, Loss 48.193523, Loss rec 10.311127, loss rec t1 9.791308, loss kl 0.179506, loss_trans 0.007651, loss flux 14.220231, loss flux t1 13.683697\n",
      "Epoch 7/10, Batch 701/1650, Loss 45.631866, Loss rec 8.560236, loss rec t1 9.519913, loss kl 0.171344, loss_trans 0.010363, loss flux 13.723112, loss flux t1 13.646901\n",
      "Epoch 7/10, Batch 711/1650, Loss 49.521473, Loss rec 7.850495, loss rec t1 8.604304, loss kl 0.230238, loss_trans 0.006687, loss flux 16.245098, loss flux t1 16.584648\n",
      "Epoch 7/10, Batch 721/1650, Loss 38.892380, Loss rec 6.216441, loss rec t1 7.437713, loss kl 0.168352, loss_trans 0.003212, loss flux 12.528283, loss flux t1 12.538381\n",
      "Epoch 7/10, Batch 731/1650, Loss 40.068138, Loss rec 7.302170, loss rec t1 8.025640, loss kl 0.111902, loss_trans 0.005745, loss flux 12.409533, loss flux t1 12.213148\n",
      "Epoch 7/10, Batch 741/1650, Loss 36.915852, Loss rec 6.970522, loss rec t1 7.214515, loss kl 0.115291, loss_trans 0.006259, loss flux 11.469104, loss flux t1 11.140159\n",
      "Epoch 7/10, Batch 751/1650, Loss 34.684116, Loss rec 5.872370, loss rec t1 6.389121, loss kl 0.143565, loss_trans 0.005360, loss flux 11.544777, loss flux t1 10.728923\n",
      "Epoch 7/10, Batch 761/1650, Loss 37.716110, Loss rec 5.903342, loss rec t1 6.978845, loss kl 0.167193, loss_trans 0.011811, loss flux 12.802290, loss flux t1 11.852631\n",
      "Epoch 7/10, Batch 771/1650, Loss 34.784195, Loss rec 4.277949, loss rec t1 6.198563, loss kl 0.108240, loss_trans 0.004036, loss flux 12.674760, loss flux t1 11.520648\n",
      "Epoch 7/10, Batch 781/1650, Loss 34.876060, Loss rec 6.442086, loss rec t1 7.470371, loss kl 0.101099, loss_trans 0.002824, loss flux 10.315881, loss flux t1 10.543802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Batch 791/1650, Loss 37.960098, Loss rec 6.897702, loss rec t1 7.315778, loss kl 0.102446, loss_trans 0.006626, loss flux 12.128240, loss flux t1 11.509307\n",
      "Epoch 7/10, Batch 801/1650, Loss 34.628006, Loss rec 6.163791, loss rec t1 6.865539, loss kl 0.144119, loss_trans 0.005103, loss flux 10.824257, loss flux t1 10.625197\n",
      "Epoch 7/10, Batch 811/1650, Loss 40.792606, Loss rec 6.737862, loss rec t1 8.255070, loss kl 0.172069, loss_trans 0.005147, loss flux 13.741383, loss flux t1 11.881078\n",
      "Epoch 7/10, Batch 821/1650, Loss 34.392357, Loss rec 6.229664, loss rec t1 6.654682, loss kl 0.113484, loss_trans 0.005087, loss flux 10.801437, loss flux t1 10.588002\n",
      "Epoch 7/10, Batch 831/1650, Loss 31.968866, Loss rec 4.946286, loss rec t1 5.823872, loss kl 0.188944, loss_trans 0.006506, loss flux 10.994294, loss flux t1 10.008964\n",
      "Epoch 7/10, Batch 841/1650, Loss 29.711161, Loss rec 5.331090, loss rec t1 6.326087, loss kl 0.079420, loss_trans 0.003301, loss flux 8.916709, loss flux t1 9.054553\n",
      "Epoch 7/10, Batch 851/1650, Loss 44.372948, Loss rec 8.490482, loss rec t1 10.767455, loss kl 0.120309, loss_trans 0.006315, loss flux 12.463794, loss flux t1 12.524592\n",
      "Epoch 7/10, Batch 861/1650, Loss 35.080585, Loss rec 5.258270, loss rec t1 6.167989, loss kl 0.163897, loss_trans 0.007138, loss flux 12.191369, loss flux t1 11.291924\n",
      "Epoch 7/10, Batch 871/1650, Loss 41.785297, Loss rec 7.632618, loss rec t1 7.781412, loss kl 0.137841, loss_trans 0.004156, loss flux 13.255322, loss flux t1 12.973949\n",
      "Epoch 7/10, Batch 881/1650, Loss 36.934391, Loss rec 5.927356, loss rec t1 7.888843, loss kl 0.120139, loss_trans 0.005595, loss flux 11.286399, loss flux t1 11.706059\n",
      "Epoch 7/10, Batch 891/1650, Loss 36.301277, Loss rec 5.479207, loss rec t1 6.171711, loss kl 0.113438, loss_trans 0.004137, loss flux 12.530797, loss flux t1 12.001984\n",
      "Epoch 7/10, Batch 901/1650, Loss 36.377945, Loss rec 6.405340, loss rec t1 7.859960, loss kl 0.155629, loss_trans 0.004271, loss flux 11.041418, loss flux t1 10.911325\n",
      "Epoch 7/10, Batch 911/1650, Loss 28.678186, Loss rec 3.792591, loss rec t1 4.964104, loss kl 0.103627, loss_trans 0.002807, loss flux 10.203631, loss flux t1 9.611426\n",
      "Epoch 7/10, Batch 921/1650, Loss 32.577995, Loss rec 5.194287, loss rec t1 6.156703, loss kl 0.117681, loss_trans 0.004844, loss flux 10.401643, loss flux t1 10.702835\n",
      "Epoch 7/10, Batch 931/1650, Loss 35.066200, Loss rec 6.511662, loss rec t1 6.644108, loss kl 0.116300, loss_trans 0.003998, loss flux 11.224056, loss flux t1 10.566075\n",
      "Epoch 7/10, Batch 941/1650, Loss 40.892681, Loss rec 5.777456, loss rec t1 6.560300, loss kl 0.157957, loss_trans 0.005172, loss flux 14.810752, loss flux t1 13.581043\n",
      "Epoch 7/10, Batch 951/1650, Loss 37.401691, Loss rec 5.592134, loss rec t1 6.324284, loss kl 0.110242, loss_trans 0.003123, loss flux 12.987164, loss flux t1 12.384743\n",
      "Epoch 7/10, Batch 961/1650, Loss 31.780834, Loss rec 5.196046, loss rec t1 6.107479, loss kl 0.071542, loss_trans 0.002353, loss flux 10.063911, loss flux t1 10.339503\n",
      "Epoch 7/10, Batch 971/1650, Loss 42.713314, Loss rec 9.127559, loss rec t1 9.694740, loss kl 0.090966, loss_trans 0.005424, loss flux 12.383142, loss flux t1 11.411483\n",
      "Epoch 7/10, Batch 981/1650, Loss 35.643951, Loss rec 6.819231, loss rec t1 7.591216, loss kl 0.095755, loss_trans 0.004370, loss flux 10.938443, loss flux t1 10.194935\n",
      "Epoch 7/10, Batch 991/1650, Loss 36.643906, Loss rec 6.226954, loss rec t1 6.969278, loss kl 0.093376, loss_trans 0.002621, loss flux 11.586265, loss flux t1 11.765413\n",
      "Epoch 7/10, Batch 1001/1650, Loss 38.347717, Loss rec 7.276795, loss rec t1 7.329192, loss kl 0.146373, loss_trans 0.006143, loss flux 11.803566, loss flux t1 11.785650\n",
      "Epoch 7/10, Batch 1011/1650, Loss 36.939564, Loss rec 6.513395, loss rec t1 7.391850, loss kl 0.100650, loss_trans 0.004447, loss flux 11.847519, loss flux t1 11.081703\n",
      "Epoch 7/10, Batch 1021/1650, Loss 35.846233, Loss rec 5.389526, loss rec t1 6.633902, loss kl 0.100654, loss_trans 0.002658, loss flux 11.190296, loss flux t1 12.529199\n",
      "Epoch 7/10, Batch 1031/1650, Loss 41.115189, Loss rec 8.444805, loss rec t1 9.654819, loss kl 0.158281, loss_trans 0.005913, loss flux 11.370605, loss flux t1 11.480768\n",
      "Epoch 7/10, Batch 1041/1650, Loss 35.651367, Loss rec 7.261347, loss rec t1 7.863532, loss kl 0.104010, loss_trans 0.004119, loss flux 10.347279, loss flux t1 10.071081\n",
      "Epoch 7/10, Batch 1051/1650, Loss 37.232517, Loss rec 7.403283, loss rec t1 7.349675, loss kl 0.093766, loss_trans 0.003618, loss flux 11.871290, loss flux t1 10.510886\n",
      "Epoch 7/10, Batch 1061/1650, Loss 45.586079, Loss rec 8.235458, loss rec t1 9.264463, loss kl 0.136947, loss_trans 0.006313, loss flux 14.382575, loss flux t1 13.560322\n",
      "Epoch 7/10, Batch 1071/1650, Loss 39.715717, Loss rec 6.769660, loss rec t1 7.191825, loss kl 0.155934, loss_trans 0.005010, loss flux 13.042747, loss flux t1 12.550539\n",
      "Epoch 7/10, Batch 1081/1650, Loss 39.370007, Loss rec 8.483593, loss rec t1 9.531527, loss kl 0.120398, loss_trans 0.005222, loss flux 10.576768, loss flux t1 10.652498\n",
      "Epoch 7/10, Batch 1091/1650, Loss 36.549637, Loss rec 6.396080, loss rec t1 6.777566, loss kl 0.082488, loss_trans 0.002564, loss flux 11.906038, loss flux t1 11.384899\n",
      "Epoch 7/10, Batch 1101/1650, Loss 31.453274, Loss rec 4.862971, loss rec t1 5.652630, loss kl 0.110953, loss_trans 0.004299, loss flux 11.150479, loss flux t1 9.671941\n",
      "Epoch 7/10, Batch 1111/1650, Loss 31.734930, Loss rec 4.424076, loss rec t1 5.319507, loss kl 0.108837, loss_trans 0.006190, loss flux 12.063630, loss flux t1 9.812690\n",
      "Epoch 7/10, Batch 1121/1650, Loss 42.251316, Loss rec 7.648298, loss rec t1 8.076745, loss kl 0.140794, loss_trans 0.004323, loss flux 13.500238, loss flux t1 12.880919\n",
      "Epoch 7/10, Batch 1131/1650, Loss 42.933949, Loss rec 8.705206, loss rec t1 8.179483, loss kl 0.199398, loss_trans 0.010422, loss flux 13.373382, loss flux t1 12.466058\n",
      "Epoch 7/10, Batch 1141/1650, Loss 41.451702, Loss rec 7.341236, loss rec t1 8.105860, loss kl 0.128882, loss_trans 0.005270, loss flux 13.796066, loss flux t1 12.074390\n",
      "Epoch 7/10, Batch 1151/1650, Loss 37.391586, Loss rec 6.213174, loss rec t1 6.845662, loss kl 0.158508, loss_trans 0.004564, loss flux 11.985529, loss flux t1 12.184149\n",
      "Epoch 7/10, Batch 1161/1650, Loss 40.209740, Loss rec 7.840297, loss rec t1 8.731860, loss kl 0.114236, loss_trans 0.006302, loss flux 11.785850, loss flux t1 11.731198\n",
      "Epoch 7/10, Batch 1171/1650, Loss 38.957829, Loss rec 5.890687, loss rec t1 6.700094, loss kl 0.106808, loss_trans 0.003151, loss flux 13.454185, loss flux t1 12.802903\n",
      "Epoch 7/10, Batch 1181/1650, Loss 44.587200, Loss rec 8.136450, loss rec t1 9.317669, loss kl 0.179268, loss_trans 0.004871, loss flux 13.504167, loss flux t1 13.444777\n",
      "Epoch 7/10, Batch 1191/1650, Loss 44.247223, Loss rec 9.127554, loss rec t1 10.410063, loss kl 0.145372, loss_trans 0.006211, loss flux 12.370606, loss flux t1 12.187416\n",
      "Epoch 7/10, Batch 1201/1650, Loss 33.930515, Loss rec 5.511070, loss rec t1 6.248243, loss kl 0.113790, loss_trans 0.005000, loss flux 11.813545, loss flux t1 10.238864\n",
      "Epoch 7/10, Batch 1211/1650, Loss 44.462051, Loss rec 8.951236, loss rec t1 9.444985, loss kl 0.148896, loss_trans 0.005125, loss flux 13.023338, loss flux t1 12.888474\n",
      "Epoch 7/10, Batch 1221/1650, Loss 37.135365, Loss rec 5.064378, loss rec t1 5.581143, loss kl 0.125374, loss_trans 0.002434, loss flux 13.752188, loss flux t1 12.609849\n",
      "Epoch 7/10, Batch 1231/1650, Loss 34.286297, Loss rec 4.798319, loss rec t1 5.745546, loss kl 0.116399, loss_trans 0.003207, loss flux 11.799361, loss flux t1 11.823465\n",
      "Epoch 7/10, Batch 1241/1650, Loss 32.661007, Loss rec 4.849237, loss rec t1 5.699740, loss kl 0.118606, loss_trans 0.003567, loss flux 11.415714, loss flux t1 10.574144\n",
      "Epoch 7/10, Batch 1251/1650, Loss 40.515221, Loss rec 8.150713, loss rec t1 8.747253, loss kl 0.093278, loss_trans 0.003297, loss flux 12.057711, loss flux t1 11.462969\n",
      "Epoch 7/10, Batch 1261/1650, Loss 36.597343, Loss rec 8.005775, loss rec t1 8.119022, loss kl 0.094280, loss_trans 0.005126, loss flux 10.130437, loss flux t1 10.242701\n",
      "Epoch 7/10, Batch 1271/1650, Loss 37.293468, Loss rec 7.442029, loss rec t1 7.733322, loss kl 0.113057, loss_trans 0.008357, loss flux 11.547207, loss flux t1 10.449494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Batch 1281/1650, Loss 30.975992, Loss rec 4.505540, loss rec t1 5.269442, loss kl 0.127454, loss_trans 0.003291, loss flux 10.939627, loss flux t1 10.130639\n",
      "Epoch 7/10, Batch 1291/1650, Loss 29.384535, Loss rec 3.933987, loss rec t1 5.069201, loss kl 0.089512, loss_trans 0.003486, loss flux 10.325233, loss flux t1 9.963116\n",
      "Epoch 7/10, Batch 1301/1650, Loss 32.244278, Loss rec 5.552434, loss rec t1 6.045060, loss kl 0.109605, loss_trans 0.004430, loss flux 10.981150, loss flux t1 9.551600\n",
      "Epoch 7/10, Batch 1311/1650, Loss 38.849030, Loss rec 6.175991, loss rec t1 6.958318, loss kl 0.108357, loss_trans 0.005163, loss flux 13.954398, loss flux t1 11.646800\n",
      "Epoch 7/10, Batch 1321/1650, Loss 38.123074, Loss rec 6.404827, loss rec t1 7.594474, loss kl 0.153542, loss_trans 0.006581, loss flux 12.348665, loss flux t1 11.614985\n",
      "Epoch 7/10, Batch 1331/1650, Loss 41.213764, Loss rec 8.893660, loss rec t1 9.410675, loss kl 0.097929, loss_trans 0.007138, loss flux 11.442598, loss flux t1 11.361766\n",
      "Epoch 7/10, Batch 1341/1650, Loss 29.658623, Loss rec 4.045903, loss rec t1 5.128010, loss kl 0.133109, loss_trans 0.004725, loss flux 10.598037, loss flux t1 9.748838\n",
      "Epoch 7/10, Batch 1351/1650, Loss 31.746918, Loss rec 5.759797, loss rec t1 7.466456, loss kl 0.073883, loss_trans 0.002304, loss flux 9.037816, loss flux t1 9.406662\n",
      "Epoch 7/10, Batch 1361/1650, Loss 40.625256, Loss rec 7.690436, loss rec t1 8.573421, loss kl 0.177058, loss_trans 0.007382, loss flux 12.441883, loss flux t1 11.735073\n",
      "Epoch 7/10, Batch 1371/1650, Loss 32.153145, Loss rec 4.056497, loss rec t1 5.177837, loss kl 0.120047, loss_trans 0.004445, loss flux 11.998495, loss flux t1 10.795826\n",
      "Epoch 7/10, Batch 1381/1650, Loss 36.228893, Loss rec 7.332253, loss rec t1 7.938244, loss kl 0.135184, loss_trans 0.003167, loss flux 10.504729, loss flux t1 10.315314\n",
      "Epoch 7/10, Batch 1391/1650, Loss 37.710072, Loss rec 5.989631, loss rec t1 6.559981, loss kl 0.180072, loss_trans 0.006465, loss flux 12.638963, loss flux t1 12.334960\n",
      "Epoch 7/10, Batch 1401/1650, Loss 36.674210, Loss rec 5.452017, loss rec t1 6.163656, loss kl 0.105916, loss_trans 0.003345, loss flux 13.218739, loss flux t1 11.730536\n",
      "Epoch 7/10, Batch 1411/1650, Loss 38.149368, Loss rec 7.855386, loss rec t1 8.842356, loss kl 0.125016, loss_trans 0.005487, loss flux 11.106428, loss flux t1 10.214696\n",
      "Epoch 7/10, Batch 1421/1650, Loss 32.177971, Loss rec 5.705148, loss rec t1 6.203215, loss kl 0.110517, loss_trans 0.004440, loss flux 10.235549, loss flux t1 9.919102\n",
      "Epoch 7/10, Batch 1431/1650, Loss 32.310646, Loss rec 5.331145, loss rec t1 5.831064, loss kl 0.117956, loss_trans 0.004437, loss flux 10.732816, loss flux t1 10.293229\n",
      "Epoch 7/10, Batch 1441/1650, Loss 38.528767, Loss rec 5.370006, loss rec t1 6.173423, loss kl 0.175186, loss_trans 0.006706, loss flux 14.470196, loss flux t1 12.333247\n",
      "Epoch 7/10, Batch 1451/1650, Loss 32.621876, Loss rec 6.416304, loss rec t1 6.921021, loss kl 0.117718, loss_trans 0.006716, loss flux 10.079995, loss flux t1 9.080122\n",
      "Epoch 7/10, Batch 1461/1650, Loss 33.378510, Loss rec 5.579072, loss rec t1 6.251905, loss kl 0.107713, loss_trans 0.003383, loss flux 11.114556, loss flux t1 10.321881\n",
      "Epoch 7/10, Batch 1471/1650, Loss 37.946964, Loss rec 7.567514, loss rec t1 8.179388, loss kl 0.138977, loss_trans 0.003884, loss flux 10.749885, loss flux t1 11.307315\n",
      "Epoch 7/10, Batch 1481/1650, Loss 38.447437, Loss rec 7.297011, loss rec t1 8.307829, loss kl 0.118363, loss_trans 0.003225, loss flux 12.069320, loss flux t1 10.651693\n",
      "Epoch 7/10, Batch 1491/1650, Loss 47.168312, Loss rec 9.474951, loss rec t1 9.552279, loss kl 0.165309, loss_trans 0.005550, loss flux 14.015824, loss flux t1 13.954398\n",
      "Epoch 7/10, Batch 1501/1650, Loss 46.950150, Loss rec 9.602961, loss rec t1 10.050830, loss kl 0.175155, loss_trans 0.008249, loss flux 13.548323, loss flux t1 13.564636\n",
      "Epoch 7/10, Batch 1511/1650, Loss 49.722801, Loss rec 8.198776, loss rec t1 8.909395, loss kl 0.092825, loss_trans 0.004995, loss flux 17.133633, loss flux t1 15.383179\n",
      "Epoch 7/10, Batch 1521/1650, Loss 35.668514, Loss rec 5.791800, loss rec t1 6.364277, loss kl 0.125273, loss_trans 0.002861, loss flux 11.534525, loss flux t1 11.849776\n",
      "Epoch 7/10, Batch 1531/1650, Loss 43.843643, Loss rec 9.443586, loss rec t1 10.629820, loss kl 0.115318, loss_trans 0.005464, loss flux 12.057898, loss flux t1 11.591559\n",
      "Epoch 7/10, Batch 1541/1650, Loss 38.752201, Loss rec 6.267225, loss rec t1 7.396916, loss kl 0.157978, loss_trans 0.004876, loss flux 12.756317, loss flux t1 12.168889\n",
      "Epoch 7/10, Batch 1551/1650, Loss 36.522717, Loss rec 5.674336, loss rec t1 6.674813, loss kl 0.083091, loss_trans 0.003352, loss flux 12.171767, loss flux t1 11.915354\n",
      "Epoch 7/10, Batch 1561/1650, Loss 40.913654, Loss rec 7.559574, loss rec t1 8.401817, loss kl 0.175126, loss_trans 0.005995, loss flux 12.278296, loss flux t1 12.492844\n",
      "Epoch 7/10, Batch 1571/1650, Loss 36.133747, Loss rec 4.432638, loss rec t1 5.747442, loss kl 0.170499, loss_trans 0.005704, loss flux 12.848660, loss flux t1 12.928805\n",
      "Epoch 7/10, Batch 1581/1650, Loss 33.369560, Loss rec 5.297987, loss rec t1 6.330871, loss kl 0.092237, loss_trans 0.002595, loss flux 11.200485, loss flux t1 10.445388\n",
      "Epoch 7/10, Batch 1591/1650, Loss 34.064339, Loss rec 5.641431, loss rec t1 6.545444, loss kl 0.138860, loss_trans 0.005401, loss flux 11.033968, loss flux t1 10.699233\n",
      "Epoch 7/10, Batch 1601/1650, Loss 33.487904, Loss rec 5.268354, loss rec t1 6.187428, loss kl 0.058646, loss_trans 0.004582, loss flux 11.542447, loss flux t1 10.426449\n",
      "Epoch 7/10, Batch 1611/1650, Loss 28.988985, Loss rec 3.679620, loss rec t1 4.494674, loss kl 0.088823, loss_trans 0.003191, loss flux 10.638407, loss flux t1 10.084270\n",
      "Epoch 7/10, Batch 1621/1650, Loss 29.626690, Loss rec 3.960737, loss rec t1 4.493955, loss kl 0.137629, loss_trans 0.004128, loss flux 11.207507, loss flux t1 9.822736\n",
      "Epoch 7/10, Batch 1631/1650, Loss 33.048210, Loss rec 6.782512, loss rec t1 7.799189, loss kl 0.081048, loss_trans 0.007199, loss flux 9.345837, loss flux t1 9.032425\n",
      "Epoch 7/10, Batch 1641/1650, Loss 34.204029, Loss rec 6.089475, loss rec t1 6.509052, loss kl 0.147040, loss_trans 0.004170, loss flux 10.975544, loss flux t1 10.478747\n",
      "Epoch 7/10, Train loss 29.351427, Eval loss 35.706589\n",
      "Epoch 8/10, Batch 1/1650, Loss 31.858349, Loss rec 4.110420, loss rec t1 5.482440, loss kl 0.156270, loss_trans 0.003266, loss flux 11.301727, loss flux t1 10.804227\n",
      "Epoch 8/10, Batch 11/1650, Loss 35.637974, Loss rec 5.400092, loss rec t1 7.514390, loss kl 0.148594, loss_trans 0.003026, loss flux 11.007831, loss flux t1 11.564043\n",
      "Epoch 8/10, Batch 21/1650, Loss 36.668842, Loss rec 7.383631, loss rec t1 7.781962, loss kl 0.102080, loss_trans 0.006843, loss flux 10.619575, loss flux t1 10.774753\n",
      "Epoch 8/10, Batch 31/1650, Loss 35.518093, Loss rec 5.785244, loss rec t1 6.925694, loss kl 0.084797, loss_trans 0.002982, loss flux 11.594282, loss flux t1 11.125092\n",
      "Epoch 8/10, Batch 41/1650, Loss 33.768967, Loss rec 5.527786, loss rec t1 6.252953, loss kl 0.097643, loss_trans 0.003564, loss flux 11.180683, loss flux t1 10.706337\n",
      "Epoch 8/10, Batch 51/1650, Loss 34.388329, Loss rec 5.836498, loss rec t1 7.104949, loss kl 0.086216, loss_trans 0.002667, loss flux 10.481191, loss flux t1 10.876809\n",
      "Epoch 8/10, Batch 61/1650, Loss 59.268429, Loss rec 11.239086, loss rec t1 14.271350, loss kl 0.154550, loss_trans 0.008822, loss flux 17.101171, loss flux t1 16.493444\n",
      "Epoch 8/10, Batch 71/1650, Loss 72.106964, Loss rec 11.559580, loss rec t1 13.257589, loss kl 0.144323, loss_trans 0.004610, loss flux 25.121229, loss flux t1 22.019630\n",
      "Epoch 8/10, Batch 81/1650, Loss 36.744007, Loss rec 6.650703, loss rec t1 6.687328, loss kl 0.084729, loss_trans 0.004413, loss flux 11.767439, loss flux t1 11.549395\n",
      "Epoch 8/10, Batch 91/1650, Loss 41.810783, Loss rec 7.853664, loss rec t1 8.460476, loss kl 0.118804, loss_trans 0.006478, loss flux 13.406227, loss flux t1 11.965132\n",
      "Epoch 8/10, Batch 101/1650, Loss 42.248051, Loss rec 8.577917, loss rec t1 9.738153, loss kl 0.088307, loss_trans 0.003939, loss flux 11.834205, loss flux t1 12.005526\n",
      "Epoch 8/10, Batch 111/1650, Loss 44.099140, Loss rec 7.820132, loss rec t1 9.291931, loss kl 0.174194, loss_trans 0.006223, loss flux 14.173054, loss flux t1 12.633605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Batch 121/1650, Loss 59.148392, Loss rec 14.635923, loss rec t1 17.383747, loss kl 0.146582, loss_trans 0.005690, loss flux 13.596158, loss flux t1 13.380296\n",
      "Epoch 8/10, Batch 131/1650, Loss 35.005733, Loss rec 6.262334, loss rec t1 6.469053, loss kl 0.071056, loss_trans 0.001677, loss flux 11.193799, loss flux t1 11.007812\n",
      "Epoch 8/10, Batch 141/1650, Loss 32.292500, Loss rec 5.174854, loss rec t1 6.475950, loss kl 0.092322, loss_trans 0.004488, loss flux 10.154925, loss flux t1 10.389961\n",
      "Epoch 8/10, Batch 151/1650, Loss 40.428581, Loss rec 7.124610, loss rec t1 8.032808, loss kl 0.172742, loss_trans 0.006212, loss flux 12.474415, loss flux t1 12.617798\n",
      "Epoch 8/10, Batch 161/1650, Loss 41.749428, Loss rec 7.390498, loss rec t1 7.688240, loss kl 0.177711, loss_trans 0.006338, loss flux 14.746649, loss flux t1 11.739994\n",
      "Epoch 8/10, Batch 171/1650, Loss 49.321835, Loss rec 10.791972, loss rec t1 9.988743, loss kl 0.171033, loss_trans 0.005681, loss flux 14.527338, loss flux t1 13.837068\n",
      "Epoch 8/10, Batch 181/1650, Loss 29.780615, Loss rec 4.609779, loss rec t1 5.139046, loss kl 0.087458, loss_trans 0.003245, loss flux 11.021242, loss flux t1 8.919846\n",
      "Epoch 8/10, Batch 191/1650, Loss 38.202053, Loss rec 6.408978, loss rec t1 7.039702, loss kl 0.160067, loss_trans 0.006996, loss flux 12.678663, loss flux t1 11.907646\n",
      "Epoch 8/10, Batch 201/1650, Loss 42.530602, Loss rec 9.895163, loss rec t1 11.400003, loss kl 0.090624, loss_trans 0.003603, loss flux 11.510306, loss flux t1 9.630900\n",
      "Epoch 8/10, Batch 211/1650, Loss 48.477238, Loss rec 10.003092, loss rec t1 13.405355, loss kl 0.066903, loss_trans 0.002758, loss flux 11.998610, loss flux t1 13.000521\n",
      "Epoch 8/10, Batch 221/1650, Loss 51.560398, Loss rec 12.150416, loss rec t1 12.089062, loss kl 0.117321, loss_trans 0.002466, loss flux 14.034440, loss flux t1 13.166689\n",
      "Epoch 8/10, Batch 231/1650, Loss 41.900581, Loss rec 7.126715, loss rec t1 8.439508, loss kl 0.156481, loss_trans 0.005178, loss flux 13.944907, loss flux t1 12.227794\n",
      "Epoch 8/10, Batch 241/1650, Loss 42.390034, Loss rec 8.715612, loss rec t1 8.750109, loss kl 0.110022, loss_trans 0.005145, loss flux 13.199073, loss flux t1 11.610075\n",
      "Epoch 8/10, Batch 251/1650, Loss 41.415905, Loss rec 8.487684, loss rec t1 9.235147, loss kl 0.135393, loss_trans 0.011150, loss flux 12.024721, loss flux t1 11.521807\n",
      "Epoch 8/10, Batch 261/1650, Loss 38.486702, Loss rec 6.486464, loss rec t1 7.618522, loss kl 0.094475, loss_trans 0.002901, loss flux 11.945861, loss flux t1 12.338484\n",
      "Epoch 8/10, Batch 271/1650, Loss 44.016674, Loss rec 10.369019, loss rec t1 10.683743, loss kl 0.137439, loss_trans 0.004673, loss flux 11.477877, loss flux t1 11.343927\n",
      "Epoch 8/10, Batch 281/1650, Loss 39.938774, Loss rec 8.172681, loss rec t1 9.319019, loss kl 0.118180, loss_trans 0.004828, loss flux 11.521694, loss flux t1 10.802373\n",
      "Epoch 8/10, Batch 291/1650, Loss 36.087715, Loss rec 5.039829, loss rec t1 5.975187, loss kl 0.150665, loss_trans 0.004592, loss flux 12.821968, loss flux t1 12.095474\n",
      "Epoch 8/10, Batch 301/1650, Loss 36.310085, Loss rec 6.387740, loss rec t1 7.388652, loss kl 0.085874, loss_trans 0.003161, loss flux 11.242205, loss flux t1 11.202453\n",
      "Epoch 8/10, Batch 311/1650, Loss 32.688076, Loss rec 5.159759, loss rec t1 6.145180, loss kl 0.099667, loss_trans 0.002657, loss flux 10.885230, loss flux t1 10.395580\n",
      "Epoch 8/10, Batch 321/1650, Loss 36.995968, Loss rec 6.398989, loss rec t1 6.884644, loss kl 0.127253, loss_trans 0.004150, loss flux 11.550873, loss flux t1 12.030059\n",
      "Epoch 8/10, Batch 331/1650, Loss 37.344772, Loss rec 7.072156, loss rec t1 7.744209, loss kl 0.079115, loss_trans 0.003486, loss flux 11.375861, loss flux t1 11.069946\n",
      "Epoch 8/10, Batch 341/1650, Loss 40.712524, Loss rec 8.650210, loss rec t1 9.396147, loss kl 0.121289, loss_trans 0.005455, loss flux 11.164746, loss flux t1 11.374680\n",
      "Epoch 8/10, Batch 351/1650, Loss 38.195919, Loss rec 7.120402, loss rec t1 7.465287, loss kl 0.169217, loss_trans 0.004675, loss flux 11.726187, loss flux t1 11.710150\n",
      "Epoch 8/10, Batch 361/1650, Loss 35.713562, Loss rec 5.756067, loss rec t1 7.018282, loss kl 0.113578, loss_trans 0.003744, loss flux 11.547462, loss flux t1 11.274429\n",
      "Epoch 8/10, Batch 371/1650, Loss 35.633224, Loss rec 6.388638, loss rec t1 7.154148, loss kl 0.167633, loss_trans 0.010059, loss flux 10.958751, loss flux t1 10.953996\n",
      "Epoch 8/10, Batch 381/1650, Loss 33.790764, Loss rec 5.632421, loss rec t1 6.233169, loss kl 0.119486, loss_trans 0.003958, loss flux 11.737408, loss flux t1 10.064318\n",
      "Epoch 8/10, Batch 391/1650, Loss 32.945415, Loss rec 4.919416, loss rec t1 5.928219, loss kl 0.125592, loss_trans 0.003067, loss flux 11.192679, loss flux t1 10.776441\n",
      "Epoch 8/10, Batch 401/1650, Loss 30.938683, Loss rec 5.725288, loss rec t1 6.481953, loss kl 0.077661, loss_trans 0.004612, loss flux 9.433910, loss flux t1 9.215259\n",
      "Epoch 8/10, Batch 411/1650, Loss 35.786972, Loss rec 6.262075, loss rec t1 7.203952, loss kl 0.169391, loss_trans 0.009821, loss flux 11.280023, loss flux t1 10.861709\n",
      "Epoch 8/10, Batch 421/1650, Loss 37.670937, Loss rec 7.530871, loss rec t1 7.971378, loss kl 0.153724, loss_trans 0.008599, loss flux 11.226151, loss flux t1 10.780213\n",
      "Epoch 8/10, Batch 431/1650, Loss 28.387827, Loss rec 4.264088, loss rec t1 5.001444, loss kl 0.132200, loss_trans 0.002090, loss flux 9.912178, loss flux t1 9.075827\n",
      "Epoch 8/10, Batch 441/1650, Loss 36.823734, Loss rec 6.290737, loss rec t1 6.640915, loss kl 0.136372, loss_trans 0.004708, loss flux 12.464687, loss flux t1 11.286315\n",
      "Epoch 8/10, Batch 451/1650, Loss 31.854248, Loss rec 5.479797, loss rec t1 6.100147, loss kl 0.097316, loss_trans 0.005528, loss flux 10.631476, loss flux t1 9.539981\n",
      "Epoch 8/10, Batch 461/1650, Loss 36.147453, Loss rec 7.908992, loss rec t1 7.249139, loss kl 0.098249, loss_trans 0.004403, loss flux 10.911199, loss flux t1 9.975471\n",
      "Epoch 8/10, Batch 471/1650, Loss 31.828238, Loss rec 4.068118, loss rec t1 5.445060, loss kl 0.102313, loss_trans 0.002839, loss flux 11.026172, loss flux t1 11.183734\n",
      "Epoch 8/10, Batch 481/1650, Loss 29.563473, Loss rec 4.348164, loss rec t1 5.329635, loss kl 0.102647, loss_trans 0.002822, loss flux 10.317222, loss flux t1 9.462984\n",
      "Epoch 8/10, Batch 491/1650, Loss 32.094860, Loss rec 5.143210, loss rec t1 6.161868, loss kl 0.085459, loss_trans 0.002341, loss flux 11.094627, loss flux t1 9.607354\n",
      "Epoch 8/10, Batch 501/1650, Loss 34.285530, Loss rec 6.507040, loss rec t1 6.641425, loss kl 0.120573, loss_trans 0.003194, loss flux 10.720175, loss flux t1 10.293126\n",
      "Epoch 8/10, Batch 511/1650, Loss 38.086830, Loss rec 7.553384, loss rec t1 8.737969, loss kl 0.118016, loss_trans 0.004897, loss flux 11.362115, loss flux t1 10.310450\n",
      "Epoch 8/10, Batch 521/1650, Loss 34.458176, Loss rec 4.938980, loss rec t1 5.509465, loss kl 0.164139, loss_trans 0.006876, loss flux 12.438444, loss flux t1 11.400272\n",
      "Epoch 8/10, Batch 531/1650, Loss 30.317896, Loss rec 4.730745, loss rec t1 5.652900, loss kl 0.081987, loss_trans 0.003967, loss flux 10.351168, loss flux t1 9.497129\n",
      "Epoch 8/10, Batch 541/1650, Loss 29.950165, Loss rec 3.537117, loss rec t1 4.893130, loss kl 0.105344, loss_trans 0.003217, loss flux 11.348644, loss flux t1 10.062714\n",
      "Epoch 8/10, Batch 551/1650, Loss 35.668465, Loss rec 4.730899, loss rec t1 6.064130, loss kl 0.133816, loss_trans 0.006735, loss flux 13.111582, loss flux t1 11.621304\n",
      "Epoch 8/10, Batch 561/1650, Loss 33.770233, Loss rec 6.164954, loss rec t1 6.887315, loss kl 0.090912, loss_trans 0.002936, loss flux 10.212395, loss flux t1 10.411720\n",
      "Epoch 8/10, Batch 571/1650, Loss 30.602087, Loss rec 5.149749, loss rec t1 5.629736, loss kl 0.115976, loss_trans 0.003135, loss flux 10.071008, loss flux t1 9.632483\n",
      "Epoch 8/10, Batch 581/1650, Loss 33.989906, Loss rec 6.471088, loss rec t1 6.441515, loss kl 0.097810, loss_trans 0.003905, loss flux 10.722276, loss flux t1 10.253311\n",
      "Epoch 8/10, Batch 591/1650, Loss 31.871971, Loss rec 4.625015, loss rec t1 5.366771, loss kl 0.082043, loss_trans 0.002068, loss flux 11.690519, loss flux t1 10.105556\n",
      "Epoch 8/10, Batch 601/1650, Loss 39.222137, Loss rec 8.090990, loss rec t1 8.226571, loss kl 0.108142, loss_trans 0.008071, loss flux 11.895840, loss flux t1 10.892521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Batch 611/1650, Loss 34.594532, Loss rec 6.813635, loss rec t1 7.178503, loss kl 0.098021, loss_trans 0.004290, loss flux 10.600460, loss flux t1 9.899622\n",
      "Epoch 8/10, Batch 621/1650, Loss 37.608223, Loss rec 6.796296, loss rec t1 7.373880, loss kl 0.120792, loss_trans 0.002807, loss flux 12.289824, loss flux t1 11.024622\n",
      "Epoch 8/10, Batch 631/1650, Loss 36.727253, Loss rec 5.872508, loss rec t1 7.208718, loss kl 0.144820, loss_trans 0.006967, loss flux 12.308278, loss flux t1 11.185963\n",
      "Epoch 8/10, Batch 641/1650, Loss 38.042969, Loss rec 7.406665, loss rec t1 8.370907, loss kl 0.110430, loss_trans 0.004855, loss flux 10.941190, loss flux t1 11.208919\n",
      "Epoch 8/10, Batch 651/1650, Loss 36.535885, Loss rec 6.393328, loss rec t1 6.710571, loss kl 0.127985, loss_trans 0.005913, loss flux 11.920232, loss flux t1 11.377856\n",
      "Epoch 8/10, Batch 661/1650, Loss 35.333195, Loss rec 5.478695, loss rec t1 6.013921, loss kl 0.152885, loss_trans 0.006245, loss flux 12.154253, loss flux t1 11.527193\n",
      "Epoch 8/10, Batch 671/1650, Loss 42.187500, Loss rec 8.571066, loss rec t1 9.741879, loss kl 0.096462, loss_trans 0.005459, loss flux 12.642997, loss flux t1 11.129638\n",
      "Epoch 8/10, Batch 681/1650, Loss 38.025307, Loss rec 5.176190, loss rec t1 6.900220, loss kl 0.115291, loss_trans 0.002618, loss flux 13.034546, loss flux t1 12.796444\n",
      "Epoch 8/10, Batch 691/1650, Loss 42.570332, Loss rec 7.832117, loss rec t1 8.885473, loss kl 0.169739, loss_trans 0.005877, loss flux 12.702839, loss flux t1 12.974287\n",
      "Epoch 8/10, Batch 701/1650, Loss 72.544792, Loss rec 18.905785, loss rec t1 19.572170, loss kl 0.168732, loss_trans 0.010375, loss flux 17.683205, loss flux t1 16.204525\n",
      "Epoch 8/10, Batch 711/1650, Loss 53.708965, Loss rec 10.238024, loss rec t1 11.112163, loss kl 0.226166, loss_trans 0.005453, loss flux 16.126095, loss flux t1 16.001070\n",
      "Epoch 8/10, Batch 721/1650, Loss 39.722221, Loss rec 6.017889, loss rec t1 6.238282, loss kl 0.166486, loss_trans 0.003061, loss flux 13.671679, loss flux t1 13.624823\n",
      "Epoch 8/10, Batch 731/1650, Loss 37.963539, Loss rec 6.850042, loss rec t1 8.120490, loss kl 0.113510, loss_trans 0.005242, loss flux 11.322104, loss flux t1 11.552151\n",
      "Epoch 8/10, Batch 741/1650, Loss 35.301041, Loss rec 6.637923, loss rec t1 7.005844, loss kl 0.112021, loss_trans 0.005528, loss flux 10.623760, loss flux t1 10.915965\n",
      "Epoch 8/10, Batch 751/1650, Loss 34.388889, Loss rec 5.569193, loss rec t1 6.391692, loss kl 0.146050, loss_trans 0.004482, loss flux 11.381461, loss flux t1 10.896011\n",
      "Epoch 8/10, Batch 761/1650, Loss 40.362511, Loss rec 6.966508, loss rec t1 8.248020, loss kl 0.158611, loss_trans 0.011016, loss flux 12.807796, loss flux t1 12.170558\n",
      "Epoch 8/10, Batch 771/1650, Loss 39.407055, Loss rec 6.721903, loss rec t1 8.556995, loss kl 0.105366, loss_trans 0.003672, loss flux 12.406033, loss flux t1 11.613081\n",
      "Epoch 8/10, Batch 781/1650, Loss 39.646526, Loss rec 8.001468, loss rec t1 9.528366, loss kl 0.101157, loss_trans 0.002884, loss flux 11.302860, loss flux t1 10.709788\n",
      "Epoch 8/10, Batch 791/1650, Loss 37.640385, Loss rec 6.179610, loss rec t1 7.016859, loss kl 0.102644, loss_trans 0.006426, loss flux 12.665116, loss flux t1 11.669732\n",
      "Epoch 8/10, Batch 801/1650, Loss 36.220802, Loss rec 6.539350, loss rec t1 6.772472, loss kl 0.147414, loss_trans 0.004816, loss flux 11.201147, loss flux t1 11.555602\n",
      "Epoch 8/10, Batch 811/1650, Loss 40.844311, Loss rec 6.697794, loss rec t1 8.439546, loss kl 0.161494, loss_trans 0.004390, loss flux 13.244689, loss flux t1 12.296396\n",
      "Epoch 8/10, Batch 821/1650, Loss 32.965816, Loss rec 5.850141, loss rec t1 6.022017, loss kl 0.110879, loss_trans 0.004740, loss flux 10.529510, loss flux t1 10.448529\n",
      "Epoch 8/10, Batch 831/1650, Loss 30.404385, Loss rec 4.967562, loss rec t1 5.625210, loss kl 0.177515, loss_trans 0.005372, loss flux 10.511828, loss flux t1 9.116899\n",
      "Epoch 8/10, Batch 841/1650, Loss 28.250317, Loss rec 5.107850, loss rec t1 6.001041, loss kl 0.078118, loss_trans 0.003548, loss flux 8.930844, loss flux t1 8.128915\n",
      "Epoch 8/10, Batch 851/1650, Loss 35.602432, Loss rec 6.530582, loss rec t1 7.424671, loss kl 0.118105, loss_trans 0.005611, loss flux 10.799109, loss flux t1 10.724353\n",
      "Epoch 8/10, Batch 861/1650, Loss 32.515583, Loss rec 5.019107, loss rec t1 5.808220, loss kl 0.159801, loss_trans 0.006022, loss flux 11.195806, loss flux t1 10.326625\n",
      "Epoch 8/10, Batch 871/1650, Loss 34.801300, Loss rec 6.071068, loss rec t1 6.224577, loss kl 0.135377, loss_trans 0.004264, loss flux 11.365184, loss flux t1 11.000829\n",
      "Epoch 8/10, Batch 881/1650, Loss 35.128181, Loss rec 5.032473, loss rec t1 6.771852, loss kl 0.117990, loss_trans 0.004904, loss flux 11.560080, loss flux t1 11.640880\n",
      "Epoch 8/10, Batch 891/1650, Loss 33.463188, Loss rec 4.663630, loss rec t1 5.567627, loss kl 0.112288, loss_trans 0.003577, loss flux 11.539750, loss flux t1 11.576314\n",
      "Epoch 8/10, Batch 901/1650, Loss 33.409958, Loss rec 5.685787, loss rec t1 7.260151, loss kl 0.147583, loss_trans 0.003876, loss flux 10.059153, loss flux t1 10.253407\n",
      "Epoch 8/10, Batch 911/1650, Loss 28.691656, Loss rec 4.198726, loss rec t1 5.453503, loss kl 0.102328, loss_trans 0.002759, loss flux 9.548731, loss flux t1 9.385608\n",
      "Epoch 8/10, Batch 921/1650, Loss 31.541122, Loss rec 4.904037, loss rec t1 6.250975, loss kl 0.113670, loss_trans 0.004431, loss flux 10.139841, loss flux t1 10.128168\n",
      "Epoch 8/10, Batch 931/1650, Loss 35.989040, Loss rec 7.699755, loss rec t1 8.451281, loss kl 0.112358, loss_trans 0.003613, loss flux 9.680347, loss flux t1 10.041688\n",
      "Epoch 8/10, Batch 941/1650, Loss 37.210979, Loss rec 5.798589, loss rec t1 6.920417, loss kl 0.153538, loss_trans 0.004875, loss flux 12.497658, loss flux t1 11.835902\n",
      "Epoch 8/10, Batch 951/1650, Loss 33.580856, Loss rec 4.679647, loss rec t1 5.187955, loss kl 0.103424, loss_trans 0.002952, loss flux 11.211379, loss flux t1 12.395498\n",
      "Epoch 8/10, Batch 961/1650, Loss 39.351257, Loss rec 6.243021, loss rec t1 6.846616, loss kl 0.075434, loss_trans 0.002537, loss flux 14.433741, loss flux t1 11.749909\n",
      "Epoch 8/10, Batch 971/1650, Loss 65.982437, Loss rec 18.653130, loss rec t1 16.783094, loss kl 0.082501, loss_trans 0.005014, loss flux 16.451252, loss flux t1 14.007448\n",
      "Epoch 8/10, Batch 981/1650, Loss 45.603775, Loss rec 9.669647, loss rec t1 8.866472, loss kl 0.096258, loss_trans 0.005249, loss flux 14.401735, loss flux t1 12.564414\n",
      "Epoch 8/10, Batch 991/1650, Loss 43.112381, Loss rec 6.266149, loss rec t1 6.801031, loss kl 0.088169, loss_trans 0.002897, loss flux 16.099535, loss flux t1 13.854597\n",
      "Epoch 8/10, Batch 1001/1650, Loss 41.749699, Loss rec 7.956017, loss rec t1 8.335471, loss kl 0.149726, loss_trans 0.005949, loss flux 12.849963, loss flux t1 12.452574\n",
      "Epoch 8/10, Batch 1011/1650, Loss 47.540260, Loss rec 10.920404, loss rec t1 12.055285, loss kl 0.101586, loss_trans 0.005293, loss flux 12.829494, loss flux t1 11.628199\n",
      "Epoch 8/10, Batch 1021/1650, Loss 34.295597, Loss rec 6.372501, loss rec t1 6.289245, loss kl 0.099392, loss_trans 0.002841, loss flux 10.778032, loss flux t1 10.753586\n",
      "Epoch 8/10, Batch 1031/1650, Loss 36.310932, Loss rec 7.046615, loss rec t1 7.114726, loss kl 0.161828, loss_trans 0.005873, loss flux 10.812017, loss flux t1 11.169871\n",
      "Epoch 8/10, Batch 1041/1650, Loss 33.840519, Loss rec 6.259508, loss rec t1 7.022840, loss kl 0.104100, loss_trans 0.004155, loss flux 10.501513, loss flux t1 9.948403\n",
      "Epoch 8/10, Batch 1051/1650, Loss 32.939541, Loss rec 5.973267, loss rec t1 6.098141, loss kl 0.093891, loss_trans 0.003496, loss flux 10.851501, loss flux t1 9.919243\n",
      "Epoch 8/10, Batch 1061/1650, Loss 39.356152, Loss rec 6.650543, loss rec t1 7.689986, loss kl 0.141488, loss_trans 0.005902, loss flux 12.276002, loss flux t1 12.592230\n",
      "Epoch 8/10, Batch 1071/1650, Loss 36.161228, Loss rec 4.954030, loss rec t1 5.909194, loss kl 0.164631, loss_trans 0.004596, loss flux 12.729363, loss flux t1 12.399414\n",
      "Epoch 8/10, Batch 1081/1650, Loss 38.981903, Loss rec 8.972649, loss rec t1 8.913774, loss kl 0.119750, loss_trans 0.005022, loss flux 10.634054, loss flux t1 10.336653\n",
      "Epoch 8/10, Batch 1091/1650, Loss 35.547745, Loss rec 5.000713, loss rec t1 5.543243, loss kl 0.079594, loss_trans 0.002514, loss flux 13.256013, loss flux t1 11.665666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Batch 1101/1650, Loss 33.109310, Loss rec 4.447235, loss rec t1 5.075871, loss kl 0.106734, loss_trans 0.004213, loss flux 12.668072, loss flux t1 10.807188\n",
      "Epoch 8/10, Batch 1111/1650, Loss 35.939919, Loss rec 5.016012, loss rec t1 4.697186, loss kl 0.108937, loss_trans 0.007646, loss flux 15.179297, loss flux t1 10.930841\n",
      "Epoch 8/10, Batch 1121/1650, Loss 36.354542, Loss rec 5.826258, loss rec t1 5.981583, loss kl 0.143372, loss_trans 0.004161, loss flux 12.276896, loss flux t1 12.122272\n",
      "Epoch 8/10, Batch 1131/1650, Loss 35.276459, Loss rec 6.586740, loss rec t1 6.729846, loss kl 0.196526, loss_trans 0.009508, loss flux 11.053494, loss flux t1 10.700344\n",
      "Epoch 8/10, Batch 1141/1650, Loss 36.220474, Loss rec 6.280298, loss rec t1 7.085526, loss kl 0.125223, loss_trans 0.004862, loss flux 12.410810, loss flux t1 10.313753\n",
      "Epoch 8/10, Batch 1151/1650, Loss 34.011154, Loss rec 6.084036, loss rec t1 6.947643, loss kl 0.159092, loss_trans 0.004274, loss flux 10.401083, loss flux t1 10.415028\n",
      "Epoch 8/10, Batch 1161/1650, Loss 36.218521, Loss rec 6.558492, loss rec t1 7.835980, loss kl 0.111644, loss_trans 0.005823, loss flux 10.987431, loss flux t1 10.719154\n",
      "Epoch 8/10, Batch 1171/1650, Loss 33.066696, Loss rec 5.546017, loss rec t1 6.279361, loss kl 0.105376, loss_trans 0.003136, loss flux 11.089009, loss flux t1 10.043797\n",
      "Epoch 8/10, Batch 1181/1650, Loss 37.388611, Loss rec 6.438338, loss rec t1 7.630481, loss kl 0.184072, loss_trans 0.005093, loss flux 11.361840, loss flux t1 11.768787\n",
      "Epoch 8/10, Batch 1191/1650, Loss 36.866585, Loss rec 7.031511, loss rec t1 7.609285, loss kl 0.142381, loss_trans 0.006348, loss flux 11.246075, loss flux t1 10.830986\n",
      "Epoch 8/10, Batch 1201/1650, Loss 32.049038, Loss rec 4.917648, loss rec t1 6.232201, loss kl 0.117884, loss_trans 0.005437, loss flux 10.947647, loss flux t1 9.828220\n",
      "Epoch 8/10, Batch 1211/1650, Loss 37.845348, Loss rec 7.152572, loss rec t1 8.478748, loss kl 0.143783, loss_trans 0.005062, loss flux 10.977103, loss flux t1 11.088078\n",
      "Epoch 8/10, Batch 1221/1650, Loss 33.418957, Loss rec 4.757952, loss rec t1 5.742784, loss kl 0.122607, loss_trans 0.002541, loss flux 11.609232, loss flux t1 11.183842\n",
      "Epoch 8/10, Batch 1231/1650, Loss 31.637758, Loss rec 4.488932, loss rec t1 5.420378, loss kl 0.114560, loss_trans 0.003198, loss flux 10.953661, loss flux t1 10.657029\n",
      "Epoch 8/10, Batch 1241/1650, Loss 28.945875, Loss rec 4.465088, loss rec t1 4.900673, loss kl 0.119613, loss_trans 0.003350, loss flux 9.954750, loss flux t1 9.502401\n",
      "Epoch 8/10, Batch 1251/1650, Loss 30.314512, Loss rec 5.239263, loss rec t1 5.532382, loss kl 0.090367, loss_trans 0.003047, loss flux 9.743875, loss flux t1 9.705580\n",
      "Epoch 8/10, Batch 1261/1650, Loss 33.556770, Loss rec 6.817466, loss rec t1 7.088311, loss kl 0.091032, loss_trans 0.005313, loss flux 9.735153, loss flux t1 9.819494\n",
      "Epoch 8/10, Batch 1271/1650, Loss 33.551723, Loss rec 6.740944, loss rec t1 7.224655, loss kl 0.105258, loss_trans 0.007085, loss flux 9.785417, loss flux t1 9.688364\n",
      "Epoch 8/10, Batch 1281/1650, Loss 29.594400, Loss rec 4.202714, loss rec t1 5.114938, loss kl 0.123045, loss_trans 0.003107, loss flux 10.462409, loss flux t1 9.688186\n",
      "Epoch 8/10, Batch 1291/1650, Loss 27.840914, Loss rec 3.494691, loss rec t1 4.550204, loss kl 0.087095, loss_trans 0.003709, loss flux 10.045111, loss flux t1 9.660103\n",
      "Epoch 8/10, Batch 1301/1650, Loss 30.174421, Loss rec 4.870431, loss rec t1 5.547345, loss kl 0.106762, loss_trans 0.003877, loss flux 9.982492, loss flux t1 9.663513\n",
      "Epoch 8/10, Batch 1311/1650, Loss 33.923500, Loss rec 4.935610, loss rec t1 5.630342, loss kl 0.106250, loss_trans 0.004895, loss flux 12.420845, loss flux t1 10.825557\n",
      "Epoch 8/10, Batch 1321/1650, Loss 36.166073, Loss rec 6.230723, loss rec t1 7.030142, loss kl 0.151879, loss_trans 0.006054, loss flux 11.628643, loss flux t1 11.118631\n",
      "Epoch 8/10, Batch 1331/1650, Loss 34.348351, Loss rec 6.440030, loss rec t1 6.756987, loss kl 0.094556, loss_trans 0.006837, loss flux 10.878017, loss flux t1 10.171923\n",
      "Epoch 8/10, Batch 1341/1650, Loss 28.028246, Loss rec 3.403253, loss rec t1 4.584613, loss kl 0.130490, loss_trans 0.004270, loss flux 9.820000, loss flux t1 10.085622\n",
      "Epoch 8/10, Batch 1351/1650, Loss 26.981007, Loss rec 4.007537, loss rec t1 4.815016, loss kl 0.074391, loss_trans 0.002525, loss flux 8.789270, loss flux t1 9.292266\n",
      "Epoch 8/10, Batch 1361/1650, Loss 34.184189, Loss rec 5.763641, loss rec t1 6.872032, loss kl 0.174422, loss_trans 0.007179, loss flux 11.093103, loss flux t1 10.273810\n",
      "Epoch 8/10, Batch 1371/1650, Loss 28.996544, Loss rec 3.332376, loss rec t1 4.459768, loss kl 0.117935, loss_trans 0.004534, loss flux 10.854999, loss flux t1 10.226933\n",
      "Epoch 8/10, Batch 1381/1650, Loss 34.870502, Loss rec 7.071613, loss rec t1 7.426688, loss kl 0.131262, loss_trans 0.002989, loss flux 10.163594, loss flux t1 10.074356\n",
      "Epoch 8/10, Batch 1391/1650, Loss 33.536037, Loss rec 4.893559, loss rec t1 5.869729, loss kl 0.174589, loss_trans 0.005943, loss flux 11.515070, loss flux t1 11.077146\n",
      "Epoch 8/10, Batch 1401/1650, Loss 48.062450, Loss rec 8.342823, loss rec t1 8.838025, loss kl 0.100408, loss_trans 0.003430, loss flux 16.754698, loss flux t1 14.023067\n",
      "Epoch 8/10, Batch 1411/1650, Loss 38.951111, Loss rec 6.492568, loss rec t1 7.061706, loss kl 0.118992, loss_trans 0.005586, loss flux 13.111178, loss flux t1 12.161081\n",
      "Epoch 8/10, Batch 1421/1650, Loss 36.088161, Loss rec 5.655035, loss rec t1 5.941524, loss kl 0.109945, loss_trans 0.004799, loss flux 12.550082, loss flux t1 11.826776\n",
      "Epoch 8/10, Batch 1431/1650, Loss 33.225571, Loss rec 5.357079, loss rec t1 5.496477, loss kl 0.121019, loss_trans 0.004305, loss flux 11.608629, loss flux t1 10.638061\n",
      "Epoch 8/10, Batch 1441/1650, Loss 42.477047, Loss rec 7.025798, loss rec t1 7.988811, loss kl 0.175672, loss_trans 0.006514, loss flux 14.207717, loss flux t1 13.072538\n",
      "Epoch 8/10, Batch 1451/1650, Loss 32.513588, Loss rec 5.698819, loss rec t1 6.500647, loss kl 0.115937, loss_trans 0.006630, loss flux 10.466596, loss flux t1 9.724960\n",
      "Epoch 8/10, Batch 1461/1650, Loss 30.528048, Loss rec 4.365234, loss rec t1 5.657165, loss kl 0.107228, loss_trans 0.003725, loss flux 10.571139, loss flux t1 9.823558\n",
      "Epoch 8/10, Batch 1471/1650, Loss 32.778267, Loss rec 5.800233, loss rec t1 6.129283, loss kl 0.134976, loss_trans 0.003932, loss flux 10.204339, loss flux t1 10.505505\n",
      "Epoch 8/10, Batch 1481/1650, Loss 33.420883, Loss rec 6.614438, loss rec t1 6.908860, loss kl 0.112955, loss_trans 0.003052, loss flux 10.208046, loss flux t1 9.573534\n",
      "Epoch 8/10, Batch 1491/1650, Loss 48.054600, Loss rec 11.109444, loss rec t1 11.398600, loss kl 0.163958, loss_trans 0.005019, loss flux 12.669084, loss flux t1 12.708495\n",
      "Epoch 8/10, Batch 1501/1650, Loss 42.425396, Loss rec 8.641528, loss rec t1 9.059192, loss kl 0.168946, loss_trans 0.007610, loss flux 12.351847, loss flux t1 12.196273\n",
      "Epoch 8/10, Batch 1511/1650, Loss 43.617397, Loss rec 7.910109, loss rec t1 8.556761, loss kl 0.088771, loss_trans 0.004758, loss flux 14.345002, loss flux t1 12.711996\n",
      "Epoch 8/10, Batch 1521/1650, Loss 34.721725, Loss rec 6.220920, loss rec t1 7.249277, loss kl 0.122532, loss_trans 0.002878, loss flux 10.701243, loss flux t1 10.424878\n",
      "Epoch 8/10, Batch 1531/1650, Loss 41.669212, Loss rec 9.962439, loss rec t1 11.549652, loss kl 0.113491, loss_trans 0.005229, loss flux 9.990672, loss flux t1 10.047730\n",
      "Epoch 8/10, Batch 1541/1650, Loss 33.900368, Loss rec 4.933095, loss rec t1 5.666155, loss kl 0.151299, loss_trans 0.005348, loss flux 11.629334, loss flux t1 11.515135\n",
      "Epoch 8/10, Batch 1551/1650, Loss 30.771721, Loss rec 4.792590, loss rec t1 5.875729, loss kl 0.082694, loss_trans 0.003296, loss flux 10.085274, loss flux t1 9.932137\n",
      "Epoch 8/10, Batch 1561/1650, Loss 35.174843, Loss rec 6.462438, loss rec t1 6.683570, loss kl 0.167565, loss_trans 0.005546, loss flux 10.844412, loss flux t1 11.011313\n",
      "Epoch 8/10, Batch 1571/1650, Loss 31.600664, Loss rec 4.167861, loss rec t1 5.040862, loss kl 0.167317, loss_trans 0.004847, loss flux 11.331592, loss flux t1 10.888186\n",
      "Epoch 8/10, Batch 1581/1650, Loss 27.339703, Loss rec 4.294123, loss rec t1 4.716540, loss kl 0.091038, loss_trans 0.002625, loss flux 9.376047, loss flux t1 8.859330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Batch 1591/1650, Loss 29.463459, Loss rec 4.825478, loss rec t1 5.495316, loss kl 0.135348, loss_trans 0.004135, loss flux 9.805448, loss flux t1 9.197736\n",
      "Epoch 8/10, Batch 1601/1650, Loss 28.581394, Loss rec 5.052549, loss rec t1 5.797520, loss kl 0.059579, loss_trans 0.004550, loss flux 8.847243, loss flux t1 8.819949\n",
      "Epoch 8/10, Batch 1611/1650, Loss 27.333212, Loss rec 3.310284, loss rec t1 4.354785, loss kl 0.089070, loss_trans 0.003421, loss flux 9.974595, loss flux t1 9.601060\n",
      "Epoch 8/10, Batch 1621/1650, Loss 27.417160, Loss rec 3.808968, loss rec t1 4.370664, loss kl 0.132026, loss_trans 0.003934, loss flux 9.866518, loss flux t1 9.235052\n",
      "Epoch 8/10, Batch 1631/1650, Loss 30.094463, Loss rec 6.044305, loss rec t1 6.790112, loss kl 0.079999, loss_trans 0.007084, loss flux 8.789950, loss flux t1 8.383013\n",
      "Epoch 8/10, Batch 1641/1650, Loss 31.350323, Loss rec 5.417386, loss rec t1 5.799251, loss kl 0.140178, loss_trans 0.003940, loss flux 10.505645, loss flux t1 9.483924\n",
      "Epoch 8/10, Train loss 27.354156, Eval loss 35.371304\n",
      "Epoch 9/10, Batch 1/1650, Loss 31.840363, Loss rec 4.424487, loss rec t1 5.534213, loss kl 0.154788, loss_trans 0.003209, loss flux 11.115101, loss flux t1 10.608566\n",
      "Epoch 9/10, Batch 11/1650, Loss 33.876659, Loss rec 5.208707, loss rec t1 6.578992, loss kl 0.147125, loss_trans 0.002824, loss flux 10.660904, loss flux t1 11.278109\n",
      "Epoch 9/10, Batch 21/1650, Loss 34.121258, Loss rec 6.713793, loss rec t1 7.259141, loss kl 0.097757, loss_trans 0.006466, loss flux 10.372863, loss flux t1 9.671238\n",
      "Epoch 9/10, Batch 31/1650, Loss 32.499199, Loss rec 5.683322, loss rec t1 6.816629, loss kl 0.084697, loss_trans 0.002996, loss flux 10.084681, loss flux t1 9.826876\n",
      "Epoch 9/10, Batch 41/1650, Loss 30.717196, Loss rec 5.148727, loss rec t1 5.723290, loss kl 0.094257, loss_trans 0.003492, loss flux 10.008731, loss flux t1 9.738696\n",
      "Epoch 9/10, Batch 51/1650, Loss 30.003958, Loss rec 4.942995, loss rec t1 5.435555, loss kl 0.086467, loss_trans 0.002932, loss flux 9.651233, loss flux t1 9.884777\n",
      "Epoch 9/10, Batch 61/1650, Loss 39.075401, Loss rec 7.081513, loss rec t1 8.259230, loss kl 0.146826, loss_trans 0.008094, loss flux 12.245233, loss flux t1 11.334507\n",
      "Epoch 9/10, Batch 71/1650, Loss 33.902874, Loss rec 6.012219, loss rec t1 5.840782, loss kl 0.145743, loss_trans 0.003623, loss flux 11.250526, loss flux t1 10.649979\n",
      "Epoch 9/10, Batch 81/1650, Loss 32.218754, Loss rec 5.857196, loss rec t1 6.415804, loss kl 0.084358, loss_trans 0.003844, loss flux 9.861128, loss flux t1 9.996421\n",
      "Epoch 9/10, Batch 91/1650, Loss 34.161263, Loss rec 6.200686, loss rec t1 6.503061, loss kl 0.109059, loss_trans 0.005879, loss flux 10.731180, loss flux t1 10.611400\n",
      "Epoch 9/10, Batch 101/1650, Loss 33.913368, Loss rec 6.739962, loss rec t1 7.674213, loss kl 0.084897, loss_trans 0.002982, loss flux 9.724757, loss flux t1 9.686556\n",
      "Epoch 9/10, Batch 111/1650, Loss 39.900406, Loss rec 6.520951, loss rec t1 8.182892, loss kl 0.165247, loss_trans 0.005042, loss flux 13.099528, loss flux t1 11.926744\n",
      "Epoch 9/10, Batch 121/1650, Loss 35.259563, Loss rec 6.335787, loss rec t1 7.339065, loss kl 0.144667, loss_trans 0.005249, loss flux 10.342029, loss flux t1 11.092766\n",
      "Epoch 9/10, Batch 131/1650, Loss 29.205988, Loss rec 5.141879, loss rec t1 5.632768, loss kl 0.069784, loss_trans 0.001788, loss flux 9.282229, loss flux t1 9.077541\n",
      "Epoch 9/10, Batch 141/1650, Loss 27.812859, Loss rec 4.313886, loss rec t1 5.673724, loss kl 0.087122, loss_trans 0.003674, loss flux 8.771725, loss flux t1 8.962729\n",
      "Epoch 9/10, Batch 151/1650, Loss 36.858555, Loss rec 6.405769, loss rec t1 6.536575, loss kl 0.164192, loss_trans 0.004717, loss flux 11.742289, loss flux t1 12.005009\n",
      "Epoch 9/10, Batch 161/1650, Loss 36.500092, Loss rec 6.701221, loss rec t1 7.390078, loss kl 0.166840, loss_trans 0.004577, loss flux 11.781281, loss flux t1 10.456094\n",
      "Epoch 9/10, Batch 171/1650, Loss 44.672981, Loss rec 8.577360, loss rec t1 8.897987, loss kl 0.163228, loss_trans 0.004577, loss flux 13.757901, loss flux t1 13.271925\n",
      "Epoch 9/10, Batch 181/1650, Loss 30.362539, Loss rec 4.764505, loss rec t1 5.263929, loss kl 0.084148, loss_trans 0.002862, loss flux 11.484159, loss flux t1 8.762936\n",
      "Epoch 9/10, Batch 191/1650, Loss 33.972099, Loss rec 5.447388, loss rec t1 6.057732, loss kl 0.148717, loss_trans 0.005535, loss flux 11.155324, loss flux t1 11.157404\n",
      "Epoch 9/10, Batch 201/1650, Loss 41.887749, Loss rec 7.802950, loss rec t1 8.336111, loss kl 0.084445, loss_trans 0.003449, loss flux 13.866439, loss flux t1 11.794354\n",
      "Epoch 9/10, Batch 211/1650, Loss 40.274918, Loss rec 7.164532, loss rec t1 9.222004, loss kl 0.062496, loss_trans 0.002607, loss flux 11.357843, loss flux t1 12.465431\n",
      "Epoch 9/10, Batch 221/1650, Loss 38.023483, Loss rec 6.505695, loss rec t1 7.816826, loss kl 0.114535, loss_trans 0.002280, loss flux 12.232788, loss flux t1 11.351357\n",
      "Epoch 9/10, Batch 231/1650, Loss 36.357037, Loss rec 6.295464, loss rec t1 7.321168, loss kl 0.146372, loss_trans 0.004086, loss flux 12.367512, loss flux t1 10.222435\n",
      "Epoch 9/10, Batch 241/1650, Loss 34.271702, Loss rec 6.123909, loss rec t1 6.097215, loss kl 0.102960, loss_trans 0.004911, loss flux 11.516811, loss flux t1 10.425899\n",
      "Epoch 9/10, Batch 251/1650, Loss 34.073765, Loss rec 6.740618, loss rec t1 6.995418, loss kl 0.126095, loss_trans 0.008761, loss flux 10.388470, loss flux t1 9.814403\n",
      "Epoch 9/10, Batch 261/1650, Loss 30.992081, Loss rec 5.435520, loss rec t1 5.909464, loss kl 0.089282, loss_trans 0.002602, loss flux 9.665118, loss flux t1 9.890095\n",
      "Epoch 9/10, Batch 271/1650, Loss 34.127148, Loss rec 5.800083, loss rec t1 6.333522, loss kl 0.133114, loss_trans 0.003605, loss flux 10.774283, loss flux t1 11.082538\n",
      "Epoch 9/10, Batch 281/1650, Loss 41.319450, Loss rec 9.404459, loss rec t1 10.584669, loss kl 0.112238, loss_trans 0.004646, loss flux 11.169146, loss flux t1 10.044293\n",
      "Epoch 9/10, Batch 291/1650, Loss 34.849899, Loss rec 5.779334, loss rec t1 6.532906, loss kl 0.139390, loss_trans 0.003760, loss flux 11.461177, loss flux t1 10.933333\n",
      "Epoch 9/10, Batch 301/1650, Loss 29.492489, Loss rec 5.285153, loss rec t1 6.301531, loss kl 0.082919, loss_trans 0.002891, loss flux 9.274196, loss flux t1 8.545801\n",
      "Epoch 9/10, Batch 311/1650, Loss 29.403519, Loss rec 3.836328, loss rec t1 4.646495, loss kl 0.095393, loss_trans 0.002632, loss flux 10.297834, loss flux t1 10.524837\n",
      "Epoch 9/10, Batch 321/1650, Loss 34.468666, Loss rec 6.035129, loss rec t1 6.079458, loss kl 0.123822, loss_trans 0.003368, loss flux 11.474323, loss flux t1 10.752563\n",
      "Epoch 9/10, Batch 331/1650, Loss 30.805473, Loss rec 5.271858, loss rec t1 5.867251, loss kl 0.077622, loss_trans 0.003292, loss flux 9.940545, loss flux t1 9.644906\n",
      "Epoch 9/10, Batch 341/1650, Loss 38.355717, Loss rec 7.174788, loss rec t1 8.106403, loss kl 0.119069, loss_trans 0.005328, loss flux 11.680196, loss flux t1 11.269932\n",
      "Epoch 9/10, Batch 351/1650, Loss 38.582779, Loss rec 7.230251, loss rec t1 7.773829, loss kl 0.161323, loss_trans 0.003654, loss flux 11.536328, loss flux t1 11.877390\n",
      "Epoch 9/10, Batch 361/1650, Loss 33.766411, Loss rec 5.683836, loss rec t1 6.088828, loss kl 0.104788, loss_trans 0.003575, loss flux 11.385664, loss flux t1 10.499719\n",
      "Epoch 9/10, Batch 371/1650, Loss 38.810501, Loss rec 7.028478, loss rec t1 7.046952, loss kl 0.156916, loss_trans 0.007959, loss flux 13.233806, loss flux t1 11.336393\n",
      "Epoch 9/10, Batch 381/1650, Loss 39.381985, Loss rec 6.125426, loss rec t1 7.547759, loss kl 0.110601, loss_trans 0.003168, loss flux 13.331285, loss flux t1 12.263743\n",
      "Epoch 9/10, Batch 391/1650, Loss 34.080311, Loss rec 5.640413, loss rec t1 6.037292, loss kl 0.120369, loss_trans 0.002548, loss flux 11.619811, loss flux t1 10.659878\n",
      "Epoch 9/10, Batch 401/1650, Loss 31.379086, Loss rec 5.221894, loss rec t1 6.280704, loss kl 0.074292, loss_trans 0.004562, loss flux 9.899819, loss flux t1 9.897815\n",
      "Epoch 9/10, Batch 411/1650, Loss 36.207024, Loss rec 5.845115, loss rec t1 6.428648, loss kl 0.166675, loss_trans 0.007888, loss flux 12.328358, loss flux t1 11.430339\n",
      "Epoch 9/10, Batch 421/1650, Loss 35.491947, Loss rec 6.520517, loss rec t1 7.271799, loss kl 0.147617, loss_trans 0.007808, loss flux 11.195155, loss flux t1 10.349051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Batch 431/1650, Loss 27.302624, Loss rec 3.718771, loss rec t1 4.511298, loss kl 0.127639, loss_trans 0.002495, loss flux 10.010719, loss flux t1 8.931701\n",
      "Epoch 9/10, Batch 441/1650, Loss 42.303379, Loss rec 8.797833, loss rec t1 9.348859, loss kl 0.128542, loss_trans 0.004314, loss flux 12.354812, loss flux t1 11.669017\n",
      "Epoch 9/10, Batch 451/1650, Loss 32.330235, Loss rec 5.923780, loss rec t1 6.378489, loss kl 0.098544, loss_trans 0.005399, loss flux 10.383407, loss flux t1 9.540615\n",
      "Epoch 9/10, Batch 461/1650, Loss 35.926193, Loss rec 7.467393, loss rec t1 7.232631, loss kl 0.094212, loss_trans 0.003852, loss flux 11.231580, loss flux t1 9.896522\n",
      "Epoch 9/10, Batch 471/1650, Loss 27.559761, Loss rec 3.513164, loss rec t1 4.436289, loss kl 0.097148, loss_trans 0.002915, loss flux 9.754862, loss flux t1 9.755382\n",
      "Epoch 9/10, Batch 481/1650, Loss 27.880253, Loss rec 4.287512, loss rec t1 5.173968, loss kl 0.099256, loss_trans 0.002535, loss flux 9.450092, loss flux t1 8.866892\n",
      "Epoch 9/10, Batch 491/1650, Loss 31.407637, Loss rec 4.947698, loss rec t1 5.918938, loss kl 0.078621, loss_trans 0.002231, loss flux 10.516624, loss flux t1 9.943525\n",
      "Epoch 9/10, Batch 501/1650, Loss 33.963570, Loss rec 6.023200, loss rec t1 6.240888, loss kl 0.116819, loss_trans 0.003021, loss flux 10.859214, loss flux t1 10.720427\n",
      "Epoch 9/10, Batch 511/1650, Loss 35.802345, Loss rec 7.401006, loss rec t1 8.466463, loss kl 0.114383, loss_trans 0.004316, loss flux 10.458560, loss flux t1 9.357619\n",
      "Epoch 9/10, Batch 521/1650, Loss 40.981289, Loss rec 7.587733, loss rec t1 8.508842, loss kl 0.150784, loss_trans 0.005833, loss flux 13.378582, loss flux t1 11.349514\n",
      "Epoch 9/10, Batch 531/1650, Loss 30.531176, Loss rec 4.910886, loss rec t1 6.044063, loss kl 0.082370, loss_trans 0.004329, loss flux 10.291532, loss flux t1 9.197998\n",
      "Epoch 9/10, Batch 541/1650, Loss 32.766014, Loss rec 4.091311, loss rec t1 5.917713, loss kl 0.105859, loss_trans 0.003679, loss flux 11.133919, loss flux t1 11.513535\n",
      "Epoch 9/10, Batch 551/1650, Loss 44.786266, Loss rec 7.588367, loss rec t1 10.350883, loss kl 0.136937, loss_trans 0.006152, loss flux 13.194970, loss flux t1 13.508957\n",
      "Epoch 9/10, Batch 561/1650, Loss 34.642712, Loss rec 5.996392, loss rec t1 7.040972, loss kl 0.089524, loss_trans 0.003397, loss flux 10.736970, loss flux t1 10.775456\n",
      "Epoch 9/10, Batch 571/1650, Loss 34.950657, Loss rec 5.849229, loss rec t1 6.516419, loss kl 0.118592, loss_trans 0.003790, loss flux 11.575466, loss flux t1 10.887161\n",
      "Epoch 9/10, Batch 581/1650, Loss 40.512794, Loss rec 8.674816, loss rec t1 8.410990, loss kl 0.096165, loss_trans 0.004372, loss flux 11.834170, loss flux t1 11.492284\n",
      "Epoch 9/10, Batch 591/1650, Loss 58.537804, Loss rec 16.593630, loss rec t1 18.400257, loss kl 0.084694, loss_trans 0.002272, loss flux 11.592398, loss flux t1 11.864551\n",
      "Epoch 9/10, Batch 601/1650, Loss 61.788307, Loss rec 17.945999, loss rec t1 15.603071, loss kl 0.117975, loss_trans 0.009042, loss flux 15.200870, loss flux t1 12.911348\n",
      "Epoch 9/10, Batch 611/1650, Loss 41.525391, Loss rec 8.131405, loss rec t1 8.046669, loss kl 0.104596, loss_trans 0.005586, loss flux 12.672100, loss flux t1 12.565036\n",
      "Epoch 9/10, Batch 621/1650, Loss 44.381432, Loss rec 8.645441, loss rec t1 8.314526, loss kl 0.121213, loss_trans 0.004174, loss flux 14.656991, loss flux t1 12.639086\n",
      "Epoch 9/10, Batch 631/1650, Loss 44.488743, Loss rec 7.618480, loss rec t1 8.607145, loss kl 0.143911, loss_trans 0.007216, loss flux 15.160329, loss flux t1 12.951660\n",
      "Epoch 9/10, Batch 641/1650, Loss 40.227856, Loss rec 8.388168, loss rec t1 8.523977, loss kl 0.112255, loss_trans 0.005665, loss flux 11.982412, loss flux t1 11.215380\n",
      "Epoch 9/10, Batch 651/1650, Loss 41.079018, Loss rec 7.516592, loss rec t1 8.684978, loss kl 0.128019, loss_trans 0.007013, loss flux 13.011344, loss flux t1 11.731070\n",
      "Epoch 9/10, Batch 661/1650, Loss 37.291958, Loss rec 5.860402, loss rec t1 6.518190, loss kl 0.156516, loss_trans 0.006806, loss flux 12.843259, loss flux t1 11.906787\n",
      "Epoch 9/10, Batch 671/1650, Loss 37.149090, Loss rec 6.939819, loss rec t1 7.210115, loss kl 0.095978, loss_trans 0.006506, loss flux 12.161825, loss flux t1 10.734844\n",
      "Epoch 9/10, Batch 681/1650, Loss 33.619705, Loss rec 4.032967, loss rec t1 5.535343, loss kl 0.115712, loss_trans 0.003103, loss flux 12.263486, loss flux t1 11.669092\n",
      "Epoch 9/10, Batch 691/1650, Loss 42.148689, Loss rec 8.250683, loss rec t1 8.293917, loss kl 0.170782, loss_trans 0.006032, loss flux 13.526195, loss flux t1 11.901081\n",
      "Epoch 9/10, Batch 701/1650, Loss 38.548763, Loss rec 6.606671, loss rec t1 7.678884, loss kl 0.162647, loss_trans 0.008855, loss flux 11.903623, loss flux t1 12.188083\n",
      "Epoch 9/10, Batch 711/1650, Loss 45.036263, Loss rec 8.922323, loss rec t1 9.143727, loss kl 0.212539, loss_trans 0.005270, loss flux 13.323730, loss flux t1 13.428672\n",
      "Epoch 9/10, Batch 721/1650, Loss 32.418751, Loss rec 4.740534, loss rec t1 5.554505, loss kl 0.162724, loss_trans 0.002383, loss flux 11.277749, loss flux t1 10.680854\n",
      "Epoch 9/10, Batch 731/1650, Loss 33.679710, Loss rec 5.780080, loss rec t1 7.013518, loss kl 0.108350, loss_trans 0.005104, loss flux 10.822762, loss flux t1 9.949895\n",
      "Epoch 9/10, Batch 741/1650, Loss 32.015381, Loss rec 5.624567, loss rec t1 6.376806, loss kl 0.110888, loss_trans 0.005795, loss flux 9.898535, loss flux t1 9.998791\n",
      "Epoch 9/10, Batch 751/1650, Loss 34.251514, Loss rec 6.191794, loss rec t1 6.605323, loss kl 0.139413, loss_trans 0.005336, loss flux 11.238442, loss flux t1 10.071207\n",
      "Epoch 9/10, Batch 761/1650, Loss 33.300331, Loss rec 5.162606, loss rec t1 6.103272, loss kl 0.158053, loss_trans 0.010232, loss flux 11.079235, loss flux t1 10.786934\n",
      "Epoch 9/10, Batch 771/1650, Loss 29.105787, Loss rec 3.941128, loss rec t1 5.280258, loss kl 0.105511, loss_trans 0.003805, loss flux 10.318686, loss flux t1 9.456399\n",
      "Epoch 9/10, Batch 781/1650, Loss 34.200684, Loss rec 6.620074, loss rec t1 8.351926, loss kl 0.099004, loss_trans 0.002959, loss flux 9.468345, loss flux t1 9.658374\n",
      "Epoch 9/10, Batch 791/1650, Loss 33.500568, Loss rec 5.909474, loss rec t1 6.776940, loss kl 0.104467, loss_trans 0.006434, loss flux 10.397276, loss flux t1 10.305977\n",
      "Epoch 9/10, Batch 801/1650, Loss 34.223568, Loss rec 6.356148, loss rec t1 6.816280, loss kl 0.133713, loss_trans 0.004778, loss flux 11.090654, loss flux t1 9.821996\n",
      "Epoch 9/10, Batch 811/1650, Loss 36.874603, Loss rec 6.640985, loss rec t1 8.077324, loss kl 0.159578, loss_trans 0.004577, loss flux 11.722187, loss flux t1 10.269949\n",
      "Epoch 9/10, Batch 821/1650, Loss 33.607712, Loss rec 6.727938, loss rec t1 7.515158, loss kl 0.106947, loss_trans 0.004511, loss flux 9.538207, loss flux t1 9.714950\n",
      "Epoch 9/10, Batch 831/1650, Loss 31.984951, Loss rec 5.339437, loss rec t1 6.581352, loss kl 0.177787, loss_trans 0.006061, loss flux 10.232039, loss flux t1 9.648275\n",
      "Epoch 9/10, Batch 841/1650, Loss 26.005730, Loss rec 4.369821, loss rec t1 5.626245, loss kl 0.076622, loss_trans 0.003636, loss flux 7.975968, loss flux t1 7.953438\n",
      "Epoch 9/10, Batch 851/1650, Loss 34.957317, Loss rec 6.246251, loss rec t1 6.943402, loss kl 0.114187, loss_trans 0.005701, loss flux 10.924376, loss flux t1 10.723395\n",
      "Epoch 9/10, Batch 861/1650, Loss 34.915108, Loss rec 5.033383, loss rec t1 6.295933, loss kl 0.152974, loss_trans 0.006295, loss flux 12.863550, loss flux t1 10.562972\n",
      "Epoch 9/10, Batch 871/1650, Loss 37.589798, Loss rec 6.835461, loss rec t1 7.234621, loss kl 0.128682, loss_trans 0.003790, loss flux 11.705393, loss flux t1 11.681852\n",
      "Epoch 9/10, Batch 881/1650, Loss 35.431938, Loss rec 5.265757, loss rec t1 7.624787, loss kl 0.116391, loss_trans 0.005029, loss flux 11.280910, loss flux t1 11.139067\n",
      "Epoch 9/10, Batch 891/1650, Loss 30.957743, Loss rec 4.396385, loss rec t1 5.370718, loss kl 0.110392, loss_trans 0.003427, loss flux 10.562877, loss flux t1 10.513943\n",
      "Epoch 9/10, Batch 901/1650, Loss 34.014278, Loss rec 6.534912, loss rec t1 7.276128, loss kl 0.149200, loss_trans 0.003655, loss flux 9.897425, loss flux t1 10.152959\n",
      "Epoch 9/10, Batch 911/1650, Loss 27.550613, Loss rec 3.496798, loss rec t1 4.871541, loss kl 0.105751, loss_trans 0.002874, loss flux 9.660066, loss flux t1 9.413584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Batch 921/1650, Loss 30.087208, Loss rec 4.663772, loss rec t1 5.731049, loss kl 0.115541, loss_trans 0.004662, loss flux 9.948407, loss flux t1 9.623776\n",
      "Epoch 9/10, Batch 931/1650, Loss 29.019234, Loss rec 4.949775, loss rec t1 5.535710, loss kl 0.117936, loss_trans 0.003516, loss flux 8.932229, loss flux t1 9.480068\n",
      "Epoch 9/10, Batch 941/1650, Loss 31.030937, Loss rec 4.809843, loss rec t1 5.100045, loss kl 0.152912, loss_trans 0.004263, loss flux 10.928721, loss flux t1 10.035154\n",
      "Epoch 9/10, Batch 951/1650, Loss 29.824123, Loss rec 4.637723, loss rec t1 5.115445, loss kl 0.099395, loss_trans 0.002629, loss flux 9.984298, loss flux t1 9.984634\n",
      "Epoch 9/10, Batch 961/1650, Loss 33.268318, Loss rec 5.754157, loss rec t1 7.079749, loss kl 0.075690, loss_trans 0.002282, loss flux 10.741287, loss flux t1 9.615156\n",
      "Epoch 9/10, Batch 971/1650, Loss 35.605042, Loss rec 7.014458, loss rec t1 7.743448, loss kl 0.082854, loss_trans 0.004598, loss flux 11.261799, loss flux t1 9.497887\n",
      "Epoch 9/10, Batch 981/1650, Loss 31.424351, Loss rec 5.978745, loss rec t1 6.678318, loss kl 0.090873, loss_trans 0.004540, loss flux 9.612081, loss flux t1 9.059795\n",
      "Epoch 9/10, Batch 991/1650, Loss 39.893585, Loss rec 7.994184, loss rec t1 8.964447, loss kl 0.096626, loss_trans 0.002684, loss flux 11.556608, loss flux t1 11.279037\n",
      "Epoch 9/10, Batch 1001/1650, Loss 63.344536, Loss rec 18.514099, loss rec t1 19.303425, loss kl 0.149672, loss_trans 0.004596, loss flux 12.512650, loss flux t1 12.860093\n",
      "Epoch 9/10, Batch 1011/1650, Loss 44.797474, Loss rec 9.232617, loss rec t1 9.598140, loss kl 0.100813, loss_trans 0.004578, loss flux 13.660069, loss flux t1 12.201260\n",
      "Epoch 9/10, Batch 1021/1650, Loss 43.090382, Loss rec 6.194044, loss rec t1 7.933957, loss kl 0.103185, loss_trans 0.002899, loss flux 14.557699, loss flux t1 14.298594\n",
      "Epoch 9/10, Batch 1031/1650, Loss 51.559475, Loss rec 14.605139, loss rec t1 15.360748, loss kl 0.156955, loss_trans 0.005564, loss flux 10.983713, loss flux t1 10.447357\n",
      "Epoch 9/10, Batch 1041/1650, Loss 31.190300, Loss rec 6.140499, loss rec t1 6.809817, loss kl 0.101314, loss_trans 0.004225, loss flux 9.580065, loss flux t1 8.554380\n",
      "Epoch 9/10, Batch 1051/1650, Loss 35.035793, Loss rec 6.975780, loss rec t1 6.966810, loss kl 0.090686, loss_trans 0.003515, loss flux 11.106993, loss flux t1 9.892013\n",
      "Epoch 9/10, Batch 1061/1650, Loss 36.383755, Loss rec 7.358037, loss rec t1 7.541521, loss kl 0.134097, loss_trans 0.005990, loss flux 10.397946, loss flux t1 10.946162\n",
      "Epoch 9/10, Batch 1071/1650, Loss 33.012154, Loss rec 5.105328, loss rec t1 5.781593, loss kl 0.153512, loss_trans 0.004468, loss flux 11.560930, loss flux t1 10.406323\n",
      "Epoch 9/10, Batch 1081/1650, Loss 34.266304, Loss rec 7.077703, loss rec t1 7.697465, loss kl 0.115786, loss_trans 0.005312, loss flux 9.746758, loss flux t1 9.623282\n",
      "Epoch 9/10, Batch 1091/1650, Loss 30.928827, Loss rec 4.993993, loss rec t1 5.174084, loss kl 0.081674, loss_trans 0.002488, loss flux 11.079878, loss flux t1 9.596712\n",
      "Epoch 9/10, Batch 1101/1650, Loss 27.914618, Loss rec 4.167028, loss rec t1 4.633168, loss kl 0.106675, loss_trans 0.004381, loss flux 10.469927, loss flux t1 8.533440\n",
      "Epoch 9/10, Batch 1111/1650, Loss 27.700380, Loss rec 3.424004, loss rec t1 4.407929, loss kl 0.108195, loss_trans 0.006865, loss flux 10.980257, loss flux t1 8.773131\n",
      "Epoch 9/10, Batch 1121/1650, Loss 30.879459, Loss rec 5.384534, loss rec t1 5.835111, loss kl 0.141535, loss_trans 0.004441, loss flux 9.880614, loss flux t1 9.633224\n",
      "Epoch 9/10, Batch 1131/1650, Loss 33.502003, Loss rec 6.768685, loss rec t1 6.856373, loss kl 0.193560, loss_trans 0.009404, loss flux 10.270396, loss flux t1 9.403583\n",
      "Epoch 9/10, Batch 1141/1650, Loss 29.469875, Loss rec 5.155771, loss rec t1 5.776671, loss kl 0.123554, loss_trans 0.004697, loss flux 9.299654, loss flux t1 9.109527\n",
      "Epoch 9/10, Batch 1151/1650, Loss 31.395401, Loss rec 5.007288, loss rec t1 5.694928, loss kl 0.150051, loss_trans 0.003842, loss flux 10.318303, loss flux t1 10.220988\n",
      "Epoch 9/10, Batch 1161/1650, Loss 35.610435, Loss rec 7.173547, loss rec t1 8.219114, loss kl 0.112909, loss_trans 0.005929, loss flux 10.233398, loss flux t1 9.865540\n",
      "Epoch 9/10, Batch 1171/1650, Loss 33.415764, Loss rec 5.658466, loss rec t1 6.981502, loss kl 0.097235, loss_trans 0.003113, loss flux 10.877813, loss flux t1 9.797633\n",
      "Epoch 9/10, Batch 1181/1650, Loss 37.512451, Loss rec 6.864482, loss rec t1 7.824061, loss kl 0.175840, loss_trans 0.005281, loss flux 11.380716, loss flux t1 11.262071\n",
      "Epoch 9/10, Batch 1191/1650, Loss 35.677769, Loss rec 6.077806, loss rec t1 6.612831, loss kl 0.139007, loss_trans 0.005937, loss flux 11.808099, loss flux t1 11.034092\n",
      "Epoch 9/10, Batch 1201/1650, Loss 31.525953, Loss rec 4.473827, loss rec t1 5.455653, loss kl 0.120234, loss_trans 0.005877, loss flux 11.420288, loss flux t1 10.050076\n",
      "Epoch 9/10, Batch 1211/1650, Loss 32.981194, Loss rec 4.942319, loss rec t1 6.016490, loss kl 0.134156, loss_trans 0.004590, loss flux 11.086675, loss flux t1 10.796967\n",
      "Epoch 9/10, Batch 1221/1650, Loss 34.763615, Loss rec 5.028755, loss rec t1 7.105093, loss kl 0.121692, loss_trans 0.002618, loss flux 11.509720, loss flux t1 10.995739\n",
      "Epoch 9/10, Batch 1231/1650, Loss 31.208609, Loss rec 4.676284, loss rec t1 5.146782, loss kl 0.118713, loss_trans 0.003551, loss flux 11.108318, loss flux t1 10.154959\n",
      "Epoch 9/10, Batch 1241/1650, Loss 31.452276, Loss rec 5.105413, loss rec t1 5.775390, loss kl 0.113263, loss_trans 0.003252, loss flux 10.258926, loss flux t1 10.196032\n",
      "Epoch 9/10, Batch 1251/1650, Loss 29.882942, Loss rec 5.412789, loss rec t1 5.739916, loss kl 0.094706, loss_trans 0.003325, loss flux 9.422534, loss flux t1 9.209673\n",
      "Epoch 9/10, Batch 1261/1650, Loss 32.163540, Loss rec 6.744125, loss rec t1 7.256177, loss kl 0.089891, loss_trans 0.004915, loss flux 9.208516, loss flux t1 8.859917\n",
      "Epoch 9/10, Batch 1271/1650, Loss 33.132179, Loss rec 6.418414, loss rec t1 6.751685, loss kl 0.102348, loss_trans 0.007521, loss flux 10.359315, loss flux t1 9.492899\n",
      "Epoch 9/10, Batch 1281/1650, Loss 28.531687, Loss rec 3.676274, loss rec t1 4.246527, loss kl 0.120803, loss_trans 0.003389, loss flux 11.382817, loss flux t1 9.101876\n",
      "Epoch 9/10, Batch 1291/1650, Loss 25.264488, Loss rec 3.402542, loss rec t1 4.220972, loss kl 0.085971, loss_trans 0.004016, loss flux 8.704090, loss flux t1 8.846895\n",
      "Epoch 9/10, Batch 1301/1650, Loss 26.740702, Loss rec 4.452321, loss rec t1 4.761640, loss kl 0.106266, loss_trans 0.004019, loss flux 9.026017, loss flux t1 8.390439\n",
      "Epoch 9/10, Batch 1311/1650, Loss 31.952497, Loss rec 5.063379, loss rec t1 6.122846, loss kl 0.104666, loss_trans 0.004883, loss flux 10.576247, loss flux t1 10.080477\n",
      "Epoch 9/10, Batch 1321/1650, Loss 33.601109, Loss rec 5.904592, loss rec t1 7.218369, loss kl 0.148315, loss_trans 0.005588, loss flux 10.731995, loss flux t1 9.592251\n",
      "Epoch 9/10, Batch 1331/1650, Loss 32.403500, Loss rec 5.723669, loss rec t1 6.445843, loss kl 0.094707, loss_trans 0.006914, loss flux 10.118773, loss flux t1 10.013596\n",
      "Epoch 9/10, Batch 1341/1650, Loss 25.417837, Loss rec 3.240454, loss rec t1 4.076296, loss kl 0.125090, loss_trans 0.003824, loss flux 9.307140, loss flux t1 8.665030\n",
      "Epoch 9/10, Batch 1351/1650, Loss 26.883123, Loss rec 4.529605, loss rec t1 5.290169, loss kl 0.073043, loss_trans 0.002397, loss flux 8.457780, loss flux t1 8.530128\n",
      "Epoch 9/10, Batch 1361/1650, Loss 36.498085, Loss rec 7.151369, loss rec t1 8.832394, loss kl 0.168497, loss_trans 0.007614, loss flux 10.420956, loss flux t1 9.917256\n",
      "Epoch 9/10, Batch 1371/1650, Loss 26.943842, Loss rec 3.334553, loss rec t1 4.432295, loss kl 0.118354, loss_trans 0.004832, loss flux 9.983250, loss flux t1 9.070558\n",
      "Epoch 9/10, Batch 1381/1650, Loss 29.560167, Loss rec 5.457427, loss rec t1 5.925412, loss kl 0.126035, loss_trans 0.002707, loss flux 8.952562, loss flux t1 9.096023\n",
      "Epoch 9/10, Batch 1391/1650, Loss 32.319149, Loss rec 5.271719, loss rec t1 6.039551, loss kl 0.172159, loss_trans 0.005953, loss flux 10.858278, loss flux t1 9.971485\n",
      "Epoch 9/10, Batch 1401/1650, Loss 32.838165, Loss rec 4.344612, loss rec t1 5.132733, loss kl 0.101086, loss_trans 0.003189, loss flux 12.168535, loss flux t1 11.088008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Batch 1411/1650, Loss 28.806301, Loss rec 5.263215, loss rec t1 5.732684, loss kl 0.121449, loss_trans 0.005364, loss flux 8.741448, loss flux t1 8.942142\n",
      "Epoch 9/10, Batch 1421/1650, Loss 31.296179, Loss rec 5.350009, loss rec t1 6.232255, loss kl 0.109103, loss_trans 0.004612, loss flux 10.078309, loss flux t1 9.521891\n",
      "Epoch 9/10, Batch 1431/1650, Loss 29.208961, Loss rec 4.906151, loss rec t1 5.215652, loss kl 0.116191, loss_trans 0.003998, loss flux 9.801683, loss flux t1 9.165287\n",
      "Epoch 9/10, Batch 1441/1650, Loss 40.287483, Loss rec 6.701065, loss rec t1 7.000772, loss kl 0.166802, loss_trans 0.006416, loss flux 14.269510, loss flux t1 12.142919\n",
      "Epoch 9/10, Batch 1451/1650, Loss 29.933016, Loss rec 5.717818, loss rec t1 6.484163, loss kl 0.116216, loss_trans 0.006690, loss flux 9.170836, loss flux t1 8.437292\n",
      "Epoch 9/10, Batch 1461/1650, Loss 28.465673, Loss rec 4.724074, loss rec t1 5.376213, loss kl 0.100940, loss_trans 0.003478, loss flux 9.510464, loss flux t1 8.750505\n",
      "Epoch 9/10, Batch 1471/1650, Loss 31.602121, Loss rec 5.379524, loss rec t1 5.890514, loss kl 0.132223, loss_trans 0.003749, loss flux 10.086366, loss flux t1 10.109745\n",
      "Epoch 9/10, Batch 1481/1650, Loss 30.700615, Loss rec 4.948360, loss rec t1 5.431723, loss kl 0.109475, loss_trans 0.002778, loss flux 10.361367, loss flux t1 9.846910\n",
      "Epoch 9/10, Batch 1491/1650, Loss 36.687233, Loss rec 6.719121, loss rec t1 7.509199, loss kl 0.155492, loss_trans 0.004500, loss flux 11.197421, loss flux t1 11.101496\n",
      "Epoch 9/10, Batch 1501/1650, Loss 35.560822, Loss rec 7.058722, loss rec t1 7.221722, loss kl 0.161529, loss_trans 0.007163, loss flux 10.841495, loss flux t1 10.270190\n",
      "Epoch 9/10, Batch 1511/1650, Loss 42.243057, Loss rec 9.554703, loss rec t1 10.314478, loss kl 0.085965, loss_trans 0.004927, loss flux 11.522726, loss flux t1 10.760256\n",
      "Epoch 9/10, Batch 1521/1650, Loss 29.254593, Loss rec 4.588996, loss rec t1 5.197725, loss kl 0.117842, loss_trans 0.003044, loss flux 10.066926, loss flux t1 9.280059\n",
      "Epoch 9/10, Batch 1531/1650, Loss 34.252350, Loss rec 6.448184, loss rec t1 7.188165, loss kl 0.110216, loss_trans 0.005467, loss flux 9.914156, loss flux t1 10.586163\n",
      "Epoch 9/10, Batch 1541/1650, Loss 32.024632, Loss rec 4.977038, loss rec t1 5.922410, loss kl 0.146605, loss_trans 0.005385, loss flux 10.861594, loss flux t1 10.111597\n",
      "Epoch 9/10, Batch 1551/1650, Loss 30.248074, Loss rec 4.952869, loss rec t1 5.945720, loss kl 0.081419, loss_trans 0.003078, loss flux 9.706930, loss flux t1 9.558057\n",
      "Epoch 9/10, Batch 1561/1650, Loss 36.606815, Loss rec 6.216337, loss rec t1 7.063835, loss kl 0.164441, loss_trans 0.005474, loss flux 11.624666, loss flux t1 11.532063\n",
      "Epoch 9/10, Batch 1571/1650, Loss 31.352022, Loss rec 3.735009, loss rec t1 4.664662, loss kl 0.161580, loss_trans 0.004777, loss flux 11.563228, loss flux t1 11.222766\n",
      "Epoch 9/10, Batch 1581/1650, Loss 27.195774, Loss rec 4.769092, loss rec t1 5.061183, loss kl 0.091633, loss_trans 0.002662, loss flux 8.905443, loss flux t1 8.365763\n",
      "Epoch 9/10, Batch 1591/1650, Loss 29.629543, Loss rec 4.659250, loss rec t1 5.220309, loss kl 0.133918, loss_trans 0.004277, loss flux 10.293530, loss flux t1 9.318261\n",
      "Epoch 9/10, Batch 1601/1650, Loss 26.021833, Loss rec 4.623124, loss rec t1 5.252314, loss kl 0.060116, loss_trans 0.004623, loss flux 8.226678, loss flux t1 7.854978\n",
      "Epoch 9/10, Batch 1611/1650, Loss 25.971054, Loss rec 3.136461, loss rec t1 4.120179, loss kl 0.088350, loss_trans 0.003668, loss flux 9.392150, loss flux t1 9.230246\n",
      "Epoch 9/10, Batch 1621/1650, Loss 26.692074, Loss rec 3.861108, loss rec t1 4.298600, loss kl 0.129882, loss_trans 0.003795, loss flux 9.545829, loss flux t1 8.852859\n",
      "Epoch 9/10, Batch 1631/1650, Loss 27.947193, Loss rec 5.510783, loss rec t1 6.020324, loss kl 0.076471, loss_trans 0.006931, loss flux 8.289173, loss flux t1 8.043511\n",
      "Epoch 9/10, Batch 1641/1650, Loss 28.918266, Loss rec 4.344454, loss rec t1 4.704932, loss kl 0.137134, loss_trans 0.003836, loss flux 10.110231, loss flux t1 9.617680\n",
      "Epoch 9/10, Train loss 26.942341, Eval loss 31.609621\n",
      "Epoch 10/10, Batch 1/1650, Loss 29.932966, Loss rec 3.952997, loss rec t1 5.588905, loss kl 0.152084, loss_trans 0.003289, loss flux 10.553754, loss flux t1 9.681933\n",
      "Epoch 10/10, Batch 11/1650, Loss 29.115088, Loss rec 4.193319, loss rec t1 5.366160, loss kl 0.146343, loss_trans 0.002527, loss flux 9.486986, loss flux t1 9.919750\n",
      "Epoch 10/10, Batch 21/1650, Loss 32.030083, Loss rec 5.928645, loss rec t1 6.190687, loss kl 0.095147, loss_trans 0.006423, loss flux 10.477034, loss flux t1 9.332146\n",
      "Epoch 10/10, Batch 31/1650, Loss 28.378675, Loss rec 4.435653, loss rec t1 5.510797, loss kl 0.082248, loss_trans 0.002891, loss flux 9.123507, loss flux t1 9.223581\n",
      "Epoch 10/10, Batch 41/1650, Loss 28.568293, Loss rec 4.977901, loss rec t1 5.481229, loss kl 0.090756, loss_trans 0.003653, loss flux 9.173900, loss flux t1 8.840853\n",
      "Epoch 10/10, Batch 51/1650, Loss 25.721415, Loss rec 3.880853, loss rec t1 4.423041, loss kl 0.082955, loss_trans 0.002912, loss flux 8.517564, loss flux t1 8.814090\n",
      "Epoch 10/10, Batch 61/1650, Loss 40.951771, Loss rec 7.241648, loss rec t1 8.535149, loss kl 0.144509, loss_trans 0.008177, loss flux 13.156605, loss flux t1 11.865682\n",
      "Epoch 10/10, Batch 71/1650, Loss 35.187473, Loss rec 5.822527, loss rec t1 5.988823, loss kl 0.139613, loss_trans 0.004059, loss flux 12.137985, loss flux t1 11.094468\n",
      "Epoch 10/10, Batch 81/1650, Loss 34.346821, Loss rec 7.259103, loss rec t1 8.082244, loss kl 0.082821, loss_trans 0.003876, loss flux 9.292274, loss flux t1 9.626504\n",
      "Epoch 10/10, Batch 91/1650, Loss 32.882275, Loss rec 5.765417, loss rec t1 6.349316, loss kl 0.110333, loss_trans 0.005635, loss flux 10.602442, loss flux t1 10.049134\n",
      "Epoch 10/10, Batch 101/1650, Loss 36.822140, Loss rec 6.971752, loss rec t1 9.133928, loss kl 0.083404, loss_trans 0.003346, loss flux 9.712274, loss flux t1 10.917435\n",
      "Epoch 10/10, Batch 111/1650, Loss 39.915443, Loss rec 5.927277, loss rec t1 7.455707, loss kl 0.161777, loss_trans 0.005508, loss flux 13.681394, loss flux t1 12.683782\n",
      "Epoch 10/10, Batch 121/1650, Loss 38.817192, Loss rec 7.085681, loss rec t1 7.538647, loss kl 0.137377, loss_trans 0.005107, loss flux 12.066784, loss flux t1 11.983598\n",
      "Epoch 10/10, Batch 131/1650, Loss 36.482586, Loss rec 5.920371, loss rec t1 5.668814, loss kl 0.072018, loss_trans 0.001972, loss flux 13.168636, loss flux t1 11.650776\n",
      "Epoch 10/10, Batch 141/1650, Loss 30.863617, Loss rec 4.494357, loss rec t1 5.702150, loss kl 0.084017, loss_trans 0.004159, loss flux 9.412607, loss flux t1 11.166328\n",
      "Epoch 10/10, Batch 151/1650, Loss 35.200626, Loss rec 5.888544, loss rec t1 6.248986, loss kl 0.161621, loss_trans 0.004893, loss flux 11.467332, loss flux t1 11.429250\n",
      "Epoch 10/10, Batch 161/1650, Loss 36.573471, Loss rec 6.719553, loss rec t1 7.050998, loss kl 0.167439, loss_trans 0.004342, loss flux 12.508067, loss flux t1 10.123075\n",
      "Epoch 10/10, Batch 171/1650, Loss 39.316784, Loss rec 7.218808, loss rec t1 7.305084, loss kl 0.163495, loss_trans 0.004020, loss flux 12.589067, loss flux t1 12.036307\n",
      "Epoch 10/10, Batch 181/1650, Loss 22.659212, Loss rec 3.216887, loss rec t1 4.033831, loss kl 0.082086, loss_trans 0.003126, loss flux 7.993937, loss flux t1 7.329343\n",
      "Epoch 10/10, Batch 191/1650, Loss 31.223171, Loss rec 4.846755, loss rec t1 5.442468, loss kl 0.148317, loss_trans 0.005741, loss flux 10.512978, loss flux t1 10.266914\n",
      "Epoch 10/10, Batch 201/1650, Loss 27.981102, Loss rec 5.997351, loss rec t1 5.882408, loss kl 0.086313, loss_trans 0.003479, loss flux 8.067109, loss flux t1 7.944443\n",
      "Epoch 10/10, Batch 211/1650, Loss 30.670715, Loss rec 5.823473, loss rec t1 6.799474, loss kl 0.061398, loss_trans 0.002464, loss flux 9.208295, loss flux t1 8.775613\n",
      "Epoch 10/10, Batch 221/1650, Loss 30.936399, Loss rec 5.399178, loss rec t1 5.984692, loss kl 0.109652, loss_trans 0.001974, loss flux 9.992352, loss flux t1 9.448552\n",
      "Epoch 10/10, Batch 231/1650, Loss 39.018456, Loss rec 8.862881, loss rec t1 9.457291, loss kl 0.141789, loss_trans 0.004039, loss flux 10.331483, loss flux t1 10.220974\n",
      "Epoch 10/10, Batch 241/1650, Loss 31.536379, Loss rec 4.709440, loss rec t1 5.701901, loss kl 0.104033, loss_trans 0.005152, loss flux 10.481797, loss flux t1 10.534055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Batch 251/1650, Loss 32.359665, Loss rec 6.578634, loss rec t1 6.585369, loss kl 0.127673, loss_trans 0.008139, loss flux 9.757561, loss flux t1 9.302290\n",
      "Epoch 10/10, Batch 261/1650, Loss 28.979313, Loss rec 4.680577, loss rec t1 5.024070, loss kl 0.085749, loss_trans 0.002889, loss flux 9.889231, loss flux t1 9.296797\n",
      "Epoch 10/10, Batch 271/1650, Loss 36.434017, Loss rec 5.859568, loss rec t1 6.748791, loss kl 0.132025, loss_trans 0.003574, loss flux 11.883625, loss flux t1 11.806434\n",
      "Epoch 10/10, Batch 281/1650, Loss 31.007025, Loss rec 5.276945, loss rec t1 6.275037, loss kl 0.107053, loss_trans 0.004373, loss flux 10.092351, loss flux t1 9.251262\n",
      "Epoch 10/10, Batch 291/1650, Loss 37.646790, Loss rec 6.350897, loss rec t1 7.678246, loss kl 0.136892, loss_trans 0.003467, loss flux 12.213326, loss flux t1 11.263963\n",
      "Epoch 10/10, Batch 301/1650, Loss 30.194576, Loss rec 5.257105, loss rec t1 6.379216, loss kl 0.082223, loss_trans 0.002743, loss flux 9.468697, loss flux t1 9.004592\n",
      "Epoch 10/10, Batch 311/1650, Loss 25.984884, Loss rec 3.462003, loss rec t1 4.707340, loss kl 0.095863, loss_trans 0.002462, loss flux 8.738918, loss flux t1 8.978298\n",
      "Epoch 10/10, Batch 321/1650, Loss 32.510185, Loss rec 5.258481, loss rec t1 6.114690, loss kl 0.119005, loss_trans 0.003242, loss flux 10.572719, loss flux t1 10.442046\n",
      "Epoch 10/10, Batch 331/1650, Loss 30.911585, Loss rec 5.045072, loss rec t1 5.726282, loss kl 0.076676, loss_trans 0.003293, loss flux 10.203049, loss flux t1 9.857212\n",
      "Epoch 10/10, Batch 341/1650, Loss 39.392925, Loss rec 8.582433, loss rec t1 9.781968, loss kl 0.112631, loss_trans 0.004691, loss flux 10.679168, loss flux t1 10.232033\n",
      "Epoch 10/10, Batch 351/1650, Loss 37.606659, Loss rec 6.853683, loss rec t1 7.299532, loss kl 0.150908, loss_trans 0.003665, loss flux 11.597268, loss flux t1 11.701603\n",
      "Epoch 10/10, Batch 361/1650, Loss 33.470375, Loss rec 5.492702, loss rec t1 6.096562, loss kl 0.103665, loss_trans 0.003266, loss flux 11.245591, loss flux t1 10.528590\n",
      "Epoch 10/10, Batch 371/1650, Loss 35.567532, Loss rec 5.937501, loss rec t1 7.432549, loss kl 0.157338, loss_trans 0.008104, loss flux 11.019903, loss flux t1 11.012137\n",
      "Epoch 10/10, Batch 381/1650, Loss 30.948950, Loss rec 5.053214, loss rec t1 5.818914, loss kl 0.113127, loss_trans 0.003780, loss flux 10.237659, loss flux t1 9.722258\n",
      "Epoch 10/10, Batch 391/1650, Loss 31.049742, Loss rec 5.547053, loss rec t1 5.914893, loss kl 0.123841, loss_trans 0.003012, loss flux 9.919771, loss flux t1 9.541172\n",
      "Epoch 10/10, Batch 401/1650, Loss 30.714100, Loss rec 5.303252, loss rec t1 6.034381, loss kl 0.073462, loss_trans 0.004517, loss flux 8.943384, loss flux t1 10.355105\n",
      "Epoch 10/10, Batch 411/1650, Loss 33.726486, Loss rec 7.057591, loss rec t1 7.284169, loss kl 0.162335, loss_trans 0.007793, loss flux 10.112940, loss flux t1 9.101659\n",
      "Epoch 10/10, Batch 421/1650, Loss 32.580673, Loss rec 6.287829, loss rec t1 6.774018, loss kl 0.143270, loss_trans 0.007183, loss flux 10.064243, loss flux t1 9.304130\n",
      "Epoch 10/10, Batch 431/1650, Loss 25.298128, Loss rec 2.974206, loss rec t1 3.749377, loss kl 0.127295, loss_trans 0.002379, loss flux 9.765407, loss flux t1 8.679464\n",
      "Epoch 10/10, Batch 441/1650, Loss 35.930336, Loss rec 6.444580, loss rec t1 7.238910, loss kl 0.128797, loss_trans 0.004747, loss flux 11.763549, loss flux t1 10.349754\n",
      "Epoch 10/10, Batch 451/1650, Loss 35.237389, Loss rec 7.850393, loss rec t1 8.672166, loss kl 0.093747, loss_trans 0.005002, loss flux 9.561665, loss flux t1 9.054418\n",
      "Epoch 10/10, Batch 461/1650, Loss 39.530605, Loss rec 9.067814, loss rec t1 10.626783, loss kl 0.088573, loss_trans 0.004178, loss flux 10.329897, loss flux t1 9.413361\n",
      "Epoch 10/10, Batch 471/1650, Loss 31.560112, Loss rec 5.324631, loss rec t1 5.825229, loss kl 0.102979, loss_trans 0.003018, loss flux 10.938693, loss flux t1 9.365561\n",
      "Epoch 10/10, Batch 481/1650, Loss 32.545315, Loss rec 5.146537, loss rec t1 6.419149, loss kl 0.099849, loss_trans 0.002640, loss flux 10.481117, loss flux t1 10.396022\n",
      "Epoch 10/10, Batch 491/1650, Loss 38.387894, Loss rec 7.786637, loss rec t1 9.025127, loss kl 0.083333, loss_trans 0.002228, loss flux 11.066317, loss flux t1 10.424253\n",
      "Epoch 10/10, Batch 501/1650, Loss 33.774082, Loss rec 5.944153, loss rec t1 6.479786, loss kl 0.120235, loss_trans 0.002933, loss flux 10.583228, loss flux t1 10.643747\n",
      "Epoch 10/10, Batch 511/1650, Loss 35.524109, Loss rec 6.463663, loss rec t1 7.361255, loss kl 0.119716, loss_trans 0.004935, loss flux 11.029925, loss flux t1 10.544613\n",
      "Epoch 10/10, Batch 521/1650, Loss 40.211155, Loss rec 6.495026, loss rec t1 8.228373, loss kl 0.152268, loss_trans 0.006381, loss flux 13.440918, loss flux t1 11.888189\n",
      "Epoch 10/10, Batch 531/1650, Loss 30.701107, Loss rec 5.021375, loss rec t1 5.936436, loss kl 0.086134, loss_trans 0.004780, loss flux 10.105762, loss flux t1 9.546620\n",
      "Epoch 10/10, Batch 541/1650, Loss 29.562719, Loss rec 4.201043, loss rec t1 4.893535, loss kl 0.101124, loss_trans 0.003298, loss flux 10.662114, loss flux t1 9.701606\n",
      "Epoch 10/10, Batch 551/1650, Loss 30.811525, Loss rec 3.465737, loss rec t1 4.052929, loss kl 0.129195, loss_trans 0.005960, loss flux 11.719123, loss flux t1 11.438580\n",
      "Epoch 10/10, Batch 561/1650, Loss 29.189512, Loss rec 4.981683, loss rec t1 5.699511, loss kl 0.089083, loss_trans 0.003230, loss flux 8.788141, loss flux t1 9.627863\n",
      "Epoch 10/10, Batch 571/1650, Loss 29.961170, Loss rec 5.250700, loss rec t1 5.062038, loss kl 0.116771, loss_trans 0.003639, loss flux 10.252873, loss flux t1 9.275147\n",
      "Epoch 10/10, Batch 581/1650, Loss 33.980869, Loss rec 6.086314, loss rec t1 6.535343, loss kl 0.094493, loss_trans 0.003914, loss flux 10.965025, loss flux t1 10.295781\n",
      "Epoch 10/10, Batch 591/1650, Loss 27.047899, Loss rec 4.355168, loss rec t1 4.839332, loss kl 0.078701, loss_trans 0.001981, loss flux 9.580545, loss flux t1 8.192171\n",
      "Epoch 10/10, Batch 601/1650, Loss 34.894032, Loss rec 6.948021, loss rec t1 7.461677, loss kl 0.101610, loss_trans 0.007498, loss flux 10.792764, loss flux t1 9.582461\n",
      "Epoch 10/10, Batch 611/1650, Loss 36.604469, Loss rec 7.199286, loss rec t1 6.512860, loss kl 0.094031, loss_trans 0.005069, loss flux 12.656592, loss flux t1 10.136630\n",
      "Epoch 10/10, Batch 621/1650, Loss 34.766647, Loss rec 5.789354, loss rec t1 6.557573, loss kl 0.121907, loss_trans 0.002823, loss flux 11.162460, loss flux t1 11.132529\n",
      "Epoch 10/10, Batch 631/1650, Loss 36.997368, Loss rec 5.312584, loss rec t1 5.885808, loss kl 0.138886, loss_trans 0.006338, loss flux 13.764998, loss flux t1 11.888754\n",
      "Epoch 10/10, Batch 641/1650, Loss 36.598263, Loss rec 7.948771, loss rec t1 8.332569, loss kl 0.109523, loss_trans 0.004713, loss flux 10.204400, loss flux t1 9.998283\n",
      "Epoch 10/10, Batch 651/1650, Loss 36.019531, Loss rec 6.266854, loss rec t1 6.876422, loss kl 0.120753, loss_trans 0.006277, loss flux 11.495207, loss flux t1 11.254019\n",
      "Epoch 10/10, Batch 661/1650, Loss 32.176537, Loss rec 5.288849, loss rec t1 6.111398, loss kl 0.142521, loss_trans 0.006128, loss flux 10.567805, loss flux t1 10.059837\n",
      "Epoch 10/10, Batch 671/1650, Loss 33.533676, Loss rec 6.118629, loss rec t1 7.513767, loss kl 0.094877, loss_trans 0.005379, loss flux 10.237093, loss flux t1 9.563931\n",
      "Epoch 10/10, Batch 681/1650, Loss 41.144794, Loss rec 8.073207, loss rec t1 9.837959, loss kl 0.105682, loss_trans 0.002630, loss flux 12.012105, loss flux t1 11.113214\n",
      "Epoch 10/10, Batch 691/1650, Loss 40.382793, Loss rec 8.254816, loss rec t1 8.647934, loss kl 0.160927, loss_trans 0.004840, loss flux 11.962658, loss flux t1 11.351620\n",
      "Epoch 10/10, Batch 701/1650, Loss 33.263210, Loss rec 6.376763, loss rec t1 6.824091, loss kl 0.151838, loss_trans 0.007722, loss flux 9.936372, loss flux t1 9.966424\n",
      "Epoch 10/10, Batch 711/1650, Loss 43.585697, Loss rec 8.867896, loss rec t1 9.121616, loss kl 0.212132, loss_trans 0.004957, loss flux 13.070900, loss flux t1 12.308198\n",
      "Epoch 10/10, Batch 721/1650, Loss 31.224684, Loss rec 4.672434, loss rec t1 5.775167, loss kl 0.159954, loss_trans 0.002265, loss flux 10.352640, loss flux t1 10.262225\n",
      "Epoch 10/10, Batch 731/1650, Loss 32.056309, Loss rec 5.956851, loss rec t1 6.289338, loss kl 0.109872, loss_trans 0.005273, loss flux 10.163319, loss flux t1 9.531659\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Batch 741/1650, Loss 30.951706, Loss rec 5.076095, loss rec t1 5.731070, loss kl 0.109147, loss_trans 0.004960, loss flux 9.973817, loss flux t1 10.056617\n",
      "Epoch 10/10, Batch 751/1650, Loss 30.734493, Loss rec 4.890276, loss rec t1 5.581216, loss kl 0.131386, loss_trans 0.004460, loss flux 10.322497, loss flux t1 9.804657\n",
      "Epoch 10/10, Batch 761/1650, Loss 33.342224, Loss rec 4.797504, loss rec t1 5.779922, loss kl 0.161136, loss_trans 0.009652, loss flux 12.054098, loss flux t1 10.539913\n",
      "Epoch 10/10, Batch 771/1650, Loss 28.516592, Loss rec 3.331267, loss rec t1 4.287283, loss kl 0.104300, loss_trans 0.003832, loss flux 11.022439, loss flux t1 9.767470\n",
      "Epoch 10/10, Batch 781/1650, Loss 32.098164, Loss rec 5.441452, loss rec t1 6.611840, loss kl 0.093036, loss_trans 0.002770, loss flux 10.177156, loss flux t1 9.771911\n",
      "Epoch 10/10, Batch 791/1650, Loss 34.228775, Loss rec 5.460433, loss rec t1 5.943467, loss kl 0.100200, loss_trans 0.005842, loss flux 11.484043, loss flux t1 11.234792\n",
      "Epoch 10/10, Batch 801/1650, Loss 31.533875, Loss rec 6.006310, loss rec t1 6.074214, loss kl 0.135430, loss_trans 0.004643, loss flux 10.185980, loss flux t1 9.127297\n",
      "Epoch 10/10, Batch 811/1650, Loss 31.659920, Loss rec 5.019206, loss rec t1 5.986628, loss kl 0.160469, loss_trans 0.004402, loss flux 10.553004, loss flux t1 9.936210\n",
      "Epoch 10/10, Batch 821/1650, Loss 27.911514, Loss rec 4.377995, loss rec t1 4.732506, loss kl 0.106780, loss_trans 0.004050, loss flux 9.242881, loss flux t1 9.447301\n",
      "Epoch 10/10, Batch 831/1650, Loss 28.320667, Loss rec 4.294087, loss rec t1 5.900059, loss kl 0.176566, loss_trans 0.005104, loss flux 9.018202, loss flux t1 8.926650\n",
      "Epoch 10/10, Batch 841/1650, Loss 24.908981, Loss rec 4.041610, loss rec t1 4.843648, loss kl 0.078127, loss_trans 0.003541, loss flux 8.202813, loss flux t1 7.739244\n",
      "Epoch 10/10, Batch 851/1650, Loss 32.812836, Loss rec 5.499488, loss rec t1 5.879783, loss kl 0.111064, loss_trans 0.005252, loss flux 11.169092, loss flux t1 10.148156\n",
      "Epoch 10/10, Batch 861/1650, Loss 31.441339, Loss rec 4.881482, loss rec t1 5.531645, loss kl 0.155036, loss_trans 0.005844, loss flux 11.036283, loss flux t1 9.831049\n",
      "Epoch 10/10, Batch 871/1650, Loss 34.398743, Loss rec 6.146835, loss rec t1 6.213817, loss kl 0.129369, loss_trans 0.003490, loss flux 11.446249, loss flux t1 10.458982\n",
      "Epoch 10/10, Batch 881/1650, Loss 31.259794, Loss rec 4.549468, loss rec t1 5.409372, loss kl 0.114282, loss_trans 0.004812, loss flux 11.052062, loss flux t1 10.129798\n",
      "Epoch 10/10, Batch 891/1650, Loss 27.060846, Loss rec 3.905619, loss rec t1 4.738201, loss kl 0.109751, loss_trans 0.002911, loss flux 9.287298, loss flux t1 9.017067\n",
      "Epoch 10/10, Batch 901/1650, Loss 30.604416, Loss rec 4.906457, loss rec t1 6.126089, loss kl 0.143131, loss_trans 0.003360, loss flux 9.634776, loss flux t1 9.790602\n",
      "Epoch 10/10, Batch 911/1650, Loss 22.836378, Loss rec 2.878742, loss rec t1 3.941216, loss kl 0.098116, loss_trans 0.002573, loss flux 8.103004, loss flux t1 7.812729\n",
      "Epoch 10/10, Batch 921/1650, Loss 26.260654, Loss rec 3.719698, loss rec t1 4.572103, loss kl 0.110128, loss_trans 0.004227, loss flux 8.875919, loss flux t1 8.978580\n",
      "Epoch 10/10, Batch 931/1650, Loss 26.747717, Loss rec 4.253554, loss rec t1 4.580701, loss kl 0.110797, loss_trans 0.003187, loss flux 9.090011, loss flux t1 8.709468\n",
      "Epoch 10/10, Batch 941/1650, Loss 28.016018, Loss rec 3.735940, loss rec t1 4.275327, loss kl 0.142467, loss_trans 0.004367, loss flux 10.544816, loss flux t1 9.313098\n",
      "Epoch 10/10, Batch 951/1650, Loss 28.262720, Loss rec 4.025684, loss rec t1 4.562048, loss kl 0.101776, loss_trans 0.002654, loss flux 9.743484, loss flux t1 9.827075\n",
      "Epoch 10/10, Batch 961/1650, Loss 27.521353, Loss rec 4.054863, loss rec t1 4.516553, loss kl 0.066754, loss_trans 0.002215, loss flux 9.324272, loss flux t1 9.556695\n",
      "Epoch 10/10, Batch 971/1650, Loss 30.380434, Loss rec 5.335181, loss rec t1 6.106830, loss kl 0.083474, loss_trans 0.004413, loss flux 9.567513, loss flux t1 9.283022\n",
      "Epoch 10/10, Batch 981/1650, Loss 27.025566, Loss rec 4.543457, loss rec t1 4.984776, loss kl 0.089198, loss_trans 0.004947, loss flux 8.661244, loss flux t1 8.741942\n",
      "Epoch 10/10, Batch 991/1650, Loss 27.697983, Loss rec 4.094009, loss rec t1 4.434738, loss kl 0.088847, loss_trans 0.002579, loss flux 9.981494, loss flux t1 9.096318\n",
      "Epoch 10/10, Batch 1001/1650, Loss 28.619421, Loss rec 4.939170, loss rec t1 5.234747, loss kl 0.134566, loss_trans 0.004159, loss flux 9.136700, loss flux t1 9.170078\n",
      "Epoch 10/10, Batch 1011/1650, Loss 29.531599, Loss rec 4.825329, loss rec t1 5.747101, loss kl 0.094159, loss_trans 0.004112, loss flux 9.709302, loss flux t1 9.151596\n",
      "Epoch 10/10, Batch 1021/1650, Loss 27.498844, Loss rec 3.997182, loss rec t1 4.610795, loss kl 0.092122, loss_trans 0.002469, loss flux 9.027176, loss flux t1 9.769098\n",
      "Epoch 10/10, Batch 1031/1650, Loss 29.473743, Loss rec 5.086466, loss rec t1 5.179387, loss kl 0.142964, loss_trans 0.004520, loss flux 9.771184, loss flux t1 9.289222\n",
      "Epoch 10/10, Batch 1041/1650, Loss 25.645929, Loss rec 4.632216, loss rec t1 4.929708, loss kl 0.095401, loss_trans 0.003331, loss flux 8.164984, loss flux t1 7.820290\n",
      "Epoch 10/10, Batch 1051/1650, Loss 30.696198, Loss rec 5.814898, loss rec t1 5.778652, loss kl 0.086445, loss_trans 0.003124, loss flux 10.083966, loss flux t1 8.929111\n",
      "Epoch 10/10, Batch 1061/1650, Loss 39.344440, Loss rec 6.417952, loss rec t1 7.001080, loss kl 0.130335, loss_trans 0.005354, loss flux 13.020586, loss flux t1 12.769133\n",
      "Epoch 10/10, Batch 1071/1650, Loss 33.103443, Loss rec 4.550374, loss rec t1 5.114796, loss kl 0.147294, loss_trans 0.003466, loss flux 11.887383, loss flux t1 11.400129\n",
      "Epoch 10/10, Batch 1081/1650, Loss 33.713631, Loss rec 6.961844, loss rec t1 7.847746, loss kl 0.107544, loss_trans 0.004484, loss flux 9.464862, loss flux t1 9.327147\n",
      "Epoch 10/10, Batch 1091/1650, Loss 36.841709, Loss rec 6.170042, loss rec t1 6.760430, loss kl 0.081622, loss_trans 0.002621, loss flux 11.862527, loss flux t1 11.964466\n",
      "Epoch 10/10, Batch 1101/1650, Loss 28.981243, Loss rec 4.498220, loss rec t1 5.394439, loss kl 0.103103, loss_trans 0.004383, loss flux 10.449124, loss flux t1 8.531974\n",
      "Epoch 10/10, Batch 1111/1650, Loss 25.642418, Loss rec 3.231543, loss rec t1 3.747811, loss kl 0.106985, loss_trans 0.006630, loss flux 10.262161, loss flux t1 8.287287\n",
      "Epoch 10/10, Batch 1121/1650, Loss 32.005955, Loss rec 5.208535, loss rec t1 5.967143, loss kl 0.131801, loss_trans 0.003965, loss flux 10.422789, loss flux t1 10.271724\n",
      "Epoch 10/10, Batch 1131/1650, Loss 33.743996, Loss rec 6.550677, loss rec t1 6.494225, loss kl 0.179115, loss_trans 0.007496, loss flux 10.634084, loss flux t1 9.878398\n",
      "Epoch 10/10, Batch 1141/1650, Loss 32.511265, Loss rec 5.677107, loss rec t1 6.419882, loss kl 0.117346, loss_trans 0.004003, loss flux 10.337911, loss flux t1 9.955016\n",
      "Epoch 10/10, Batch 1151/1650, Loss 30.860861, Loss rec 4.931545, loss rec t1 5.357530, loss kl 0.147220, loss_trans 0.003217, loss flux 10.168081, loss flux t1 10.253266\n",
      "Epoch 10/10, Batch 1161/1650, Loss 30.877296, Loss rec 5.313298, loss rec t1 6.139578, loss kl 0.105400, loss_trans 0.005253, loss flux 9.332639, loss flux t1 9.981129\n",
      "Epoch 10/10, Batch 1171/1650, Loss 32.226063, Loss rec 4.942447, loss rec t1 5.584968, loss kl 0.097256, loss_trans 0.003082, loss flux 11.535750, loss flux t1 10.062561\n",
      "Epoch 10/10, Batch 1181/1650, Loss 37.950829, Loss rec 6.693846, loss rec t1 7.743594, loss kl 0.168943, loss_trans 0.004047, loss flux 11.561848, loss flux t1 11.778548\n",
      "Epoch 10/10, Batch 1191/1650, Loss 38.877007, Loss rec 7.657273, loss rec t1 7.894299, loss kl 0.135023, loss_trans 0.005027, loss flux 12.063615, loss flux t1 11.121771\n",
      "Epoch 10/10, Batch 1201/1650, Loss 28.170912, Loss rec 4.082115, loss rec t1 5.072743, loss kl 0.110818, loss_trans 0.005099, loss flux 9.929953, loss flux t1 8.970184\n",
      "Epoch 10/10, Batch 1211/1650, Loss 38.496449, Loss rec 7.690724, loss rec t1 8.304432, loss kl 0.136679, loss_trans 0.004563, loss flux 11.487349, loss flux t1 10.872701\n",
      "Epoch 10/10, Batch 1221/1650, Loss 33.060551, Loss rec 4.527676, loss rec t1 5.188505, loss kl 0.118200, loss_trans 0.002506, loss flux 12.044489, loss flux t1 11.179174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Batch 1231/1650, Loss 28.187290, Loss rec 4.182763, loss rec t1 4.584816, loss kl 0.112985, loss_trans 0.003292, loss flux 9.572219, loss flux t1 9.731216\n",
      "Epoch 10/10, Batch 1241/1650, Loss 31.351027, Loss rec 4.835472, loss rec t1 5.660447, loss kl 0.107257, loss_trans 0.003146, loss flux 10.390506, loss flux t1 10.354198\n",
      "Epoch 10/10, Batch 1251/1650, Loss 30.980707, Loss rec 5.093291, loss rec t1 5.352796, loss kl 0.090541, loss_trans 0.003458, loss flux 10.514562, loss flux t1 9.926060\n",
      "Epoch 10/10, Batch 1261/1650, Loss 33.682724, Loss rec 7.098945, loss rec t1 7.941061, loss kl 0.085998, loss_trans 0.004823, loss flux 9.478573, loss flux t1 9.073325\n",
      "Epoch 10/10, Batch 1271/1650, Loss 33.293056, Loss rec 6.465392, loss rec t1 6.843697, loss kl 0.100345, loss_trans 0.006616, loss flux 10.289912, loss flux t1 9.587098\n",
      "Epoch 10/10, Batch 1281/1650, Loss 26.815670, Loss rec 3.591741, loss rec t1 4.331963, loss kl 0.117606, loss_trans 0.003152, loss flux 9.672795, loss flux t1 9.098416\n",
      "Epoch 10/10, Batch 1291/1650, Loss 24.481121, Loss rec 3.033895, loss rec t1 3.756132, loss kl 0.084208, loss_trans 0.003852, loss flux 8.683581, loss flux t1 8.919454\n",
      "Epoch 10/10, Batch 1301/1650, Loss 29.574066, Loss rec 4.608913, loss rec t1 4.720525, loss kl 0.101458, loss_trans 0.003478, loss flux 10.496833, loss flux t1 9.642859\n",
      "Epoch 10/10, Batch 1311/1650, Loss 33.483582, Loss rec 4.749658, loss rec t1 5.679327, loss kl 0.100555, loss_trans 0.004496, loss flux 11.947021, loss flux t1 11.002527\n",
      "Epoch 10/10, Batch 1321/1650, Loss 32.178974, Loss rec 5.368835, loss rec t1 5.999562, loss kl 0.144830, loss_trans 0.004930, loss flux 10.472837, loss flux t1 10.187982\n",
      "Epoch 10/10, Batch 1331/1650, Loss 29.936098, Loss rec 5.173297, loss rec t1 5.757296, loss kl 0.091049, loss_trans 0.006438, loss flux 9.506002, loss flux t1 9.402015\n",
      "Epoch 10/10, Batch 1341/1650, Loss 23.475826, Loss rec 2.821852, loss rec t1 3.618514, loss kl 0.120342, loss_trans 0.003668, loss flux 8.732535, loss flux t1 8.178915\n",
      "Epoch 10/10, Batch 1351/1650, Loss 25.751362, Loss rec 3.665259, loss rec t1 4.233507, loss kl 0.070665, loss_trans 0.002538, loss flux 8.927186, loss flux t1 8.852205\n",
      "Epoch 10/10, Batch 1361/1650, Loss 32.413910, Loss rec 6.305236, loss rec t1 7.250094, loss kl 0.163272, loss_trans 0.006756, loss flux 9.614919, loss flux t1 9.073633\n",
      "Epoch 10/10, Batch 1371/1650, Loss 26.517006, Loss rec 3.081310, loss rec t1 3.890157, loss kl 0.115698, loss_trans 0.004437, loss flux 9.902814, loss flux t1 9.522591\n",
      "Epoch 10/10, Batch 1381/1650, Loss 30.733927, Loss rec 5.936681, loss rec t1 6.082893, loss kl 0.123592, loss_trans 0.002427, loss flux 9.040914, loss flux t1 9.547420\n",
      "Epoch 10/10, Batch 1391/1650, Loss 27.589161, Loss rec 3.797302, loss rec t1 4.573041, loss kl 0.167396, loss_trans 0.005583, loss flux 9.857049, loss flux t1 9.188791\n",
      "Epoch 10/10, Batch 1401/1650, Loss 41.683842, Loss rec 6.818093, loss rec t1 7.385917, loss kl 0.096597, loss_trans 0.003300, loss flux 15.895788, loss flux t1 11.484145\n",
      "Epoch 10/10, Batch 1411/1650, Loss 30.955254, Loss rec 5.432606, loss rec t1 5.699338, loss kl 0.114755, loss_trans 0.004978, loss flux 10.096286, loss flux t1 9.607289\n",
      "Epoch 10/10, Batch 1421/1650, Loss 31.865107, Loss rec 4.941220, loss rec t1 5.149746, loss kl 0.105982, loss_trans 0.004262, loss flux 11.144800, loss flux t1 10.519098\n",
      "Epoch 10/10, Batch 1431/1650, Loss 28.762360, Loss rec 4.915255, loss rec t1 5.167459, loss kl 0.113494, loss_trans 0.003578, loss flux 9.606439, loss flux t1 8.956135\n",
      "Epoch 10/10, Batch 1441/1650, Loss 38.582340, Loss rec 7.658382, loss rec t1 8.557272, loss kl 0.170610, loss_trans 0.005723, loss flux 11.546651, loss flux t1 10.643704\n",
      "Epoch 10/10, Batch 1451/1650, Loss 30.090761, Loss rec 5.646746, loss rec t1 6.305580, loss kl 0.109843, loss_trans 0.006086, loss flux 9.468605, loss flux t1 8.553901\n",
      "Epoch 10/10, Batch 1461/1650, Loss 27.353140, Loss rec 4.136762, loss rec t1 5.116908, loss kl 0.102147, loss_trans 0.003542, loss flux 9.239746, loss flux t1 8.754035\n",
      "Epoch 10/10, Batch 1471/1650, Loss 31.089539, Loss rec 5.648729, loss rec t1 6.242677, loss kl 0.128871, loss_trans 0.003253, loss flux 9.917372, loss flux t1 9.148638\n",
      "Epoch 10/10, Batch 1481/1650, Loss 30.214462, Loss rec 4.948457, loss rec t1 5.380210, loss kl 0.107730, loss_trans 0.002483, loss flux 10.113922, loss flux t1 9.661660\n",
      "Epoch 10/10, Batch 1491/1650, Loss 29.307421, Loss rec 5.304616, loss rec t1 5.694485, loss kl 0.156547, loss_trans 0.003973, loss flux 9.004880, loss flux t1 9.142920\n",
      "Epoch 10/10, Batch 1501/1650, Loss 31.229908, Loss rec 5.263595, loss rec t1 5.774517, loss kl 0.160727, loss_trans 0.006610, loss flux 10.381548, loss flux t1 9.642909\n",
      "Epoch 10/10, Batch 1511/1650, Loss 31.386395, Loss rec 6.350262, loss rec t1 6.837087, loss kl 0.081822, loss_trans 0.004469, loss flux 9.423457, loss flux t1 8.689299\n",
      "Epoch 10/10, Batch 1521/1650, Loss 25.943563, Loss rec 3.948585, loss rec t1 4.292079, loss kl 0.114046, loss_trans 0.002729, loss flux 9.017131, loss flux t1 8.568994\n",
      "Epoch 10/10, Batch 1531/1650, Loss 29.862507, Loss rec 5.532806, loss rec t1 5.849977, loss kl 0.105381, loss_trans 0.005058, loss flux 8.997266, loss flux t1 9.372020\n",
      "Epoch 10/10, Batch 1541/1650, Loss 29.396894, Loss rec 4.783409, loss rec t1 5.451296, loss kl 0.139191, loss_trans 0.005551, loss flux 9.761179, loss flux t1 9.256269\n",
      "Epoch 10/10, Batch 1551/1650, Loss 26.116806, Loss rec 4.030778, loss rec t1 4.943281, loss kl 0.079560, loss_trans 0.002910, loss flux 8.568809, loss flux t1 8.491467\n",
      "Epoch 10/10, Batch 1561/1650, Loss 31.436710, Loss rec 5.170490, loss rec t1 5.629169, loss kl 0.157486, loss_trans 0.005037, loss flux 10.257742, loss flux t1 10.216787\n",
      "Epoch 10/10, Batch 1571/1650, Loss 29.967987, Loss rec 3.390211, loss rec t1 4.212870, loss kl 0.156886, loss_trans 0.004232, loss flux 11.166805, loss flux t1 11.036983\n",
      "Epoch 10/10, Batch 1581/1650, Loss 24.640387, Loss rec 3.743262, loss rec t1 4.424342, loss kl 0.087804, loss_trans 0.002654, loss flux 8.363732, loss flux t1 8.018593\n",
      "Epoch 10/10, Batch 1591/1650, Loss 25.980892, Loss rec 4.041205, loss rec t1 4.373366, loss kl 0.130448, loss_trans 0.003551, loss flux 8.965683, loss flux t1 8.466636\n",
      "Epoch 10/10, Batch 1601/1650, Loss 25.557318, Loss rec 4.239987, loss rec t1 5.581666, loss kl 0.059668, loss_trans 0.004325, loss flux 8.094605, loss flux t1 7.577069\n",
      "Epoch 10/10, Batch 1611/1650, Loss 24.093037, Loss rec 2.814185, loss rec t1 3.880746, loss kl 0.085236, loss_trans 0.003314, loss flux 8.733589, loss flux t1 8.575965\n",
      "Epoch 10/10, Batch 1621/1650, Loss 23.420763, Loss rec 3.236947, loss rec t1 3.632255, loss kl 0.125743, loss_trans 0.003454, loss flux 8.593005, loss flux t1 7.829360\n",
      "Epoch 10/10, Batch 1631/1650, Loss 27.497169, Loss rec 5.181449, loss rec t1 5.593127, loss kl 0.074833, loss_trans 0.006588, loss flux 8.531768, loss flux t1 8.109406\n",
      "Epoch 10/10, Batch 1641/1650, Loss 29.805851, Loss rec 4.605670, loss rec t1 4.951155, loss kl 0.135511, loss_trans 0.003631, loss flux 10.689043, loss flux t1 9.420842\n",
      "Epoch 10/10, Train loss 24.347816, Eval loss 32.201271\n"
     ]
    }
   ],
   "source": [
    "# Optimization\n",
    "opt = Adam(lr=learning_rate)\n",
    "\n",
    "trainable_weights = encoder.trainable_weights + decoder.trainable_weights + transition.trainable_weights\n",
    "\n",
    "updates = opt.get_updates(loss, trainable_weights)\n",
    "\n",
    "iterate = K.function([xt, ut, xt1, m_tf], [loss, loss_rec_t, loss_rec_t1, loss_kl, loss_trans, loss_flux_t, loss_flux_t1], updates=updates)\n",
    "\n",
    "eval_loss = K.function([xt, ut, xt1, m_tf], [loss])\n",
    "\n",
    "num_batch = int(num_train/batch_size)\n",
    "\n",
    "for e in range(epoch):\n",
    "    for ib in range(num_batch):\n",
    "        ind0 = ib * batch_size\n",
    "        state_t_batch = state_t_train[ind0:ind0+batch_size, ...]\n",
    "        state_t1_batch = state_t1_train[ind0:ind0 + batch_size, ...]\n",
    "        bhp_batch = bhp_train[ind0:ind0 + batch_size, ...]\n",
    "        m_batch = m[ind0:ind0 + batch_size, ...]\n",
    "\n",
    "        output = iterate([state_t_batch, bhp_batch, state_t1_batch, m_batch])\n",
    "\n",
    "        # tf.session.run(feed_dict={xt: sat_t_batch, ut: bhp_batch, xt1: sat_t1_batch}, ...\n",
    "        #                fetches= [loss, loss_rec_t, loss_rec_t1, loss_kl, loss_trans, updates])\n",
    "        # But output tensor for the updates operation is not returned\n",
    "\n",
    "        if ib % 10 == 0:\n",
    "            print('Epoch %d/%d, Batch %d/%d, Loss %f, Loss rec %f, loss rec t1 %f, loss kl %f, loss_trans %f, loss flux %f, loss flux t1 %f'\n",
    "                  % (e+1, epoch, ib+1, num_batch, output[0], output[1], output[2], output[3], output[4], output[5], output[6]))\n",
    "    eval_loss_val = eval_loss([state_t_eval, bhp_eval, state_t1_eval, m_eval])\n",
    "\n",
    "    print('Epoch %d/%d, Train loss %f, Eval loss %f' % (e + 1, epoch, output[0], eval_loss_val[0]))\n",
    "\n",
    "\n",
    "encoder.save_weights(output_dir + 'e2c_encoder_' + case_name + case_suffix + train_suffix + model_suffix + '_nt%d_l%d_lr%.0e_ep%d.h5' \\\n",
    "                     % (num_train, latent_dim, learning_rate, epoch))\n",
    "decoder.save_weights(output_dir + 'e2c_decoder_' + case_name + case_suffix + train_suffix + model_suffix + '_nt%d_l%d_lr%.0e_ep%d.h5' \\\n",
    "                     % (num_train, latent_dim, learning_rate, epoch))\n",
    "transition.save_weights(output_dir + 'e2c_transition_' + case_name + case_suffix + train_suffix + model_suffix + '_nt%d_l%d_lr%.0e_ep%d.h5' \\\n",
    "                        % (num_train, latent_dim, learning_rate, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
