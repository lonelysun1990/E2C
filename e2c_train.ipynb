{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import e2c as e2c_util\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use, usually either \"0\" or \"1\"\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_loss(x, t_decoded):\n",
    "    '''Reconstruction loss for the plain VAE'''\n",
    "    v = 0.1\n",
    "    # return K.mean(K.sum((K.batch_flatten(x) - K.batch_flatten(t_decoded)) ** 2 / (2*v) + 0.5*K.log(2*np.pi*v), axis=-1))\n",
    "    return K.mean(K.sum((K.batch_flatten(x) - K.batch_flatten(t_decoded)) ** 2 / (2*v), axis=-1))\n",
    "    # return K.sum((K.batch_flatten(x) - K.batch_flatten(t_decoded)) ** 2, axis=-1)\n",
    "\n",
    "\n",
    "def kl_normal_loss(qm, q_logv, pm, p_logv):\n",
    "    # 0.5 * (torch.log(pv) - torch.log(qv) + qv / pv + (qm - pm).pow(2) / pv - 1)\n",
    "    # -0.5 * K.sum(1 + t_log_var - K.square(t_mean) - K.exp(t_log_var), axis=-1)\n",
    "    kl = -0.5 * (1 - p_logv + q_logv - K.exp(q_logv) / K.exp(p_logv) - K.square(qm - pm) / K.exp(p_logv))\n",
    "    return K.mean(K.sum(kl, axis=-1))\n",
    "\n",
    "\n",
    "def get_flux_loss(m, state, state_pred):\n",
    "    # state, state_pred shape (batch_size, 60, 60, 2)\n",
    "    # p, p_pred shape (batch_size, 60, 60, 1)\n",
    "    # k shape (batch_size, 60, 60, 1)\n",
    "    \n",
    "    # Only consider discrepancies in total flux, not in phases (saturation not used) \n",
    "    \n",
    "    perm = K.exp(m)\n",
    "    p = K.expand_dims(state[:, :, :, 1], -1)\n",
    "    p_pred = K.expand_dims(state_pred[:, :, :, 1], -1)\n",
    "\n",
    "    #print(K.in_shape(xxx))\n",
    "    \n",
    "    tran_x = 1./perm[:, 1:, ...] + 1./perm[:, :-1, ...]\n",
    "    tran_y = 1./perm[:, :, 1:, ...] + 1./perm[:, :, :-1, ...]\n",
    "    flux_x = (p[:, 1:, ...] - p[:, :-1, ...]) / tran_x\n",
    "    flux_y = (p[:, :, 1:, :] - p[:, :, :-1, :]) / tran_y\n",
    "    flux_x_pred = (p_pred[:, 1:, ...] - p_pred[:, :-1, ...]) / tran_x\n",
    "    flux_y_pred = (p_pred[:, :, 1:, :] - p_pred[:, :, :-1, :]) / tran_y\n",
    "\n",
    "    loss_x = K.sum(K.abs(K.batch_flatten(flux_x) - K.batch_flatten(flux_x_pred)), axis=-1)\n",
    "    loss_y = K.sum(K.abs(K.batch_flatten(flux_y) - K.batch_flatten(flux_y_pred)), axis=-1)\n",
    "\n",
    "    loss_flux = K.mean(loss_x + loss_y)\n",
    "    return loss_flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_sat_loss(state, state_pred):\n",
    "    \n",
    "    sat_threshold = 0.105\n",
    "    sat = K.expand_dims(state[:, :, :, 0], -1)\n",
    "    sat_pred = K.expand_dims(state_pred[:, :, :, 0], -1)\n",
    "    \n",
    "    \n",
    "    sat_bool = K.greater_equal(sat, sat_threshold) #will return boolean values\n",
    "    sat_bin = K.cast(sat_bool, dtype=K.floatx()) #will convert bool to 0 and 1  \n",
    "    \n",
    "    sat_pred_bool = K.greater_equal(sat_pred, sat_threshold) #will return boolean values\n",
    "    sat_pred_bin = K.cast(sat_pred_bool, dtype=K.floatx()) #will convert bool to 0 and 1  \n",
    "    \n",
    "#     binary_loss = K.sum(K.abs(K.batch_flatten(sat_bin) - K.batch_flatten(sat_pred_bin)), axis=-1)\n",
    "    \n",
    "    binary_loss = losses.binary_crossentropy(sat_bin, sat_pred_bin)\n",
    "    return K.mean(binary_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_e2c(latent_dim, u_dim, input_shape):\n",
    "    '''\n",
    "    Creates a E2C.\n",
    "\n",
    "    Args:\n",
    "        latent_dim: dimensionality of latent space\n",
    "        return_kl_loss_op: whether to return the operation for\n",
    "                           computing the KL divergence loss.\n",
    "\n",
    "    Returns:\n",
    "        The VAE model. If return_kl_loss_op is True, then the\n",
    "        operation for computing the KL divergence loss is\n",
    "        additionally returned.\n",
    "    '''\n",
    "\n",
    "    encoder_ = e2c_util.create_encoder(latent_dim, input_shape)\n",
    "    decoder_ = e2c_util.create_decoder(latent_dim, input_shape)\n",
    "    transition_ = e2c_util.create_trans(latent_dim, u_dim)\n",
    "    sampler_ = e2c_util.create_sampler()\n",
    "\n",
    "    return encoder_, decoder_, transition_, sampler_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m shape is  (60, 60, 1)\n",
      "m_eval shape is  (2200, 60, 60, 1)\n",
      "m shape is  (6600, 60, 60, 1)\n"
     ]
    }
   ],
   "source": [
    "# Create plain E2C model and associated loss operations\n",
    "\n",
    "################### case specification ######################\n",
    "\n",
    "#     data_dir = '/data/cees/zjin/lstm_rom/datasets/9W_BHP/'\n",
    "data_dir = '/data/cees/zjin/lstm_rom/datasets/9W_BHP_RATE/'\n",
    "output_dir = '/data3/Astro/lstm_rom/e2c_larry/saved_models/'\n",
    "\n",
    "#     case_name = '9w_bhp'\n",
    "case_name = '9w_bhp_rate'\n",
    "\n",
    "#     case_suffix = '_single_out_rel_2'\n",
    "case_suffix = '_fix_wl_rel_1'\n",
    "#     case_suffix = '_single_out_rel_3'\n",
    "train_suffix = '_with_p'\n",
    "model_suffix = '_flux_loss'\n",
    "\n",
    "\n",
    "train_file = case_name + '_e2c_train' + case_suffix + train_suffix + '_n6600_dt20day_nt22_nrun300.mat'\n",
    "eval_file = case_name + '_e2c_eval' + case_suffix + train_suffix +'_n2200_dt20day_nt22_nrun100.mat'\n",
    "\n",
    "#################### model specification ##################\n",
    "epoch = 10\n",
    "batch_size = 4\n",
    "learning_rate = 1e-4\n",
    "latent_dim = 50\n",
    "u_dim = 9 # control dimension\n",
    "\n",
    "# load data\n",
    "hf_r = h5py.File(data_dir + train_file, 'r')\n",
    "state_t_train = np.array(hf_r.get('state_t'))\n",
    "state_t1_train = np.array(hf_r.get('state_t1'))\n",
    "bhp_train = np.array(hf_r.get('bhp'))\n",
    "hf_r.close()\n",
    "\n",
    "num_train = state_t_train.shape[0]\n",
    "\n",
    "hf_r = h5py.File(data_dir + eval_file, 'r')\n",
    "state_t_eval = np.array(hf_r.get('state_t'))\n",
    "state_t1_eval = np.array(hf_r.get('state_t1'))\n",
    "bhp_eval = np.array(hf_r.get('bhp'))\n",
    "hf_r.close()\n",
    "\n",
    "m = np.loadtxt(\"/data/cees/zjin/lstm_rom/sim_runs/case4_9w_bhp_rate/template/logk1.dat\")\n",
    "m = m.reshape(60,60,1)\n",
    "print('m shape is ', m.shape)\n",
    "#     m_tf = K.placeholder((batch_size, 60, 60 ,1))\n",
    "m_tf = Input(shape=(60, 60, 1))\n",
    "\n",
    "\n",
    "\n",
    "m_eval = np.repeat(np.expand_dims(m, axis = 0), state_t_eval.shape[0], axis = 0)\n",
    "print(\"m_eval shape is \", m_eval.shape)\n",
    "m = np.repeat(np.expand_dims(m,axis = 0), state_t_train.shape[0], axis = 0)\n",
    "print(\"m shape is \", m.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Construct E2C\n",
    "input_shape = (60, 60, 2)\n",
    "encoder, decoder, transition, sampler = create_e2c(latent_dim, u_dim, input_shape)\n",
    "\n",
    "xt = Input(shape=input_shape)\n",
    "xt1 = Input(shape=input_shape)\n",
    "ut = Input(shape=(u_dim, ))\n",
    "\n",
    "zt_mean, zt_logvar = encoder(xt)\n",
    "zt = sampler([zt_mean, zt_logvar])\n",
    "xt_rec = decoder(zt)\n",
    "\n",
    "zt1_mean, zt1_logvar = encoder(xt1)\n",
    "\n",
    "# zt1_pred, zt1_mean_pred, zt1_logvar_pred = transition([zt, ut])\n",
    "zt1_pred, zt1_mean_pred = transition([zt, zt_mean, ut])\n",
    "xt1_pred = decoder(zt1_pred)\n",
    "\n",
    "# Compute loss\n",
    "loss_rec_t = reconstruction_loss(xt, xt_rec)\n",
    "loss_rec_t1 = reconstruction_loss(xt1, xt1_pred)\n",
    "\n",
    "loss_flux_t = get_flux_loss(m_tf, xt, xt_rec) / 1000.\n",
    "loss_flux_t1 = get_flux_loss(m_tf, xt1, xt1_pred) / 1000.\n",
    "\n",
    "binary_sat_loss_t = get_binary_sat_loss(xt, xt_rec) * 20\n",
    "binary_sat_loss_t1 = get_binary_sat_loss(xt1, xt1_pred) * 20\n",
    "\n",
    "\n",
    "loss_kl = kl_normal_loss(zt_mean, zt_logvar, 0., 0.)  # log(1.) = 0.\n",
    "# loss_bound = loss_rec_t + loss_rec_t1 + loss_kl  + loss_flux_t + loss_flux_t1 + binary_sat_loss_t + binary_sat_loss_t1\n",
    "loss_bound = loss_rec_t + loss_rec_t1 + loss_kl + binary_sat_loss_t + binary_sat_loss_t1\n",
    "\n",
    "# loss_trans = kl_normal_loss(zt1_mean_pred, zt1_logvar_pred, zt1_mean, zt1_logvar)\n",
    "\n",
    "# Use zt_logvar to approximate zt1_logvar_pred\n",
    "loss_trans = kl_normal_loss(zt1_mean_pred, zt_logvar, zt1_mean, zt1_logvar)\n",
    "\n",
    "\n",
    "trans_loss_weight = 1.0 # lambda in E2C paper Eq. (11)\n",
    "loss = loss_bound + trans_loss_weight * loss_trans\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Batch 1/1650, Loss 3994.166504, Loss rec 1699.668335, loss rec t1 2089.065918, loss kl 0.009152, loss_trans 0.006770, loss flux 35.480938, loss flux t1 38.295868, binary loss 82.045586, binary loss t1 123.370590\n",
      "Epoch 1/10, Batch 11/1650, Loss 1711.158936, Loss rec 638.012512, loss rec t1 775.507568, loss kl 5.425941, loss_trans 4.968709, loss flux 192.247787, loss flux t1 185.470734, binary loss 163.482285, binary loss t1 123.761917\n",
      "Epoch 1/10, Batch 21/1650, Loss 1258.066162, Loss rec 452.084656, loss rec t1 467.091461, loss kl 5.420256, loss_trans 4.436678, loss flux 204.095932, loss flux t1 201.001984, binary loss 175.654083, binary loss t1 153.379013\n",
      "Epoch 1/10, Batch 31/1650, Loss 1027.259277, Loss rec 325.748077, loss rec t1 344.808136, loss kl 3.507523, loss_trans 3.334332, loss flux 193.965866, loss flux t1 191.596573, binary loss 188.391708, binary loss t1 161.469482\n",
      "Epoch 1/10, Batch 41/1650, Loss 1001.368164, Loss rec 289.152985, loss rec t1 375.389893, loss kl 2.897450, loss_trans 2.162613, loss flux 168.773666, loss flux t1 146.350006, binary loss 178.545746, binary loss t1 153.219452\n",
      "Epoch 1/10, Batch 51/1650, Loss 906.946350, Loss rec 260.447021, loss rec t1 255.577637, loss kl 2.029340, loss_trans 1.823519, loss flux 163.427704, loss flux t1 138.263779, binary loss 211.657288, binary loss t1 175.411514\n",
      "Epoch 1/10, Batch 61/1650, Loss 786.877686, Loss rec 309.394379, loss rec t1 281.527740, loss kl 5.285730, loss_trans 3.780580, loss flux 226.302536, loss flux t1 237.609222, binary loss 98.348404, binary loss t1 88.540871\n",
      "Epoch 1/10, Batch 71/1650, Loss 860.987549, Loss rec 331.653564, loss rec t1 337.446533, loss kl 4.077690, loss_trans 3.182142, loss flux 195.260147, loss flux t1 199.722015, binary loss 97.085068, binary loss t1 87.542526\n",
      "Epoch 1/10, Batch 81/1650, Loss 857.227905, Loss rec 306.758850, loss rec t1 254.010071, loss kl 2.910607, loss_trans 2.112034, loss flux 184.570099, loss flux t1 157.303085, binary loss 159.822403, binary loss t1 131.613983\n",
      "Epoch 1/10, Batch 91/1650, Loss 845.387695, Loss rec 310.302582, loss rec t1 281.514557, loss kl 3.115645, loss_trans 2.348677, loss flux 175.828384, loss flux t1 167.670334, binary loss 133.275436, binary loss t1 114.830742\n",
      "Epoch 1/10, Batch 101/1650, Loss 759.579041, Loss rec 262.617279, loss rec t1 281.775269, loss kl 2.485360, loss_trans 1.793221, loss flux 168.143250, loss flux t1 153.485077, binary loss 112.816223, binary loss t1 98.091660\n",
      "Epoch 1/10, Batch 111/1650, Loss 793.586975, Loss rec 290.264313, loss rec t1 274.312866, loss kl 3.063680, loss_trans 2.374788, loss flux 185.957474, loss flux t1 186.257828, binary loss 121.637848, binary loss t1 101.933487\n",
      "Epoch 1/10, Batch 121/1650, Loss 761.549377, Loss rec 285.205872, loss rec t1 238.033478, loss kl 3.375848, loss_trans 2.464770, loss flux 185.420471, loss flux t1 175.921356, binary loss 125.081360, binary loss t1 107.388031\n",
      "Epoch 1/10, Batch 131/1650, Loss 648.442200, Loss rec 189.297531, loss rec t1 190.812286, loss kl 1.478150, loss_trans 1.706405, loss flux 136.442413, loss flux t1 143.035782, binary loss 141.339783, binary loss t1 123.808029\n",
      "Epoch 1/10, Batch 141/1650, Loss 515.748718, Loss rec 140.064346, loss rec t1 138.080643, loss kl 1.781916, loss_trans 1.354102, loss flux 151.543289, loss flux t1 143.891953, binary loss 127.561455, binary loss t1 106.906204\n",
      "Epoch 1/10, Batch 151/1650, Loss 611.374084, Loss rec 215.430191, loss rec t1 191.241592, loss kl 3.290498, loss_trans 2.368203, loss flux 199.652832, loss flux t1 212.900986, binary loss 108.566391, binary loss t1 90.477188\n",
      "Epoch 1/10, Batch 161/1650, Loss 564.455261, Loss rec 207.405884, loss rec t1 190.682053, loss kl 3.774692, loss_trans 2.150862, loss flux 207.208038, loss flux t1 204.200470, binary loss 81.891373, binary loss t1 78.550346\n",
      "Epoch 1/10, Batch 171/1650, Loss 533.505188, Loss rec 197.998474, loss rec t1 166.914566, loss kl 3.395602, loss_trans 2.261800, loss flux 196.768661, loss flux t1 207.506805, binary loss 81.577484, binary loss t1 81.357277\n",
      "Epoch 1/10, Batch 181/1650, Loss 453.060394, Loss rec 95.211731, loss rec t1 127.100464, loss kl 1.652139, loss_trans 1.518283, loss flux 132.913544, loss flux t1 130.552322, binary loss 132.410614, binary loss t1 95.167191\n",
      "Epoch 1/10, Batch 191/1650, Loss 473.121033, Loss rec 178.144547, loss rec t1 155.722260, loss kl 4.573582, loss_trans 2.416748, loss flux 214.547211, loss flux t1 213.792130, binary loss 67.559517, binary loss t1 64.704391\n",
      "Epoch 1/10, Batch 201/1650, Loss 915.560120, Loss rec 285.976837, loss rec t1 368.423370, loss kl 3.619708, loss_trans 2.548714, loss flux 221.890915, loss flux t1 219.966354, binary loss 135.289825, binary loss t1 119.701706\n",
      "Epoch 1/10, Batch 211/1650, Loss 452.629639, Loss rec 154.455582, loss rec t1 186.375839, loss kl 1.218840, loss_trans 1.044520, loss flux 144.994064, loss flux t1 141.287689, binary loss 49.252312, binary loss t1 60.282539\n",
      "Epoch 1/10, Batch 221/1650, Loss 433.651550, Loss rec 105.151558, loss rec t1 118.794273, loss kl 1.968264, loss_trans 1.635195, loss flux 169.233841, loss flux t1 180.589172, binary loss 112.151222, binary loss t1 93.951065\n",
      "Epoch 1/10, Batch 231/1650, Loss 320.374054, Loss rec 97.508339, loss rec t1 110.767883, loss kl 2.720085, loss_trans 1.786604, loss flux 167.562012, loss flux t1 178.715546, binary loss 51.260170, binary loss t1 56.330978\n",
      "Epoch 1/10, Batch 241/1650, Loss 421.128448, Loss rec 102.576920, loss rec t1 118.306625, loss kl 2.121800, loss_trans 1.492286, loss flux 161.296204, loss flux t1 151.415787, binary loss 98.934525, binary loss t1 97.696274\n",
      "Epoch 1/10, Batch 251/1650, Loss 456.664062, Loss rec 163.932922, loss rec t1 149.585724, loss kl 2.938411, loss_trans 1.815554, loss flux 175.921295, loss flux t1 182.006638, binary loss 68.222076, binary loss t1 70.169365\n",
      "Epoch 1/10, Batch 261/1650, Loss 346.571106, Loss rec 80.564217, loss rec t1 84.427345, loss kl 1.947050, loss_trans 1.452472, loss flux 161.087219, loss flux t1 172.167130, binary loss 85.270599, binary loss t1 92.909401\n",
      "Epoch 1/10, Batch 271/1650, Loss 308.043152, Loss rec 98.597702, loss rec t1 105.512131, loss kl 2.877808, loss_trans 1.736276, loss flux 180.066910, loss flux t1 189.242157, binary loss 50.291779, binary loss t1 49.027477\n",
      "Epoch 1/10, Batch 281/1650, Loss 308.938202, Loss rec 77.614319, loss rec t1 82.257820, loss kl 2.429682, loss_trans 1.512492, loss flux 169.440552, loss flux t1 166.843826, binary loss 77.612328, binary loss t1 67.511574\n",
      "Epoch 1/10, Batch 291/1650, Loss 294.796234, Loss rec 78.567902, loss rec t1 74.053238, loss kl 2.474276, loss_trans 1.419844, loss flux 164.291092, loss flux t1 166.436523, binary loss 80.288849, binary loss t1 57.992134\n",
      "Epoch 1/10, Batch 301/1650, Loss 247.160263, Loss rec 54.370903, loss rec t1 59.952568, loss kl 1.946960, loss_trans 1.267931, loss flux 164.618820, loss flux t1 168.434204, binary loss 61.068684, binary loss t1 68.553230\n",
      "Epoch 1/10, Batch 311/1650, Loss 298.681061, Loss rec 62.849579, loss rec t1 66.984909, loss kl 1.805813, loss_trans 1.346024, loss flux 150.462814, loss flux t1 160.780365, binary loss 83.302139, binary loss t1 82.392593\n",
      "Epoch 1/10, Batch 321/1650, Loss 291.327026, Loss rec 85.440292, loss rec t1 73.979370, loss kl 2.605795, loss_trans 1.648630, loss flux 179.466400, loss flux t1 189.332520, binary loss 65.121925, binary loss t1 62.531044\n",
      "Epoch 1/10, Batch 331/1650, Loss 267.688599, Loss rec 68.025894, loss rec t1 78.316734, loss kl 1.686110, loss_trans 1.059384, loss flux 151.946625, loss flux t1 149.536942, binary loss 58.504578, binary loss t1 60.095886\n",
      "Epoch 1/10, Batch 341/1650, Loss 386.447754, Loss rec 105.421326, loss rec t1 107.331146, loss kl 1.954352, loss_trans 1.057616, loss flux 159.065430, loss flux t1 151.789291, binary loss 85.696907, binary loss t1 84.986404\n",
      "Epoch 1/10, Batch 351/1650, Loss 260.292786, Loss rec 77.962730, loss rec t1 69.557205, loss kl 2.785301, loss_trans 1.532366, loss flux 184.208160, loss flux t1 196.498199, binary loss 55.179829, binary loss t1 53.275356\n",
      "Epoch 1/10, Batch 361/1650, Loss 262.518799, Loss rec 64.812683, loss rec t1 74.817825, loss kl 1.821682, loss_trans 1.038068, loss flux 155.702332, loss flux t1 162.038925, binary loss 64.462784, binary loss t1 55.565765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Batch 371/1650, Loss 284.475647, Loss rec 72.454689, loss rec t1 76.818710, loss kl 2.516236, loss_trans 1.333847, loss flux 168.147888, loss flux t1 173.684692, binary loss 65.589104, binary loss t1 65.763069\n",
      "Epoch 1/10, Batch 381/1650, Loss 224.523529, Loss rec 61.518127, loss rec t1 70.384827, loss kl 2.144515, loss_trans 1.093054, loss flux 166.211823, loss flux t1 167.397049, binary loss 47.811848, binary loss t1 41.571159\n",
      "Epoch 1/10, Batch 391/1650, Loss 360.215912, Loss rec 73.209908, loss rec t1 82.546211, loss kl 2.401870, loss_trans 1.307721, loss flux 166.333282, loss flux t1 177.086777, binary loss 105.335327, binary loss t1 95.414894\n",
      "Epoch 1/10, Batch 401/1650, Loss 251.751511, Loss rec 71.430481, loss rec t1 75.874115, loss kl 1.618123, loss_trans 0.825736, loss flux 155.069260, loss flux t1 144.989975, binary loss 50.338249, binary loss t1 51.664833\n",
      "Epoch 1/10, Batch 411/1650, Loss 230.476028, Loss rec 63.455208, loss rec t1 70.713493, loss kl 2.565700, loss_trans 1.252434, loss flux 168.073227, loss flux t1 176.547134, binary loss 49.133797, binary loss t1 43.355408\n",
      "Epoch 1/10, Batch 421/1650, Loss 281.160675, Loss rec 67.746117, loss rec t1 69.964417, loss kl 2.500353, loss_trans 1.164135, loss flux 174.261459, loss flux t1 175.311203, binary loss 75.217545, binary loss t1 64.568115\n",
      "Epoch 1/10, Batch 431/1650, Loss 308.250793, Loss rec 40.439770, loss rec t1 43.124245, loss kl 1.813374, loss_trans 0.936763, loss flux 139.572327, loss flux t1 142.846100, binary loss 128.403839, binary loss t1 93.532806\n",
      "Epoch 1/10, Batch 441/1650, Loss 214.627426, Loss rec 59.918304, loss rec t1 65.008858, loss kl 1.811887, loss_trans 0.930766, loss flux 150.623886, loss flux t1 156.542801, binary loss 43.835522, binary loss t1 43.122093\n",
      "Epoch 1/10, Batch 451/1650, Loss 263.257874, Loss rec 39.512444, loss rec t1 50.544594, loss kl 1.229875, loss_trans 0.631665, loss flux 134.655853, loss flux t1 137.337479, binary loss 83.499947, binary loss t1 87.839340\n",
      "Epoch 1/10, Batch 461/1650, Loss 232.576294, Loss rec 54.391735, loss rec t1 61.722328, loss kl 1.490886, loss_trans 0.783042, loss flux 147.144485, loss flux t1 147.950577, binary loss 55.976215, binary loss t1 58.212093\n",
      "Epoch 1/10, Batch 471/1650, Loss 289.549805, Loss rec 38.340134, loss rec t1 46.634930, loss kl 1.292290, loss_trans 0.631885, loss flux 134.842453, loss flux t1 135.837723, binary loss 104.446960, binary loss t1 98.203583\n",
      "Epoch 1/10, Batch 481/1650, Loss 225.130707, Loss rec 40.773598, loss rec t1 44.473251, loss kl 1.312700, loss_trans 0.700628, loss flux 135.865433, loss flux t1 142.619202, binary loss 67.100143, binary loss t1 70.770378\n",
      "Epoch 1/10, Batch 491/1650, Loss 219.542892, Loss rec 46.175690, loss rec t1 52.858219, loss kl 0.886793, loss_trans 0.537541, loss flux 130.609863, loss flux t1 137.493561, binary loss 57.104980, binary loss t1 61.979679\n",
      "Epoch 1/10, Batch 501/1650, Loss 219.526306, Loss rec 46.259460, loss rec t1 51.751663, loss kl 1.597052, loss_trans 0.790411, loss flux 153.416336, loss flux t1 152.347824, binary loss 62.884583, binary loss t1 56.243141\n",
      "Epoch 1/10, Batch 511/1650, Loss 322.832764, Loss rec 60.359177, loss rec t1 62.065323, loss kl 1.339374, loss_trans 0.612600, loss flux 139.210480, loss flux t1 133.955154, binary loss 104.666489, binary loss t1 93.789787\n",
      "Epoch 1/10, Batch 521/1650, Loss 148.416229, Loss rec 31.270264, loss rec t1 37.171021, loss kl 1.700934, loss_trans 0.741715, loss flux 140.081573, loss flux t1 144.176666, binary loss 36.008102, binary loss t1 41.524193\n",
      "Epoch 1/10, Batch 531/1650, Loss 275.519867, Loss rec 34.520668, loss rec t1 37.662849, loss kl 1.061042, loss_trans 0.545933, loss flux 123.754646, loss flux t1 128.690308, binary loss 98.959839, binary loss t1 102.769531\n",
      "Epoch 1/10, Batch 541/1650, Loss 268.199127, Loss rec 25.227972, loss rec t1 40.968651, loss kl 1.255610, loss_trans 0.632157, loss flux 126.877411, loss flux t1 133.354385, binary loss 99.311440, binary loss t1 100.803268\n",
      "Epoch 1/10, Batch 551/1650, Loss 149.852478, Loss rec 26.310928, loss rec t1 32.475002, loss kl 1.361552, loss_trans 0.685796, loss flux 130.474579, loss flux t1 145.457504, binary loss 43.533764, binary loss t1 45.485451\n",
      "Epoch 1/10, Batch 561/1650, Loss 263.596161, Loss rec 46.061344, loss rec t1 53.628860, loss kl 1.155662, loss_trans 0.604622, loss flux 131.830521, loss flux t1 130.403580, binary loss 86.341469, binary loss t1 75.804222\n",
      "Epoch 1/10, Batch 571/1650, Loss 198.428116, Loss rec 49.989407, loss rec t1 52.750061, loss kl 1.229061, loss_trans 0.545170, loss flux 132.120728, loss flux t1 130.394180, binary loss 46.957329, binary loss t1 46.957088\n",
      "Epoch 1/10, Batch 581/1650, Loss 227.278107, Loss rec 48.047546, loss rec t1 49.262344, loss kl 1.268532, loss_trans 0.684630, loss flux 137.697113, loss flux t1 137.187500, binary loss 65.236786, binary loss t1 62.778267\n",
      "Epoch 1/10, Batch 591/1650, Loss 285.983429, Loss rec 35.425323, loss rec t1 42.891052, loss kl 1.061802, loss_trans 0.519010, loss flux 126.747589, loss flux t1 129.297775, binary loss 104.600975, binary loss t1 101.485275\n",
      "Epoch 1/10, Batch 601/1650, Loss 214.957062, Loss rec 54.210934, loss rec t1 51.514565, loss kl 1.208438, loss_trans 0.645826, loss flux 133.203766, loss flux t1 132.957321, binary loss 56.245342, binary loss t1 51.131954\n",
      "Epoch 1/10, Batch 611/1650, Loss 191.387604, Loss rec 48.872864, loss rec t1 54.089355, loss kl 1.246494, loss_trans 0.623990, loss flux 131.544754, loss flux t1 128.646255, binary loss 44.343086, binary loss t1 42.211823\n",
      "Epoch 1/10, Batch 621/1650, Loss 177.269287, Loss rec 36.986607, loss rec t1 40.120083, loss kl 1.364124, loss_trans 0.624042, loss flux 135.117645, loss flux t1 135.983398, binary loss 52.354416, binary loss t1 45.820026\n",
      "Epoch 1/10, Batch 631/1650, Loss 220.039932, Loss rec 48.843025, loss rec t1 54.597057, loss kl 1.504568, loss_trans 0.584878, loss flux 128.129227, loss flux t1 126.698486, binary loss 57.953281, binary loss t1 56.557106\n",
      "Epoch 1/10, Batch 641/1650, Loss 280.816742, Loss rec 67.984497, loss rec t1 64.857765, loss kl 1.252921, loss_trans 0.624633, loss flux 132.075348, loss flux t1 131.784302, binary loss 73.181435, binary loss t1 72.915497\n",
      "Epoch 1/10, Batch 651/1650, Loss 201.857025, Loss rec 44.066071, loss rec t1 41.038498, loss kl 1.255802, loss_trans 0.634079, loss flux 119.995628, loss flux t1 121.239525, binary loss 59.745754, binary loss t1 55.116821\n",
      "Epoch 1/10, Batch 661/1650, Loss 185.389496, Loss rec 32.366581, loss rec t1 37.227966, loss kl 1.510013, loss_trans 0.596389, loss flux 131.052811, loss flux t1 130.213348, binary loss 61.138035, binary loss t1 52.550522\n",
      "Epoch 1/10, Batch 671/1650, Loss 206.966202, Loss rec 40.680389, loss rec t1 52.666176, loss kl 1.166389, loss_trans 0.578572, loss flux 122.556435, loss flux t1 122.364838, binary loss 58.162991, binary loss t1 53.711681\n",
      "Epoch 1/10, Batch 681/1650, Loss 291.710632, Loss rec 26.047800, loss rec t1 43.145988, loss kl 1.090578, loss_trans 0.502762, loss flux 121.890236, loss flux t1 130.788223, binary loss 120.197632, binary loss t1 100.725906\n",
      "Epoch 1/10, Batch 691/1650, Loss 200.822296, Loss rec 36.527534, loss rec t1 39.784767, loss kl 1.868121, loss_trans 0.694770, loss flux 157.187851, loss flux t1 160.109650, binary loss 64.861588, binary loss t1 57.085526\n",
      "Epoch 1/10, Batch 701/1650, Loss 222.631744, Loss rec 54.409767, loss rec t1 57.355438, loss kl 1.769282, loss_trans 0.752042, loss flux 145.571762, loss flux t1 141.836868, binary loss 56.175987, binary loss t1 52.169224\n",
      "Epoch 1/10, Batch 711/1650, Loss 203.013092, Loss rec 49.095573, loss rec t1 43.474056, loss kl 1.960290, loss_trans 0.831377, loss flux 154.353943, loss flux t1 157.327118, binary loss 56.497452, binary loss t1 51.154343\n",
      "Epoch 1/10, Batch 721/1650, Loss 178.606934, Loss rec 50.070969, loss rec t1 51.474747, loss kl 1.404070, loss_trans 0.536780, loss flux 128.656525, loss flux t1 129.134644, binary loss 40.726402, binary loss t1 34.393982\n",
      "Epoch 1/10, Batch 731/1650, Loss 428.550873, Loss rec 95.957092, loss rec t1 93.722054, loss kl 1.165396, loss_trans 0.470399, loss flux 130.171936, loss flux t1 128.201019, binary loss 123.799240, binary loss t1 113.436699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Batch 741/1650, Loss 184.266876, Loss rec 34.562340, loss rec t1 39.742981, loss kl 1.238271, loss_trans 0.596800, loss flux 125.674194, loss flux t1 127.396774, binary loss 56.751930, binary loss t1 51.374546\n",
      "Epoch 1/10, Batch 751/1650, Loss 207.357773, Loss rec 35.141182, loss rec t1 34.695145, loss kl 1.270299, loss_trans 0.550329, loss flux 116.872383, loss flux t1 114.924538, binary loss 68.982224, binary loss t1 66.718597\n",
      "Epoch 1/10, Batch 761/1650, Loss 277.755432, Loss rec 41.972031, loss rec t1 47.764313, loss kl 1.529584, loss_trans 0.621046, loss flux 122.735069, loss flux t1 119.983429, binary loss 100.948730, binary loss t1 84.919731\n",
      "Epoch 1/10, Batch 771/1650, Loss 128.029312, Loss rec 33.268806, loss rec t1 34.882355, loss kl 0.939799, loss_trans 0.522696, loss flux 105.936218, loss flux t1 108.293770, binary loss 30.565823, binary loss t1 27.849831\n",
      "Epoch 1/10, Batch 781/1650, Loss 179.820663, Loss rec 24.643578, loss rec t1 28.682842, loss kl 0.954843, loss_trans 0.506957, loss flux 119.399445, loss flux t1 119.727661, binary loss 63.687561, binary loss t1 61.344875\n",
      "Epoch 1/10, Batch 791/1650, Loss 210.786942, Loss rec 34.176476, loss rec t1 40.197254, loss kl 0.889019, loss_trans 0.483174, loss flux 109.850769, loss flux t1 112.577759, binary loss 68.200729, binary loss t1 66.840294\n",
      "Epoch 1/10, Batch 801/1650, Loss 165.452988, Loss rec 27.486736, loss rec t1 31.637850, loss kl 1.311212, loss_trans 0.579442, loss flux 129.678589, loss flux t1 131.951294, binary loss 56.514954, binary loss t1 47.922802\n",
      "Epoch 1/10, Batch 811/1650, Loss 214.929794, Loss rec 43.519310, loss rec t1 41.329803, loss kl 1.668516, loss_trans 0.623826, loss flux 135.727356, loss flux t1 136.947952, binary loss 70.954834, binary loss t1 56.833488\n",
      "Epoch 1/10, Batch 821/1650, Loss 156.175674, Loss rec 20.426556, loss rec t1 23.920444, loss kl 0.956036, loss_trans 0.415148, loss flux 108.737503, loss flux t1 111.363174, binary loss 57.444920, binary loss t1 53.012581\n",
      "Epoch 1/10, Batch 831/1650, Loss 159.137100, Loss rec 22.634106, loss rec t1 25.238703, loss kl 1.630492, loss_trans 0.537646, loss flux 122.382690, loss flux t1 119.720871, binary loss 61.277233, binary loss t1 47.818924\n",
      "Epoch 1/10, Batch 841/1650, Loss 157.484940, Loss rec 19.330467, loss rec t1 21.977182, loss kl 0.665937, loss_trans 0.323725, loss flux 101.405510, loss flux t1 101.465111, binary loss 58.635719, binary loss t1 56.551914\n",
      "Epoch 1/10, Batch 851/1650, Loss 211.879059, Loss rec 22.648291, loss rec t1 26.865967, loss kl 1.144307, loss_trans 0.454684, loss flux 119.089272, loss flux t1 120.554863, binary loss 83.484390, binary loss t1 77.281410\n",
      "Epoch 1/10, Batch 861/1650, Loss 144.747040, Loss rec 32.260132, loss rec t1 31.986334, loss kl 1.320155, loss_trans 0.498203, loss flux 117.689362, loss flux t1 120.173004, binary loss 42.051945, binary loss t1 36.630280\n",
      "Epoch 1/10, Batch 871/1650, Loss 175.597031, Loss rec 25.958614, loss rec t1 25.977776, loss kl 1.434547, loss_trans 0.517184, loss flux 133.559097, loss flux t1 131.549606, binary loss 65.746048, binary loss t1 55.962864\n",
      "Epoch 1/10, Batch 881/1650, Loss 234.656204, Loss rec 21.662792, loss rec t1 25.814533, loss kl 0.930598, loss_trans 0.393913, loss flux 107.436890, loss flux t1 114.899925, binary loss 95.751411, binary loss t1 90.102959\n",
      "Epoch 1/10, Batch 891/1650, Loss 158.249023, Loss rec 20.744572, loss rec t1 23.502701, loss kl 0.898212, loss_trans 0.364172, loss flux 112.701218, loss flux t1 114.054665, binary loss 61.274796, binary loss t1 51.464577\n",
      "Epoch 1/10, Batch 901/1650, Loss 143.659164, Loss rec 22.503780, loss rec t1 23.442795, loss kl 1.505428, loss_trans 0.572009, loss flux 128.803986, loss flux t1 133.623169, binary loss 50.300068, binary loss t1 45.335091\n",
      "Epoch 1/10, Batch 911/1650, Loss 130.356506, Loss rec 16.248692, loss rec t1 14.638607, loss kl 0.807324, loss_trans 0.280172, loss flux 103.890053, loss flux t1 106.756882, binary loss 48.294586, binary loss t1 50.087128\n",
      "Epoch 1/10, Batch 921/1650, Loss 169.170349, Loss rec 16.859547, loss rec t1 22.701122, loss kl 1.002650, loss_trans 0.374691, loss flux 110.727448, loss flux t1 115.735748, binary loss 64.636749, binary loss t1 63.595577\n",
      "Epoch 1/10, Batch 931/1650, Loss 170.727798, Loss rec 25.897591, loss rec t1 28.985924, loss kl 0.922657, loss_trans 0.333220, loss flux 107.360428, loss flux t1 107.259224, binary loss 58.510674, binary loss t1 56.077724\n",
      "Epoch 1/10, Batch 941/1650, Loss 141.863678, Loss rec 19.140676, loss rec t1 27.167980, loss kl 1.336601, loss_trans 0.397816, loss flux 115.421638, loss flux t1 115.776810, binary loss 53.034054, binary loss t1 40.786556\n",
      "Epoch 1/10, Batch 951/1650, Loss 158.210220, Loss rec 23.524799, loss rec t1 23.829470, loss kl 0.797942, loss_trans 0.315344, loss flux 108.378090, loss flux t1 114.314445, binary loss 57.073387, binary loss t1 52.669281\n",
      "Epoch 1/10, Batch 961/1650, Loss 553.989929, Loss rec 133.908325, loss rec t1 143.135864, loss kl 0.917240, loss_trans 0.334987, loss flux 126.470947, loss flux t1 124.494896, binary loss 142.927902, binary loss t1 132.765625\n",
      "Epoch 1/10, Batch 971/1650, Loss 414.491333, Loss rec 171.147980, loss rec t1 185.959442, loss kl 0.766555, loss_trans 0.331844, loss flux 105.112961, loss flux t1 102.964600, binary loss 29.265457, binary loss t1 27.020065\n",
      "Epoch 1/10, Batch 981/1650, Loss 435.518707, Loss rec 91.771187, loss rec t1 101.184326, loss kl 0.562496, loss_trans 0.312118, loss flux 98.512253, loss flux t1 99.785461, binary loss 125.635895, binary loss t1 116.052711\n",
      "Epoch 1/10, Batch 991/1650, Loss 168.385941, Loss rec 55.751015, loss rec t1 68.847687, loss kl 0.830094, loss_trans 0.465564, loss flux 97.072929, loss flux t1 100.971161, binary loss 21.311113, binary loss t1 21.180458\n",
      "Epoch 1/10, Batch 1001/1650, Loss 204.180405, Loss rec 43.089016, loss rec t1 44.300255, loss kl 1.836707, loss_trans 0.727882, loss flux 134.740891, loss flux t1 135.438278, binary loss 59.728741, binary loss t1 54.497818\n",
      "Epoch 1/10, Batch 1011/1650, Loss 153.671158, Loss rec 26.194817, loss rec t1 25.914608, loss kl 0.989836, loss_trans 0.451153, loss flux 105.348122, loss flux t1 108.129784, binary loss 52.397476, binary loss t1 47.723274\n",
      "Epoch 1/10, Batch 1021/1650, Loss 120.890053, Loss rec 23.105183, loss rec t1 31.187014, loss kl 1.007541, loss_trans 0.418191, loss flux 111.430145, loss flux t1 111.846802, binary loss 33.448387, binary loss t1 31.723743\n",
      "Epoch 1/10, Batch 1031/1650, Loss 160.031876, Loss rec 27.560408, loss rec t1 34.941086, loss kl 1.638776, loss_trans 0.611752, loss flux 120.400932, loss flux t1 121.959206, binary loss 46.477943, binary loss t1 48.801899\n",
      "Epoch 1/10, Batch 1041/1650, Loss 125.622955, Loss rec 18.055119, loss rec t1 22.898762, loss kl 1.017628, loss_trans 0.386275, loss flux 105.127678, loss flux t1 100.927490, binary loss 43.092384, binary loss t1 40.172787\n",
      "Epoch 1/10, Batch 1051/1650, Loss 119.298302, Loss rec 19.174629, loss rec t1 22.829937, loss kl 0.818083, loss_trans 0.412318, loss flux 100.318939, loss flux t1 100.338860, binary loss 38.086296, binary loss t1 37.977043\n",
      "Epoch 1/10, Batch 1061/1650, Loss 152.236099, Loss rec 22.707150, loss rec t1 22.344259, loss kl 1.460054, loss_trans 0.583702, loss flux 120.477783, loss flux t1 125.004204, binary loss 54.829460, binary loss t1 50.311474\n",
      "Epoch 1/10, Batch 1071/1650, Loss 108.268951, Loss rec 16.366430, loss rec t1 18.276514, loss kl 1.336631, loss_trans 0.468066, loss flux 112.595734, loss flux t1 114.397034, binary loss 36.208111, binary loss t1 35.613201\n",
      "Epoch 1/10, Batch 1081/1650, Loss 146.107956, Loss rec 25.098745, loss rec t1 23.220966, loss kl 1.193780, loss_trans 0.511393, loss flux 108.913933, loss flux t1 105.678474, binary loss 51.682095, binary loss t1 44.400974\n",
      "Epoch 1/10, Batch 1091/1650, Loss 125.883972, Loss rec 12.540028, loss rec t1 19.029057, loss kl 0.557588, loss_trans 0.283354, loss flux 94.087227, loss flux t1 97.656609, binary loss 45.726822, binary loss t1 47.747124\n",
      "Epoch 1/10, Batch 1101/1650, Loss 175.082138, Loss rec 16.318790, loss rec t1 19.167980, loss kl 0.780679, loss_trans 0.288431, loss flux 96.092102, loss flux t1 96.183189, binary loss 71.676010, binary loss t1 66.850235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Batch 1111/1650, Loss 131.879837, Loss rec 13.253901, loss rec t1 12.442616, loss kl 0.671845, loss_trans 0.240865, loss flux 87.195175, loss flux t1 91.815605, binary loss 51.283779, binary loss t1 53.986832\n",
      "Epoch 1/10, Batch 1121/1650, Loss 139.285843, Loss rec 24.742865, loss rec t1 21.517204, loss kl 1.254977, loss_trans 0.471608, loss flux 112.613457, loss flux t1 114.577271, binary loss 49.351860, binary loss t1 41.947334\n",
      "Epoch 1/10, Batch 1131/1650, Loss 107.282700, Loss rec 19.994045, loss rec t1 21.114084, loss kl 1.801281, loss_trans 0.575744, loss flux 122.413048, loss flux t1 120.702019, binary loss 33.725258, binary loss t1 30.072281\n",
      "Epoch 1/10, Batch 1141/1650, Loss 131.763657, Loss rec 17.790386, loss rec t1 20.260170, loss kl 1.181509, loss_trans 0.482798, loss flux 112.615486, loss flux t1 111.256577, binary loss 47.342220, binary loss t1 44.706570\n",
      "Epoch 1/10, Batch 1151/1650, Loss 91.749977, Loss rec 12.804768, loss rec t1 15.063910, loss kl 1.387040, loss_trans 0.379034, loss flux 120.271332, loss flux t1 125.136421, binary loss 31.467485, binary loss t1 30.647738\n",
      "Epoch 1/10, Batch 1161/1650, Loss 127.667023, Loss rec 24.699911, loss rec t1 25.286501, loss kl 1.091528, loss_trans 0.423999, loss flux 106.417786, loss flux t1 106.658043, binary loss 39.069096, binary loss t1 37.095993\n",
      "Epoch 1/10, Batch 1171/1650, Loss 123.808395, Loss rec 19.456615, loss rec t1 21.176979, loss kl 0.842244, loss_trans 0.324862, loss flux 103.547112, loss flux t1 104.233017, binary loss 40.751656, binary loss t1 41.256042\n",
      "Epoch 1/10, Batch 1181/1650, Loss 139.456985, Loss rec 34.342033, loss rec t1 24.894344, loss kl 1.428756, loss_trans 0.474516, loss flux 116.243004, loss flux t1 123.036781, binary loss 39.678158, binary loss t1 38.639179\n",
      "Epoch 1/10, Batch 1191/1650, Loss 132.377625, Loss rec 21.890604, loss rec t1 21.090763, loss kl 1.222157, loss_trans 0.409665, loss flux 115.084480, loss flux t1 114.849625, binary loss 46.020771, binary loss t1 41.743664\n",
      "Epoch 1/10, Batch 1201/1650, Loss 137.244354, Loss rec 14.359343, loss rec t1 13.679552, loss kl 0.843658, loss_trans 0.291741, loss flux 95.081055, loss flux t1 92.309753, binary loss 60.792545, binary loss t1 47.277508\n",
      "Epoch 1/10, Batch 1211/1650, Loss 141.916809, Loss rec 21.792648, loss rec t1 22.889944, loss kl 1.099750, loss_trans 0.385488, loss flux 108.705437, loss flux t1 107.764603, binary loss 50.376923, binary loss t1 45.372051\n",
      "Epoch 1/10, Batch 1221/1650, Loss 128.934280, Loss rec 11.674697, loss rec t1 13.574671, loss kl 0.948667, loss_trans 0.340715, loss flux 106.365868, loss flux t1 106.966934, binary loss 55.339211, binary loss t1 47.056328\n",
      "Epoch 1/10, Batch 1231/1650, Loss 100.981461, Loss rec 9.529923, loss rec t1 11.577554, loss kl 0.853845, loss_trans 0.314561, loss flux 97.517067, loss flux t1 102.631844, binary loss 37.913303, binary loss t1 40.792278\n",
      "Epoch 1/10, Batch 1241/1650, Loss 116.771011, Loss rec 12.202709, loss rec t1 11.211658, loss kl 0.953599, loss_trans 0.276846, loss flux 102.828476, loss flux t1 105.852501, binary loss 49.010941, binary loss t1 43.115257\n",
      "Epoch 1/10, Batch 1251/1650, Loss 117.438286, Loss rec 15.380743, loss rec t1 20.235897, loss kl 0.819255, loss_trans 0.284553, loss flux 104.065941, loss flux t1 102.111168, binary loss 42.094769, binary loss t1 38.623074\n",
      "Epoch 1/10, Batch 1261/1650, Loss 114.554634, Loss rec 19.694010, loss rec t1 22.047855, loss kl 0.804963, loss_trans 0.318303, loss flux 103.167816, loss flux t1 98.449005, binary loss 37.927219, binary loss t1 33.762287\n",
      "Epoch 1/10, Batch 1271/1650, Loss 119.415230, Loss rec 21.873806, loss rec t1 21.788151, loss kl 1.009839, loss_trans 0.376930, loss flux 109.373055, loss flux t1 107.191711, binary loss 37.993401, binary loss t1 36.373112\n",
      "Epoch 1/10, Batch 1281/1650, Loss 113.547798, Loss rec 12.280828, loss rec t1 13.850807, loss kl 0.809641, loss_trans 0.219302, loss flux 94.926414, loss flux t1 95.611214, binary loss 49.161301, binary loss t1 37.225922\n",
      "Epoch 1/10, Batch 1291/1650, Loss 84.546257, Loss rec 9.852131, loss rec t1 10.582312, loss kl 0.574040, loss_trans 0.194235, loss flux 87.790230, loss flux t1 92.530388, binary loss 31.871168, binary loss t1 31.472368\n",
      "Epoch 1/10, Batch 1301/1650, Loss 90.886452, Loss rec 13.009500, loss rec t1 13.451054, loss kl 0.759148, loss_trans 0.237337, loss flux 97.206848, loss flux t1 96.228065, binary loss 32.181648, binary loss t1 31.247770\n",
      "Epoch 1/10, Batch 1311/1650, Loss 131.105835, Loss rec 12.109617, loss rec t1 15.674976, loss kl 0.711266, loss_trans 0.257243, loss flux 94.488113, loss flux t1 98.511147, binary loss 52.635185, binary loss t1 49.717545\n",
      "Epoch 1/10, Batch 1321/1650, Loss 111.707634, Loss rec 20.186340, loss rec t1 17.766796, loss kl 1.185908, loss_trans 0.340173, loss flux 107.212173, loss flux t1 108.372070, binary loss 36.503281, binary loss t1 35.725132\n",
      "Epoch 1/10, Batch 1331/1650, Loss 129.797592, Loss rec 15.755716, loss rec t1 17.740139, loss kl 0.737645, loss_trans 0.294903, loss flux 101.572693, loss flux t1 103.528221, binary loss 47.567795, binary loss t1 47.701378\n",
      "Epoch 1/10, Batch 1341/1650, Loss 90.998100, Loss rec 8.851517, loss rec t1 11.209869, loss kl 0.783877, loss_trans 0.231852, loss flux 90.549828, loss flux t1 95.777191, binary loss 36.898666, binary loss t1 33.022320\n",
      "Epoch 1/10, Batch 1351/1650, Loss 95.898598, Loss rec 8.521908, loss rec t1 9.638961, loss kl 0.548640, loss_trans 0.212791, loss flux 96.266693, loss flux t1 99.979889, binary loss 34.767891, binary loss t1 42.208405\n",
      "Epoch 1/10, Batch 1361/1650, Loss 129.116623, Loss rec 15.487206, loss rec t1 16.940779, loss kl 1.359490, loss_trans 0.336126, loss flux 113.744759, loss flux t1 109.839241, binary loss 51.825684, binary loss t1 43.167347\n",
      "Epoch 1/10, Batch 1371/1650, Loss 120.312698, Loss rec 10.634113, loss rec t1 11.055345, loss kl 0.618804, loss_trans 0.193789, loss flux 84.950882, loss flux t1 89.828148, binary loss 52.679710, binary loss t1 45.130936\n",
      "Epoch 1/10, Batch 1381/1650, Loss 108.284119, Loss rec 14.922019, loss rec t1 15.351899, loss kl 1.066539, loss_trans 0.302655, loss flux 111.257660, loss flux t1 112.824768, binary loss 39.283440, binary loss t1 37.357555\n",
      "Epoch 1/10, Batch 1391/1650, Loss 93.574127, Loss rec 12.897317, loss rec t1 13.111123, loss kl 1.140016, loss_trans 0.339428, loss flux 100.307663, loss flux t1 105.648071, binary loss 34.636501, binary loss t1 31.449736\n",
      "Epoch 1/10, Batch 1401/1650, Loss 100.102478, Loss rec 15.523187, loss rec t1 17.823261, loss kl 0.715225, loss_trans 0.227154, loss flux 99.564865, loss flux t1 104.774246, binary loss 33.471573, binary loss t1 32.342079\n",
      "Epoch 1/10, Batch 1411/1650, Loss 90.448715, Loss rec 12.853695, loss rec t1 13.627254, loss kl 0.999645, loss_trans 0.338748, loss flux 104.844841, loss flux t1 104.846039, binary loss 33.198971, binary loss t1 29.430405\n",
      "Epoch 1/10, Batch 1421/1650, Loss 131.485214, Loss rec 13.471952, loss rec t1 14.967752, loss kl 0.742570, loss_trans 0.269245, loss flux 91.096748, loss flux t1 91.306335, binary loss 52.477753, binary loss t1 49.555954\n",
      "Epoch 1/10, Batch 1431/1650, Loss 85.897575, Loss rec 8.317571, loss rec t1 9.401634, loss kl 0.886817, loss_trans 0.276082, loss flux 99.907425, loss flux t1 101.056763, binary loss 34.193901, binary loss t1 32.821575\n",
      "Epoch 1/10, Batch 1441/1650, Loss 103.422264, Loss rec 10.316526, loss rec t1 12.383112, loss kl 1.087306, loss_trans 0.304616, loss flux 103.322243, loss flux t1 109.345947, binary loss 41.213718, binary loss t1 38.116982\n",
      "Epoch 1/10, Batch 1451/1650, Loss 114.555420, Loss rec 14.338175, loss rec t1 14.764662, loss kl 0.871975, loss_trans 0.310259, loss flux 97.297050, loss flux t1 99.463455, binary loss 42.766350, binary loss t1 41.504002\n",
      "Epoch 1/10, Batch 1461/1650, Loss 114.588463, Loss rec 11.047683, loss rec t1 11.016931, loss kl 0.704758, loss_trans 0.227969, loss flux 98.169960, loss flux t1 100.120193, binary loss 48.008926, binary loss t1 43.582199\n",
      "Epoch 1/10, Batch 1471/1650, Loss 99.755020, Loss rec 12.354107, loss rec t1 14.433608, loss kl 0.938925, loss_trans 0.260616, loss flux 104.300598, loss flux t1 104.949883, binary loss 37.312538, binary loss t1 34.455219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Batch 1481/1650, Loss 79.112968, Loss rec 13.771149, loss rec t1 12.356915, loss kl 0.846596, loss_trans 0.240342, loss flux 101.137665, loss flux t1 104.656197, binary loss 25.917114, binary loss t1 25.980854\n",
      "Epoch 1/10, Batch 1491/1650, Loss 94.276962, Loss rec 14.006546, loss rec t1 12.463839, loss kl 1.281126, loss_trans 0.310988, loss flux 112.275780, loss flux t1 111.829376, binary loss 35.078377, binary loss t1 31.136084\n",
      "Epoch 1/10, Batch 1501/1650, Loss 137.513077, Loss rec 15.465912, loss rec t1 19.369797, loss kl 1.159825, loss_trans 0.346162, loss flux 108.043503, loss flux t1 109.580696, binary loss 52.013496, binary loss t1 49.157883\n",
      "Epoch 1/10, Batch 1511/1650, Loss 107.152878, Loss rec 17.309219, loss rec t1 19.116594, loss kl 0.702352, loss_trans 0.284940, loss flux 95.441689, loss flux t1 94.396362, binary loss 35.224159, binary loss t1 34.515610\n",
      "Epoch 1/10, Batch 1521/1650, Loss 88.277916, Loss rec 8.457202, loss rec t1 9.076288, loss kl 0.751772, loss_trans 0.211845, loss flux 94.300423, loss flux t1 99.502678, binary loss 34.391476, binary loss t1 35.389339\n",
      "Epoch 1/10, Batch 1531/1650, Loss 95.715759, Loss rec 15.638664, loss rec t1 15.296902, loss kl 0.785035, loss_trans 0.266171, loss flux 97.252342, loss flux t1 96.561737, binary loss 33.206047, binary loss t1 30.522936\n",
      "Epoch 1/10, Batch 1541/1650, Loss 138.048660, Loss rec 12.387711, loss rec t1 13.941227, loss kl 1.001292, loss_trans 0.328812, loss flux 99.723740, loss flux t1 103.435471, binary loss 60.718555, binary loss t1 49.671062\n",
      "Epoch 1/10, Batch 1551/1650, Loss 107.009987, Loss rec 12.458774, loss rec t1 12.922873, loss kl 0.524950, loss_trans 0.188948, loss flux 92.200401, loss flux t1 91.743240, binary loss 40.900555, binary loss t1 40.013885\n",
      "Epoch 1/10, Batch 1561/1650, Loss 106.535347, Loss rec 14.152230, loss rec t1 15.276065, loss kl 1.221574, loss_trans 0.337681, loss flux 109.596458, loss flux t1 113.176666, binary loss 40.156254, binary loss t1 35.391537\n",
      "Epoch 1/10, Batch 1571/1650, Loss 106.415825, Loss rec 9.531696, loss rec t1 11.163670, loss kl 0.969843, loss_trans 0.208214, loss flux 96.653099, loss flux t1 102.130318, binary loss 43.852295, binary loss t1 40.690109\n",
      "Epoch 1/10, Batch 1581/1650, Loss 88.813057, Loss rec 10.167748, loss rec t1 11.092634, loss kl 0.548148, loss_trans 0.171310, loss flux 85.934044, loss flux t1 84.804039, binary loss 35.188351, binary loss t1 31.644867\n",
      "Epoch 1/10, Batch 1591/1650, Loss 73.992203, Loss rec 10.795151, loss rec t1 12.526753, loss kl 0.849283, loss_trans 0.208745, loss flux 96.136330, loss flux t1 99.112617, binary loss 24.660378, binary loss t1 24.951887\n",
      "Epoch 1/10, Batch 1601/1650, Loss 133.102402, Loss rec 13.938195, loss rec t1 17.813559, loss kl 0.341197, loss_trans 0.157463, loss flux 81.834396, loss flux t1 78.772751, binary loss 49.797142, binary loss t1 51.054855\n",
      "Epoch 1/10, Batch 1611/1650, Loss 140.072067, Loss rec 6.945212, loss rec t1 7.046892, loss kl 0.369254, loss_trans 0.128368, loss flux 79.972626, loss flux t1 83.015038, binary loss 61.984558, binary loss t1 63.597771\n",
      "Epoch 1/10, Batch 1621/1650, Loss 130.342468, Loss rec 10.067703, loss rec t1 8.660721, loss kl 0.877076, loss_trans 0.207426, loss flux 95.985420, loss flux t1 96.729546, binary loss 61.341953, binary loss t1 49.187592\n",
      "Epoch 1/10, Batch 1631/1650, Loss 130.851654, Loss rec 16.638426, loss rec t1 17.250036, loss kl 0.577338, loss_trans 0.243606, loss flux 90.090034, loss flux t1 90.574455, binary loss 47.948853, binary loss t1 48.193390\n",
      "Epoch 1/10, Batch 1641/1650, Loss 116.151802, Loss rec 12.404053, loss rec t1 12.387053, loss kl 0.864858, loss_trans 0.242211, loss flux 97.334991, loss flux t1 99.111549, binary loss 47.840088, binary loss t1 42.413540\n",
      "Epoch 1/10, Train loss 80.662247, Eval loss 79.905655\n",
      "Epoch 2/10, Batch 1/1650, Loss 88.341606, Loss rec 9.418799, loss rec t1 9.830574, loss kl 0.904889, loss_trans 0.236946, loss flux 94.957588, loss flux t1 101.766899, binary loss 38.635033, binary loss t1 29.315365\n",
      "Epoch 2/10, Batch 11/1650, Loss 83.613274, Loss rec 10.507265, loss rec t1 11.705627, loss kl 0.925766, loss_trans 0.216404, loss flux 97.880020, loss flux t1 104.963440, binary loss 28.811398, binary loss t1 31.446804\n",
      "Epoch 2/10, Batch 21/1650, Loss 112.596245, Loss rec 13.323742, loss rec t1 14.349323, loss kl 0.687128, loss_trans 0.246281, loss flux 89.212341, loss flux t1 91.764641, binary loss 43.666130, binary loss t1 40.323635\n",
      "Epoch 2/10, Batch 31/1650, Loss 121.263634, Loss rec 10.973061, loss rec t1 13.857326, loss kl 0.490908, loss_trans 0.157802, loss flux 89.797363, loss flux t1 91.729225, binary loss 50.249680, binary loss t1 45.534859\n",
      "Epoch 2/10, Batch 41/1650, Loss 79.310608, Loss rec 10.200968, loss rec t1 12.696502, loss kl 0.592781, loss_trans 0.184023, loss flux 91.173225, loss flux t1 94.192055, binary loss 28.571980, binary loss t1 27.064360\n",
      "Epoch 2/10, Batch 51/1650, Loss 86.490990, Loss rec 8.309046, loss rec t1 11.503653, loss kl 0.529497, loss_trans 0.163019, loss flux 88.870178, loss flux t1 91.769501, binary loss 34.043789, binary loss t1 31.941988\n",
      "Epoch 2/10, Batch 61/1650, Loss 110.917778, Loss rec 23.391199, loss rec t1 22.550922, loss kl 0.974892, loss_trans 0.277632, loss flux 97.762291, loss flux t1 97.718330, binary loss 33.135715, binary loss t1 30.587410\n",
      "Epoch 2/10, Batch 71/1650, Loss 138.644562, Loss rec 14.684399, loss rec t1 17.003881, loss kl 1.048449, loss_trans 0.232080, loss flux 111.351639, loss flux t1 110.736320, binary loss 53.990250, binary loss t1 51.685509\n",
      "Epoch 2/10, Batch 81/1650, Loss 106.429192, Loss rec 17.214373, loss rec t1 16.517813, loss kl 0.549431, loss_trans 0.183220, loss flux 83.939835, loss flux t1 85.342682, binary loss 36.380611, binary loss t1 35.583736\n",
      "Epoch 2/10, Batch 91/1650, Loss 117.298027, Loss rec 18.876364, loss rec t1 21.306705, loss kl 0.628803, loss_trans 0.214374, loss flux 88.591576, loss flux t1 89.231133, binary loss 38.755753, binary loss t1 37.516029\n",
      "Epoch 2/10, Batch 101/1650, Loss 113.917564, Loss rec 13.971886, loss rec t1 17.315762, loss kl 0.536501, loss_trans 0.203995, loss flux 86.237831, loss flux t1 88.121353, binary loss 41.432449, binary loss t1 40.456970\n",
      "Epoch 2/10, Batch 111/1650, Loss 100.262360, Loss rec 14.128092, loss rec t1 13.942141, loss kl 1.022517, loss_trans 0.235442, loss flux 103.339607, loss flux t1 105.560707, binary loss 36.431976, binary loss t1 34.502186\n",
      "Epoch 2/10, Batch 121/1650, Loss 93.991020, Loss rec 16.930977, loss rec t1 16.873667, loss kl 0.947294, loss_trans 0.269951, loss flux 96.711708, loss flux t1 98.045471, binary loss 31.214468, binary loss t1 27.754671\n",
      "Epoch 2/10, Batch 131/1650, Loss 131.323837, Loss rec 13.447299, loss rec t1 18.800270, loss kl 0.377611, loss_trans 0.139820, loss flux 85.464195, loss flux t1 86.139740, binary loss 49.533810, binary loss t1 49.025024\n",
      "Epoch 2/10, Batch 141/1650, Loss 77.965698, Loss rec 9.089883, loss rec t1 9.286713, loss kl 0.572692, loss_trans 0.157493, loss flux 82.516800, loss flux t1 83.790276, binary loss 30.326584, binary loss t1 28.532333\n",
      "Epoch 2/10, Batch 151/1650, Loss 123.555412, Loss rec 27.259830, loss rec t1 28.919853, loss kl 0.998151, loss_trans 0.248921, loss flux 99.827446, loss flux t1 101.473228, binary loss 33.917652, binary loss t1 32.211002\n",
      "Epoch 2/10, Batch 161/1650, Loss 98.158676, Loss rec 15.842986, loss rec t1 17.032743, loss kl 1.132158, loss_trans 0.235464, loss flux 104.236664, loss flux t1 106.166573, binary loss 32.225201, binary loss t1 31.690125\n",
      "Epoch 2/10, Batch 171/1650, Loss 136.934387, Loss rec 18.278811, loss rec t1 23.845741, loss kl 1.070087, loss_trans 0.251467, loss flux 103.876480, loss flux t1 108.534592, binary loss 48.250298, binary loss t1 45.237984\n",
      "Epoch 2/10, Batch 181/1650, Loss 87.319984, Loss rec 13.246557, loss rec t1 15.466105, loss kl 0.476876, loss_trans 0.129951, loss flux 76.015167, loss flux t1 79.353455, binary loss 30.044106, binary loss t1 27.956390\n",
      "Epoch 2/10, Batch 191/1650, Loss 127.219116, Loss rec 19.621557, loss rec t1 26.008682, loss kl 1.063729, loss_trans 0.301517, loss flux 99.204285, loss flux t1 105.200142, binary loss 40.211700, binary loss t1 40.011936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Batch 201/1650, Loss 170.500046, Loss rec 26.119013, loss rec t1 28.680729, loss kl 0.744713, loss_trans 0.236117, loss flux 92.941788, loss flux t1 91.896179, binary loss 60.006100, binary loss t1 54.713379\n",
      "Epoch 2/10, Batch 211/1650, Loss 63.398766, Loss rec 13.144177, loss rec t1 13.247449, loss kl 0.421810, loss_trans 0.130721, loss flux 84.682281, loss flux t1 81.895882, binary loss 18.292387, binary loss t1 18.162220\n",
      "Epoch 2/10, Batch 221/1650, Loss 90.787956, Loss rec 14.805029, loss rec t1 17.874615, loss kl 0.625394, loss_trans 0.176337, loss flux 90.643837, loss flux t1 88.035828, binary loss 30.838539, binary loss t1 26.468050\n",
      "Epoch 2/10, Batch 231/1650, Loss 164.404739, Loss rec 11.903913, loss rec t1 13.512708, loss kl 0.783572, loss_trans 0.189533, loss flux 91.699844, loss flux t1 95.214973, binary loss 74.044983, binary loss t1 63.970036\n",
      "Epoch 2/10, Batch 241/1650, Loss 81.775467, Loss rec 11.520901, loss rec t1 14.270891, loss kl 0.601323, loss_trans 0.278333, loss flux 84.461250, loss flux t1 86.788460, binary loss 26.673367, binary loss t1 28.430653\n",
      "Epoch 2/10, Batch 251/1650, Loss 87.112854, Loss rec 14.718480, loss rec t1 15.110682, loss kl 0.892674, loss_trans 0.244917, loss flux 98.100922, loss flux t1 98.603119, binary loss 28.525743, binary loss t1 27.620356\n",
      "Epoch 2/10, Batch 261/1650, Loss 197.765671, Loss rec 18.248650, loss rec t1 24.347399, loss kl 0.551407, loss_trans 0.190931, loss flux 85.574226, loss flux t1 90.782333, binary loss 81.551682, binary loss t1 72.875595\n",
      "Epoch 2/10, Batch 271/1650, Loss 166.720032, Loss rec 55.647552, loss rec t1 63.617149, loss kl 0.705380, loss_trans 0.189150, loss flux 90.285683, loss flux t1 91.865738, binary loss 22.804470, binary loss t1 23.756340\n",
      "Epoch 2/10, Batch 281/1650, Loss 170.218338, Loss rec 22.116205, loss rec t1 25.510983, loss kl 0.665975, loss_trans 0.192903, loss flux 91.686653, loss flux t1 89.919785, binary loss 63.358597, binary loss t1 58.373676\n",
      "Epoch 2/10, Batch 291/1650, Loss 204.229401, Loss rec 12.932032, loss rec t1 12.515444, loss kl 0.726944, loss_trans 0.176932, loss flux 85.220497, loss flux t1 89.272850, binary loss 93.866890, binary loss t1 84.011169\n",
      "Epoch 2/10, Batch 301/1650, Loss 89.995338, Loss rec 14.144044, loss rec t1 16.241457, loss kl 0.477445, loss_trans 0.143856, loss flux 81.422646, loss flux t1 82.526070, binary loss 28.321096, binary loss t1 30.667437\n",
      "Epoch 2/10, Batch 311/1650, Loss 84.840729, Loss rec 9.417275, loss rec t1 10.337450, loss kl 0.502422, loss_trans 0.162334, loss flux 81.810104, loss flux t1 85.291084, binary loss 30.330242, binary loss t1 34.091003\n",
      "Epoch 2/10, Batch 321/1650, Loss 94.273193, Loss rec 11.527419, loss rec t1 12.989167, loss kl 0.737156, loss_trans 0.238691, loss flux 89.563072, loss flux t1 91.220642, binary loss 35.542625, binary loss t1 33.238129\n",
      "Epoch 2/10, Batch 331/1650, Loss 83.325943, Loss rec 10.765539, loss rec t1 10.677978, loss kl 0.506932, loss_trans 0.173898, loss flux 83.853943, loss flux t1 84.026222, binary loss 30.101501, binary loss t1 31.100098\n",
      "Epoch 2/10, Batch 341/1650, Loss 134.176437, Loss rec 25.963856, loss rec t1 25.384315, loss kl 0.706066, loss_trans 0.266732, loss flux 87.078575, loss flux t1 85.883827, binary loss 43.506561, binary loss t1 38.348892\n",
      "Epoch 2/10, Batch 351/1650, Loss 80.796448, Loss rec 13.165302, loss rec t1 13.236320, loss kl 1.002383, loss_trans 0.245054, loss flux 96.215515, loss flux t1 97.277443, binary loss 28.898746, binary loss t1 24.248638\n",
      "Epoch 2/10, Batch 361/1650, Loss 167.795090, Loss rec 30.987854, loss rec t1 36.018509, loss kl 0.551803, loss_trans 0.166671, loss flux 81.502319, loss flux t1 84.278069, binary loss 53.169590, binary loss t1 46.900665\n",
      "Epoch 2/10, Batch 371/1650, Loss 180.595642, Loss rec 34.747463, loss rec t1 43.506271, loss kl 1.080374, loss_trans 0.281622, loss flux 102.667770, loss flux t1 106.565445, binary loss 50.511242, binary loss t1 50.468666\n",
      "Epoch 2/10, Batch 381/1650, Loss 116.511665, Loss rec 25.220123, loss rec t1 27.306818, loss kl 0.740138, loss_trans 0.182115, loss flux 88.564285, loss flux t1 91.278893, binary loss 30.644451, binary loss t1 32.418022\n",
      "Epoch 2/10, Batch 391/1650, Loss 128.474884, Loss rec 13.722195, loss rec t1 14.339161, loss kl 0.740261, loss_trans 0.190741, loss flux 87.225288, loss flux t1 87.072067, binary loss 53.991962, binary loss t1 45.490574\n",
      "Epoch 2/10, Batch 401/1650, Loss 83.023735, Loss rec 11.420849, loss rec t1 9.856287, loss kl 0.539934, loss_trans 0.169579, loss flux 85.265175, loss flux t1 85.834251, binary loss 31.492311, binary loss t1 29.544775\n",
      "Epoch 2/10, Batch 411/1650, Loss 92.217560, Loss rec 11.019011, loss rec t1 14.901484, loss kl 1.082856, loss_trans 0.261126, loss flux 94.346756, loss flux t1 98.211075, binary loss 34.215805, binary loss t1 30.737278\n",
      "Epoch 2/10, Batch 421/1650, Loss 68.169609, Loss rec 12.944403, loss rec t1 12.377811, loss kl 0.970049, loss_trans 0.263852, loss flux 91.082397, loss flux t1 92.994392, binary loss 21.726868, binary loss t1 19.886625\n",
      "Epoch 2/10, Batch 431/1650, Loss 103.631714, Loss rec 10.061243, loss rec t1 12.118053, loss kl 0.754599, loss_trans 0.172117, loss flux 83.199059, loss flux t1 85.347397, binary loss 44.499054, binary loss t1 36.026646\n",
      "Epoch 2/10, Batch 441/1650, Loss 97.948891, Loss rec 14.301174, loss rec t1 14.071154, loss kl 0.776871, loss_trans 0.214071, loss flux 87.056129, loss flux t1 87.657875, binary loss 36.166996, binary loss t1 32.418625\n",
      "Epoch 2/10, Batch 451/1650, Loss 84.955978, Loss rec 10.279966, loss rec t1 10.508128, loss kl 0.516054, loss_trans 0.163062, loss flux 78.295631, loss flux t1 78.182205, binary loss 31.977486, binary loss t1 31.511284\n",
      "Epoch 2/10, Batch 461/1650, Loss 145.954681, Loss rec 19.937063, loss rec t1 25.030842, loss kl 0.623720, loss_trans 0.168611, loss flux 85.456711, loss flux t1 83.728172, binary loss 51.281830, binary loss t1 48.912617\n",
      "Epoch 2/10, Batch 471/1650, Loss 78.670425, Loss rec 12.638240, loss rec t1 15.672466, loss kl 0.612656, loss_trans 0.147421, loss flux 83.468178, loss flux t1 84.279907, binary loss 24.176178, binary loss t1 25.423460\n",
      "Epoch 2/10, Batch 481/1650, Loss 91.671539, Loss rec 8.755102, loss rec t1 9.354494, loss kl 0.548938, loss_trans 0.134477, loss flux 81.718079, loss flux t1 82.466972, binary loss 38.310646, binary loss t1 34.567883\n",
      "Epoch 2/10, Batch 491/1650, Loss 289.203491, Loss rec 35.607826, loss rec t1 39.410873, loss kl 0.335561, loss_trans 0.110553, loss flux 78.916466, loss flux t1 80.802643, binary loss 115.825844, binary loss t1 97.912819\n",
      "Epoch 2/10, Batch 501/1650, Loss 111.477867, Loss rec 29.670340, loss rec t1 28.865932, loss kl 0.737251, loss_trans 0.193511, loss flux 87.447945, loss flux t1 88.168427, binary loss 26.331846, binary loss t1 25.678986\n",
      "Epoch 2/10, Batch 511/1650, Loss 145.857880, Loss rec 24.738043, loss rec t1 25.427074, loss kl 0.666426, loss_trans 0.144366, loss flux 86.198784, loss flux t1 79.487534, binary loss 58.091503, binary loss t1 36.790462\n",
      "Epoch 2/10, Batch 521/1650, Loss 84.970100, Loss rec 11.790833, loss rec t1 12.542082, loss kl 0.921649, loss_trans 0.221996, loss flux 87.423447, loss flux t1 91.368362, binary loss 32.365131, binary loss t1 27.128412\n",
      "Epoch 2/10, Batch 531/1650, Loss 82.201294, Loss rec 12.167643, loss rec t1 12.015680, loss kl 0.427709, loss_trans 0.123198, loss flux 74.504974, loss flux t1 78.712822, binary loss 29.763756, binary loss t1 27.703312\n",
      "Epoch 2/10, Batch 541/1650, Loss 287.695099, Loss rec 18.029369, loss rec t1 24.106459, loss kl 0.494728, loss_trans 0.149646, loss flux 80.263542, loss flux t1 85.455582, binary loss 132.764633, binary loss t1 112.150253\n",
      "Epoch 2/10, Batch 551/1650, Loss 85.184059, Loss rec 8.522335, loss rec t1 12.034744, loss kl 0.682578, loss_trans 0.177481, loss flux 82.578346, loss flux t1 91.435905, binary loss 31.449005, binary loss t1 32.317917\n",
      "Epoch 2/10, Batch 561/1650, Loss 76.519279, Loss rec 14.615635, loss rec t1 15.798559, loss kl 0.560476, loss_trans 0.168275, loss flux 82.663376, loss flux t1 84.113533, binary loss 22.370766, binary loss t1 23.005569\n",
      "Epoch 2/10, Batch 571/1650, Loss 136.141495, Loss rec 9.191519, loss rec t1 10.429564, loss kl 0.679793, loss_trans 0.161463, loss flux 87.359459, loss flux t1 84.598907, binary loss 62.377266, binary loss t1 53.301891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Batch 581/1650, Loss 115.448418, Loss rec 12.647194, loss rec t1 13.378975, loss kl 0.562162, loss_trans 0.187340, loss flux 82.850441, loss flux t1 82.315926, binary loss 45.708584, binary loss t1 42.964169\n",
      "Epoch 2/10, Batch 591/1650, Loss 74.299431, Loss rec 8.228466, loss rec t1 10.299215, loss kl 0.432096, loss_trans 0.112539, loss flux 77.363304, loss flux t1 78.048096, binary loss 28.994390, binary loss t1 26.232718\n",
      "Epoch 2/10, Batch 601/1650, Loss 96.252266, Loss rec 19.255106, loss rec t1 19.862263, loss kl 0.555660, loss_trans 0.199507, loss flux 78.866501, loss flux t1 78.951744, binary loss 30.346777, binary loss t1 26.032951\n",
      "Epoch 2/10, Batch 611/1650, Loss 91.111786, Loss rec 13.064262, loss rec t1 15.436579, loss kl 0.633872, loss_trans 0.186111, loss flux 81.907410, loss flux t1 83.341331, binary loss 30.861170, binary loss t1 30.929794\n",
      "Epoch 2/10, Batch 621/1650, Loss 85.610649, Loss rec 11.509589, loss rec t1 13.505033, loss kl 0.739987, loss_trans 0.163283, loss flux 88.024376, loss flux t1 89.414085, binary loss 29.790291, binary loss t1 29.902466\n",
      "Epoch 2/10, Batch 631/1650, Loss 173.375519, Loss rec 16.208038, loss rec t1 19.348555, loss kl 0.750883, loss_trans 0.182753, loss flux 88.197418, loss flux t1 86.976471, binary loss 68.907509, binary loss t1 67.977776\n",
      "Epoch 2/10, Batch 641/1650, Loss 71.108498, Loss rec 10.680190, loss rec t1 13.904215, loss kl 0.625660, loss_trans 0.172770, loss flux 84.319626, loss flux t1 85.551804, binary loss 21.866554, binary loss t1 23.859110\n",
      "Epoch 2/10, Batch 651/1650, Loss 79.741013, Loss rec 13.577995, loss rec t1 15.026178, loss kl 0.569490, loss_trans 0.174075, loss flux 76.918739, loss flux t1 78.667023, binary loss 26.004705, binary loss t1 24.388569\n",
      "Epoch 2/10, Batch 661/1650, Loss 126.946945, Loss rec 14.310144, loss rec t1 15.734840, loss kl 0.812144, loss_trans 0.196267, loss flux 86.532829, loss flux t1 87.090271, binary loss 49.010452, binary loss t1 46.883095\n",
      "Epoch 2/10, Batch 671/1650, Loss 75.384506, Loss rec 10.281754, loss rec t1 12.703974, loss kl 0.541254, loss_trans 0.181882, loss flux 81.706627, loss flux t1 84.043953, binary loss 25.485252, binary loss t1 26.190386\n",
      "Epoch 2/10, Batch 681/1650, Loss 70.203896, Loss rec 5.353088, loss rec t1 6.089287, loss kl 0.458522, loss_trans 0.119084, loss flux 79.337540, loss flux t1 84.731949, binary loss 28.836712, binary loss t1 29.347200\n",
      "Epoch 2/10, Batch 691/1650, Loss 115.395691, Loss rec 20.235334, loss rec t1 19.301542, loss kl 1.113658, loss_trans 0.225910, loss flux 101.413445, loss flux t1 104.532494, binary loss 37.934231, binary loss t1 36.585018\n",
      "Epoch 2/10, Batch 701/1650, Loss 130.910858, Loss rec 49.667053, loss rec t1 43.466202, loss kl 0.895861, loss_trans 0.238348, loss flux 87.689804, loss flux t1 88.002472, binary loss 19.361444, binary loss t1 17.281967\n",
      "Epoch 2/10, Batch 711/1650, Loss 160.008026, Loss rec 29.863485, loss rec t1 30.753590, loss kl 1.236155, loss_trans 0.304737, loss flux 106.828255, loss flux t1 107.548241, binary loss 55.268894, binary loss t1 42.581169\n",
      "Epoch 2/10, Batch 721/1650, Loss 64.864311, Loss rec 13.768461, loss rec t1 14.310853, loss kl 0.770798, loss_trans 0.186829, loss flux 87.489014, loss flux t1 91.166397, binary loss 17.528393, binary loss t1 18.298977\n",
      "Epoch 2/10, Batch 731/1650, Loss 202.148773, Loss rec 15.624978, loss rec t1 17.955500, loss kl 0.534362, loss_trans 0.160252, loss flux 81.400177, loss flux t1 84.510513, binary loss 87.866837, binary loss t1 80.006851\n",
      "Epoch 2/10, Batch 741/1650, Loss 114.916489, Loss rec 16.653404, loss rec t1 16.586235, loss kl 0.560896, loss_trans 0.177426, loss flux 78.829163, loss flux t1 81.281174, binary loss 42.516445, binary loss t1 38.422085\n",
      "Epoch 2/10, Batch 751/1650, Loss 61.868633, Loss rec 11.231323, loss rec t1 10.463037, loss kl 0.703124, loss_trans 0.187891, loss flux 79.533882, loss flux t1 79.673538, binary loss 21.625675, binary loss t1 17.657585\n",
      "Epoch 2/10, Batch 761/1650, Loss 102.222977, Loss rec 8.643477, loss rec t1 11.307642, loss kl 0.839470, loss_trans 0.227907, loss flux 82.124756, loss flux t1 82.410522, binary loss 43.934765, binary loss t1 37.269714\n",
      "Epoch 2/10, Batch 771/1650, Loss 66.285240, Loss rec 7.882208, loss rec t1 10.457807, loss kl 0.483401, loss_trans 0.170403, loss flux 72.731956, loss flux t1 77.161392, binary loss 22.860270, binary loss t1 24.431149\n",
      "Epoch 2/10, Batch 781/1650, Loss 76.007805, Loss rec 7.572081, loss rec t1 10.343067, loss kl 0.499415, loss_trans 0.147512, loss flux 79.312813, loss flux t1 80.607430, binary loss 29.682753, binary loss t1 27.762970\n",
      "Epoch 2/10, Batch 791/1650, Loss 96.570923, Loss rec 8.594254, loss rec t1 11.462051, loss kl 0.461375, loss_trans 0.167031, loss flux 77.790596, loss flux t1 80.488441, binary loss 37.290398, binary loss t1 38.595814\n",
      "Epoch 2/10, Batch 801/1650, Loss 69.503334, Loss rec 7.262402, loss rec t1 8.397722, loss kl 0.762696, loss_trans 0.193466, loss flux 87.771095, loss flux t1 89.973549, binary loss 27.396492, binary loss t1 25.490553\n",
      "Epoch 2/10, Batch 811/1650, Loss 106.576645, Loss rec 10.390873, loss rec t1 12.013968, loss kl 0.912054, loss_trans 0.221727, loss flux 95.755455, loss flux t1 96.627953, binary loss 46.473862, binary loss t1 36.564163\n",
      "Epoch 2/10, Batch 821/1650, Loss 81.346855, Loss rec 5.715366, loss rec t1 5.971902, loss kl 0.534773, loss_trans 0.142584, loss flux 75.149162, loss flux t1 79.792130, binary loss 35.124363, binary loss t1 33.857868\n",
      "Epoch 2/10, Batch 831/1650, Loss 77.511627, Loss rec 7.216152, loss rec t1 9.508898, loss kl 0.955222, loss_trans 0.176053, loss flux 84.725456, loss flux t1 82.992630, binary loss 33.093380, binary loss t1 26.561924\n",
      "Epoch 2/10, Batch 841/1650, Loss 113.010002, Loss rec 6.409403, loss rec t1 9.203547, loss kl 0.315982, loss_trans 0.096767, loss flux 71.188911, loss flux t1 71.916283, binary loss 48.315262, binary loss t1 48.669044\n",
      "Epoch 2/10, Batch 851/1650, Loss 82.368683, Loss rec 7.696491, loss rec t1 7.237882, loss kl 0.609744, loss_trans 0.159453, loss flux 80.997528, loss flux t1 83.812317, binary loss 33.954735, binary loss t1 32.710377\n",
      "Epoch 2/10, Batch 861/1650, Loss 69.417191, Loss rec 8.179228, loss rec t1 9.024097, loss kl 0.795634, loss_trans 0.179160, loss flux 84.391533, loss flux t1 87.609505, binary loss 27.509399, binary loss t1 23.729670\n",
      "Epoch 2/10, Batch 871/1650, Loss 74.542374, Loss rec 7.048231, loss rec t1 7.742239, loss kl 0.726864, loss_trans 0.159285, loss flux 88.526398, loss flux t1 90.234184, binary loss 30.285229, binary loss t1 28.580523\n",
      "Epoch 2/10, Batch 881/1650, Loss 99.965309, Loss rec 5.830358, loss rec t1 7.244326, loss kl 0.536476, loss_trans 0.141137, loss flux 79.877975, loss flux t1 83.548798, binary loss 43.382675, binary loss t1 42.830338\n",
      "Epoch 2/10, Batch 891/1650, Loss 86.059662, Loss rec 4.662586, loss rec t1 5.632001, loss kl 0.513545, loss_trans 0.128585, loss flux 82.104332, loss flux t1 86.087891, binary loss 39.487110, binary loss t1 35.635830\n",
      "Epoch 2/10, Batch 901/1650, Loss 65.146164, Loss rec 5.729458, loss rec t1 6.806718, loss kl 0.878911, loss_trans 0.210008, loss flux 90.134163, loss flux t1 93.491386, binary loss 27.555637, binary loss t1 23.965427\n",
      "Epoch 2/10, Batch 911/1650, Loss 76.498322, Loss rec 3.913273, loss rec t1 4.512548, loss kl 0.451798, loss_trans 0.098153, loss flux 74.789185, loss flux t1 78.054108, binary loss 35.233608, binary loss t1 32.288940\n",
      "Epoch 2/10, Batch 921/1650, Loss 109.866524, Loss rec 5.340104, loss rec t1 6.303143, loss kl 0.540530, loss_trans 0.138299, loss flux 80.067520, loss flux t1 84.582161, binary loss 49.337952, binary loss t1 48.206501\n",
      "Epoch 2/10, Batch 931/1650, Loss 76.173111, Loss rec 6.187595, loss rec t1 6.764156, loss kl 0.577254, loss_trans 0.117153, loss flux 79.745094, loss flux t1 81.556946, binary loss 31.960712, binary loss t1 30.566242\n",
      "Epoch 2/10, Batch 941/1650, Loss 84.756348, Loss rec 5.986037, loss rec t1 5.974365, loss kl 0.729440, loss_trans 0.148821, loss flux 80.733887, loss flux t1 83.377922, binary loss 37.715733, binary loss t1 34.201958\n",
      "Epoch 2/10, Batch 951/1650, Loss 83.161446, Loss rec 9.113685, loss rec t1 9.369259, loss kl 0.447675, loss_trans 0.096565, loss flux 83.635612, loss flux t1 88.539925, binary loss 33.677685, binary loss t1 30.456577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Batch 961/1650, Loss 96.078270, Loss rec 12.838019, loss rec t1 12.819681, loss kl 0.422831, loss_trans 0.092615, loss flux 76.744225, loss flux t1 76.355644, binary loss 34.963757, binary loss t1 34.941368\n",
      "Epoch 2/10, Batch 971/1650, Loss 63.535625, Loss rec 14.850245, loss rec t1 14.988851, loss kl 0.467405, loss_trans 0.126087, loss flux 78.950859, loss flux t1 80.685287, binary loss 17.281967, binary loss t1 15.821070\n",
      "Epoch 2/10, Batch 981/1650, Loss 96.123642, Loss rec 9.496337, loss rec t1 10.558311, loss kl 0.421347, loss_trans 0.112063, loss flux 75.852753, loss flux t1 75.941109, binary loss 39.484425, binary loss t1 36.051163\n",
      "Epoch 2/10, Batch 991/1650, Loss 93.568382, Loss rec 8.158414, loss rec t1 9.935240, loss kl 0.432337, loss_trans 0.130623, loss flux 79.424194, loss flux t1 83.914772, binary loss 37.369267, binary loss t1 37.542503\n",
      "Epoch 2/10, Batch 1001/1650, Loss 80.085548, Loss rec 16.056881, loss rec t1 15.764413, loss kl 0.772980, loss_trans 0.184305, loss flux 87.762596, loss flux t1 89.707474, binary loss 24.891253, binary loss t1 22.415718\n",
      "Epoch 2/10, Batch 1011/1650, Loss 61.976765, Loss rec 8.518728, loss rec t1 8.944955, loss kl 0.476442, loss_trans 0.149509, loss flux 79.710434, loss flux t1 82.626335, binary loss 22.416937, binary loss t1 21.470194\n",
      "Epoch 2/10, Batch 1021/1650, Loss 73.806747, Loss rec 9.469057, loss rec t1 10.224148, loss kl 0.492249, loss_trans 0.123165, loss flux 80.104317, loss flux t1 83.271317, binary loss 27.015751, binary loss t1 26.482382\n",
      "Epoch 2/10, Batch 1031/1650, Loss 71.659485, Loss rec 8.739867, loss rec t1 8.886480, loss kl 0.854863, loss_trans 0.157885, loss flux 84.397469, loss flux t1 85.286072, binary loss 26.976036, binary loss t1 26.044353\n",
      "Epoch 2/10, Batch 1041/1650, Loss 70.295555, Loss rec 5.915886, loss rec t1 7.135469, loss kl 0.531663, loss_trans 0.108283, loss flux 77.628830, loss flux t1 77.746658, binary loss 29.387825, binary loss t1 27.216427\n",
      "Epoch 2/10, Batch 1051/1650, Loss 67.475250, Loss rec 7.800450, loss rec t1 7.919148, loss kl 0.407616, loss_trans 0.113116, loss flux 75.980286, loss flux t1 77.174911, binary loss 25.210026, binary loss t1 26.024897\n",
      "Epoch 2/10, Batch 1061/1650, Loss 86.989967, Loss rec 8.592738, loss rec t1 10.258864, loss kl 0.813533, loss_trans 0.199133, loss flux 90.512909, loss flux t1 94.129318, binary loss 35.212685, binary loss t1 31.913013\n",
      "Epoch 2/10, Batch 1071/1650, Loss 58.551640, Loss rec 5.920166, loss rec t1 6.214160, loss kl 0.757310, loss_trans 0.155270, loss flux 83.983582, loss flux t1 87.476402, binary loss 23.773470, binary loss t1 21.731262\n",
      "Epoch 2/10, Batch 1081/1650, Loss 96.752480, Loss rec 11.369730, loss rec t1 9.258108, loss kl 0.646871, loss_trans 0.161650, loss flux 81.412964, loss flux t1 79.818031, binary loss 39.374447, binary loss t1 35.941673\n",
      "Epoch 2/10, Batch 1091/1650, Loss 83.683022, Loss rec 13.334938, loss rec t1 16.735241, loss kl 0.330407, loss_trans 0.105571, loss flux 70.881386, loss flux t1 74.987267, binary loss 26.884668, binary loss t1 26.292198\n",
      "Epoch 2/10, Batch 1101/1650, Loss 150.797379, Loss rec 7.531652, loss rec t1 8.559403, loss kl 0.413037, loss_trans 0.107883, loss flux 73.517365, loss flux t1 73.598045, binary loss 68.531822, binary loss t1 65.653580\n",
      "Epoch 2/10, Batch 1111/1650, Loss 129.341095, Loss rec 9.672340, loss rec t1 9.007790, loss kl 0.346120, loss_trans 0.087318, loss flux 66.304153, loss flux t1 70.130341, binary loss 60.913929, binary loss t1 49.313614\n",
      "Epoch 2/10, Batch 1121/1650, Loss 71.504990, Loss rec 10.656889, loss rec t1 10.841639, loss kl 0.738533, loss_trans 0.179266, loss flux 84.895821, loss flux t1 86.943985, binary loss 26.972683, binary loss t1 22.115976\n",
      "Epoch 2/10, Batch 1131/1650, Loss 75.121704, Loss rec 10.255487, loss rec t1 9.946137, loss kl 1.120376, loss_trans 0.212401, loss flux 88.344818, loss flux t1 91.132416, binary loss 27.058746, binary loss t1 26.528553\n",
      "Epoch 2/10, Batch 1141/1650, Loss 75.001389, Loss rec 7.543805, loss rec t1 7.545339, loss kl 0.686015, loss_trans 0.179750, loss flux 83.071022, loss flux t1 83.730377, binary loss 30.873550, binary loss t1 28.172934\n",
      "Epoch 2/10, Batch 1151/1650, Loss 68.705208, Loss rec 6.680828, loss rec t1 7.717724, loss kl 0.839492, loss_trans 0.128979, loss flux 90.389084, loss flux t1 94.201065, binary loss 26.890392, binary loss t1 26.447796\n",
      "Epoch 2/10, Batch 1161/1650, Loss 78.083832, Loss rec 12.281054, loss rec t1 11.959034, loss kl 0.606348, loss_trans 0.149780, loss flux 80.316551, loss flux t1 83.238548, binary loss 27.163179, binary loss t1 25.924435\n",
      "Epoch 2/10, Batch 1171/1650, Loss 85.980965, Loss rec 7.748301, loss rec t1 9.613354, loss kl 0.527727, loss_trans 0.110149, loss flux 80.836815, loss flux t1 83.133240, binary loss 33.770763, binary loss t1 34.210678\n",
      "Epoch 2/10, Batch 1181/1650, Loss 78.680855, Loss rec 14.195679, loss rec t1 11.766030, loss kl 0.903039, loss_trans 0.175485, loss flux 89.198784, loss flux t1 95.768700, binary loss 24.535334, binary loss t1 27.105293\n",
      "Epoch 2/10, Batch 1191/1650, Loss 85.326202, Loss rec 10.383522, loss rec t1 12.181625, loss kl 0.729799, loss_trans 0.153743, loss flux 84.109093, loss flux t1 85.791061, binary loss 31.649506, binary loss t1 30.228012\n",
      "Epoch 2/10, Batch 1201/1650, Loss 80.925339, Loss rec 7.531854, loss rec t1 7.725080, loss kl 0.472108, loss_trans 0.127622, loss flux 73.766006, loss flux t1 72.745087, binary loss 34.838951, binary loss t1 30.229717\n",
      "Epoch 2/10, Batch 1211/1650, Loss 87.285828, Loss rec 13.027845, loss rec t1 14.143192, loss kl 0.679802, loss_trans 0.151532, loss flux 82.089355, loss flux t1 83.235733, binary loss 31.114920, binary loss t1 28.168537\n",
      "Epoch 2/10, Batch 1221/1650, Loss 109.906883, Loss rec 8.173280, loss rec t1 13.102785, loss kl 0.560153, loss_trans 0.139108, loss flux 80.093864, loss flux t1 82.768982, binary loss 45.683018, binary loss t1 42.248539\n",
      "Epoch 2/10, Batch 1231/1650, Loss 61.966541, Loss rec 5.902375, loss rec t1 7.317559, loss kl 0.487956, loss_trans 0.124857, loss flux 72.507202, loss flux t1 76.193420, binary loss 23.657635, binary loss t1 24.476162\n",
      "Epoch 2/10, Batch 1241/1650, Loss 87.000351, Loss rec 6.886052, loss rec t1 6.525309, loss kl 0.554343, loss_trans 0.112810, loss flux 76.266670, loss flux t1 80.200600, binary loss 37.911598, binary loss t1 35.010239\n",
      "Epoch 2/10, Batch 1251/1650, Loss 73.050064, Loss rec 8.319221, loss rec t1 7.864026, loss kl 0.445569, loss_trans 0.114054, loss flux 73.716934, loss flux t1 73.782860, binary loss 27.664639, binary loss t1 28.642557\n",
      "Epoch 2/10, Batch 1261/1650, Loss 71.743942, Loss rec 10.298605, loss rec t1 9.358728, loss kl 0.489696, loss_trans 0.140261, loss flux 77.565491, loss flux t1 75.969360, binary loss 26.440052, binary loss t1 25.016603\n",
      "Epoch 2/10, Batch 1271/1650, Loss 82.087860, Loss rec 10.074491, loss rec t1 9.690225, loss kl 0.612935, loss_trans 0.150669, loss flux 81.725433, loss flux t1 82.863983, binary loss 30.569906, binary loss t1 30.989630\n",
      "Epoch 2/10, Batch 1281/1650, Loss 74.995354, Loss rec 6.422748, loss rec t1 6.595197, loss kl 0.494672, loss_trans 0.096924, loss flux 71.524490, loss flux t1 73.908257, binary loss 33.204823, binary loss t1 28.180988\n",
      "Epoch 2/10, Batch 1291/1650, Loss 70.097527, Loss rec 4.361588, loss rec t1 4.768018, loss kl 0.337962, loss_trans 0.081466, loss flux 68.436050, loss flux t1 71.075668, binary loss 30.297363, binary loss t1 30.251129\n",
      "Epoch 2/10, Batch 1301/1650, Loss 66.949242, Loss rec 8.236263, loss rec t1 7.391521, loss kl 0.461332, loss_trans 0.095253, loss flux 74.253944, loss flux t1 74.559288, binary loss 25.196915, binary loss t1 25.567963\n",
      "Epoch 2/10, Batch 1311/1650, Loss 81.545959, Loss rec 6.427367, loss rec t1 7.041415, loss kl 0.433017, loss_trans 0.114047, loss flux 73.919739, loss flux t1 78.975471, binary loss 32.755882, binary loss t1 34.774239\n",
      "Epoch 2/10, Batch 1321/1650, Loss 64.440231, Loss rec 7.883795, loss rec t1 8.221683, loss kl 0.767415, loss_trans 0.156437, loss flux 80.668350, loss flux t1 84.237282, binary loss 24.277859, binary loss t1 23.133051\n",
      "Epoch 2/10, Batch 1331/1650, Loss 96.806282, Loss rec 7.944245, loss rec t1 9.148136, loss kl 0.421979, loss_trans 0.122333, loss flux 78.306831, loss flux t1 79.812378, binary loss 39.730186, binary loss t1 39.439407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Batch 1341/1650, Loss 66.262497, Loss rec 3.646525, loss rec t1 4.753272, loss kl 0.483677, loss_trans 0.112703, loss flux 68.879425, loss flux t1 74.677597, binary loss 28.699465, binary loss t1 28.566856\n",
      "Epoch 2/10, Batch 1351/1650, Loss 67.428749, Loss rec 4.675194, loss rec t1 4.506829, loss kl 0.335805, loss_trans 0.091775, loss flux 73.775658, loss flux t1 76.400177, binary loss 27.504274, binary loss t1 30.314869\n",
      "Epoch 2/10, Batch 1361/1650, Loss 69.625938, Loss rec 6.171356, loss rec t1 8.103832, loss kl 0.853332, loss_trans 0.154781, loss flux 86.284485, loss flux t1 85.544800, binary loss 29.282724, binary loss t1 25.059912\n",
      "Epoch 2/10, Batch 1371/1650, Loss 81.295631, Loss rec 4.947868, loss rec t1 5.739788, loss kl 0.384825, loss_trans 0.093913, loss flux 67.093002, loss flux t1 72.101036, binary loss 35.607830, binary loss t1 34.521404\n",
      "Epoch 2/10, Batch 1381/1650, Loss 73.590858, Loss rec 6.379683, loss rec t1 6.906523, loss kl 0.651461, loss_trans 0.116399, loss flux 84.920738, loss flux t1 87.253227, binary loss 31.650234, binary loss t1 27.886551\n",
      "Epoch 2/10, Batch 1391/1650, Loss 49.909004, Loss rec 5.327597, loss rec t1 6.273734, loss kl 0.757941, loss_trans 0.164910, loss flux 77.343819, loss flux t1 83.417725, binary loss 18.160023, binary loss t1 19.224800\n",
      "Epoch 2/10, Batch 1401/1650, Loss 71.003700, Loss rec 4.995137, loss rec t1 5.177480, loss kl 0.459487, loss_trans 0.106562, loss flux 78.357941, loss flux t1 84.710449, binary loss 28.837688, binary loss t1 31.427349\n",
      "Epoch 2/10, Batch 1411/1650, Loss 59.990757, Loss rec 6.020117, loss rec t1 6.041549, loss kl 0.608505, loss_trans 0.134023, loss flux 80.161766, loss flux t1 80.507225, binary loss 24.233332, binary loss t1 22.953234\n",
      "Epoch 2/10, Batch 1421/1650, Loss 69.227303, Loss rec 6.383735, loss rec t1 6.890065, loss kl 0.471672, loss_trans 0.114856, loss flux 72.015755, loss flux t1 72.682755, binary loss 28.128405, binary loss t1 27.238569\n",
      "Epoch 2/10, Batch 1431/1650, Loss 59.136475, Loss rec 5.384903, loss rec t1 6.652482, loss kl 0.541504, loss_trans 0.118979, loss flux 77.387566, loss flux t1 79.486794, binary loss 24.147932, binary loss t1 22.290672\n",
      "Epoch 2/10, Batch 1441/1650, Loss 62.030586, Loss rec 6.061626, loss rec t1 5.732505, loss kl 0.721915, loss_trans 0.142492, loss flux 80.099800, loss flux t1 83.462379, binary loss 26.425896, binary loss t1 22.946152\n",
      "Epoch 2/10, Batch 1451/1650, Loss 79.998497, Loss rec 7.609728, loss rec t1 7.398062, loss kl 0.565182, loss_trans 0.144457, loss flux 76.094360, loss flux t1 79.088570, binary loss 34.289062, binary loss t1 29.992008\n",
      "Epoch 2/10, Batch 1461/1650, Loss 72.079781, Loss rec 4.901053, loss rec t1 4.959630, loss kl 0.415811, loss_trans 0.106333, loss flux 74.679993, loss flux t1 76.343391, binary loss 31.622965, binary loss t1 30.073990\n",
      "Epoch 2/10, Batch 1471/1650, Loss 68.654968, Loss rec 7.053142, loss rec t1 7.300184, loss kl 0.592329, loss_trans 0.113969, loss flux 81.465408, loss flux t1 82.073486, binary loss 27.042215, binary loss t1 26.553135\n",
      "Epoch 2/10, Batch 1481/1650, Loss 48.845486, Loss rec 5.196569, loss rec t1 5.642787, loss kl 0.524117, loss_trans 0.106642, loss flux 78.870209, loss flux t1 82.326180, binary loss 18.499964, binary loss t1 18.875406\n",
      "Epoch 2/10, Batch 1491/1650, Loss 58.064842, Loss rec 6.015906, loss rec t1 5.910793, loss kl 0.829566, loss_trans 0.145739, loss flux 84.574318, loss flux t1 86.777451, binary loss 23.213326, binary loss t1 21.949512\n",
      "Epoch 2/10, Batch 1501/1650, Loss 76.460121, Loss rec 6.589804, loss rec t1 7.787579, loss kl 0.800477, loss_trans 0.161245, loss flux 85.043396, loss flux t1 86.192070, binary loss 31.135351, binary loss t1 29.985666\n",
      "Epoch 2/10, Batch 1511/1650, Loss 76.131493, Loss rec 7.652987, loss rec t1 8.779306, loss kl 0.436675, loss_trans 0.142294, loss flux 73.010689, loss flux t1 74.636665, binary loss 29.573265, binary loss t1 29.546968\n",
      "Epoch 2/10, Batch 1521/1650, Loss 61.864529, Loss rec 4.430091, loss rec t1 4.926756, loss kl 0.497060, loss_trans 0.101245, loss flux 75.272316, loss flux t1 79.062157, binary loss 26.441692, binary loss t1 25.467682\n",
      "Epoch 2/10, Batch 1531/1650, Loss 65.650108, Loss rec 6.510036, loss rec t1 6.262712, loss kl 0.486420, loss_trans 0.117044, loss flux 75.897942, loss flux t1 78.066841, binary loss 26.313232, binary loss t1 25.960667\n",
      "Epoch 2/10, Batch 1541/1650, Loss 76.710289, Loss rec 4.738910, loss rec t1 5.203832, loss kl 0.647446, loss_trans 0.165495, loss flux 78.994568, loss flux t1 83.578896, binary loss 34.659622, binary loss t1 31.294985\n",
      "Epoch 2/10, Batch 1551/1650, Loss 49.743393, Loss rec 6.644003, loss rec t1 6.727633, loss kl 0.313270, loss_trans 0.087279, loss flux 73.007637, loss flux t1 73.801323, binary loss 18.153986, binary loss t1 17.817217\n",
      "Epoch 2/10, Batch 1561/1650, Loss 80.667305, Loss rec 7.961386, loss rec t1 9.697330, loss kl 0.835778, loss_trans 0.171229, loss flux 86.234756, loss flux t1 89.608101, binary loss 32.772171, binary loss t1 29.229416\n",
      "Epoch 2/10, Batch 1571/1650, Loss 68.503784, Loss rec 6.581944, loss rec t1 10.430358, loss kl 0.665750, loss_trans 0.105874, loss flux 77.769096, loss flux t1 82.176849, binary loss 26.072109, binary loss t1 24.647753\n",
      "Epoch 2/10, Batch 1581/1650, Loss 80.190674, Loss rec 4.598134, loss rec t1 6.066850, loss kl 0.333967, loss_trans 0.076157, loss flux 67.910934, loss flux t1 68.538811, binary loss 35.344807, binary loss t1 33.770763\n",
      "Epoch 2/10, Batch 1591/1650, Loss 73.975143, Loss rec 6.985651, loss rec t1 7.938936, loss kl 0.547659, loss_trans 0.104324, loss flux 74.476120, loss flux t1 77.064514, binary loss 29.220695, binary loss t1 29.177876\n",
      "Epoch 2/10, Batch 1601/1650, Loss 60.745399, Loss rec 7.244612, loss rec t1 8.172710, loss kl 0.211166, loss_trans 0.075457, loss flux 66.164734, loss flux t1 64.236786, binary loss 22.711618, binary loss t1 22.329834\n",
      "Epoch 2/10, Batch 1611/1650, Loss 55.098171, Loss rec 4.031210, loss rec t1 4.484261, loss kl 0.238655, loss_trans 0.065313, loss flux 64.976181, loss flux t1 67.473801, binary loss 23.151291, binary loss t1 23.127441\n",
      "Epoch 2/10, Batch 1621/1650, Loss 80.369545, Loss rec 4.773113, loss rec t1 4.718581, loss kl 0.538939, loss_trans 0.116480, loss flux 73.591820, loss flux t1 75.648010, binary loss 35.765755, binary loss t1 34.456680\n",
      "Epoch 2/10, Batch 1631/1650, Loss 75.215485, Loss rec 7.152757, loss rec t1 7.432847, loss kl 0.365882, loss_trans 0.121571, loss flux 73.523483, loss flux t1 74.923210, binary loss 29.707335, binary loss t1 30.435097\n",
      "Epoch 2/10, Batch 1641/1650, Loss 78.664482, Loss rec 7.860593, loss rec t1 8.148457, loss kl 0.587606, loss_trans 0.136513, loss flux 78.121460, loss flux t1 80.350090, binary loss 32.052212, binary loss t1 29.879105\n",
      "Epoch 2/10, Train loss 66.929337, Eval loss 55.575718\n",
      "Epoch 3/10, Batch 1/1650, Loss 49.578949, Loss rec 5.052805, loss rec t1 5.200051, loss kl 0.571353, loss_trans 0.132819, loss flux 76.256500, loss flux t1 81.200272, binary loss 20.605181, binary loss t1 18.016741\n",
      "Epoch 3/10, Batch 11/1650, Loss 52.978825, Loss rec 6.328792, loss rec t1 7.378382, loss kl 0.614523, loss_trans 0.109927, loss flux 80.067612, loss flux t1 86.728401, binary loss 18.432076, binary loss t1 20.115126\n",
      "Epoch 3/10, Batch 21/1650, Loss 75.411346, Loss rec 7.225993, loss rec t1 7.454700, loss kl 0.434991, loss_trans 0.118952, loss flux 70.955421, loss flux t1 73.508751, binary loss 30.875744, binary loss t1 29.300966\n",
      "Epoch 3/10, Batch 31/1650, Loss 70.531937, Loss rec 5.041742, loss rec t1 6.240107, loss kl 0.323550, loss_trans 0.079585, loss flux 71.917221, loss flux t1 74.714745, binary loss 29.500244, binary loss t1 29.346712\n",
      "Epoch 3/10, Batch 41/1650, Loss 50.926147, Loss rec 5.050458, loss rec t1 6.341651, loss kl 0.389757, loss_trans 0.096107, loss flux 72.715553, loss flux t1 75.107697, binary loss 19.048639, binary loss t1 19.999535\n",
      "Epoch 3/10, Batch 51/1650, Loss 60.887505, Loss rec 4.586504, loss rec t1 6.043406, loss kl 0.345644, loss_trans 0.079727, loss flux 72.709923, loss flux t1 74.296600, binary loss 25.833914, binary loss t1 23.998308\n",
      "Epoch 3/10, Batch 61/1650, Loss 88.248917, Loss rec 13.044858, loss rec t1 12.356033, loss kl 0.712790, loss_trans 0.144335, loss flux 81.163658, loss flux t1 83.505333, binary loss 31.959007, binary loss t1 30.031900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Batch 71/1650, Loss 66.367424, Loss rec 8.264318, loss rec t1 10.863092, loss kl 0.721168, loss_trans 0.115318, loss flux 86.762489, loss flux t1 88.312302, binary loss 23.147873, binary loss t1 23.255655\n",
      "Epoch 3/10, Batch 81/1650, Loss 63.953297, Loss rec 7.143076, loss rec t1 7.498683, loss kl 0.380212, loss_trans 0.092155, loss flux 70.973099, loss flux t1 72.787140, binary loss 25.361116, binary loss t1 23.478054\n",
      "Epoch 3/10, Batch 91/1650, Loss 75.154243, Loss rec 6.080800, loss rec t1 7.739484, loss kl 0.406072, loss_trans 0.104658, loss flux 71.160934, loss flux t1 72.346825, binary loss 31.429058, binary loss t1 29.394171\n",
      "Epoch 3/10, Batch 101/1650, Loss 62.805367, Loss rec 6.655574, loss rec t1 8.246037, loss kl 0.340171, loss_trans 0.103085, loss flux 69.581673, loss flux t1 71.491112, binary loss 23.231318, binary loss t1 24.229183\n",
      "Epoch 3/10, Batch 111/1650, Loss 102.141479, Loss rec 12.004832, loss rec t1 18.551584, loss kl 0.754580, loss_trans 0.125064, loss flux 84.605286, loss flux t1 88.171318, binary loss 35.829742, binary loss t1 34.875679\n",
      "Epoch 3/10, Batch 121/1650, Loss 64.589211, Loss rec 7.378604, loss rec t1 8.435164, loss kl 0.663940, loss_trans 0.151184, loss flux 79.575989, loss flux t1 81.560585, binary loss 25.320005, binary loss t1 22.640314\n",
      "Epoch 3/10, Batch 131/1650, Loss 131.492950, Loss rec 9.126869, loss rec t1 7.424947, loss kl 0.244708, loss_trans 0.055270, loss flux 71.637375, loss flux t1 71.915100, binary loss 59.833351, binary loss t1 54.807800\n",
      "Epoch 3/10, Batch 141/1650, Loss 79.767410, Loss rec 7.290351, loss rec t1 9.206853, loss kl 0.352482, loss_trans 0.078280, loss flux 66.942955, loss flux t1 67.649475, binary loss 31.967791, binary loss t1 30.871662\n",
      "Epoch 3/10, Batch 151/1650, Loss 61.520027, Loss rec 9.093777, loss rec t1 9.603750, loss kl 0.752498, loss_trans 0.137487, loss flux 80.476288, loss flux t1 84.182663, binary loss 21.265789, binary loss t1 20.666729\n",
      "Epoch 3/10, Batch 161/1650, Loss 76.324020, Loss rec 13.338448, loss rec t1 12.049639, loss kl 0.759589, loss_trans 0.117511, loss flux 81.938118, loss flux t1 84.252251, binary loss 24.965799, binary loss t1 25.093040\n",
      "Epoch 3/10, Batch 171/1650, Loss 72.980873, Loss rec 15.756825, loss rec t1 14.487738, loss kl 0.698258, loss_trans 0.111501, loss flux 81.169052, loss flux t1 83.214455, binary loss 21.637634, binary loss t1 20.288910\n",
      "Epoch 3/10, Batch 181/1650, Loss 136.063843, Loss rec 11.686424, loss rec t1 10.475208, loss kl 0.328786, loss_trans 0.071530, loss flux 66.475494, loss flux t1 70.283096, binary loss 58.699219, binary loss t1 54.802681\n",
      "Epoch 3/10, Batch 191/1650, Loss 78.380501, Loss rec 9.624426, loss rec t1 9.652936, loss kl 0.677611, loss_trans 0.146696, loss flux 76.913773, loss flux t1 81.010109, binary loss 28.952793, binary loss t1 29.326036\n",
      "Epoch 3/10, Batch 201/1650, Loss 64.727142, Loss rec 6.811487, loss rec t1 5.808473, loss kl 0.460813, loss_trans 0.102922, loss flux 74.462349, loss flux t1 73.567741, binary loss 26.225395, binary loss t1 25.318054\n",
      "Epoch 3/10, Batch 211/1650, Loss 59.142075, Loss rec 4.585856, loss rec t1 4.711489, loss kl 0.283193, loss_trans 0.061277, loss flux 69.733589, loss flux t1 68.078293, binary loss 24.518492, binary loss t1 24.981770\n",
      "Epoch 3/10, Batch 221/1650, Loss 64.536232, Loss rec 7.298090, loss rec t1 6.913629, loss kl 0.444642, loss_trans 0.087791, loss flux 73.847176, loss flux t1 72.048828, binary loss 26.146587, binary loss t1 23.645496\n",
      "Epoch 3/10, Batch 231/1650, Loss 77.075386, Loss rec 6.200914, loss rec t1 6.477446, loss kl 0.588735, loss_trans 0.093465, loss flux 75.788643, loss flux t1 80.074539, binary loss 33.839870, binary loss t1 29.874954\n",
      "Epoch 3/10, Batch 241/1650, Loss 71.057632, Loss rec 13.673168, loss rec t1 16.657412, loss kl 0.399012, loss_trans 0.151396, loss flux 69.809441, loss flux t1 70.964325, binary loss 19.295198, binary loss t1 20.881447\n",
      "Epoch 3/10, Batch 251/1650, Loss 62.040432, Loss rec 9.756532, loss rec t1 9.941719, loss kl 0.593868, loss_trans 0.130359, loss flux 76.912041, loss flux t1 79.623428, binary loss 20.874306, binary loss t1 20.743649\n",
      "Epoch 3/10, Batch 261/1650, Loss 113.752243, Loss rec 10.831759, loss rec t1 14.277180, loss kl 0.355332, loss_trans 0.091922, loss flux 70.518814, loss flux t1 74.387619, binary loss 45.282269, binary loss t1 42.913784\n",
      "Epoch 3/10, Batch 271/1650, Loss 89.354477, Loss rec 11.629574, loss rec t1 13.450343, loss kl 0.553005, loss_trans 0.108094, loss flux 77.563133, loss flux t1 80.406517, binary loss 31.220814, binary loss t1 32.392643\n",
      "Epoch 3/10, Batch 281/1650, Loss 80.718590, Loss rec 7.863644, loss rec t1 9.269999, loss kl 0.470365, loss_trans 0.095619, loss flux 73.084404, loss flux t1 72.293182, binary loss 33.981266, binary loss t1 29.037701\n",
      "Epoch 3/10, Batch 291/1650, Loss 76.913933, Loss rec 6.697593, loss rec t1 6.864273, loss kl 0.563154, loss_trans 0.094341, loss flux 71.466858, loss flux t1 74.670235, binary loss 32.863174, binary loss t1 29.831402\n",
      "Epoch 3/10, Batch 301/1650, Loss 49.302570, Loss rec 5.552051, loss rec t1 4.993699, loss kl 0.355423, loss_trans 0.074154, loss flux 68.800224, loss flux t1 70.378357, binary loss 18.015278, binary loss t1 20.311964\n",
      "Epoch 3/10, Batch 311/1650, Loss 106.413490, Loss rec 7.053620, loss rec t1 10.330205, loss kl 0.381070, loss_trans 0.098514, loss flux 69.108757, loss flux t1 75.198677, binary loss 44.994907, binary loss t1 43.555176\n",
      "Epoch 3/10, Batch 321/1650, Loss 76.012611, Loss rec 6.199273, loss rec t1 6.325939, loss kl 0.489159, loss_trans 0.118478, loss flux 75.459854, loss flux t1 77.992973, binary loss 32.314743, binary loss t1 30.565023\n",
      "Epoch 3/10, Batch 331/1650, Loss 83.977547, Loss rec 13.370403, loss rec t1 13.091218, loss kl 0.326418, loss_trans 0.087122, loss flux 68.654236, loss flux t1 69.526222, binary loss 28.708382, binary loss t1 28.394001\n",
      "Epoch 3/10, Batch 341/1650, Loss 102.503746, Loss rec 16.062418, loss rec t1 15.818482, loss kl 0.532479, loss_trans 0.152044, loss flux 75.856674, loss flux t1 76.393814, binary loss 35.224159, binary loss t1 34.714157\n",
      "Epoch 3/10, Batch 351/1650, Loss 84.645599, Loss rec 11.257372, loss rec t1 10.580803, loss kl 0.731231, loss_trans 0.123224, loss flux 81.837906, loss flux t1 85.255615, binary loss 32.095764, binary loss t1 29.857208\n",
      "Epoch 3/10, Batch 361/1650, Loss 82.127380, Loss rec 10.303440, loss rec t1 11.135825, loss kl 0.436171, loss_trans 0.096877, loss flux 69.431656, loss flux t1 72.774414, binary loss 29.547703, binary loss t1 30.607357\n",
      "Epoch 3/10, Batch 371/1650, Loss 58.875290, Loss rec 11.131798, loss rec t1 9.819675, loss kl 0.736887, loss_trans 0.147599, loss flux 78.650032, loss flux t1 80.804276, binary loss 18.299709, binary loss t1 18.739624\n",
      "Epoch 3/10, Batch 381/1650, Loss 59.885525, Loss rec 10.255745, loss rec t1 10.494661, loss kl 0.497807, loss_trans 0.095730, loss flux 69.477379, loss flux t1 72.720795, binary loss 19.626043, binary loss t1 18.915541\n",
      "Epoch 3/10, Batch 391/1650, Loss 90.245232, Loss rec 8.133152, loss rec t1 6.117654, loss kl 0.512305, loss_trans 0.100306, loss flux 74.556801, loss flux t1 73.210564, binary loss 39.285149, binary loss t1 36.096668\n",
      "Epoch 3/10, Batch 401/1650, Loss 57.718464, Loss rec 6.238945, loss rec t1 8.144769, loss kl 0.329335, loss_trans 0.078633, loss flux 67.685379, loss flux t1 68.497757, binary loss 21.029301, binary loss t1 21.897484\n",
      "Epoch 3/10, Batch 411/1650, Loss 56.714970, Loss rec 7.125892, loss rec t1 7.222614, loss kl 0.733733, loss_trans 0.137937, loss flux 78.797142, loss flux t1 84.311096, binary loss 21.380159, binary loss t1 20.114635\n",
      "Epoch 3/10, Batch 421/1650, Loss 53.450481, Loss rec 9.356823, loss rec t1 9.889788, loss kl 0.648643, loss_trans 0.134348, loss flux 74.441879, loss flux t1 76.000198, binary loss 16.788914, binary loss t1 16.631966\n",
      "Epoch 3/10, Batch 431/1650, Loss 78.084503, Loss rec 3.700072, loss rec t1 4.462183, loss kl 0.464791, loss_trans 0.086609, loss flux 68.393433, loss flux t1 69.701431, binary loss 37.850052, binary loss t1 31.520802\n",
      "Epoch 3/10, Batch 441/1650, Loss 93.818985, Loss rec 11.320786, loss rec t1 10.727963, loss kl 0.540964, loss_trans 0.119680, loss flux 72.255287, loss flux t1 73.016777, binary loss 38.800701, binary loss t1 32.308891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Batch 451/1650, Loss 82.291954, Loss rec 6.403323, loss rec t1 7.294015, loss kl 0.367160, loss_trans 0.089554, loss flux 66.857529, loss flux t1 67.944527, binary loss 35.784725, binary loss t1 32.353176\n",
      "Epoch 3/10, Batch 461/1650, Loss 60.360928, Loss rec 6.455224, loss rec t1 6.005356, loss kl 0.390256, loss_trans 0.078255, loss flux 69.447861, loss flux t1 70.040688, binary loss 23.420904, binary loss t1 24.010933\n",
      "Epoch 3/10, Batch 471/1650, Loss 87.824120, Loss rec 9.013142, loss rec t1 10.194605, loss kl 0.358473, loss_trans 0.081564, loss flux 64.551910, loss flux t1 66.361969, binary loss 34.984924, binary loss t1 33.191406\n",
      "Epoch 3/10, Batch 481/1650, Loss 57.697845, Loss rec 7.459030, loss rec t1 9.976425, loss kl 0.350061, loss_trans 0.061781, loss flux 67.549911, loss flux t1 68.377991, binary loss 19.134834, binary loss t1 20.715714\n",
      "Epoch 3/10, Batch 491/1650, Loss 127.468361, Loss rec 7.462724, loss rec t1 9.728958, loss kl 0.228936, loss_trans 0.059381, loss flux 64.512825, loss flux t1 66.340904, binary loss 57.351475, binary loss t1 52.636890\n",
      "Epoch 3/10, Batch 501/1650, Loss 135.079742, Loss rec 7.940605, loss rec t1 11.790987, loss kl 0.521893, loss_trans 0.095795, loss flux 75.700020, loss flux t1 77.960167, binary loss 59.456444, binary loss t1 55.274014\n",
      "Epoch 3/10, Batch 511/1650, Loss 81.519691, Loss rec 13.563600, loss rec t1 14.872412, loss kl 0.440479, loss_trans 0.076371, loss flux 72.178757, loss flux t1 69.687347, binary loss 27.014351, binary loss t1 25.552479\n",
      "Epoch 3/10, Batch 521/1650, Loss 148.689499, Loss rec 14.779596, loss rec t1 15.666325, loss kl 0.655845, loss_trans 0.136464, loss flux 71.480194, loss flux t1 76.044052, binary loss 66.873108, binary loss t1 50.578156\n",
      "Epoch 3/10, Batch 531/1650, Loss 79.217026, Loss rec 10.216742, loss rec t1 10.269072, loss kl 0.287513, loss_trans 0.072149, loss flux 61.404118, loss flux t1 66.675850, binary loss 30.237284, binary loss t1 28.134266\n",
      "Epoch 3/10, Batch 541/1650, Loss 144.765091, Loss rec 15.341043, loss rec t1 18.294628, loss kl 0.349125, loss_trans 0.089710, loss flux 66.918480, loss flux t1 70.384109, binary loss 56.087662, binary loss t1 54.602913\n",
      "Epoch 3/10, Batch 551/1650, Loss 65.742447, Loss rec 10.697101, loss rec t1 9.440188, loss kl 0.509842, loss_trans 0.115472, loss flux 68.689407, loss flux t1 76.811165, binary loss 22.144888, binary loss t1 22.834957\n",
      "Epoch 3/10, Batch 561/1650, Loss 71.900627, Loss rec 9.777456, loss rec t1 9.944777, loss kl 0.398534, loss_trans 0.094111, loss flux 68.596291, loss flux t1 70.170601, binary loss 25.554787, binary loss t1 26.130970\n",
      "Epoch 3/10, Batch 571/1650, Loss 108.237427, Loss rec 13.219748, loss rec t1 12.656519, loss kl 0.408012, loss_trans 0.079941, loss flux 68.839096, loss flux t1 68.709518, binary loss 44.213406, binary loss t1 37.659801\n",
      "Epoch 3/10, Batch 581/1650, Loss 59.263287, Loss rec 6.643327, loss rec t1 7.574640, loss kl 0.394294, loss_trans 0.102071, loss flux 69.609703, loss flux t1 69.662834, binary loss 22.331297, binary loss t1 22.217657\n",
      "Epoch 3/10, Batch 591/1650, Loss 71.453629, Loss rec 8.597195, loss rec t1 7.650201, loss kl 0.311516, loss_trans 0.063554, loss flux 66.209900, loss flux t1 68.272499, binary loss 28.100164, binary loss t1 26.731005\n",
      "Epoch 3/10, Batch 601/1650, Loss 116.969299, Loss rec 12.410864, loss rec t1 12.883803, loss kl 0.409801, loss_trans 0.115080, loss flux 68.997002, loss flux t1 70.004608, binary loss 47.500641, binary loss t1 43.649109\n",
      "Epoch 3/10, Batch 611/1650, Loss 69.222244, Loss rec 18.607704, loss rec t1 20.524595, loss kl 0.436416, loss_trans 0.098969, loss flux 69.717628, loss flux t1 70.678642, binary loss 15.266359, binary loss t1 14.288197\n",
      "Epoch 3/10, Batch 621/1650, Loss 105.170021, Loss rec 14.319550, loss rec t1 16.593370, loss kl 0.547390, loss_trans 0.086694, loss flux 72.597832, loss flux t1 75.051079, binary loss 36.412582, binary loss t1 37.210434\n",
      "Epoch 3/10, Batch 631/1650, Loss 187.998444, Loss rec 15.245317, loss rec t1 15.448697, loss kl 0.595492, loss_trans 0.115876, loss flux 76.140800, loss flux t1 74.003113, binary loss 83.189468, binary loss t1 73.403595\n",
      "Epoch 3/10, Batch 641/1650, Loss 60.435280, Loss rec 13.810282, loss rec t1 16.824060, loss kl 0.456664, loss_trans 0.099349, loss flux 70.284355, loss flux t1 70.644814, binary loss 13.582998, binary loss t1 15.661924\n",
      "Epoch 3/10, Batch 651/1650, Loss 99.290085, Loss rec 12.117550, loss rec t1 13.395964, loss kl 0.429018, loss_trans 0.111093, loss flux 65.969727, loss flux t1 67.605110, binary loss 36.386227, binary loss t1 36.850235\n",
      "Epoch 3/10, Batch 661/1650, Loss 99.559532, Loss rec 11.399857, loss rec t1 14.312720, loss kl 0.624780, loss_trans 0.130219, loss flux 73.289253, loss flux t1 73.421928, binary loss 37.698475, binary loss t1 35.393486\n",
      "Epoch 3/10, Batch 671/1650, Loss 48.323940, Loss rec 6.360721, loss rec t1 8.763474, loss kl 0.379731, loss_trans 0.109569, loss flux 67.510788, loss flux t1 70.334923, binary loss 15.491553, binary loss t1 17.218891\n",
      "Epoch 3/10, Batch 681/1650, Loss 68.546448, Loss rec 4.540066, loss rec t1 4.857062, loss kl 0.343313, loss_trans 0.081956, loss flux 65.542755, loss flux t1 69.692848, binary loss 28.232285, binary loss t1 30.491764\n",
      "Epoch 3/10, Batch 691/1650, Loss 111.101486, Loss rec 19.150043, loss rec t1 21.058432, loss kl 0.857333, loss_trans 0.144147, loss flux 86.208961, loss flux t1 90.667793, binary loss 35.677429, binary loss t1 34.214096\n",
      "Epoch 3/10, Batch 701/1650, Loss 165.524506, Loss rec 68.137978, loss rec t1 71.489349, loss kl 0.642437, loss_trans 0.132400, loss flux 72.594536, loss flux t1 72.948906, binary loss 13.145655, binary loss t1 11.976689\n",
      "Epoch 3/10, Batch 711/1650, Loss 199.453629, Loss rec 46.332588, loss rec t1 43.495071, loss kl 0.895437, loss_trans 0.210861, loss flux 88.097832, loss flux t1 90.816750, binary loss 60.470840, binary loss t1 48.048820\n",
      "Epoch 3/10, Batch 721/1650, Loss 108.457710, Loss rec 25.087021, loss rec t1 26.997768, loss kl 0.607760, loss_trans 0.129302, loss flux 78.108582, loss flux t1 80.453148, binary loss 32.846893, binary loss t1 22.788965\n",
      "Epoch 3/10, Batch 731/1650, Loss 199.712143, Loss rec 23.637333, loss rec t1 23.777500, loss kl 0.406182, loss_trans 0.100484, loss flux 70.475616, loss flux t1 73.146584, binary loss 79.339172, binary loss t1 72.451485\n",
      "Epoch 3/10, Batch 741/1650, Loss 76.370872, Loss rec 13.071713, loss rec t1 15.191707, loss kl 0.437514, loss_trans 0.125930, loss flux 68.642990, loss flux t1 71.909821, binary loss 23.216009, binary loss t1 24.328001\n",
      "Epoch 3/10, Batch 751/1650, Loss 102.407906, Loss rec 16.094131, loss rec t1 20.834156, loss kl 0.586672, loss_trans 0.139141, loss flux 70.141312, loss flux t1 70.510239, binary loss 32.310356, binary loss t1 32.443451\n",
      "Epoch 3/10, Batch 761/1650, Loss 134.550980, Loss rec 9.017824, loss rec t1 9.121517, loss kl 0.664621, loss_trans 0.158638, loss flux 70.082191, loss flux t1 71.240318, binary loss 62.444424, binary loss t1 53.143967\n",
      "Epoch 3/10, Batch 771/1650, Loss 43.275555, Loss rec 7.767125, loss rec t1 9.235552, loss kl 0.389875, loss_trans 0.116180, loss flux 61.435524, loss flux t1 65.248276, binary loss 12.728659, binary loss t1 13.038163\n",
      "Epoch 3/10, Batch 781/1650, Loss 68.023666, Loss rec 7.187048, loss rec t1 9.241612, loss kl 0.388596, loss_trans 0.095303, loss flux 66.799950, loss flux t1 69.050919, binary loss 25.432184, binary loss t1 25.678917\n",
      "Epoch 3/10, Batch 791/1650, Loss 78.784012, Loss rec 6.123930, loss rec t1 7.016213, loss kl 0.351355, loss_trans 0.111417, loss flux 66.801674, loss flux t1 69.261566, binary loss 32.005974, binary loss t1 33.175121\n",
      "Epoch 3/10, Batch 801/1650, Loss 81.325531, Loss rec 9.594625, loss rec t1 10.647504, loss kl 0.610553, loss_trans 0.132171, loss flux 74.046722, loss flux t1 76.630127, binary loss 31.797913, binary loss t1 28.542763\n",
      "Epoch 3/10, Batch 811/1650, Loss 75.920830, Loss rec 6.970262, loss rec t1 7.605371, loss kl 0.760793, loss_trans 0.163817, loss flux 81.093597, loss flux t1 83.879379, binary loss 33.585392, binary loss t1 26.835194\n",
      "Epoch 3/10, Batch 821/1650, Loss 69.815788, Loss rec 4.980515, loss rec t1 5.563516, loss kl 0.439776, loss_trans 0.096953, loss flux 63.957848, loss flux t1 68.526436, binary loss 29.324816, binary loss t1 29.410212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Batch 831/1650, Loss 56.703747, Loss rec 6.930299, loss rec t1 8.188072, loss kl 0.781339, loss_trans 0.131607, loss flux 71.911278, loss flux t1 70.367271, binary loss 22.981232, binary loss t1 17.691196\n",
      "Epoch 3/10, Batch 841/1650, Loss 71.344887, Loss rec 3.828950, loss rec t1 4.918871, loss kl 0.245766, loss_trans 0.061375, loss flux 60.299229, loss flux t1 61.490410, binary loss 30.470352, binary loss t1 31.819569\n",
      "Epoch 3/10, Batch 851/1650, Loss 60.363293, Loss rec 4.778841, loss rec t1 5.119198, loss kl 0.467756, loss_trans 0.112514, loss flux 67.260574, loss flux t1 70.849030, binary loss 25.808109, binary loss t1 24.076872\n",
      "Epoch 3/10, Batch 861/1650, Loss 51.052872, Loss rec 5.857168, loss rec t1 6.271439, loss kl 0.642403, loss_trans 0.122972, loss flux 72.461494, loss flux t1 74.393738, binary loss 19.342590, binary loss t1 18.816301\n",
      "Epoch 3/10, Batch 871/1650, Loss 58.728416, Loss rec 4.565063, loss rec t1 4.642084, loss kl 0.590422, loss_trans 0.112107, loss flux 73.995407, loss flux t1 75.847252, binary loss 24.476162, binary loss t1 24.342577\n",
      "Epoch 3/10, Batch 881/1650, Loss 68.236267, Loss rec 4.618299, loss rec t1 5.963740, loss kl 0.427500, loss_trans 0.100765, loss flux 66.903381, loss flux t1 71.084801, binary loss 28.814812, binary loss t1 28.311155\n",
      "Epoch 3/10, Batch 891/1650, Loss 76.790756, Loss rec 4.790213, loss rec t1 5.286357, loss kl 0.406563, loss_trans 0.090485, loss flux 69.549995, loss flux t1 74.028252, binary loss 35.476933, binary loss t1 30.740206\n",
      "Epoch 3/10, Batch 901/1650, Loss 51.722630, Loss rec 4.955216, loss rec t1 5.902389, loss kl 0.710081, loss_trans 0.153129, loss flux 76.448219, loss flux t1 80.064140, binary loss 21.520576, binary loss t1 18.481239\n",
      "Epoch 3/10, Batch 911/1650, Loss 64.172508, Loss rec 3.411040, loss rec t1 3.539225, loss kl 0.354621, loss_trans 0.067740, loss flux 63.023979, loss flux t1 66.323715, binary loss 29.318960, binary loss t1 27.480915\n",
      "Epoch 3/10, Batch 921/1650, Loss 78.058075, Loss rec 3.539835, loss rec t1 4.048787, loss kl 0.431144, loss_trans 0.096880, loss flux 68.232063, loss flux t1 71.234863, binary loss 35.943626, binary loss t1 33.997799\n",
      "Epoch 3/10, Batch 931/1650, Loss 44.019279, Loss rec 3.903222, loss rec t1 4.433876, loss kl 0.468730, loss_trans 0.077613, loss flux 67.767799, loss flux t1 69.697014, binary loss 17.942505, binary loss t1 17.193333\n",
      "Epoch 3/10, Batch 941/1650, Loss 64.256081, Loss rec 4.743430, loss rec t1 4.411226, loss kl 0.579722, loss_trans 0.107568, loss flux 68.857330, loss flux t1 71.284447, binary loss 28.500673, binary loss t1 25.913456\n",
      "Epoch 3/10, Batch 951/1650, Loss 60.753517, Loss rec 6.218740, loss rec t1 5.644724, loss kl 0.356020, loss_trans 0.067486, loss flux 70.286110, loss flux t1 73.764381, binary loss 24.568947, binary loss t1 23.897602\n",
      "Epoch 3/10, Batch 961/1650, Loss 100.283333, Loss rec 11.847145, loss rec t1 12.258821, loss kl 0.322729, loss_trans 0.058710, loss flux 65.652008, loss flux t1 65.950333, binary loss 37.732754, binary loss t1 38.063179\n",
      "Epoch 3/10, Batch 971/1650, Loss 53.588112, Loss rec 13.220539, loss rec t1 13.967499, loss kl 0.371399, loss_trans 0.086043, loss flux 67.898483, loss flux t1 70.735771, binary loss 12.570070, binary loss t1 13.372559\n",
      "Epoch 3/10, Batch 981/1650, Loss 87.835930, Loss rec 7.939386, loss rec t1 10.156763, loss kl 0.321592, loss_trans 0.073875, loss flux 65.217354, loss flux t1 65.406693, binary loss 36.343159, binary loss t1 33.001152\n",
      "Epoch 3/10, Batch 991/1650, Loss 115.306030, Loss rec 8.485174, loss rec t1 9.175598, loss kl 0.345945, loss_trans 0.096939, loss flux 68.232674, loss flux t1 72.483597, binary loss 50.516853, binary loss t1 46.685520\n",
      "Epoch 3/10, Batch 1001/1650, Loss 50.895290, Loss rec 10.047932, loss rec t1 11.241959, loss kl 0.626233, loss_trans 0.125544, loss flux 76.714539, loss flux t1 79.294846, binary loss 14.568659, binary loss t1 14.284960\n",
      "Epoch 3/10, Batch 1011/1650, Loss 91.305206, Loss rec 8.525893, loss rec t1 9.608561, loss kl 0.361961, loss_trans 0.109606, loss flux 66.014549, loss flux t1 69.888969, binary loss 36.980160, binary loss t1 35.719032\n",
      "Epoch 3/10, Batch 1021/1650, Loss 52.871437, Loss rec 7.921535, loss rec t1 8.673622, loss kl 0.388702, loss_trans 0.083506, loss flux 67.434380, loss flux t1 69.717255, binary loss 17.735970, binary loss t1 18.068102\n",
      "Epoch 3/10, Batch 1031/1650, Loss 67.894424, Loss rec 8.228262, loss rec t1 7.776654, loss kl 0.705597, loss_trans 0.119112, loss flux 72.517708, loss flux t1 74.707062, binary loss 25.909306, binary loss t1 25.155495\n",
      "Epoch 3/10, Batch 1041/1650, Loss 43.038204, Loss rec 6.569547, loss rec t1 7.649910, loss kl 0.430616, loss_trans 0.073736, loss flux 66.179764, loss flux t1 67.566132, binary loss 14.436294, binary loss t1 13.878103\n",
      "Epoch 3/10, Batch 1051/1650, Loss 54.366364, Loss rec 5.204236, loss rec t1 5.543051, loss kl 0.325744, loss_trans 0.075108, loss flux 64.121193, loss flux t1 66.364220, binary loss 20.491297, binary loss t1 22.726929\n",
      "Epoch 3/10, Batch 1061/1650, Loss 79.612274, Loss rec 7.455473, loss rec t1 8.757808, loss kl 0.649990, loss_trans 0.140061, loss flux 77.779564, loss flux t1 81.553673, binary loss 32.756615, binary loss t1 29.852325\n",
      "Epoch 3/10, Batch 1071/1650, Loss 42.226051, Loss rec 4.316530, loss rec t1 4.353415, loss kl 0.612309, loss_trans 0.114897, loss flux 70.490662, loss flux t1 75.038033, binary loss 16.658747, binary loss t1 16.170153\n",
      "Epoch 3/10, Batch 1081/1650, Loss 79.495575, Loss rec 9.917696, loss rec t1 8.940538, loss kl 0.525738, loss_trans 0.112033, loss flux 71.800888, loss flux t1 70.978676, binary loss 31.848782, binary loss t1 28.150791\n",
      "Epoch 3/10, Batch 1091/1650, Loss 46.330860, Loss rec 4.065763, loss rec t1 4.962987, loss kl 0.239991, loss_trans 0.071704, loss flux 61.450291, loss flux t1 63.624996, binary loss 18.716995, binary loss t1 18.273417\n",
      "Epoch 3/10, Batch 1101/1650, Loss 84.921555, Loss rec 5.496468, loss rec t1 5.243515, loss kl 0.313329, loss_trans 0.072371, loss flux 62.452801, loss flux t1 63.053528, binary loss 37.784359, binary loss t1 36.011517\n",
      "Epoch 3/10, Batch 1111/1650, Loss 68.205307, Loss rec 4.306376, loss rec t1 5.296182, loss kl 0.302005, loss_trans 0.068157, loss flux 59.599792, loss flux t1 61.395618, binary loss 32.093323, binary loss t1 26.139269\n",
      "Epoch 3/10, Batch 1121/1650, Loss 57.193218, Loss rec 5.530509, loss rec t1 5.803254, loss kl 0.567804, loss_trans 0.126620, loss flux 71.312073, loss flux t1 73.381226, binary loss 23.301891, binary loss t1 21.863138\n",
      "Epoch 3/10, Batch 1131/1650, Loss 50.961563, Loss rec 6.317061, loss rec t1 5.765344, loss kl 0.838171, loss_trans 0.148116, loss flux 75.655006, loss flux t1 78.537720, binary loss 18.845697, binary loss t1 19.047174\n",
      "Epoch 3/10, Batch 1141/1650, Loss 66.170128, Loss rec 5.062082, loss rec t1 6.467693, loss kl 0.528325, loss_trans 0.119331, loss flux 72.060173, loss flux t1 73.513489, binary loss 27.483351, binary loss t1 26.509342\n",
      "Epoch 3/10, Batch 1151/1650, Loss 51.995949, Loss rec 4.653111, loss rec t1 5.322956, loss kl 0.645660, loss_trans 0.094012, loss flux 77.397369, loss flux t1 80.295753, binary loss 21.158981, binary loss t1 20.121227\n",
      "Epoch 3/10, Batch 1161/1650, Loss 60.825623, Loss rec 8.327620, loss rec t1 7.366303, loss kl 0.460042, loss_trans 0.096347, loss flux 69.183144, loss flux t1 73.052567, binary loss 22.962261, binary loss t1 21.613049\n",
      "Epoch 3/10, Batch 1171/1650, Loss 109.317024, Loss rec 12.713066, loss rec t1 13.344183, loss kl 0.417777, loss_trans 0.071757, loss flux 70.455902, loss flux t1 72.235268, binary loss 41.895241, binary loss t1 40.874996\n",
      "Epoch 3/10, Batch 1181/1650, Loss 75.327339, Loss rec 9.322597, loss rec t1 8.874925, loss kl 0.736895, loss_trans 0.122378, loss flux 77.386139, loss flux t1 83.696518, binary loss 28.102180, binary loss t1 28.168365\n",
      "Epoch 3/10, Batch 1191/1650, Loss 69.823921, Loss rec 7.994278, loss rec t1 11.441715, loss kl 0.584711, loss_trans 0.107572, loss flux 73.614807, loss flux t1 75.474113, binary loss 24.781027, binary loss t1 24.914616\n",
      "Epoch 3/10, Batch 1201/1650, Loss 55.018372, Loss rec 7.533665, loss rec t1 6.018041, loss kl 0.380123, loss_trans 0.087350, loss flux 63.585114, loss flux t1 61.548611, binary loss 22.831114, binary loss t1 18.168077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Batch 1211/1650, Loss 119.609688, Loss rec 18.965988, loss rec t1 23.281677, loss kl 0.526399, loss_trans 0.103376, loss flux 72.871063, loss flux t1 74.240807, binary loss 41.034870, binary loss t1 35.697380\n",
      "Epoch 3/10, Batch 1221/1650, Loss 64.048767, Loss rec 4.684278, loss rec t1 6.796236, loss kl 0.451513, loss_trans 0.099585, loss flux 69.754829, loss flux t1 72.280098, binary loss 26.861176, binary loss t1 25.155979\n",
      "Epoch 3/10, Batch 1231/1650, Loss 60.153999, Loss rec 3.926749, loss rec t1 5.168512, loss kl 0.389047, loss_trans 0.087877, loss flux 62.015244, loss flux t1 65.731110, binary loss 24.472012, binary loss t1 26.109802\n",
      "Epoch 3/10, Batch 1241/1650, Loss 69.415215, Loss rec 4.846259, loss rec t1 4.121039, loss kl 0.441798, loss_trans 0.082251, loss flux 65.101997, loss flux t1 69.912529, binary loss 30.870132, binary loss t1 29.053738\n",
      "Epoch 3/10, Batch 1251/1650, Loss 47.278641, Loss rec 6.476369, loss rec t1 6.465123, loss kl 0.352759, loss_trans 0.077536, loss flux 64.094208, loss flux t1 64.240822, binary loss 16.156063, binary loss t1 17.750790\n",
      "Epoch 3/10, Batch 1261/1650, Loss 54.070942, Loss rec 11.018247, loss rec t1 10.303965, loss kl 0.360267, loss_trans 0.086697, loss flux 67.326622, loss flux t1 66.406639, binary loss 17.061275, binary loss t1 15.240490\n",
      "Epoch 3/10, Batch 1271/1650, Loss 62.978836, Loss rec 7.151267, loss rec t1 6.136205, loss kl 0.484236, loss_trans 0.102245, loss flux 71.279396, loss flux t1 72.521927, binary loss 24.342823, binary loss t1 24.762058\n",
      "Epoch 3/10, Batch 1281/1650, Loss 53.338337, Loss rec 3.840099, loss rec t1 4.296398, loss kl 0.408916, loss_trans 0.070975, loss flux 64.136772, loss flux t1 64.473045, binary loss 23.897781, binary loss t1 20.824165\n",
      "Epoch 3/10, Batch 1291/1650, Loss 49.897511, Loss rec 2.725494, loss rec t1 3.782509, loss kl 0.274264, loss_trans 0.060064, loss flux 59.501743, loss flux t1 61.703350, binary loss 21.019295, binary loss t1 22.035883\n",
      "Epoch 3/10, Batch 1301/1650, Loss 45.765892, Loss rec 4.443128, loss rec t1 4.349685, loss kl 0.376801, loss_trans 0.065728, loss flux 64.252861, loss flux t1 64.489349, binary loss 18.476116, binary loss t1 18.054436\n",
      "Epoch 3/10, Batch 1311/1650, Loss 56.151432, Loss rec 4.671074, loss rec t1 4.973767, loss kl 0.347975, loss_trans 0.081603, loss flux 64.643066, loss flux t1 69.448792, binary loss 22.726929, binary loss t1 23.350082\n",
      "Epoch 3/10, Batch 1321/1650, Loss 51.859158, Loss rec 4.677217, loss rec t1 5.247972, loss kl 0.618593, loss_trans 0.113795, loss flux 71.159424, loss flux t1 74.778442, binary loss 21.286713, binary loss t1 19.914869\n",
      "Epoch 3/10, Batch 1331/1650, Loss 59.086578, Loss rec 4.898211, loss rec t1 5.269644, loss kl 0.329874, loss_trans 0.084739, loss flux 68.572769, loss flux t1 69.727852, binary loss 24.673733, binary loss t1 23.830376\n",
      "Epoch 3/10, Batch 1341/1650, Loss 47.386513, Loss rec 2.740869, loss rec t1 3.145234, loss kl 0.403530, loss_trans 0.082932, loss flux 60.090729, loss flux t1 65.322906, binary loss 20.794212, binary loss t1 20.219734\n",
      "Epoch 3/10, Batch 1351/1650, Loss 46.817631, Loss rec 2.687272, loss rec t1 2.756069, loss kl 0.265679, loss_trans 0.065928, loss flux 63.321098, loss flux t1 65.968430, binary loss 20.289333, binary loss t1 20.753345\n",
      "Epoch 3/10, Batch 1361/1650, Loss 54.073185, Loss rec 4.553901, loss rec t1 5.541147, loss kl 0.691017, loss_trans 0.108540, loss flux 75.704132, loss flux t1 75.169479, binary loss 22.771456, binary loss t1 20.407122\n",
      "Epoch 3/10, Batch 1371/1650, Loss 56.609089, Loss rec 3.038362, loss rec t1 3.777106, loss kl 0.315523, loss_trans 0.073231, loss flux 59.803246, loss flux t1 64.322174, binary loss 24.381983, binary loss t1 25.022884\n",
      "Epoch 3/10, Batch 1381/1650, Loss 70.945923, Loss rec 5.902423, loss rec t1 5.889942, loss kl 0.516173, loss_trans 0.082425, loss flux 73.502594, loss flux t1 75.577271, binary loss 30.538734, binary loss t1 28.016226\n",
      "Epoch 3/10, Batch 1391/1650, Loss 35.514057, Loss rec 5.326176, loss rec t1 6.061274, loss kl 0.607398, loss_trans 0.126237, loss flux 67.271500, loss flux t1 72.449638, binary loss 11.574095, binary loss t1 11.818877\n",
      "Epoch 3/10, Batch 1401/1650, Loss 53.348824, Loss rec 4.066382, loss rec t1 4.060291, loss kl 0.362225, loss_trans 0.079300, loss flux 67.312706, loss flux t1 72.381866, binary loss 20.233156, binary loss t1 24.547472\n",
      "Epoch 3/10, Batch 1411/1650, Loss 53.500256, Loss rec 5.023471, loss rec t1 5.301267, loss kl 0.479956, loss_trans 0.090723, loss flux 69.417610, loss flux t1 70.789055, binary loss 21.134644, binary loss t1 21.470194\n",
      "Epoch 3/10, Batch 1421/1650, Loss 51.746059, Loss rec 4.348097, loss rec t1 4.752398, loss kl 0.370663, loss_trans 0.078633, loss flux 63.568604, loss flux t1 64.891403, binary loss 21.221748, binary loss t1 20.974522\n",
      "Epoch 3/10, Batch 1431/1650, Loss 43.674412, Loss rec 4.739660, loss rec t1 6.511836, loss kl 0.421684, loss_trans 0.084736, loss flux 67.394447, loss flux t1 68.484627, binary loss 16.620073, binary loss t1 15.296422\n",
      "Epoch 3/10, Batch 1441/1650, Loss 58.492970, Loss rec 4.529257, loss rec t1 6.168324, loss kl 0.601598, loss_trans 0.109465, loss flux 70.274231, loss flux t1 73.956261, binary loss 24.163733, binary loss t1 22.920593\n",
      "Epoch 3/10, Batch 1451/1650, Loss 69.869087, Loss rec 7.083758, loss rec t1 7.056780, loss kl 0.436306, loss_trans 0.101363, loss flux 66.403519, loss flux t1 68.471405, binary loss 30.308836, binary loss t1 24.882042\n",
      "Epoch 3/10, Batch 1461/1650, Loss 51.364334, Loss rec 3.370401, loss rec t1 4.024044, loss kl 0.329079, loss_trans 0.077338, loss flux 65.206322, loss flux t1 66.853302, binary loss 21.835138, binary loss t1 21.728333\n",
      "Epoch 3/10, Batch 1471/1650, Loss 52.726505, Loss rec 6.511964, loss rec t1 6.152638, loss kl 0.469896, loss_trans 0.083241, loss flux 69.776276, loss flux t1 70.779861, binary loss 19.423347, binary loss t1 20.085419\n",
      "Epoch 3/10, Batch 1481/1650, Loss 29.787598, Loss rec 4.185874, loss rec t1 4.826186, loss kl 0.412623, loss_trans 0.074973, loss flux 68.483536, loss flux t1 72.145096, binary loss 10.112220, binary loss t1 10.175719\n",
      "Epoch 3/10, Batch 1491/1650, Loss 50.507534, Loss rec 5.505306, loss rec t1 5.775846, loss kl 0.647431, loss_trans 0.106473, loss flux 73.549866, loss flux t1 75.414955, binary loss 19.755482, binary loss t1 18.716993\n",
      "Epoch 3/10, Batch 1501/1650, Loss 44.184944, Loss rec 5.403767, loss rec t1 6.241860, loss kl 0.623522, loss_trans 0.109763, loss flux 73.397926, loss flux t1 75.072815, binary loss 16.199615, binary loss t1 15.606414\n",
      "Epoch 3/10, Batch 1511/1650, Loss 67.268143, Loss rec 5.323696, loss rec t1 6.464425, loss kl 0.343117, loss_trans 0.102557, loss flux 64.581772, loss flux t1 66.119011, binary loss 27.374838, binary loss t1 27.659515\n",
      "Epoch 3/10, Batch 1521/1650, Loss 52.707283, Loss rec 3.342058, loss rec t1 3.923293, loss kl 0.399228, loss_trans 0.074752, loss flux 65.129333, loss flux t1 68.836143, binary loss 23.545216, binary loss t1 21.422737\n",
      "Epoch 3/10, Batch 1531/1650, Loss 71.195297, Loss rec 5.493798, loss rec t1 4.854957, loss kl 0.374394, loss_trans 0.080608, loss flux 66.496323, loss flux t1 68.708893, binary loss 30.627789, binary loss t1 29.763756\n",
      "Epoch 3/10, Batch 1541/1650, Loss 50.066525, Loss rec 3.437717, loss rec t1 3.809349, loss kl 0.524094, loss_trans 0.120991, loss flux 68.804817, loss flux t1 72.396820, binary loss 21.109329, binary loss t1 21.065042\n",
      "Epoch 3/10, Batch 1551/1650, Loss 40.080048, Loss rec 4.691993, loss rec t1 4.920910, loss kl 0.256393, loss_trans 0.065628, loss flux 64.049355, loss flux t1 65.174576, binary loss 14.631670, binary loss t1 15.513453\n",
      "Epoch 3/10, Batch 1561/1650, Loss 57.840183, Loss rec 5.338987, loss rec t1 5.801726, loss kl 0.667578, loss_trans 0.127451, loss flux 74.734970, loss flux t1 77.823456, binary loss 24.380028, binary loss t1 21.524418\n",
      "Epoch 3/10, Batch 1571/1650, Loss 57.743946, Loss rec 5.885583, loss rec t1 7.606734, loss kl 0.551992, loss_trans 0.084315, loss flux 67.834892, loss flux t1 71.931046, binary loss 22.833248, binary loss t1 20.782074\n",
      "Epoch 3/10, Batch 1581/1650, Loss 54.285976, Loss rec 3.943356, loss rec t1 5.374926, loss kl 0.263315, loss_trans 0.052032, loss flux 59.901581, loss flux t1 59.632713, binary loss 23.103104, binary loss t1 21.549244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Batch 1591/1650, Loss 51.599026, Loss rec 5.412093, loss rec t1 5.825406, loss kl 0.449437, loss_trans 0.075695, loss flux 65.632607, loss flux t1 67.504395, binary loss 20.415176, binary loss t1 19.421219\n",
      "Epoch 3/10, Batch 1601/1650, Loss 78.273750, Loss rec 5.638461, loss rec t1 5.881495, loss kl 0.178161, loss_trans 0.055339, loss flux 59.692493, loss flux t1 58.621246, binary loss 32.552208, binary loss t1 33.968090\n",
      "Epoch 3/10, Batch 1611/1650, Loss 50.260757, Loss rec 3.027184, loss rec t1 2.868684, loss kl 0.198742, loss_trans 0.050094, loss flux 59.207550, loss flux t1 60.968975, binary loss 22.833736, binary loss t1 21.282314\n",
      "Epoch 3/10, Batch 1621/1650, Loss 63.241913, Loss rec 3.265704, loss rec t1 3.609488, loss kl 0.444990, loss_trans 0.088792, loss flux 64.025757, loss flux t1 66.885658, binary loss 27.419369, binary loss t1 28.413570\n",
      "Epoch 3/10, Batch 1631/1650, Loss 45.920963, Loss rec 5.675353, loss rec t1 5.880328, loss kl 0.299024, loss_trans 0.088651, loss flux 64.080338, loss flux t1 65.455139, binary loss 16.479412, binary loss t1 17.498198\n",
      "Epoch 3/10, Batch 1641/1650, Loss 47.028088, Loss rec 3.643141, loss rec t1 3.897593, loss kl 0.481400, loss_trans 0.106432, loss flux 68.778030, loss flux t1 72.188843, binary loss 19.008015, binary loss t1 19.891506\n",
      "Epoch 3/10, Train loss 46.446854, Eval loss 43.380520\n",
      "Epoch 4/10, Batch 1/1650, Loss 40.086372, Loss rec 3.977782, loss rec t1 4.663488, loss kl 0.478007, loss_trans 0.106833, loss flux 67.508278, loss flux t1 71.536736, binary loss 15.249700, binary loss t1 15.610562\n",
      "Epoch 4/10, Batch 11/1650, Loss 39.233398, Loss rec 4.439536, loss rec t1 4.676268, loss kl 0.506358, loss_trans 0.088778, loss flux 69.186501, loss flux t1 76.007759, binary loss 13.653021, binary loss t1 15.869436\n",
      "Epoch 4/10, Batch 21/1650, Loss 74.637680, Loss rec 6.079165, loss rec t1 5.806446, loss kl 0.345066, loss_trans 0.083240, loss flux 63.370495, loss flux t1 64.913658, binary loss 31.096680, binary loss t1 31.227091\n",
      "Epoch 4/10, Batch 31/1650, Loss 56.572281, Loss rec 4.215837, loss rec t1 5.700362, loss kl 0.258693, loss_trans 0.058579, loss flux 64.470970, loss flux t1 66.545769, binary loss 23.013557, binary loss t1 23.325254\n",
      "Epoch 4/10, Batch 41/1650, Loss 34.719433, Loss rec 5.270905, loss rec t1 5.324492, loss kl 0.331231, loss_trans 0.074044, loss flux 63.981106, loss flux t1 65.540314, binary loss 11.484304, binary loss t1 12.234455\n",
      "Epoch 4/10, Batch 51/1650, Loss 41.128731, Loss rec 3.578929, loss rec t1 4.479012, loss kl 0.279178, loss_trans 0.058049, loss flux 63.855381, loss flux t1 65.829475, binary loss 16.243170, binary loss t1 16.490395\n",
      "Epoch 4/10, Batch 61/1650, Loss 85.458633, Loss rec 10.327410, loss rec t1 10.109800, loss kl 0.577623, loss_trans 0.106554, loss flux 71.613991, loss flux t1 74.038658, binary loss 32.555870, binary loss t1 31.781380\n",
      "Epoch 4/10, Batch 71/1650, Loss 46.708569, Loss rec 4.734430, loss rec t1 5.850465, loss kl 0.574207, loss_trans 0.084911, loss flux 75.234428, loss flux t1 75.809769, binary loss 17.633980, binary loss t1 17.830574\n",
      "Epoch 4/10, Batch 81/1650, Loss 56.659103, Loss rec 6.039925, loss rec t1 6.323195, loss kl 0.295099, loss_trans 0.066360, loss flux 61.649158, loss flux t1 63.590363, binary loss 22.366798, binary loss t1 21.567726\n",
      "Epoch 4/10, Batch 91/1650, Loss 63.961231, Loss rec 8.965654, loss rec t1 9.905195, loss kl 0.326628, loss_trans 0.074316, loss flux 64.174622, loss flux t1 65.761581, binary loss 22.610914, binary loss t1 22.078526\n",
      "Epoch 4/10, Batch 101/1650, Loss 51.104095, Loss rec 4.934223, loss rec t1 5.081849, loss kl 0.277877, loss_trans 0.072089, loss flux 63.239117, loss flux t1 64.813477, binary loss 20.668924, binary loss t1 20.069132\n",
      "Epoch 4/10, Batch 111/1650, Loss 60.733650, Loss rec 6.180315, loss rec t1 6.967092, loss kl 0.565728, loss_trans 0.088495, loss flux 73.313766, loss flux t1 76.360832, binary loss 24.075651, binary loss t1 22.856367\n",
      "Epoch 4/10, Batch 121/1650, Loss 45.538651, Loss rec 5.175996, loss rec t1 5.187601, loss kl 0.529535, loss_trans 0.123079, loss flux 69.566895, loss flux t1 72.711388, binary loss 17.707727, binary loss t1 16.814716\n",
      "Epoch 4/10, Batch 131/1650, Loss 47.521664, Loss rec 3.827142, loss rec t1 3.928040, loss kl 0.185120, loss_trans 0.038983, loss flux 62.491989, loss flux t1 63.530418, binary loss 19.209492, binary loss t1 20.332886\n",
      "Epoch 4/10, Batch 141/1650, Loss 51.232334, Loss rec 5.137696, loss rec t1 7.589507, loss kl 0.275322, loss_trans 0.052860, loss flux 59.151863, loss flux t1 60.056286, binary loss 19.102442, binary loss t1 19.074509\n",
      "Epoch 4/10, Batch 151/1650, Loss 58.883099, Loss rec 6.707855, loss rec t1 8.658298, loss kl 0.616416, loss_trans 0.101056, loss flux 73.625282, loss flux t1 77.504929, binary loss 21.576752, binary loss t1 21.222725\n",
      "Epoch 4/10, Batch 161/1650, Loss 81.202553, Loss rec 9.186974, loss rec t1 8.002243, loss kl 0.616157, loss_trans 0.091089, loss flux 73.367424, loss flux t1 75.593346, binary loss 31.633221, binary loss t1 31.672869\n",
      "Epoch 4/10, Batch 171/1650, Loss 68.048721, Loss rec 7.717981, loss rec t1 8.214087, loss kl 0.612856, loss_trans 0.084167, loss flux 72.995453, loss flux t1 75.820480, binary loss 26.608160, binary loss t1 24.811468\n",
      "Epoch 4/10, Batch 181/1650, Loss 58.274818, Loss rec 2.927823, loss rec t1 3.358662, loss kl 0.266049, loss_trans 0.054526, loss flux 57.317448, loss flux t1 60.658623, binary loss 26.042400, binary loss t1 25.625360\n",
      "Epoch 4/10, Batch 191/1650, Loss 46.547230, Loss rec 7.134317, loss rec t1 7.241413, loss kl 0.565046, loss_trans 0.107732, loss flux 69.521034, loss flux t1 72.432816, binary loss 14.786664, binary loss t1 16.712059\n",
      "Epoch 4/10, Batch 201/1650, Loss 50.637051, Loss rec 4.379089, loss rec t1 4.530972, loss kl 0.362674, loss_trans 0.073438, loss flux 64.983513, loss flux t1 65.063713, binary loss 21.399374, binary loss t1 19.891506\n",
      "Epoch 4/10, Batch 211/1650, Loss 34.436092, Loss rec 4.197039, loss rec t1 4.550099, loss kl 0.220630, loss_trans 0.041931, loss flux 60.604958, loss flux t1 59.247269, binary loss 12.215240, binary loss t1 13.211151\n",
      "Epoch 4/10, Batch 221/1650, Loss 51.357841, Loss rec 6.491662, loss rec t1 6.475388, loss kl 0.352677, loss_trans 0.059714, loss flux 66.078384, loss flux t1 64.924614, binary loss 18.999294, binary loss t1 18.979107\n",
      "Epoch 4/10, Batch 231/1650, Loss 69.274506, Loss rec 5.609710, loss rec t1 6.430848, loss kl 0.488557, loss_trans 0.075933, loss flux 67.247070, loss flux t1 72.288643, binary loss 29.498047, binary loss t1 27.171412\n",
      "Epoch 4/10, Batch 241/1650, Loss 66.804512, Loss rec 7.312619, loss rec t1 7.733864, loss kl 0.326743, loss_trans 0.113832, loss flux 62.439236, loss flux t1 64.996628, binary loss 25.345810, binary loss t1 25.971645\n",
      "Epoch 4/10, Batch 251/1650, Loss 51.034920, Loss rec 8.039236, loss rec t1 7.699305, loss kl 0.486163, loss_trans 0.103625, loss flux 67.953194, loss flux t1 70.578102, binary loss 17.518873, binary loss t1 17.187717\n",
      "Epoch 4/10, Batch 261/1650, Loss 61.178886, Loss rec 5.540519, loss rec t1 8.170343, loss kl 0.281789, loss_trans 0.064148, loss flux 61.075863, loss flux t1 65.555420, binary loss 24.277367, binary loss t1 22.844717\n",
      "Epoch 4/10, Batch 271/1650, Loss 67.316719, Loss rec 10.229203, loss rec t1 12.324027, loss kl 0.430393, loss_trans 0.074542, loss flux 68.312798, loss flux t1 71.393448, binary loss 21.664169, binary loss t1 22.594385\n",
      "Epoch 4/10, Batch 281/1650, Loss 82.097313, Loss rec 8.108242, loss rec t1 11.470874, loss kl 0.372637, loss_trans 0.070719, loss flux 65.290558, loss flux t1 65.328003, binary loss 33.087280, binary loss t1 28.987560\n",
      "Epoch 4/10, Batch 291/1650, Loss 46.506744, Loss rec 7.326271, loss rec t1 8.227601, loss kl 0.439532, loss_trans 0.068726, loss flux 62.967209, loss flux t1 65.685852, binary loss 15.906155, binary loss t1 14.538464\n",
      "Epoch 4/10, Batch 301/1650, Loss 68.511185, Loss rec 8.550270, loss rec t1 9.116289, loss kl 0.279486, loss_trans 0.049744, loss flux 61.082127, loss flux t1 63.182198, binary loss 23.984642, binary loss t1 26.530750\n",
      "Epoch 4/10, Batch 311/1650, Loss 50.456749, Loss rec 9.652823, loss rec t1 12.150450, loss kl 0.342730, loss_trans 0.083387, loss flux 59.557861, loss flux t1 63.033241, binary loss 14.155522, binary loss t1 14.071835\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Batch 321/1650, Loss 78.892601, Loss rec 13.235330, loss rec t1 13.771130, loss kl 0.401730, loss_trans 0.087731, loss flux 64.298195, loss flux t1 68.065422, binary loss 26.417599, binary loss t1 24.979088\n",
      "Epoch 4/10, Batch 331/1650, Loss 78.402588, Loss rec 19.376881, loss rec t1 25.034286, loss kl 0.284063, loss_trans 0.066633, loss flux 61.334789, loss flux t1 61.522007, binary loss 15.607878, binary loss t1 18.032848\n",
      "Epoch 4/10, Batch 341/1650, Loss 153.179596, Loss rec 49.896126, loss rec t1 58.182610, loss kl 0.409663, loss_trans 0.102884, loss flux 64.647362, loss flux t1 63.603127, binary loss 22.424568, binary loss t1 22.163742\n",
      "Epoch 4/10, Batch 351/1650, Loss 108.720474, Loss rec 20.316669, loss rec t1 22.253038, loss kl 0.589013, loss_trans 0.103794, loss flux 73.055969, loss flux t1 76.162697, binary loss 34.212387, binary loss t1 31.245573\n",
      "Epoch 4/10, Batch 361/1650, Loss 65.505486, Loss rec 15.250511, loss rec t1 20.099062, loss kl 0.336019, loss_trans 0.073332, loss flux 60.659489, loss flux t1 62.526428, binary loss 14.538464, binary loss t1 15.208097\n",
      "Epoch 4/10, Batch 371/1650, Loss 108.707893, Loss rec 16.953360, loss rec t1 20.700111, loss kl 0.621966, loss_trans 0.124123, loss flux 72.361832, loss flux t1 76.192802, binary loss 36.517128, binary loss t1 33.791195\n",
      "Epoch 4/10, Batch 381/1650, Loss 63.672516, Loss rec 14.794910, loss rec t1 15.722044, loss kl 0.412105, loss_trans 0.065691, loss flux 66.442070, loss flux t1 69.228889, binary loss 16.247383, binary loss t1 16.430380\n",
      "Epoch 4/10, Batch 391/1650, Loss 74.589211, Loss rec 7.173426, loss rec t1 8.022246, loss kl 0.439894, loss_trans 0.082103, loss flux 65.041405, loss flux t1 64.011299, binary loss 30.918564, binary loss t1 27.952978\n",
      "Epoch 4/10, Batch 401/1650, Loss 59.258663, Loss rec 8.626482, loss rec t1 8.390391, loss kl 0.289321, loss_trans 0.062532, loss flux 61.244160, loss flux t1 61.641987, binary loss 20.336302, binary loss t1 21.553638\n",
      "Epoch 4/10, Batch 411/1650, Loss 50.971439, Loss rec 8.729602, loss rec t1 6.931304, loss kl 0.651992, loss_trans 0.129331, loss flux 69.206345, loss flux t1 74.729706, binary loss 17.852228, binary loss t1 16.676983\n",
      "Epoch 4/10, Batch 421/1650, Loss 49.349121, Loss rec 9.234202, loss rec t1 8.721253, loss kl 0.555029, loss_trans 0.110318, loss flux 66.936768, loss flux t1 68.926735, binary loss 15.619039, binary loss t1 15.109281\n",
      "Epoch 4/10, Batch 431/1650, Loss 89.294975, Loss rec 3.801266, loss rec t1 7.301704, loss kl 0.429443, loss_trans 0.070093, loss flux 62.209435, loss flux t1 62.788921, binary loss 40.930500, binary loss t1 36.761974\n",
      "Epoch 4/10, Batch 441/1650, Loss 69.531738, Loss rec 7.047362, loss rec t1 6.065039, loss kl 0.447982, loss_trans 0.097490, loss flux 64.652641, loss flux t1 64.471855, binary loss 31.658047, binary loss t1 24.215824\n",
      "Epoch 4/10, Batch 451/1650, Loss 42.837322, Loss rec 5.138220, loss rec t1 4.575926, loss kl 0.310864, loss_trans 0.071007, loss flux 60.904285, loss flux t1 60.581966, binary loss 17.234932, binary loss t1 15.506374\n",
      "Epoch 4/10, Batch 461/1650, Loss 59.527920, Loss rec 7.218729, loss rec t1 7.302562, loss kl 0.332865, loss_trans 0.069850, loss flux 62.398457, loss flux t1 63.677887, binary loss 21.905716, binary loss t1 22.698196\n",
      "Epoch 4/10, Batch 471/1650, Loss 52.138046, Loss rec 3.165273, loss rec t1 3.707545, loss kl 0.323456, loss_trans 0.065316, loss flux 57.827511, loss flux t1 59.510643, binary loss 23.234249, binary loss t1 21.642206\n",
      "Epoch 4/10, Batch 481/1650, Loss 43.896755, Loss rec 4.132666, loss rec t1 4.155848, loss kl 0.295047, loss_trans 0.052006, loss flux 59.275936, loss flux t1 60.703201, binary loss 17.375349, binary loss t1 17.885839\n",
      "Epoch 4/10, Batch 491/1650, Loss 134.107605, Loss rec 9.184359, loss rec t1 11.352638, loss kl 0.198265, loss_trans 0.047090, loss flux 59.422031, loss flux t1 60.832043, binary loss 61.068680, binary loss t1 52.256569\n",
      "Epoch 4/10, Batch 501/1650, Loss 60.670273, Loss rec 8.160255, loss rec t1 10.055207, loss kl 0.405869, loss_trans 0.070544, loss flux 65.775627, loss flux t1 67.394745, binary loss 20.533209, binary loss t1 21.445187\n",
      "Epoch 4/10, Batch 511/1650, Loss 58.584751, Loss rec 10.875898, loss rec t1 11.917950, loss kl 0.377933, loss_trans 0.056491, loss flux 65.380829, loss flux t1 62.482044, binary loss 17.950380, binary loss t1 17.406097\n",
      "Epoch 4/10, Batch 521/1650, Loss 48.169304, Loss rec 7.013041, loss rec t1 5.640549, loss kl 0.527244, loss_trans 0.101325, loss flux 64.239670, loss flux t1 67.641472, binary loss 19.026985, binary loss t1 15.860162\n",
      "Epoch 4/10, Batch 531/1650, Loss 42.168404, Loss rec 6.041958, loss rec t1 5.857445, loss kl 0.235051, loss_trans 0.057978, loss flux 55.682610, loss flux t1 60.276157, binary loss 15.552612, binary loss t1 14.423359\n",
      "Epoch 4/10, Batch 541/1650, Loss 46.294525, Loss rec 4.274345, loss rec t1 4.943661, loss kl 0.290840, loss_trans 0.074508, loss flux 57.486423, loss flux t1 61.564476, binary loss 17.733528, binary loss t1 18.977642\n",
      "Epoch 4/10, Batch 551/1650, Loss 58.564411, Loss rec 4.332988, loss rec t1 4.251140, loss kl 0.429297, loss_trans 0.094024, loss flux 60.832176, loss flux t1 69.246193, binary loss 25.291033, binary loss t1 24.165928\n",
      "Epoch 4/10, Batch 561/1650, Loss 60.706024, Loss rec 8.642857, loss rec t1 9.505440, loss kl 0.296760, loss_trans 0.062433, loss flux 63.097713, loss flux t1 64.630859, binary loss 21.433229, binary loss t1 20.765303\n",
      "Epoch 4/10, Batch 571/1650, Loss 54.322216, Loss rec 4.820429, loss rec t1 5.999448, loss kl 0.381078, loss_trans 0.062423, loss flux 64.300545, loss flux t1 62.950924, binary loss 23.588764, binary loss t1 19.470074\n",
      "Epoch 4/10, Batch 581/1650, Loss 59.145470, Loss rec 6.961101, loss rec t1 7.245440, loss kl 0.318752, loss_trans 0.069688, loss flux 63.724350, loss flux t1 63.924614, binary loss 21.700645, binary loss t1 22.849844\n",
      "Epoch 4/10, Batch 591/1650, Loss 62.566399, Loss rec 3.398692, loss rec t1 4.355310, loss kl 0.264758, loss_trans 0.048364, loss flux 57.996113, loss flux t1 59.816860, binary loss 27.768272, binary loss t1 26.731005\n",
      "Epoch 4/10, Batch 601/1650, Loss 52.652588, Loss rec 9.881047, loss rec t1 11.465233, loss kl 0.334163, loss_trans 0.082177, loss flux 61.609478, loss flux t1 62.706135, binary loss 15.717369, binary loss t1 15.172600\n",
      "Epoch 4/10, Batch 611/1650, Loss 48.674583, Loss rec 5.470739, loss rec t1 6.154869, loss kl 0.357495, loss_trans 0.073822, loss flux 62.723602, loss flux t1 62.816238, binary loss 18.675396, binary loss t1 17.942261\n",
      "Epoch 4/10, Batch 621/1650, Loss 49.034481, Loss rec 5.591016, loss rec t1 6.613635, loss kl 0.434429, loss_trans 0.068768, loss flux 65.110451, loss flux t1 66.863945, binary loss 17.609154, binary loss t1 18.717482\n",
      "Epoch 4/10, Batch 631/1650, Loss 70.088074, Loss rec 5.102171, loss rec t1 5.803608, loss kl 0.441100, loss_trans 0.081131, loss flux 63.949100, loss flux t1 63.724869, binary loss 29.452301, binary loss t1 29.207762\n",
      "Epoch 4/10, Batch 641/1650, Loss 42.362450, Loss rec 4.830732, loss rec t1 6.994837, loss kl 0.408958, loss_trans 0.083574, loss flux 64.952774, loss flux t1 65.927475, binary loss 14.223347, binary loss t1 15.821003\n",
      "Epoch 4/10, Batch 651/1650, Loss 48.439468, Loss rec 7.139752, loss rec t1 8.322605, loss kl 0.349486, loss_trans 0.079498, loss flux 61.736179, loss flux t1 62.663731, binary loss 15.933423, binary loss t1 16.614706\n",
      "Epoch 4/10, Batch 661/1650, Loss 70.784691, Loss rec 7.549070, loss rec t1 9.648792, loss kl 0.499911, loss_trans 0.091773, loss flux 65.024055, loss flux t1 65.497131, binary loss 28.204107, binary loss t1 24.791031\n",
      "Epoch 4/10, Batch 671/1650, Loss 54.022552, Loss rec 5.088104, loss rec t1 7.598324, loss kl 0.308628, loss_trans 0.081619, loss flux 63.059452, loss flux t1 64.703346, binary loss 19.453299, binary loss t1 21.492579\n",
      "Epoch 4/10, Batch 681/1650, Loss 41.406349, Loss rec 4.956161, loss rec t1 5.734936, loss kl 0.294148, loss_trans 0.066877, loss flux 59.559391, loss flux t1 63.537670, binary loss 14.648264, binary loss t1 15.705966\n",
      "Epoch 4/10, Batch 691/1650, Loss 101.693077, Loss rec 15.838701, loss rec t1 19.250797, loss kl 0.653668, loss_trans 0.111871, loss flux 74.758163, loss flux t1 78.590050, binary loss 34.303883, binary loss t1 31.534157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Batch 701/1650, Loss 83.422211, Loss rec 28.339867, loss rec t1 27.991554, loss kl 0.521849, loss_trans 0.095811, loss flux 66.703629, loss flux t1 68.201797, binary loss 13.717869, binary loss t1 12.755261\n",
      "Epoch 4/10, Batch 711/1650, Loss 134.063065, Loss rec 27.402035, loss rec t1 25.592064, loss kl 0.718697, loss_trans 0.142674, loss flux 77.925797, loss flux t1 80.895927, binary loss 44.420677, binary loss t1 35.786922\n",
      "Epoch 4/10, Batch 721/1650, Loss 51.873135, Loss rec 14.164160, loss rec t1 14.556756, loss kl 0.510835, loss_trans 0.091949, loss flux 69.823174, loss flux t1 71.774643, binary loss 10.698167, binary loss t1 11.851269\n",
      "Epoch 4/10, Batch 731/1650, Loss 127.397881, Loss rec 15.256952, loss rec t1 15.584557, loss kl 0.362090, loss_trans 0.072794, loss flux 65.072090, loss flux t1 67.007416, binary loss 48.248833, binary loss t1 47.872662\n",
      "Epoch 4/10, Batch 741/1650, Loss 78.736176, Loss rec 8.264409, loss rec t1 8.450557, loss kl 0.362053, loss_trans 0.085290, loss flux 64.099266, loss flux t1 66.539963, binary loss 30.718555, binary loss t1 30.855312\n",
      "Epoch 4/10, Batch 751/1650, Loss 58.285721, Loss rec 7.898257, loss rec t1 8.908520, loss kl 0.455949, loss_trans 0.094930, loss flux 62.161034, loss flux t1 62.679668, binary loss 22.147570, binary loss t1 18.780495\n",
      "Epoch 4/10, Batch 761/1650, Loss 75.491196, Loss rec 5.775897, loss rec t1 7.182983, loss kl 0.538547, loss_trans 0.121139, loss flux 63.296497, loss flux t1 65.056183, binary loss 33.283630, binary loss t1 28.589001\n",
      "Epoch 4/10, Batch 771/1650, Loss 40.839516, Loss rec 6.722791, loss rec t1 7.640019, loss kl 0.304861, loss_trans 0.085025, loss flux 56.215767, loss flux t1 59.431698, binary loss 13.021633, binary loss t1 13.065186\n",
      "Epoch 4/10, Batch 781/1650, Loss 48.955833, Loss rec 8.177509, loss rec t1 9.994291, loss kl 0.300904, loss_trans 0.069550, loss flux 59.726955, loss flux t1 62.080929, binary loss 15.130024, binary loss t1 15.283556\n",
      "Epoch 4/10, Batch 791/1650, Loss 108.611618, Loss rec 7.266647, loss rec t1 8.599227, loss kl 0.272776, loss_trans 0.082530, loss flux 61.303703, loss flux t1 62.541206, binary loss 45.819778, binary loss t1 46.570663\n",
      "Epoch 4/10, Batch 801/1650, Loss 92.548080, Loss rec 14.578375, loss rec t1 17.707150, loss kl 0.509359, loss_trans 0.101132, loss flux 65.919281, loss flux t1 68.434143, binary loss 31.287176, binary loss t1 28.364891\n",
      "Epoch 4/10, Batch 811/1650, Loss 67.897308, Loss rec 8.440929, loss rec t1 12.088507, loss kl 0.611362, loss_trans 0.124774, loss flux 71.884979, loss flux t1 74.780960, binary loss 25.745411, binary loss t1 20.886328\n",
      "Epoch 4/10, Batch 821/1650, Loss 44.891762, Loss rec 4.531734, loss rec t1 4.347154, loss kl 0.359609, loss_trans 0.074584, loss flux 57.741020, loss flux t1 61.171753, binary loss 16.662651, binary loss t1 18.916029\n",
      "Epoch 4/10, Batch 831/1650, Loss 49.041813, Loss rec 5.965107, loss rec t1 6.376722, loss kl 0.637064, loss_trans 0.092204, loss flux 64.140884, loss flux t1 63.894756, binary loss 20.012955, binary loss t1 15.957761\n",
      "Epoch 4/10, Batch 841/1650, Loss 72.872917, Loss rec 3.297305, loss rec t1 4.101487, loss kl 0.213344, loss_trans 0.045889, loss flux 55.239212, loss flux t1 56.781441, binary loss 32.286259, binary loss t1 32.928627\n",
      "Epoch 4/10, Batch 851/1650, Loss 54.598034, Loss rec 4.092494, loss rec t1 5.132957, loss kl 0.393914, loss_trans 0.087882, loss flux 60.691315, loss flux t1 64.680878, binary loss 22.257549, binary loss t1 22.633236\n",
      "Epoch 4/10, Batch 861/1650, Loss 42.125156, Loss rec 4.841326, loss rec t1 4.887959, loss kl 0.519818, loss_trans 0.094849, loss flux 64.457626, loss flux t1 66.119392, binary loss 16.286476, binary loss t1 15.494727\n",
      "Epoch 4/10, Batch 871/1650, Loss 49.828239, Loss rec 4.516193, loss rec t1 4.330346, loss kl 0.465581, loss_trans 0.077803, loss flux 65.921959, loss flux t1 67.403252, binary loss 20.474770, binary loss t1 19.963547\n",
      "Epoch 4/10, Batch 881/1650, Loss 49.072483, Loss rec 3.460107, loss rec t1 4.388851, loss kl 0.362059, loss_trans 0.080587, loss flux 61.409813, loss flux t1 63.971222, binary loss 20.201742, binary loss t1 20.579136\n",
      "Epoch 4/10, Batch 891/1650, Loss 44.242016, Loss rec 2.785061, loss rec t1 3.030123, loss kl 0.335133, loss_trans 0.069814, loss flux 62.471535, loss flux t1 66.051613, binary loss 19.232365, binary loss t1 18.789522\n",
      "Epoch 4/10, Batch 901/1650, Loss 44.124855, Loss rec 3.451735, loss rec t1 4.546159, loss kl 0.568614, loss_trans 0.117402, loss flux 67.312263, loss flux t1 70.792191, binary loss 17.921095, binary loss t1 17.519852\n",
      "Epoch 4/10, Batch 911/1650, Loss 41.867680, Loss rec 2.528108, loss rec t1 2.653183, loss kl 0.299966, loss_trans 0.055638, loss flux 56.893982, loss flux t1 59.302643, binary loss 18.608969, binary loss t1 17.721815\n",
      "Epoch 4/10, Batch 921/1650, Loss 56.203796, Loss rec 2.798132, loss rec t1 3.477803, loss kl 0.352304, loss_trans 0.075041, loss flux 62.199871, loss flux t1 63.919373, binary loss 25.646284, binary loss t1 23.854229\n",
      "Epoch 4/10, Batch 931/1650, Loss 36.151939, Loss rec 3.467575, loss rec t1 3.441913, loss kl 0.382432, loss_trans 0.057100, loss flux 60.780754, loss flux t1 62.683445, binary loss 15.153564, binary loss t1 13.649359\n",
      "Epoch 4/10, Batch 941/1650, Loss 43.860752, Loss rec 2.806736, loss rec t1 2.809037, loss kl 0.463994, loss_trans 0.079095, loss flux 62.219543, loss flux t1 65.246765, binary loss 19.114822, binary loss t1 18.587069\n",
      "Epoch 4/10, Batch 951/1650, Loss 44.043865, Loss rec 4.063542, loss rec t1 3.756822, loss kl 0.295665, loss_trans 0.054408, loss flux 62.558655, loss flux t1 65.505104, binary loss 17.475143, binary loss t1 18.398283\n",
      "Epoch 4/10, Batch 961/1650, Loss 53.319843, Loss rec 3.785641, loss rec t1 3.464338, loss kl 0.248626, loss_trans 0.041592, loss flux 58.737442, loss flux t1 58.856686, binary loss 22.835443, binary loss t1 22.944201\n",
      "Epoch 4/10, Batch 971/1650, Loss 46.865803, Loss rec 5.430972, loss rec t1 5.071563, loss kl 0.316173, loss_trans 0.070103, loss flux 63.087784, loss flux t1 64.924049, binary loss 18.562243, binary loss t1 17.414751\n",
      "Epoch 4/10, Batch 981/1650, Loss 46.472668, Loss rec 6.125588, loss rec t1 6.493517, loss kl 0.272680, loss_trans 0.057457, loss flux 59.728027, loss flux t1 59.963776, binary loss 17.051270, binary loss t1 16.472157\n",
      "Epoch 4/10, Batch 991/1650, Loss 138.768997, Loss rec 6.390086, loss rec t1 8.979090, loss kl 0.275756, loss_trans 0.073517, loss flux 62.020351, loss flux t1 65.125526, binary loss 63.883179, binary loss t1 59.167374\n",
      "Epoch 4/10, Batch 1001/1650, Loss 68.019081, Loss rec 9.356449, loss rec t1 10.615029, loss kl 0.462552, loss_trans 0.086721, loss flux 67.016823, loss flux t1 69.459419, binary loss 24.641409, binary loss t1 22.856920\n",
      "Epoch 4/10, Batch 1011/1650, Loss 55.509251, Loss rec 6.242889, loss rec t1 7.223901, loss kl 0.299698, loss_trans 0.086936, loss flux 60.170403, loss flux t1 64.455940, binary loss 20.262310, binary loss t1 21.393517\n",
      "Epoch 4/10, Batch 1021/1650, Loss 50.054642, Loss rec 4.987380, loss rec t1 5.441258, loss kl 0.307418, loss_trans 0.062529, loss flux 59.907879, loss flux t1 62.442520, binary loss 18.975933, binary loss t1 20.280125\n",
      "Epoch 4/10, Batch 1031/1650, Loss 60.065533, Loss rec 5.456877, loss rec t1 5.852839, loss kl 0.526163, loss_trans 0.077865, loss flux 64.285141, loss flux t1 65.215225, binary loss 24.827755, binary loss t1 23.324036\n",
      "Epoch 4/10, Batch 1041/1650, Loss 45.550629, Loss rec 6.135947, loss rec t1 6.743020, loss kl 0.348739, loss_trans 0.055877, loss flux 60.110996, loss flux t1 60.786625, binary loss 16.344360, binary loss t1 15.922685\n",
      "Epoch 4/10, Batch 1051/1650, Loss 39.283367, Loss rec 5.875509, loss rec t1 5.668905, loss kl 0.268591, loss_trans 0.053789, loss flux 59.401604, loss flux t1 60.618530, binary loss 13.332113, binary loss t1 14.084459\n",
      "Epoch 4/10, Batch 1061/1650, Loss 75.751709, Loss rec 6.526902, loss rec t1 7.082133, loss kl 0.515787, loss_trans 0.108283, loss flux 68.726738, loss flux t1 72.007881, binary loss 31.622725, binary loss t1 29.895880\n",
      "Epoch 4/10, Batch 1071/1650, Loss 33.497421, Loss rec 3.844731, loss rec t1 3.872032, loss kl 0.496896, loss_trans 0.092456, loss flux 62.348270, loss flux t1 66.896126, binary loss 11.744642, binary loss t1 13.446664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Batch 1081/1650, Loss 54.501091, Loss rec 6.442609, loss rec t1 5.966098, loss kl 0.410877, loss_trans 0.078686, loss flux 64.666000, loss flux t1 64.300369, binary loss 22.152451, binary loss t1 19.450371\n",
      "Epoch 4/10, Batch 1091/1650, Loss 46.823593, Loss rec 4.567738, loss rec t1 4.386285, loss kl 0.206368, loss_trans 0.056952, loss flux 56.310928, loss flux t1 57.881916, binary loss 19.336489, binary loss t1 18.269758\n",
      "Epoch 4/10, Batch 1101/1650, Loss 62.143085, Loss rec 6.252014, loss rec t1 5.707294, loss kl 0.256720, loss_trans 0.056654, loss flux 57.091393, loss flux t1 58.019775, binary loss 26.717405, binary loss t1 23.153000\n",
      "Epoch 4/10, Batch 1111/1650, Loss 57.527523, Loss rec 5.567172, loss rec t1 6.560406, loss kl 0.258410, loss_trans 0.057447, loss flux 54.547691, loss flux t1 56.468437, binary loss 24.818787, binary loss t1 20.265305\n",
      "Epoch 4/10, Batch 1121/1650, Loss 52.839508, Loss rec 5.014579, loss rec t1 5.473603, loss kl 0.458153, loss_trans 0.098153, loss flux 63.483910, loss flux t1 66.107880, binary loss 21.948290, binary loss t1 19.846733\n",
      "Epoch 4/10, Batch 1131/1650, Loss 40.843033, Loss rec 5.710766, loss rec t1 6.179871, loss kl 0.670261, loss_trans 0.108221, loss flux 67.992950, loss flux t1 70.602127, binary loss 14.507292, binary loss t1 13.666620\n",
      "Epoch 4/10, Batch 1141/1650, Loss 52.789471, Loss rec 4.797114, loss rec t1 6.821894, loss kl 0.418702, loss_trans 0.088190, loss flux 64.919861, loss flux t1 66.938530, binary loss 20.175938, binary loss t1 20.487637\n",
      "Epoch 4/10, Batch 1151/1650, Loss 50.790455, Loss rec 4.959197, loss rec t1 5.997157, loss kl 0.520495, loss_trans 0.071941, loss flux 68.982750, loss flux t1 71.583786, binary loss 19.674967, binary loss t1 19.566696\n",
      "Epoch 4/10, Batch 1161/1650, Loss 50.761478, Loss rec 8.926145, loss rec t1 8.591214, loss kl 0.362214, loss_trans 0.070141, loss flux 63.562206, loss flux t1 66.790024, binary loss 16.217674, binary loss t1 16.594093\n",
      "Epoch 4/10, Batch 1171/1650, Loss 99.209335, Loss rec 12.300998, loss rec t1 12.128151, loss kl 0.347219, loss_trans 0.053893, loss flux 63.332745, loss flux t1 65.143867, binary loss 37.799179, binary loss t1 36.579891\n",
      "Epoch 4/10, Batch 1181/1650, Loss 59.439457, Loss rec 9.029630, loss rec t1 8.307103, loss kl 0.604045, loss_trans 0.095803, loss flux 68.241264, loss flux t1 73.863129, binary loss 20.260670, binary loss t1 21.142208\n",
      "Epoch 4/10, Batch 1191/1650, Loss 62.027721, Loss rec 7.096383, loss rec t1 9.829519, loss kl 0.484683, loss_trans 0.082581, loss flux 66.768250, loss flux t1 69.239487, binary loss 22.278229, binary loss t1 22.256329\n",
      "Epoch 4/10, Batch 1201/1650, Loss 47.139462, Loss rec 7.095862, loss rec t1 5.048455, loss kl 0.310719, loss_trans 0.069995, loss flux 57.552822, loss flux t1 56.645283, binary loss 19.082008, binary loss t1 15.532422\n",
      "Epoch 4/10, Batch 1211/1650, Loss 67.664185, Loss rec 10.277612, loss rec t1 11.367104, loss kl 0.410277, loss_trans 0.073358, loss flux 64.444832, loss flux t1 65.610703, binary loss 24.118471, binary loss t1 21.417368\n",
      "Epoch 4/10, Batch 1221/1650, Loss 50.449974, Loss rec 4.510618, loss rec t1 4.945852, loss kl 0.359601, loss_trans 0.075670, loss flux 62.297272, loss flux t1 64.536674, binary loss 20.845818, binary loss t1 19.712418\n",
      "Epoch 4/10, Batch 1231/1650, Loss 51.953014, Loss rec 3.037037, loss rec t1 3.698728, loss kl 0.327632, loss_trans 0.066478, loss flux 56.910500, loss flux t1 59.623432, binary loss 22.921083, binary loss t1 21.902054\n",
      "Epoch 4/10, Batch 1241/1650, Loss 57.240063, Loss rec 3.757215, loss rec t1 3.166499, loss kl 0.355883, loss_trans 0.063830, loss flux 58.722813, loss flux t1 64.163651, binary loss 25.800793, binary loss t1 24.095839\n",
      "Epoch 4/10, Batch 1251/1650, Loss 43.111771, Loss rec 4.642725, loss rec t1 5.020279, loss kl 0.291183, loss_trans 0.058096, loss flux 58.170906, loss flux t1 58.182110, binary loss 16.150452, binary loss t1 16.949034\n",
      "Epoch 4/10, Batch 1261/1650, Loss 42.973427, Loss rec 6.077744, loss rec t1 5.205336, loss kl 0.294316, loss_trans 0.063531, loss flux 61.348793, loss flux t1 61.109909, binary loss 16.111778, binary loss t1 15.220722\n",
      "Epoch 4/10, Batch 1271/1650, Loss 45.247028, Loss rec 5.722098, loss rec t1 4.950999, loss kl 0.385456, loss_trans 0.075992, loss flux 64.276512, loss flux t1 65.094963, binary loss 16.468983, binary loss t1 17.643497\n",
      "Epoch 4/10, Batch 1281/1650, Loss 54.803761, Loss rec 4.646166, loss rec t1 4.275299, loss kl 0.338532, loss_trans 0.056357, loss flux 59.254234, loss flux t1 59.665531, binary loss 24.846479, binary loss t1 20.640926\n",
      "Epoch 4/10, Batch 1291/1650, Loss 31.175028, Loss rec 3.807704, loss rec t1 4.554320, loss kl 0.230588, loss_trans 0.049820, loss flux 54.755299, loss flux t1 56.885532, binary loss 11.777033, binary loss t1 10.755564\n",
      "Epoch 4/10, Batch 1301/1650, Loss 53.869171, Loss rec 5.406457, loss rec t1 5.394611, loss kl 0.324303, loss_trans 0.049729, loss flux 57.558838, loss flux t1 58.198498, binary loss 22.299395, binary loss t1 20.394676\n",
      "Epoch 4/10, Batch 1311/1650, Loss 56.137287, Loss rec 3.690947, loss rec t1 4.589487, loss kl 0.285002, loss_trans 0.064628, loss flux 58.872208, loss flux t1 62.445675, binary loss 23.787558, binary loss t1 23.719666\n",
      "Epoch 4/10, Batch 1321/1650, Loss 40.014664, Loss rec 5.004603, loss rec t1 5.794188, loss kl 0.503702, loss_trans 0.090467, loss flux 64.165634, loss flux t1 67.599884, binary loss 13.788803, binary loss t1 14.832902\n",
      "Epoch 4/10, Batch 1331/1650, Loss 49.674881, Loss rec 5.457506, loss rec t1 8.365521, loss kl 0.273531, loss_trans 0.067467, loss flux 61.820847, loss flux t1 63.195473, binary loss 17.288244, binary loss t1 18.222610\n",
      "Epoch 4/10, Batch 1341/1650, Loss 38.600880, Loss rec 2.944350, loss rec t1 3.071604, loss kl 0.346631, loss_trans 0.071400, loss flux 56.097404, loss flux t1 60.666416, binary loss 16.802824, binary loss t1 15.364071\n",
      "Epoch 4/10, Batch 1351/1650, Loss 43.944397, Loss rec 2.695596, loss rec t1 2.914982, loss kl 0.229377, loss_trans 0.052913, loss flux 57.988163, loss flux t1 61.018536, binary loss 18.671001, binary loss t1 19.380527\n",
      "Epoch 4/10, Batch 1361/1650, Loss 50.830292, Loss rec 5.207712, loss rec t1 7.594295, loss kl 0.581551, loss_trans 0.090022, loss flux 67.023682, loss flux t1 67.380608, binary loss 19.902245, binary loss t1 17.454468\n",
      "Epoch 4/10, Batch 1371/1650, Loss 47.287987, Loss rec 3.075675, loss rec t1 3.454084, loss kl 0.279322, loss_trans 0.064264, loss flux 55.245262, loss flux t1 59.345333, binary loss 20.639460, binary loss t1 19.775183\n",
      "Epoch 4/10, Batch 1381/1650, Loss 64.606148, Loss rec 6.053863, loss rec t1 6.707738, loss kl 0.444350, loss_trans 0.067743, loss flux 65.929626, loss flux t1 67.887383, binary loss 25.908573, binary loss t1 25.423885\n",
      "Epoch 4/10, Batch 1391/1650, Loss 34.422478, Loss rec 6.104208, loss rec t1 6.632829, loss kl 0.518496, loss_trans 0.105009, loss flux 61.323433, loss flux t1 65.533485, binary loss 10.197617, binary loss t1 10.864324\n",
      "Epoch 4/10, Batch 1401/1650, Loss 48.506237, Loss rec 3.548949, loss rec t1 3.513153, loss kl 0.305231, loss_trans 0.063835, loss flux 61.137238, loss flux t1 65.006798, binary loss 19.009968, binary loss t1 22.065102\n",
      "Epoch 4/10, Batch 1411/1650, Loss 40.649734, Loss rec 4.456320, loss rec t1 4.436147, loss kl 0.386156, loss_trans 0.068498, loss flux 62.255291, loss flux t1 63.762848, binary loss 15.163570, binary loss t1 16.139046\n",
      "Epoch 4/10, Batch 1421/1650, Loss 44.218300, Loss rec 3.856742, loss rec t1 4.094401, loss kl 0.316382, loss_trans 0.062104, loss flux 59.066597, loss flux t1 60.184612, binary loss 17.702845, binary loss t1 18.185827\n",
      "Epoch 4/10, Batch 1431/1650, Loss 35.225952, Loss rec 2.899291, loss rec t1 3.098835, loss kl 0.355697, loss_trans 0.068473, loss flux 61.246315, loss flux t1 62.422230, binary loss 14.466913, binary loss t1 14.336743\n",
      "Epoch 4/10, Batch 1441/1650, Loss 45.996655, Loss rec 3.491203, loss rec t1 4.697698, loss kl 0.505187, loss_trans 0.090245, loss flux 62.644619, loss flux t1 67.065338, binary loss 18.451532, binary loss t1 18.760792\n",
      "Epoch 4/10, Batch 1451/1650, Loss 65.141052, Loss rec 6.148564, loss rec t1 5.920088, loss kl 0.367296, loss_trans 0.078647, loss flux 60.755886, loss flux t1 62.488354, binary loss 28.949131, binary loss t1 23.677334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Batch 1461/1650, Loss 34.293056, Loss rec 3.363123, loss rec t1 3.954767, loss kl 0.284840, loss_trans 0.063616, loss flux 59.063751, loss flux t1 60.225395, binary loss 13.323326, binary loss t1 13.303381\n",
      "Epoch 4/10, Batch 1471/1650, Loss 46.245190, Loss rec 4.520212, loss rec t1 4.804273, loss kl 0.402007, loss_trans 0.066778, loss flux 64.177841, loss flux t1 65.444221, binary loss 18.491425, binary loss t1 17.960499\n",
      "Epoch 4/10, Batch 1481/1650, Loss 35.532688, Loss rec 6.407252, loss rec t1 6.712188, loss kl 0.337916, loss_trans 0.057726, loss flux 62.571705, loss flux t1 65.609131, binary loss 11.242270, binary loss t1 10.775331\n",
      "Epoch 4/10, Batch 1491/1650, Loss 39.369488, Loss rec 4.273080, loss rec t1 4.467911, loss kl 0.511348, loss_trans 0.079631, loss flux 66.305840, loss flux t1 67.472046, binary loss 15.416099, binary loss t1 14.621419\n",
      "Epoch 4/10, Batch 1501/1650, Loss 42.844498, Loss rec 5.693473, loss rec t1 5.764462, loss kl 0.516876, loss_trans 0.085856, loss flux 66.725754, loss flux t1 69.438675, binary loss 15.690102, binary loss t1 15.093728\n",
      "Epoch 4/10, Batch 1511/1650, Loss 51.270020, Loss rec 4.611718, loss rec t1 5.147378, loss kl 0.280652, loss_trans 0.077614, loss flux 59.264511, loss flux t1 60.050308, binary loss 20.622442, binary loss t1 20.530214\n",
      "Epoch 4/10, Batch 1521/1650, Loss 33.315472, Loss rec 2.538000, loss rec t1 3.091461, loss kl 0.327083, loss_trans 0.056306, loss flux 59.062065, loss flux t1 62.605927, binary loss 13.892922, binary loss t1 13.409700\n",
      "Epoch 4/10, Batch 1531/1650, Loss 57.674881, Loss rec 5.843342, loss rec t1 4.747030, loss kl 0.317822, loss_trans 0.063173, loss flux 61.127541, loss flux t1 62.887012, binary loss 23.363194, binary loss t1 23.340321\n",
      "Epoch 4/10, Batch 1541/1650, Loss 37.643757, Loss rec 3.310476, loss rec t1 3.715147, loss kl 0.437047, loss_trans 0.095134, loss flux 63.037827, loss flux t1 65.657112, binary loss 14.400730, binary loss t1 15.685221\n",
      "Epoch 4/10, Batch 1551/1650, Loss 32.104610, Loss rec 5.148689, loss rec t1 5.324513, loss kl 0.211170, loss_trans 0.051657, loss flux 58.498016, loss flux t1 59.962807, binary loss 10.254835, binary loss t1 11.113744\n",
      "Epoch 4/10, Batch 1561/1650, Loss 62.255527, Loss rec 5.812583, loss rec t1 6.659218, loss kl 0.547956, loss_trans 0.099782, loss flux 67.020882, loss flux t1 69.401672, binary loss 25.510015, binary loss t1 23.625975\n",
      "Epoch 4/10, Batch 1571/1650, Loss 49.994175, Loss rec 4.444489, loss rec t1 6.961321, loss kl 0.471472, loss_trans 0.068957, loss flux 61.350182, loss flux t1 65.144791, binary loss 20.379370, binary loss t1 17.668566\n",
      "Epoch 4/10, Batch 1581/1650, Loss 40.345459, Loss rec 3.400832, loss rec t1 4.689106, loss kl 0.225588, loss_trans 0.040974, loss flux 55.050007, loss flux t1 55.128170, binary loss 16.283548, binary loss t1 15.705410\n",
      "Epoch 4/10, Batch 1591/1650, Loss 39.265450, Loss rec 3.497175, loss rec t1 4.027940, loss kl 0.384471, loss_trans 0.061544, loss flux 60.640869, loss flux t1 62.556335, binary loss 15.400790, binary loss t1 15.893531\n",
      "Epoch 4/10, Batch 1601/1650, Loss 55.083553, Loss rec 3.766540, loss rec t1 3.623549, loss kl 0.144233, loss_trans 0.042498, loss flux 55.356892, loss flux t1 54.588982, binary loss 22.991413, binary loss t1 24.515322\n",
      "Epoch 4/10, Batch 1611/1650, Loss 48.258862, Loss rec 2.725675, loss rec t1 2.606588, loss kl 0.165999, loss_trans 0.041944, loss flux 55.116917, loss flux t1 56.075783, binary loss 21.592310, binary loss t1 21.126347\n",
      "Epoch 4/10, Batch 1621/1650, Loss 45.695068, Loss rec 2.293286, loss rec t1 2.448121, loss kl 0.365576, loss_trans 0.069986, loss flux 58.358429, loss flux t1 60.997231, binary loss 20.248466, binary loss t1 20.269632\n",
      "Epoch 4/10, Batch 1631/1650, Loss 41.173496, Loss rec 5.014776, loss rec t1 4.560721, loss kl 0.253846, loss_trans 0.070578, loss flux 58.925003, loss flux t1 60.645870, binary loss 15.193455, binary loss t1 16.080120\n",
      "Epoch 4/10, Batch 1641/1650, Loss 44.078117, Loss rec 4.273965, loss rec t1 4.366824, loss kl 0.397161, loss_trans 0.085791, loss flux 63.407986, loss flux t1 67.103821, binary loss 18.020157, binary loss t1 16.934216\n",
      "Epoch 4/10, Train loss 45.683903, Eval loss 47.076702\n",
      "Epoch 5/10, Batch 1/1650, Loss 42.483326, Loss rec 2.796766, loss rec t1 2.823470, loss kl 0.409396, loss_trans 0.087898, loss flux 60.902061, loss flux t1 65.104836, binary loss 18.270247, binary loss t1 18.095549\n",
      "Epoch 5/10, Batch 11/1650, Loss 34.649021, Loss rec 3.909720, loss rec t1 3.654482, loss kl 0.425283, loss_trans 0.069303, loss flux 63.327965, loss flux t1 68.763199, binary loss 12.642776, binary loss t1 13.947458\n",
      "Epoch 5/10, Batch 21/1650, Loss 50.114071, Loss rec 5.322164, loss rec t1 5.071222, loss kl 0.288733, loss_trans 0.062810, loss flux 58.637077, loss flux t1 60.253796, binary loss 19.763777, binary loss t1 19.605368\n",
      "Epoch 5/10, Batch 31/1650, Loss 46.317295, Loss rec 2.665060, loss rec t1 3.695093, loss kl 0.219638, loss_trans 0.045744, loss flux 59.566181, loss flux t1 61.308903, binary loss 18.671976, binary loss t1 21.019783\n",
      "Epoch 5/10, Batch 41/1650, Loss 40.572155, Loss rec 3.544658, loss rec t1 3.956388, loss kl 0.274325, loss_trans 0.058652, loss flux 58.443092, loss flux t1 59.912403, binary loss 16.171373, binary loss t1 16.566759\n",
      "Epoch 5/10, Batch 51/1650, Loss 30.639669, Loss rec 4.169839, loss rec t1 4.414204, loss kl 0.239891, loss_trans 0.047133, loss flux 58.340870, loss flux t1 60.525127, binary loss 10.851942, binary loss t1 10.916660\n",
      "Epoch 5/10, Batch 61/1650, Loss 79.303757, Loss rec 12.143490, loss rec t1 12.870061, loss kl 0.517551, loss_trans 0.088483, loss flux 65.418076, loss flux t1 68.273933, binary loss 27.217648, binary loss t1 26.466520\n",
      "Epoch 5/10, Batch 71/1650, Loss 43.818436, Loss rec 4.953656, loss rec t1 6.400623, loss kl 0.491958, loss_trans 0.069612, loss flux 66.940781, loss flux t1 67.353043, binary loss 15.817586, binary loss t1 16.085001\n",
      "Epoch 5/10, Batch 81/1650, Loss 52.447422, Loss rec 4.542884, loss rec t1 4.904300, loss kl 0.249330, loss_trans 0.052444, loss flux 57.654312, loss flux t1 59.984001, binary loss 21.239498, binary loss t1 21.458965\n",
      "Epoch 5/10, Batch 91/1650, Loss 46.891281, Loss rec 4.995755, loss rec t1 5.759647, loss kl 0.281884, loss_trans 0.057797, loss flux 57.191181, loss flux t1 59.615128, binary loss 18.275616, binary loss t1 17.520584\n",
      "Epoch 5/10, Batch 101/1650, Loss 43.725998, Loss rec 5.560235, loss rec t1 5.713067, loss kl 0.229178, loss_trans 0.055963, loss flux 58.356346, loss flux t1 60.082001, binary loss 15.618062, binary loss t1 16.549498\n",
      "Epoch 5/10, Batch 111/1650, Loss 49.050110, Loss rec 6.602898, loss rec t1 6.719010, loss kl 0.500089, loss_trans 0.072575, loss flux 68.872910, loss flux t1 70.809517, binary loss 18.012592, binary loss t1 17.142946\n",
      "Epoch 5/10, Batch 121/1650, Loss 40.214951, Loss rec 6.664988, loss rec t1 8.100807, loss kl 0.433560, loss_trans 0.094567, loss flux 63.413548, loss flux t1 65.725410, binary loss 12.683887, binary loss t1 12.237139\n",
      "Epoch 5/10, Batch 131/1650, Loss 44.930553, Loss rec 4.044937, loss rec t1 3.948274, loss kl 0.159937, loss_trans 0.030558, loss flux 57.192131, loss flux t1 58.409973, binary loss 16.660210, binary loss t1 20.086636\n",
      "Epoch 5/10, Batch 141/1650, Loss 38.225807, Loss rec 4.053002, loss rec t1 4.531600, loss kl 0.234269, loss_trans 0.040697, loss flux 54.923058, loss flux t1 56.362392, binary loss 14.378586, binary loss t1 14.987652\n",
      "Epoch 5/10, Batch 151/1650, Loss 45.883095, Loss rec 5.554768, loss rec t1 5.745496, loss kl 0.505850, loss_trans 0.079665, loss flux 65.445534, loss flux t1 69.118164, binary loss 16.589148, binary loss t1 17.408165\n",
      "Epoch 5/10, Batch 161/1650, Loss 56.037201, Loss rec 9.516527, loss rec t1 8.286567, loss kl 0.517673, loss_trans 0.072122, loss flux 65.839615, loss flux t1 68.344742, binary loss 18.827038, binary loss t1 18.817276\n",
      "Epoch 5/10, Batch 171/1650, Loss 51.143566, Loss rec 6.697351, loss rec t1 7.327790, loss kl 0.508655, loss_trans 0.067263, loss flux 65.816315, loss flux t1 68.032623, binary loss 18.812883, binary loss t1 17.729626\n",
      "Epoch 5/10, Batch 181/1650, Loss 35.729919, Loss rec 2.563434, loss rec t1 3.017797, loss kl 0.227473, loss_trans 0.041871, loss flux 53.237213, loss flux t1 55.984035, binary loss 14.152773, binary loss t1 15.726576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Batch 191/1650, Loss 43.240192, Loss rec 6.054438, loss rec t1 5.552772, loss kl 0.469819, loss_trans 0.083433, loss flux 63.639492, loss flux t1 66.462616, binary loss 15.143137, binary loss t1 15.936594\n",
      "Epoch 5/10, Batch 201/1650, Loss 61.937756, Loss rec 6.330791, loss rec t1 6.588166, loss kl 0.309939, loss_trans 0.055122, loss flux 60.691254, loss flux t1 60.695923, binary loss 25.866726, binary loss t1 22.787010\n",
      "Epoch 5/10, Batch 211/1650, Loss 29.096249, Loss rec 5.896647, loss rec t1 5.332516, loss kl 0.188604, loss_trans 0.030769, loss flux 56.124077, loss flux t1 55.418308, binary loss 8.439663, binary loss t1 9.208051\n",
      "Epoch 5/10, Batch 221/1650, Loss 49.394142, Loss rec 4.760707, loss rec t1 4.932433, loss kl 0.317441, loss_trans 0.051383, loss flux 61.121696, loss flux t1 60.973598, binary loss 19.763777, binary loss t1 19.568403\n",
      "Epoch 5/10, Batch 231/1650, Loss 54.009384, Loss rec 4.484460, loss rec t1 5.902503, loss kl 0.410852, loss_trans 0.064162, loss flux 61.695263, loss flux t1 66.002373, binary loss 21.972385, binary loss t1 21.175022\n",
      "Epoch 5/10, Batch 241/1650, Loss 59.353630, Loss rec 8.208713, loss rec t1 8.447824, loss kl 0.284350, loss_trans 0.092339, loss flux 59.185154, loss flux t1 60.547413, binary loss 20.981844, binary loss t1 21.338560\n",
      "Epoch 5/10, Batch 251/1650, Loss 49.398914, Loss rec 8.429300, loss rec t1 8.476209, loss kl 0.423767, loss_trans 0.082632, loss flux 62.617645, loss flux t1 65.065216, binary loss 15.882061, binary loss t1 16.104946\n",
      "Epoch 5/10, Batch 261/1650, Loss 82.530602, Loss rec 10.545200, loss rec t1 13.163026, loss kl 0.255663, loss_trans 0.054091, loss flux 57.571980, loss flux t1 60.889450, binary loss 30.051846, binary loss t1 28.460779\n",
      "Epoch 5/10, Batch 271/1650, Loss 66.320969, Loss rec 9.345324, loss rec t1 9.486002, loss kl 0.355007, loss_trans 0.058299, loss flux 63.242905, loss flux t1 65.576599, binary loss 23.441336, binary loss t1 23.635004\n",
      "Epoch 5/10, Batch 281/1650, Loss 47.692345, Loss rec 7.293984, loss rec t1 9.729361, loss kl 0.306585, loss_trans 0.055215, loss flux 59.929188, loss flux t1 59.999058, binary loss 15.607880, binary loss t1 14.699316\n",
      "Epoch 5/10, Batch 291/1650, Loss 38.987553, Loss rec 5.940093, loss rec t1 6.309408, loss kl 0.385913, loss_trans 0.060735, loss flux 59.554817, loss flux t1 62.019009, binary loss 14.271293, binary loss t1 12.020109\n",
      "Epoch 5/10, Batch 301/1650, Loss 54.327679, Loss rec 6.750782, loss rec t1 8.065618, loss kl 0.233260, loss_trans 0.039042, loss flux 56.405331, loss flux t1 57.751457, binary loss 19.187593, binary loss t1 20.051384\n",
      "Epoch 5/10, Batch 311/1650, Loss 53.420261, Loss rec 5.062519, loss rec t1 5.385358, loss kl 0.318310, loss_trans 0.068944, loss flux 55.916897, loss flux t1 59.570950, binary loss 21.890650, binary loss t1 20.694483\n",
      "Epoch 5/10, Batch 321/1650, Loss 51.574905, Loss rec 7.415262, loss rec t1 7.233493, loss kl 0.335039, loss_trans 0.068861, loss flux 59.764355, loss flux t1 62.127731, binary loss 19.776890, binary loss t1 16.745361\n",
      "Epoch 5/10, Batch 331/1650, Loss 47.939884, Loss rec 9.130228, loss rec t1 9.736328, loss kl 0.231535, loss_trans 0.049784, loss flux 56.647907, loss flux t1 56.832375, binary loss 14.365231, binary loss t1 14.426777\n",
      "Epoch 5/10, Batch 341/1650, Loss 83.577271, Loss rec 21.853153, loss rec t1 25.301935, loss kl 0.376930, loss_trans 0.083251, loss flux 62.143658, loss flux t1 61.357601, binary loss 17.648376, binary loss t1 18.313620\n",
      "Epoch 5/10, Batch 351/1650, Loss 84.614281, Loss rec 9.482529, loss rec t1 10.014229, loss kl 0.511830, loss_trans 0.078190, loss flux 64.915062, loss flux t1 67.549706, binary loss 32.951500, binary loss t1 31.576000\n",
      "Epoch 5/10, Batch 361/1650, Loss 34.845383, Loss rec 6.027037, loss rec t1 8.004854, loss kl 0.307802, loss_trans 0.062510, loss flux 57.640965, loss flux t1 59.398670, binary loss 9.688834, binary loss t1 10.754345\n",
      "Epoch 5/10, Batch 371/1650, Loss 68.946198, Loss rec 12.848047, loss rec t1 14.326548, loss kl 0.563546, loss_trans 0.098711, loss flux 66.050209, loss flux t1 70.334198, binary loss 20.578157, binary loss t1 20.531189\n",
      "Epoch 5/10, Batch 381/1650, Loss 41.176605, Loss rec 5.628824, loss rec t1 7.763401, loss kl 0.343558, loss_trans 0.052917, loss flux 58.911282, loss flux t1 61.789890, binary loss 13.605871, binary loss t1 13.782034\n",
      "Epoch 5/10, Batch 391/1650, Loss 69.651207, Loss rec 4.108899, loss rec t1 4.675961, loss kl 0.369632, loss_trans 0.060148, loss flux 60.382526, loss flux t1 60.754078, binary loss 32.332741, binary loss t1 28.103821\n",
      "Epoch 5/10, Batch 401/1650, Loss 33.134995, Loss rec 5.719644, loss rec t1 5.911935, loss kl 0.250453, loss_trans 0.050118, loss flux 55.627934, loss flux t1 56.196735, binary loss 10.867251, binary loss t1 10.335594\n",
      "Epoch 5/10, Batch 411/1650, Loss 49.465633, Loss rec 6.510338, loss rec t1 5.717143, loss kl 0.526218, loss_trans 0.094525, loss flux 63.666489, loss flux t1 68.501366, binary loss 18.918959, binary loss t1 17.698454\n",
      "Epoch 5/10, Batch 421/1650, Loss 45.357109, Loss rec 7.177831, loss rec t1 6.662444, loss kl 0.459263, loss_trans 0.085444, loss flux 61.668861, loss flux t1 63.978519, binary loss 15.862359, binary loss t1 15.109768\n",
      "Epoch 5/10, Batch 431/1650, Loss 49.143017, Loss rec 3.743798, loss rec t1 6.829866, loss kl 0.348572, loss_trans 0.055726, loss flux 56.036800, loss flux t1 56.600414, binary loss 19.927071, binary loss t1 18.237986\n",
      "Epoch 5/10, Batch 441/1650, Loss 54.201397, Loss rec 5.136341, loss rec t1 4.896105, loss kl 0.379735, loss_trans 0.078490, loss flux 59.573788, loss flux t1 59.853947, binary loss 24.413395, binary loss t1 19.297329\n",
      "Epoch 5/10, Batch 451/1650, Loss 55.027149, Loss rec 5.891853, loss rec t1 6.033661, loss kl 0.264902, loss_trans 0.055070, loss flux 56.808598, loss flux t1 56.961529, binary loss 21.169653, binary loss t1 21.612011\n",
      "Epoch 5/10, Batch 461/1650, Loss 37.846535, Loss rec 5.708497, loss rec t1 4.348103, loss kl 0.283827, loss_trans 0.054105, loss flux 58.359619, loss flux t1 59.231941, binary loss 13.407503, binary loss t1 14.044502\n",
      "Epoch 5/10, Batch 471/1650, Loss 41.246719, Loss rec 2.642836, loss rec t1 3.311455, loss kl 0.283024, loss_trans 0.053634, loss flux 53.723774, loss flux t1 56.187450, binary loss 18.185093, binary loss t1 16.770678\n",
      "Epoch 5/10, Batch 481/1650, Loss 39.162285, Loss rec 2.893980, loss rec t1 3.148637, loss kl 0.257319, loss_trans 0.042413, loss flux 54.738239, loss flux t1 56.578754, binary loss 16.263847, binary loss t1 16.556087\n",
      "Epoch 5/10, Batch 491/1650, Loss 59.748188, Loss rec 4.377012, loss rec t1 7.275678, loss kl 0.163791, loss_trans 0.036662, loss flux 55.199688, loss flux t1 56.301556, binary loss 24.933338, binary loss t1 22.961708\n",
      "Epoch 5/10, Batch 501/1650, Loss 50.918461, Loss rec 6.119158, loss rec t1 8.041937, loss kl 0.349394, loss_trans 0.056134, loss flux 60.816483, loss flux t1 62.876644, binary loss 18.319965, binary loss t1 18.031872\n",
      "Epoch 5/10, Batch 511/1650, Loss 53.120907, Loss rec 6.708050, loss rec t1 6.758130, loss kl 0.312829, loss_trans 0.044175, loss flux 60.408123, loss flux t1 58.794971, binary loss 19.957512, binary loss t1 19.340214\n",
      "Epoch 5/10, Batch 521/1650, Loss 57.150982, Loss rec 6.914099, loss rec t1 6.766555, loss kl 0.447727, loss_trans 0.081547, loss flux 58.869751, loss flux t1 63.030022, binary loss 23.208691, binary loss t1 19.732363\n",
      "Epoch 5/10, Batch 531/1650, Loss 37.338684, Loss rec 4.994860, loss rec t1 5.617627, loss kl 0.209342, loss_trans 0.049290, loss flux 52.143093, loss flux t1 56.933033, binary loss 13.032794, binary loss t1 13.434772\n",
      "Epoch 5/10, Batch 541/1650, Loss 34.636921, Loss rec 3.530671, loss rec t1 3.440807, loss kl 0.255915, loss_trans 0.061827, loss flux 53.411839, loss flux t1 57.072285, binary loss 13.240370, binary loss t1 14.107333\n",
      "Epoch 5/10, Batch 551/1650, Loss 88.636810, Loss rec 3.407204, loss rec t1 3.394739, loss kl 0.354728, loss_trans 0.076136, loss flux 55.679291, loss flux t1 64.103592, binary loss 43.954464, binary loss t1 37.449539\n",
      "Epoch 5/10, Batch 561/1650, Loss 47.847069, Loss rec 7.365475, loss rec t1 8.675145, loss kl 0.258087, loss_trans 0.047616, loss flux 58.115917, loss flux t1 59.496769, binary loss 15.864621, binary loss t1 15.636122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Batch 571/1650, Loss 41.785866, Loss rec 5.587184, loss rec t1 5.632659, loss kl 0.340570, loss_trans 0.053618, loss flux 61.063553, loss flux t1 59.794254, binary loss 16.346802, binary loss t1 13.825033\n",
      "Epoch 5/10, Batch 581/1650, Loss 60.576962, Loss rec 8.052964, loss rec t1 7.845132, loss kl 0.273880, loss_trans 0.056464, loss flux 58.779705, loss flux t1 58.528111, binary loss 22.208939, binary loss t1 22.139584\n",
      "Epoch 5/10, Batch 591/1650, Loss 65.487030, Loss rec 4.327734, loss rec t1 5.170835, loss kl 0.219070, loss_trans 0.037650, loss flux 54.153297, loss flux t1 55.763992, binary loss 27.134445, binary loss t1 28.597294\n",
      "Epoch 5/10, Batch 601/1650, Loss 46.896767, Loss rec 8.416386, loss rec t1 10.328205, loss kl 0.298945, loss_trans 0.067077, loss flux 58.095348, loss flux t1 59.490471, binary loss 14.320702, binary loss t1 13.465452\n",
      "Epoch 5/10, Batch 611/1650, Loss 50.646500, Loss rec 6.835118, loss rec t1 6.382069, loss kl 0.316338, loss_trans 0.056381, loss flux 58.921158, loss flux t1 59.538017, binary loss 19.249870, binary loss t1 17.806725\n",
      "Epoch 5/10, Batch 621/1650, Loss 49.564983, Loss rec 6.991980, loss rec t1 7.398162, loss kl 0.372192, loss_trans 0.056897, loss flux 60.859745, loss flux t1 62.375950, binary loss 17.095734, binary loss t1 17.650021\n",
      "Epoch 5/10, Batch 631/1650, Loss 52.251537, Loss rec 4.117218, loss rec t1 4.977509, loss kl 0.387717, loss_trans 0.069651, loss flux 59.300175, loss flux t1 59.236668, binary loss 22.258282, binary loss t1 20.441158\n",
      "Epoch 5/10, Batch 641/1650, Loss 50.804192, Loss rec 5.061771, loss rec t1 6.647628, loss kl 0.347829, loss_trans 0.065933, loss flux 60.010784, loss flux t1 61.050480, binary loss 19.206562, binary loss t1 19.474466\n",
      "Epoch 5/10, Batch 651/1650, Loss 46.957199, Loss rec 4.501898, loss rec t1 4.837501, loss kl 0.312653, loss_trans 0.068733, loss flux 57.659370, loss flux t1 59.716221, binary loss 17.742981, binary loss t1 19.493435\n",
      "Epoch 5/10, Batch 661/1650, Loss 54.075943, Loss rec 4.893450, loss rec t1 5.731838, loss kl 0.430676, loss_trans 0.073006, loss flux 59.063808, loss flux t1 59.850788, binary loss 23.044727, binary loss t1 19.902245\n",
      "Epoch 5/10, Batch 671/1650, Loss 55.146595, Loss rec 4.324352, loss rec t1 5.412374, loss kl 0.269164, loss_trans 0.066683, loss flux 58.024986, loss flux t1 60.382629, binary loss 21.773350, binary loss t1 23.300671\n",
      "Epoch 5/10, Batch 681/1650, Loss 33.020931, Loss rec 4.091470, loss rec t1 4.482342, loss kl 0.267634, loss_trans 0.057887, loss flux 55.726978, loss flux t1 59.640419, binary loss 12.261056, binary loss t1 11.860544\n",
      "Epoch 5/10, Batch 691/1650, Loss 73.055649, Loss rec 8.904282, loss rec t1 10.459702, loss kl 0.540087, loss_trans 0.086906, loss flux 66.831871, loss flux t1 70.029816, binary loss 27.042458, binary loss t1 26.022215\n",
      "Epoch 5/10, Batch 701/1650, Loss 50.043720, Loss rec 11.086720, loss rec t1 11.601138, loss kl 0.470578, loss_trans 0.072587, loss flux 62.989414, loss flux t1 63.648537, binary loss 14.404457, binary loss t1 12.408241\n",
      "Epoch 5/10, Batch 711/1650, Loss 73.238098, Loss rec 11.045347, loss rec t1 12.362845, loss kl 0.675572, loss_trans 0.113932, loss flux 73.060371, loss flux t1 76.733925, binary loss 25.671352, binary loss t1 23.369055\n",
      "Epoch 5/10, Batch 721/1650, Loss 38.786083, Loss rec 8.269865, loss rec t1 9.368893, loss kl 0.413871, loss_trans 0.067080, loss flux 62.653561, loss flux t1 65.085266, binary loss 10.165290, binary loss t1 10.501083\n",
      "Epoch 5/10, Batch 731/1650, Loss 62.857681, Loss rec 7.055403, loss rec t1 7.875710, loss kl 0.302708, loss_trans 0.056798, loss flux 58.981651, loss flux t1 60.641731, binary loss 23.317936, binary loss t1 24.249126\n",
      "Epoch 5/10, Batch 741/1650, Loss 77.227798, Loss rec 5.860187, loss rec t1 5.365270, loss kl 0.299215, loss_trans 0.061936, loss flux 58.663467, loss flux t1 60.537556, binary loss 32.952961, binary loss t1 32.688232\n",
      "Epoch 5/10, Batch 751/1650, Loss 52.209625, Loss rec 6.234537, loss rec t1 7.710146, loss kl 0.368498, loss_trans 0.070974, loss flux 57.290737, loss flux t1 58.099064, binary loss 19.378088, binary loss t1 18.447384\n",
      "Epoch 5/10, Batch 761/1650, Loss 44.653465, Loss rec 5.874638, loss rec t1 8.348162, loss kl 0.441144, loss_trans 0.093399, loss flux 57.811531, loss flux t1 60.748192, binary loss 15.612693, binary loss t1 14.283429\n",
      "Epoch 5/10, Batch 771/1650, Loss 29.840685, Loss rec 5.098778, loss rec t1 6.375892, loss kl 0.261560, loss_trans 0.067393, loss flux 52.049995, loss flux t1 54.948410, binary loss 9.218056, binary loss t1 8.819009\n",
      "Epoch 5/10, Batch 781/1650, Loss 39.315918, Loss rec 2.939503, loss rec t1 3.308906, loss kl 0.255426, loss_trans 0.052545, loss flux 55.136387, loss flux t1 57.147114, binary loss 16.590855, binary loss t1 16.168688\n",
      "Epoch 5/10, Batch 791/1650, Loss 80.974808, Loss rec 4.460931, loss rec t1 4.721575, loss kl 0.238827, loss_trans 0.066981, loss flux 56.875610, loss flux t1 57.893799, binary loss 35.720741, binary loss t1 35.765755\n",
      "Epoch 5/10, Batch 801/1650, Loss 42.396992, Loss rec 3.834866, loss rec t1 4.373920, loss kl 0.405228, loss_trans 0.073757, loss flux 60.912159, loss flux t1 63.453083, binary loss 16.366993, binary loss t1 17.342226\n",
      "Epoch 5/10, Batch 811/1650, Loss 66.573204, Loss rec 7.382387, loss rec t1 7.573499, loss kl 0.508001, loss_trans 0.095089, loss flux 65.863838, loss flux t1 68.633881, binary loss 28.882946, binary loss t1 22.131289\n",
      "Epoch 5/10, Batch 821/1650, Loss 38.605572, Loss rec 4.341903, loss rec t1 4.959250, loss kl 0.305536, loss_trans 0.055058, loss flux 54.352039, loss flux t1 57.420765, binary loss 13.631365, binary loss t1 15.312464\n",
      "Epoch 5/10, Batch 831/1650, Loss 43.061409, Loss rec 4.604169, loss rec t1 5.251338, loss kl 0.545474, loss_trans 0.071919, loss flux 59.739666, loss flux t1 59.953228, binary loss 18.384617, binary loss t1 14.203891\n",
      "Epoch 5/10, Batch 841/1650, Loss 28.946968, Loss rec 5.967129, loss rec t1 5.891118, loss kl 0.193399, loss_trans 0.035942, loss flux 50.947910, loss flux t1 52.775188, binary loss 8.534089, binary loss t1 8.325290\n",
      "Epoch 5/10, Batch 851/1650, Loss 61.745705, Loss rec 4.634263, loss rec t1 6.283498, loss kl 0.345506, loss_trans 0.071835, loss flux 57.536762, loss flux t1 60.329723, binary loss 24.616337, binary loss t1 25.794266\n",
      "Epoch 5/10, Batch 861/1650, Loss 75.084518, Loss rec 4.744109, loss rec t1 6.568321, loss kl 0.448370, loss_trans 0.077048, loss flux 60.067165, loss flux t1 63.137817, binary loss 33.239349, binary loss t1 30.007322\n",
      "Epoch 5/10, Batch 871/1650, Loss 37.922318, Loss rec 4.440952, loss rec t1 4.127390, loss kl 0.402708, loss_trans 0.062459, loss flux 61.396614, loss flux t1 62.206245, binary loss 14.401217, binary loss t1 14.487590\n",
      "Epoch 5/10, Batch 881/1650, Loss 45.265171, Loss rec 4.419853, loss rec t1 5.198089, loss kl 0.321342, loss_trans 0.066651, loss flux 57.021557, loss flux t1 59.255329, binary loss 16.775558, binary loss t1 18.483679\n",
      "Epoch 5/10, Batch 891/1650, Loss 41.740955, Loss rec 3.008111, loss rec t1 2.834136, loss kl 0.283952, loss_trans 0.054559, loss flux 57.764805, loss flux t1 61.119198, binary loss 17.747618, binary loss t1 17.812580\n",
      "Epoch 5/10, Batch 901/1650, Loss 39.361408, Loss rec 3.593557, loss rec t1 4.485146, loss kl 0.500179, loss_trans 0.098005, loss flux 62.464520, loss flux t1 66.324661, binary loss 15.002474, binary loss t1 15.682049\n",
      "Epoch 5/10, Batch 911/1650, Loss 34.595879, Loss rec 2.364578, loss rec t1 2.157030, loss kl 0.258969, loss_trans 0.046175, loss flux 52.612972, loss flux t1 55.005901, binary loss 15.395420, binary loss t1 14.373707\n",
      "Epoch 5/10, Batch 921/1650, Loss 41.550205, Loss rec 2.490814, loss rec t1 3.014052, loss kl 0.309851, loss_trans 0.060184, loss flux 57.599422, loss flux t1 59.281796, binary loss 18.633551, binary loss t1 17.041752\n",
      "Epoch 5/10, Batch 931/1650, Loss 28.004910, Loss rec 4.322148, loss rec t1 3.481443, loss kl 0.331255, loss_trans 0.044914, loss flux 56.618084, loss flux t1 58.312176, binary loss 10.731958, binary loss t1 9.093190\n",
      "Epoch 5/10, Batch 941/1650, Loss 36.230942, Loss rec 3.849936, loss rec t1 3.897036, loss kl 0.402585, loss_trans 0.062224, loss flux 57.328629, loss flux t1 60.648006, binary loss 13.931351, binary loss t1 14.087811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Batch 951/1650, Loss 40.341766, Loss rec 3.525168, loss rec t1 3.730247, loss kl 0.242863, loss_trans 0.044655, loss flux 57.928993, loss flux t1 60.531990, binary loss 15.813746, binary loss t1 16.985088\n",
      "Epoch 5/10, Batch 961/1650, Loss 56.717091, Loss rec 4.517660, loss rec t1 4.246545, loss kl 0.217761, loss_trans 0.033740, loss flux 55.384674, loss flux t1 55.658230, binary loss 24.183189, binary loss t1 23.518190\n",
      "Epoch 5/10, Batch 971/1650, Loss 39.070267, Loss rec 4.197956, loss rec t1 3.885834, loss kl 0.263387, loss_trans 0.055831, loss flux 57.649746, loss flux t1 60.001308, binary loss 15.377426, binary loss t1 15.289832\n",
      "Epoch 5/10, Batch 981/1650, Loss 34.018894, Loss rec 4.926418, loss rec t1 5.307961, loss kl 0.237002, loss_trans 0.046206, loss flux 54.698837, loss flux t1 55.768223, binary loss 11.919647, binary loss t1 11.581658\n",
      "Epoch 5/10, Batch 991/1650, Loss 125.902206, Loss rec 6.780858, loss rec t1 9.309496, loss kl 0.236267, loss_trans 0.059042, loss flux 57.538879, loss flux t1 60.203384, binary loss 57.370930, binary loss t1 52.145615\n",
      "Epoch 5/10, Batch 1001/1650, Loss 53.902145, Loss rec 6.337748, loss rec t1 7.860422, loss kl 0.412292, loss_trans 0.071124, loss flux 62.090355, loss flux t1 64.304977, binary loss 20.413954, binary loss t1 18.806606\n",
      "Epoch 5/10, Batch 1011/1650, Loss 59.149353, Loss rec 4.499074, loss rec t1 5.328329, loss kl 0.250262, loss_trans 0.066604, loss flux 56.137283, loss flux t1 59.905003, binary loss 24.159824, binary loss t1 24.845259\n",
      "Epoch 5/10, Batch 1021/1650, Loss 36.823315, Loss rec 3.085604, loss rec t1 3.524222, loss kl 0.274109, loss_trans 0.051244, loss flux 55.980785, loss flux t1 58.251968, binary loss 14.291726, binary loss t1 15.596409\n",
      "Epoch 5/10, Batch 1031/1650, Loss 54.128334, Loss rec 4.660451, loss rec t1 4.810087, loss kl 0.456461, loss_trans 0.060454, loss flux 59.817707, loss flux t1 60.449955, binary loss 22.213509, binary loss t1 21.927372\n",
      "Epoch 5/10, Batch 1041/1650, Loss 49.665142, Loss rec 7.139612, loss rec t1 7.674392, loss kl 0.306630, loss_trans 0.043540, loss flux 56.884758, loss flux t1 57.011147, binary loss 17.803795, binary loss t1 16.697174\n",
      "Epoch 5/10, Batch 1051/1650, Loss 28.464802, Loss rec 4.922876, loss rec t1 5.301941, loss kl 0.231052, loss_trans 0.042197, loss flux 55.685150, loss flux t1 56.713268, binary loss 8.748434, binary loss t1 9.218301\n",
      "Epoch 5/10, Batch 1061/1650, Loss 62.934742, Loss rec 5.260234, loss rec t1 5.575466, loss kl 0.449829, loss_trans 0.089964, loss flux 64.135880, loss flux t1 66.270798, binary loss 26.864349, binary loss t1 24.694901\n",
      "Epoch 5/10, Batch 1071/1650, Loss 33.231262, Loss rec 4.346153, loss rec t1 3.481666, loss kl 0.425242, loss_trans 0.076700, loss flux 57.351677, loss flux t1 61.330849, binary loss 11.653387, binary loss t1 13.248115\n",
      "Epoch 5/10, Batch 1081/1650, Loss 45.498734, Loss rec 7.848416, loss rec t1 5.822050, loss kl 0.355121, loss_trans 0.062324, loss flux 59.880207, loss flux t1 59.758652, binary loss 16.303249, binary loss t1 15.107571\n",
      "Epoch 5/10, Batch 1091/1650, Loss 33.168896, Loss rec 3.501916, loss rec t1 3.863569, loss kl 0.172418, loss_trans 0.045034, loss flux 52.389297, loss flux t1 54.382870, binary loss 12.453192, binary loss t1 13.132767\n",
      "Epoch 5/10, Batch 1101/1650, Loss 40.527565, Loss rec 3.573802, loss rec t1 3.938274, loss kl 0.232763, loss_trans 0.047456, loss flux 53.430378, loss flux t1 54.510597, binary loss 17.792635, binary loss t1 14.942636\n",
      "Epoch 5/10, Batch 1111/1650, Loss 77.727676, Loss rec 3.318046, loss rec t1 3.325034, loss kl 0.227966, loss_trans 0.048245, loss flux 51.241676, loss flux t1 53.541084, binary loss 37.896286, binary loss t1 32.912098\n",
      "Epoch 5/10, Batch 1121/1650, Loss 43.215195, Loss rec 6.718343, loss rec t1 7.749228, loss kl 0.382603, loss_trans 0.079353, loss flux 58.166885, loss flux t1 60.611580, binary loss 14.052555, binary loss t1 14.233111\n",
      "Epoch 5/10, Batch 1131/1650, Loss 39.858612, Loss rec 6.046412, loss rec t1 6.046804, loss kl 0.573619, loss_trans 0.081419, loss flux 63.404957, loss flux t1 64.906288, binary loss 14.307281, binary loss t1 12.803076\n",
      "Epoch 5/10, Batch 1141/1650, Loss 56.022709, Loss rec 5.903071, loss rec t1 7.024941, loss kl 0.347954, loss_trans 0.069444, loss flux 60.097092, loss flux t1 61.962448, binary loss 20.884491, binary loss t1 21.792809\n",
      "Epoch 5/10, Batch 1151/1650, Loss 47.505970, Loss rec 4.944051, loss rec t1 5.977332, loss kl 0.455360, loss_trans 0.057983, loss flux 65.204475, loss flux t1 67.653793, binary loss 18.309227, binary loss t1 17.762016\n",
      "Epoch 5/10, Batch 1161/1650, Loss 40.361923, Loss rec 7.301395, loss rec t1 7.272551, loss kl 0.310554, loss_trans 0.058843, loss flux 58.819317, loss flux t1 61.577190, binary loss 12.542736, binary loss t1 12.875847\n",
      "Epoch 5/10, Batch 1171/1650, Loss 52.209568, Loss rec 4.538028, loss rec t1 4.808425, loss kl 0.284345, loss_trans 0.043291, loss flux 57.917152, loss flux t1 59.562988, binary loss 21.777985, binary loss t1 20.757492\n",
      "Epoch 5/10, Batch 1181/1650, Loss 52.490917, Loss rec 7.303500, loss rec t1 6.529241, loss kl 0.539400, loss_trans 0.081516, loss flux 62.993923, loss flux t1 67.974991, binary loss 17.912132, binary loss t1 20.125132\n",
      "Epoch 5/10, Batch 1191/1650, Loss 44.744320, Loss rec 4.395913, loss rec t1 5.351276, loss kl 0.406623, loss_trans 0.063248, loss flux 61.936794, loss flux t1 64.211929, binary loss 17.407677, binary loss t1 17.119583\n",
      "Epoch 5/10, Batch 1201/1650, Loss 36.579651, Loss rec 3.615514, loss rec t1 4.027197, loss kl 0.261105, loss_trans 0.057129, loss flux 54.511909, loss flux t1 54.209244, binary loss 15.152100, binary loss t1 13.466608\n",
      "Epoch 5/10, Batch 1211/1650, Loss 62.729111, Loss rec 7.064166, loss rec t1 8.005564, loss kl 0.380069, loss_trans 0.063350, loss flux 60.493095, loss flux t1 61.408928, binary loss 27.416439, binary loss t1 19.799522\n",
      "Epoch 5/10, Batch 1221/1650, Loss 80.436737, Loss rec 5.550381, loss rec t1 8.491935, loss kl 0.322106, loss_trans 0.064459, loss flux 56.841049, loss flux t1 59.856831, binary loss 34.941856, binary loss t1 31.065996\n",
      "Epoch 5/10, Batch 1231/1650, Loss 31.980562, Loss rec 3.644483, loss rec t1 4.791691, loss kl 0.280354, loss_trans 0.055770, loss flux 53.466682, loss flux t1 55.883049, binary loss 11.169921, binary loss t1 12.038346\n",
      "Epoch 5/10, Batch 1241/1650, Loss 34.689541, Loss rec 3.516587, loss rec t1 3.897227, loss kl 0.309271, loss_trans 0.052451, loss flux 55.035938, loss flux t1 59.524345, binary loss 13.687542, binary loss t1 13.226460\n",
      "Epoch 5/10, Batch 1251/1650, Loss 44.425262, Loss rec 4.826956, loss rec t1 6.215885, loss kl 0.270436, loss_trans 0.048486, loss flux 55.139259, loss flux t1 55.619102, binary loss 16.175522, binary loss t1 16.887978\n",
      "Epoch 5/10, Batch 1261/1650, Loss 40.394241, Loss rec 4.080069, loss rec t1 3.525540, loss kl 0.280698, loss_trans 0.054961, loss flux 57.629868, loss flux t1 57.545727, binary loss 16.571154, binary loss t1 15.881817\n",
      "Epoch 5/10, Batch 1271/1650, Loss 42.143768, Loss rec 4.909622, loss rec t1 4.803637, loss kl 0.332095, loss_trans 0.063707, loss flux 59.574173, loss flux t1 60.835918, binary loss 15.065484, binary loss t1 16.969225\n",
      "Epoch 5/10, Batch 1281/1650, Loss 38.277748, Loss rec 2.685549, loss rec t1 2.753183, loss kl 0.309366, loss_trans 0.050143, loss flux 54.481434, loss flux t1 55.303352, binary loss 18.850092, binary loss t1 13.629414\n",
      "Epoch 5/10, Batch 1291/1650, Loss 40.282402, Loss rec 1.752698, loss rec t1 2.492019, loss kl 0.203093, loss_trans 0.042307, loss flux 50.923256, loss flux t1 53.084377, binary loss 17.541992, binary loss t1 18.250298\n",
      "Epoch 5/10, Batch 1301/1650, Loss 33.494110, Loss rec 2.819973, loss rec t1 3.135303, loss kl 0.288931, loss_trans 0.040973, loss flux 53.261196, loss flux t1 53.891422, binary loss 14.113369, binary loss t1 13.095561\n",
      "Epoch 5/10, Batch 1311/1650, Loss 44.567715, Loss rec 3.580201, loss rec t1 3.981261, loss kl 0.255786, loss_trans 0.053515, loss flux 54.725109, loss flux t1 58.562042, binary loss 18.603598, binary loss t1 18.093351\n",
      "Epoch 5/10, Batch 1321/1650, Loss 35.167473, Loss rec 3.656207, loss rec t1 4.610740, loss kl 0.447344, loss_trans 0.077113, loss flux 59.718292, loss flux t1 63.591290, binary loss 13.120631, binary loss t1 13.255436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Batch 1331/1650, Loss 45.966064, Loss rec 5.829072, loss rec t1 6.578970, loss kl 0.247821, loss_trans 0.057365, loss flux 58.066525, loss flux t1 59.662693, binary loss 16.715963, binary loss t1 16.536873\n",
      "Epoch 5/10, Batch 1341/1650, Loss 28.516762, Loss rec 2.066008, loss rec t1 2.290504, loss kl 0.304889, loss_trans 0.058041, loss flux 50.948601, loss flux t1 56.027214, binary loss 11.942945, binary loss t1 11.854377\n",
      "Epoch 5/10, Batch 1351/1650, Loss 23.481518, Loss rec 1.816649, loss rec t1 2.028126, loss kl 0.196788, loss_trans 0.043320, loss flux 53.903618, loss flux t1 56.840488, binary loss 9.045978, binary loss t1 10.350658\n",
      "Epoch 5/10, Batch 1361/1650, Loss 42.858204, Loss rec 4.680690, loss rec t1 6.475605, loss kl 0.504557, loss_trans 0.073090, loss flux 62.172657, loss flux t1 61.979198, binary loss 17.242496, binary loss t1 13.881763\n",
      "Epoch 5/10, Batch 1371/1650, Loss 35.289074, Loss rec 2.287967, loss rec t1 2.289416, loss kl 0.248763, loss_trans 0.057045, loss flux 51.706200, loss flux t1 56.114922, binary loss 14.793433, binary loss t1 15.612449\n",
      "Epoch 5/10, Batch 1381/1650, Loss 43.091019, Loss rec 4.027093, loss rec t1 3.808810, loss kl 0.385352, loss_trans 0.053926, loss flux 60.318268, loss flux t1 62.368874, binary loss 17.939089, binary loss t1 16.876753\n",
      "Epoch 5/10, Batch 1391/1650, Loss 29.560745, Loss rec 4.000652, loss rec t1 4.352128, loss kl 0.460173, loss_trans 0.086852, loss flux 57.217354, loss flux t1 61.766792, binary loss 10.264287, binary loss t1 10.396652\n",
      "Epoch 5/10, Batch 1401/1650, Loss 35.397903, Loss rec 2.869345, loss rec t1 3.126339, loss kl 0.272830, loss_trans 0.056123, loss flux 57.902771, loss flux t1 61.506035, binary loss 12.455388, binary loss t1 16.617878\n",
      "Epoch 5/10, Batch 1411/1650, Loss 33.215977, Loss rec 4.142344, loss rec t1 4.131598, loss kl 0.340261, loss_trans 0.055945, loss flux 57.399651, loss flux t1 59.130852, binary loss 11.577021, binary loss t1 12.968808\n",
      "Epoch 5/10, Batch 1421/1650, Loss 48.190792, Loss rec 4.085938, loss rec t1 4.190473, loss kl 0.284040, loss_trans 0.051243, loss flux 56.005543, loss flux t1 57.011066, binary loss 20.044306, binary loss t1 19.534792\n",
      "Epoch 5/10, Batch 1431/1650, Loss 32.922451, Loss rec 2.962827, loss rec t1 3.010434, loss kl 0.317227, loss_trans 0.056861, loss flux 57.401886, loss flux t1 58.576351, binary loss 13.099220, binary loss t1 13.475882\n",
      "Epoch 5/10, Batch 1441/1650, Loss 36.371166, Loss rec 2.523922, loss rec t1 3.140445, loss kl 0.440676, loss_trans 0.073363, loss flux 57.391754, loss flux t1 61.538853, binary loss 14.664483, binary loss t1 15.528275\n",
      "Epoch 5/10, Batch 1451/1650, Loss 44.225300, Loss rec 4.220085, loss rec t1 4.302622, loss kl 0.318778, loss_trans 0.063763, loss flux 56.519081, loss flux t1 58.073467, binary loss 19.076393, binary loss t1 16.243658\n",
      "Epoch 5/10, Batch 1461/1650, Loss 35.030128, Loss rec 2.206070, loss rec t1 2.666512, loss kl 0.255579, loss_trans 0.056410, loss flux 55.636856, loss flux t1 56.435699, binary loss 15.508084, binary loss t1 14.337475\n",
      "Epoch 5/10, Batch 1471/1650, Loss 44.956665, Loss rec 3.928746, loss rec t1 4.355238, loss kl 0.348039, loss_trans 0.053276, loss flux 59.263046, loss flux t1 60.603027, binary loss 18.113787, binary loss t1 18.157581\n",
      "Epoch 5/10, Batch 1481/1650, Loss 27.365658, Loss rec 4.503109, loss rec t1 4.435287, loss kl 0.299840, loss_trans 0.049489, loss flux 59.139496, loss flux t1 61.463963, binary loss 9.040917, binary loss t1 9.037014\n",
      "Epoch 5/10, Batch 1491/1650, Loss 34.647152, Loss rec 3.864514, loss rec t1 4.152724, loss kl 0.447190, loss_trans 0.066328, loss flux 61.476555, loss flux t1 62.809986, binary loss 13.401402, binary loss t1 12.714993\n",
      "Epoch 5/10, Batch 1501/1650, Loss 32.531101, Loss rec 3.557421, loss rec t1 4.037771, loss kl 0.466129, loss_trans 0.070471, loss flux 62.785908, loss flux t1 64.897522, binary loss 12.474602, binary loss t1 11.924706\n",
      "Epoch 5/10, Batch 1511/1650, Loss 41.652809, Loss rec 4.216070, loss rec t1 4.474763, loss kl 0.246746, loss_trans 0.064690, loss flux 55.786964, loss flux t1 57.294174, binary loss 15.839727, binary loss t1 16.810814\n",
      "Epoch 5/10, Batch 1521/1650, Loss 30.576796, Loss rec 1.987784, loss rec t1 2.197909, loss kl 0.287887, loss_trans 0.047389, loss flux 55.262028, loss flux t1 58.578033, binary loss 13.116238, binary loss t1 12.939589\n",
      "Epoch 5/10, Batch 1531/1650, Loss 50.956020, Loss rec 4.841240, loss rec t1 3.968863, loss kl 0.283578, loss_trans 0.051272, loss flux 57.844479, loss flux t1 58.893024, binary loss 20.749929, binary loss t1 21.061138\n",
      "Epoch 5/10, Batch 1541/1650, Loss 32.705746, Loss rec 2.558175, loss rec t1 3.021802, loss kl 0.381459, loss_trans 0.079905, loss flux 57.967129, loss flux t1 60.463886, binary loss 12.699441, binary loss t1 13.964963\n",
      "Epoch 5/10, Batch 1551/1650, Loss 28.811043, Loss rec 3.516499, loss rec t1 3.713432, loss kl 0.182481, loss_trans 0.043963, loss flux 54.519653, loss flux t1 56.282188, binary loss 10.467715, binary loss t1 10.886953\n",
      "Epoch 5/10, Batch 1561/1650, Loss 44.889244, Loss rec 3.732007, loss rec t1 3.891209, loss kl 0.489627, loss_trans 0.082621, loss flux 62.565998, loss flux t1 64.430771, binary loss 18.823557, binary loss t1 17.870224\n",
      "Epoch 5/10, Batch 1571/1650, Loss 39.823994, Loss rec 4.002257, loss rec t1 4.902881, loss kl 0.423592, loss_trans 0.057234, loss flux 57.062626, loss flux t1 60.508972, binary loss 16.966053, binary loss t1 13.471976\n",
      "Epoch 5/10, Batch 1581/1650, Loss 38.680649, Loss rec 2.516766, loss rec t1 3.633069, loss kl 0.200084, loss_trans 0.034951, loss flux 51.347027, loss flux t1 51.730190, binary loss 16.591587, binary loss t1 15.704191\n",
      "Epoch 5/10, Batch 1591/1650, Loss 30.748047, Loss rec 3.285563, loss rec t1 3.297315, loss kl 0.335434, loss_trans 0.051560, loss flux 56.673851, loss flux t1 58.950157, binary loss 11.488208, binary loss t1 12.289967\n",
      "Epoch 5/10, Batch 1601/1650, Loss 54.277718, Loss rec 3.571949, loss rec t1 3.836078, loss kl 0.129574, loss_trans 0.035621, loss flux 51.765244, loss flux t1 51.566067, binary loss 22.213266, binary loss t1 24.491226\n",
      "Epoch 5/10, Batch 1611/1650, Loss 38.197735, Loss rec 2.489948, loss rec t1 2.340269, loss kl 0.154169, loss_trans 0.037494, loss flux 51.404385, loss flux t1 52.811405, binary loss 15.880352, binary loss t1 17.295502\n",
      "Epoch 5/10, Batch 1621/1650, Loss 37.160721, Loss rec 2.024463, loss rec t1 2.290295, loss kl 0.330855, loss_trans 0.062805, loss flux 54.818729, loss flux t1 56.809551, binary loss 16.932262, binary loss t1 15.520041\n",
      "Epoch 5/10, Batch 1631/1650, Loss 45.544781, Loss rec 6.014208, loss rec t1 5.695928, loss kl 0.225108, loss_trans 0.059220, loss flux 56.039677, loss flux t1 57.717022, binary loss 16.166246, binary loss t1 17.384071\n",
      "Epoch 5/10, Batch 1641/1650, Loss 37.952480, Loss rec 3.027855, loss rec t1 3.382867, loss kl 0.351415, loss_trans 0.073896, loss flux 58.892910, loss flux t1 62.578224, binary loss 15.868216, binary loss t1 15.248234\n",
      "Epoch 5/10, Train loss 29.176283, Eval loss 42.971905\n",
      "Epoch 6/10, Batch 1/1650, Loss 36.821793, Loss rec 2.304026, loss rec t1 2.656459, loss kl 0.348171, loss_trans 0.078220, loss flux 56.172649, loss flux t1 60.410049, binary loss 16.524183, binary loss t1 14.910731\n",
      "Epoch 6/10, Batch 11/1650, Loss 37.767822, Loss rec 2.783771, loss rec t1 2.831039, loss kl 0.383348, loss_trans 0.062696, loss flux 59.049812, loss flux t1 64.317276, binary loss 15.709315, binary loss t1 15.997653\n",
      "Epoch 6/10, Batch 21/1650, Loss 44.039284, Loss rec 4.574001, loss rec t1 4.662538, loss kl 0.245517, loss_trans 0.051316, loss flux 55.278763, loss flux t1 56.822659, binary loss 17.551754, binary loss t1 16.954159\n",
      "Epoch 6/10, Batch 31/1650, Loss 36.007607, Loss rec 4.038410, loss rec t1 4.824637, loss kl 0.196784, loss_trans 0.039323, loss flux 56.312004, loss flux t1 58.493458, binary loss 12.791425, binary loss t1 14.117030\n",
      "Epoch 6/10, Batch 41/1650, Loss 35.706573, Loss rec 4.789123, loss rec t1 4.572204, loss kl 0.244671, loss_trans 0.049386, loss flux 54.966839, loss flux t1 56.361141, binary loss 13.182177, binary loss t1 12.869014\n",
      "Epoch 6/10, Batch 51/1650, Loss 26.940042, Loss rec 3.297377, loss rec t1 3.670329, loss kl 0.213218, loss_trans 0.041019, loss flux 54.239204, loss flux t1 56.077168, binary loss 9.915136, binary loss t1 9.802961\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Batch 61/1650, Loss 85.858757, Loss rec 13.877085, loss rec t1 14.370981, loss kl 0.448789, loss_trans 0.072472, loss flux 61.136040, loss flux t1 63.046284, binary loss 29.364464, binary loss t1 27.724964\n",
      "Epoch 6/10, Batch 71/1650, Loss 47.697361, Loss rec 5.956065, loss rec t1 7.236517, loss kl 0.435324, loss_trans 0.061407, loss flux 62.068447, loss flux t1 61.910507, binary loss 17.613300, binary loss t1 16.394749\n",
      "Epoch 6/10, Batch 81/1650, Loss 51.578964, Loss rec 4.498377, loss rec t1 5.032357, loss kl 0.213669, loss_trans 0.044662, loss flux 53.688255, loss flux t1 56.114891, binary loss 20.618538, binary loss t1 21.171362\n",
      "Epoch 6/10, Batch 91/1650, Loss 63.682137, Loss rec 8.297956, loss rec t1 8.824404, loss kl 0.271924, loss_trans 0.051033, loss flux 55.633396, loss flux t1 57.337440, binary loss 23.561499, binary loss t1 22.675323\n",
      "Epoch 6/10, Batch 101/1650, Loss 37.215088, Loss rec 5.498341, loss rec t1 6.923323, loss kl 0.205592, loss_trans 0.046331, loss flux 54.583702, loss flux t1 56.118343, binary loss 11.803080, binary loss t1 12.738422\n",
      "Epoch 6/10, Batch 111/1650, Loss 56.721054, Loss rec 8.066011, loss rec t1 8.829855, loss kl 0.450699, loss_trans 0.062567, loss flux 63.633961, loss flux t1 64.393623, binary loss 19.845026, binary loss t1 19.466900\n",
      "Epoch 6/10, Batch 121/1650, Loss 38.203224, Loss rec 7.716154, loss rec t1 9.738863, loss kl 0.391256, loss_trans 0.080173, loss flux 58.771603, loss flux t1 61.430603, binary loss 9.985224, binary loss t1 10.291553\n",
      "Epoch 6/10, Batch 131/1650, Loss 61.594749, Loss rec 5.981488, loss rec t1 6.289442, loss kl 0.154079, loss_trans 0.027898, loss flux 54.715034, loss flux t1 55.900890, binary loss 21.883085, binary loss t1 27.258759\n",
      "Epoch 6/10, Batch 141/1650, Loss 42.405247, Loss rec 7.054341, loss rec t1 7.652473, loss kl 0.216200, loss_trans 0.035351, loss flux 51.542728, loss flux t1 52.915512, binary loss 13.666864, binary loss t1 13.780016\n",
      "Epoch 6/10, Batch 151/1650, Loss 41.108696, Loss rec 6.977075, loss rec t1 8.118019, loss kl 0.466248, loss_trans 0.074546, loss flux 60.976822, loss flux t1 65.324165, binary loss 12.847603, binary loss t1 12.625207\n",
      "Epoch 6/10, Batch 161/1650, Loss 56.935982, Loss rec 7.499722, loss rec t1 6.689783, loss kl 0.476128, loss_trans 0.062118, loss flux 61.541550, loss flux t1 63.674416, binary loss 20.829777, binary loss t1 21.378450\n",
      "Epoch 6/10, Batch 171/1650, Loss 51.873650, Loss rec 6.740980, loss rec t1 7.876370, loss kl 0.469879, loss_trans 0.061892, loss flux 61.596382, loss flux t1 64.051117, binary loss 18.794891, binary loss t1 17.929638\n",
      "Epoch 6/10, Batch 181/1650, Loss 37.760323, Loss rec 3.497034, loss rec t1 3.151134, loss kl 0.201773, loss_trans 0.036340, loss flux 50.297215, loss flux t1 52.567772, binary loss 15.701751, binary loss t1 15.172290\n",
      "Epoch 6/10, Batch 191/1650, Loss 35.050159, Loss rec 7.213519, loss rec t1 6.634522, loss kl 0.433524, loss_trans 0.074776, loss flux 59.170681, loss flux t1 62.010235, binary loss 10.163094, binary loss t1 10.530725\n",
      "Epoch 6/10, Batch 201/1650, Loss 52.425270, Loss rec 5.957664, loss rec t1 5.970493, loss kl 0.275604, loss_trans 0.047255, loss flux 56.386971, loss flux t1 56.402618, binary loss 21.083281, binary loss t1 19.090973\n",
      "Epoch 6/10, Batch 211/1650, Loss 34.031433, Loss rec 5.365969, loss rec t1 5.033134, loss kl 0.172228, loss_trans 0.026932, loss flux 53.449650, loss flux t1 53.156910, binary loss 11.453687, binary loss t1 11.979486\n",
      "Epoch 6/10, Batch 221/1650, Loss 39.402813, Loss rec 3.387303, loss rec t1 3.543183, loss kl 0.293644, loss_trans 0.048333, loss flux 57.013569, loss flux t1 57.522648, binary loss 16.727367, binary loss t1 15.402986\n",
      "Epoch 6/10, Batch 231/1650, Loss 44.208656, Loss rec 5.263006, loss rec t1 5.744444, loss kl 0.377458, loss_trans 0.056816, loss flux 58.561775, loss flux t1 61.526394, binary loss 17.226944, binary loss t1 15.539988\n",
      "Epoch 6/10, Batch 241/1650, Loss 51.903831, Loss rec 7.622911, loss rec t1 7.287284, loss kl 0.254264, loss_trans 0.081092, loss flux 55.473248, loss flux t1 57.413033, binary loss 17.874859, binary loss t1 18.783421\n",
      "Epoch 6/10, Batch 251/1650, Loss 43.413631, Loss rec 5.861762, loss rec t1 6.330723, loss kl 0.380862, loss_trans 0.074270, loss flux 58.041775, loss flux t1 60.297119, binary loss 15.459408, binary loss t1 15.306607\n",
      "Epoch 6/10, Batch 261/1650, Loss 50.003563, Loss rec 6.557338, loss rec t1 7.925456, loss kl 0.224600, loss_trans 0.044983, loss flux 53.244785, loss flux t1 55.914738, binary loss 17.368273, binary loss t1 17.882912\n",
      "Epoch 6/10, Batch 271/1650, Loss 57.146133, Loss rec 5.378341, loss rec t1 5.921778, loss kl 0.332408, loss_trans 0.050780, loss flux 58.201008, loss flux t1 60.873314, binary loss 22.323000, binary loss t1 23.139822\n",
      "Epoch 6/10, Batch 281/1650, Loss 35.012951, Loss rec 5.815660, loss rec t1 7.597766, loss kl 0.274264, loss_trans 0.045982, loss flux 54.761292, loss flux t1 55.007965, binary loss 10.827359, binary loss t1 10.451919\n",
      "Epoch 6/10, Batch 291/1650, Loss 27.609943, Loss rec 3.256061, loss rec t1 3.373252, loss kl 0.361093, loss_trans 0.054733, loss flux 55.440712, loss flux t1 58.082096, binary loss 10.414157, binary loss t1 10.150647\n",
      "Epoch 6/10, Batch 301/1650, Loss 42.468391, Loss rec 4.625201, loss rec t1 4.817891, loss kl 0.211442, loss_trans 0.033993, loss flux 52.480293, loss flux t1 54.303761, binary loss 16.171682, binary loss t1 16.608181\n",
      "Epoch 6/10, Batch 311/1650, Loss 46.242958, Loss rec 2.650159, loss rec t1 3.620978, loss kl 0.273792, loss_trans 0.058119, loss flux 53.229271, loss flux t1 56.308018, binary loss 20.328007, binary loss t1 19.311903\n",
      "Epoch 6/10, Batch 321/1650, Loss 54.312107, Loss rec 8.304756, loss rec t1 9.223349, loss kl 0.300160, loss_trans 0.058680, loss flux 58.599159, loss flux t1 60.436493, binary loss 18.158203, binary loss t1 18.266962\n",
      "Epoch 6/10, Batch 331/1650, Loss 52.155533, Loss rec 4.262497, loss rec t1 5.667998, loss kl 0.208109, loss_trans 0.043062, loss flux 54.068111, loss flux t1 54.584721, binary loss 21.089136, binary loss t1 20.884731\n",
      "Epoch 6/10, Batch 341/1650, Loss 75.662758, Loss rec 14.324769, loss rec t1 15.229519, loss kl 0.327205, loss_trans 0.073705, loss flux 59.054249, loss flux t1 58.974911, binary loss 23.108780, binary loss t1 22.598778\n",
      "Epoch 6/10, Batch 351/1650, Loss 63.223831, Loss rec 7.574073, loss rec t1 8.015522, loss kl 0.421927, loss_trans 0.060020, loss flux 59.912033, loss flux t1 61.746857, binary loss 23.025272, binary loss t1 24.127014\n",
      "Epoch 6/10, Batch 361/1650, Loss 44.944485, Loss rec 7.436717, loss rec t1 7.339693, loss kl 0.269910, loss_trans 0.053762, loss flux 55.286884, loss flux t1 57.292244, binary loss 14.659180, binary loss t1 15.185224\n",
      "Epoch 6/10, Batch 371/1650, Loss 34.890881, Loss rec 7.105787, loss rec t1 6.982366, loss kl 0.456078, loss_trans 0.071271, loss flux 58.694458, loss flux t1 60.671085, binary loss 10.503768, binary loss t1 9.771611\n",
      "Epoch 6/10, Batch 381/1650, Loss 54.773640, Loss rec 10.598398, loss rec t1 12.570628, loss kl 0.329067, loss_trans 0.047587, loss flux 54.245853, loss flux t1 56.631767, binary loss 14.502232, binary loss t1 16.725727\n",
      "Epoch 6/10, Batch 391/1650, Loss 57.899940, Loss rec 5.288573, loss rec t1 6.261020, loss kl 0.336142, loss_trans 0.047420, loss flux 55.711845, loss flux t1 56.627098, binary loss 24.698071, binary loss t1 21.268715\n",
      "Epoch 6/10, Batch 401/1650, Loss 40.073330, Loss rec 5.568711, loss rec t1 5.704912, loss kl 0.227416, loss_trans 0.041665, loss flux 52.634544, loss flux t1 53.696194, binary loss 14.486614, binary loss t1 14.044013\n",
      "Epoch 6/10, Batch 411/1650, Loss 72.568237, Loss rec 9.985794, loss rec t1 12.237777, loss kl 0.462918, loss_trans 0.073065, loss flux 60.760105, loss flux t1 65.077171, binary loss 25.890646, binary loss t1 23.918037\n",
      "Epoch 6/10, Batch 421/1650, Loss 46.978127, Loss rec 8.887507, loss rec t1 8.768019, loss kl 0.410948, loss_trans 0.066574, loss flux 57.649143, loss flux t1 59.183170, binary loss 15.030961, binary loss t1 13.814116\n",
      "Epoch 6/10, Batch 431/1650, Loss 38.402935, Loss rec 4.152627, loss rec t1 6.396827, loss kl 0.323652, loss_trans 0.050735, loss flux 52.736839, loss flux t1 53.930271, binary loss 14.032610, binary loss t1 13.446485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Batch 441/1650, Loss 46.997761, Loss rec 7.346715, loss rec t1 7.951448, loss kl 0.354879, loss_trans 0.069124, loss flux 55.770184, loss flux t1 57.063709, binary loss 15.958494, binary loss t1 15.317101\n",
      "Epoch 6/10, Batch 451/1650, Loss 41.890995, Loss rec 6.064727, loss rec t1 5.721607, loss kl 0.263682, loss_trans 0.047268, loss flux 53.616074, loss flux t1 54.385574, binary loss 14.952333, binary loss t1 14.841376\n",
      "Epoch 6/10, Batch 461/1650, Loss 34.088928, Loss rec 5.454812, loss rec t1 4.929079, loss kl 0.258404, loss_trans 0.044146, loss flux 53.870613, loss flux t1 55.365433, binary loss 11.603800, binary loss t1 11.798688\n",
      "Epoch 6/10, Batch 471/1650, Loss 48.255375, Loss rec 3.214656, loss rec t1 3.627203, loss kl 0.264961, loss_trans 0.049453, loss flux 51.368217, loss flux t1 53.770306, binary loss 21.146294, binary loss t1 19.952808\n",
      "Epoch 6/10, Batch 481/1650, Loss 31.637659, Loss rec 2.961675, loss rec t1 3.480989, loss kl 0.244753, loss_trans 0.039221, loss flux 51.103153, loss flux t1 52.965675, binary loss 12.874382, binary loss t1 12.036638\n",
      "Epoch 6/10, Batch 491/1650, Loss 26.016996, Loss rec 3.156345, loss rec t1 4.430468, loss kl 0.154539, loss_trans 0.031378, loss flux 50.283909, loss flux t1 51.844631, binary loss 8.359570, binary loss t1 9.884697\n",
      "Epoch 6/10, Batch 501/1650, Loss 29.315306, Loss rec 3.886056, loss rec t1 4.295141, loss kl 0.320237, loss_trans 0.051917, loss flux 56.174862, loss flux t1 58.296524, binary loss 11.023955, binary loss t1 9.737999\n",
      "Epoch 6/10, Batch 511/1650, Loss 52.749939, Loss rec 3.643674, loss rec t1 3.977735, loss kl 0.279837, loss_trans 0.037932, loss flux 55.765888, loss flux t1 54.676582, binary loss 22.417183, binary loss t1 22.393574\n",
      "Epoch 6/10, Batch 521/1650, Loss 46.123562, Loss rec 4.012574, loss rec t1 3.180045, loss kl 0.393280, loss_trans 0.065189, loss flux 53.774151, loss flux t1 57.729145, binary loss 20.641899, binary loss t1 17.830574\n",
      "Epoch 6/10, Batch 531/1650, Loss 29.153994, Loss rec 3.339158, loss rec t1 3.747524, loss kl 0.195076, loss_trans 0.043376, loss flux 49.128571, loss flux t1 53.859779, binary loss 10.481560, binary loss t1 11.347302\n",
      "Epoch 6/10, Batch 541/1650, Loss 21.119558, Loss rec 2.836041, loss rec t1 4.365190, loss kl 0.237255, loss_trans 0.058115, loss flux 50.590626, loss flux t1 53.741997, binary loss 6.020061, binary loss t1 7.602896\n",
      "Epoch 6/10, Batch 551/1650, Loss 36.788498, Loss rec 2.233773, loss rec t1 2.304308, loss kl 0.312355, loss_trans 0.067803, loss flux 51.764881, loss flux t1 58.791191, binary loss 15.823932, binary loss t1 16.046329\n",
      "Epoch 6/10, Batch 561/1650, Loss 34.042145, Loss rec 3.421590, loss rec t1 4.110352, loss kl 0.261147, loss_trans 0.043776, loss flux 53.751057, loss flux t1 55.009480, binary loss 12.613801, binary loss t1 13.591475\n",
      "Epoch 6/10, Batch 571/1650, Loss 56.527630, Loss rec 5.056428, loss rec t1 5.791945, loss kl 0.283001, loss_trans 0.043900, loss flux 55.877689, loss flux t1 56.325581, binary loss 23.561012, binary loss t1 21.791344\n",
      "Epoch 6/10, Batch 581/1650, Loss 38.361290, Loss rec 5.225876, loss rec t1 4.331337, loss kl 0.255886, loss_trans 0.051599, loss flux 55.250435, loss flux t1 55.437042, binary loss 14.759397, binary loss t1 13.737196\n",
      "Epoch 6/10, Batch 591/1650, Loss 35.727867, Loss rec 3.297303, loss rec t1 4.214705, loss kl 0.202903, loss_trans 0.031183, loss flux 51.563770, loss flux t1 53.512138, binary loss 12.791670, binary loss t1 15.190104\n",
      "Epoch 6/10, Batch 601/1650, Loss 57.711063, Loss rec 8.079659, loss rec t1 7.764931, loss kl 0.278235, loss_trans 0.064776, loss flux 55.691647, loss flux t1 57.624882, binary loss 21.038019, binary loss t1 20.485441\n",
      "Epoch 6/10, Batch 611/1650, Loss 44.626305, Loss rec 11.398655, loss rec t1 12.237316, loss kl 0.262919, loss_trans 0.044624, loss flux 55.995682, loss flux t1 56.234463, binary loss 10.608444, binary loss t1 10.074347\n",
      "Epoch 6/10, Batch 621/1650, Loss 72.659729, Loss rec 4.763937, loss rec t1 6.519085, loss kl 0.353800, loss_trans 0.051025, loss flux 57.076736, loss flux t1 59.358761, binary loss 30.163292, binary loss t1 30.808590\n",
      "Epoch 6/10, Batch 631/1650, Loss 63.452469, Loss rec 4.356897, loss rec t1 5.042040, loss kl 0.360707, loss_trans 0.060019, loss flux 55.837925, loss flux t1 55.898643, binary loss 27.302555, binary loss t1 26.330252\n",
      "Epoch 6/10, Batch 641/1650, Loss 37.343338, Loss rec 5.378372, loss rec t1 6.173204, loss kl 0.309888, loss_trans 0.054992, loss flux 56.339130, loss flux t1 56.915363, binary loss 12.434955, binary loss t1 12.991926\n",
      "Epoch 6/10, Batch 651/1650, Loss 48.998547, Loss rec 8.004016, loss rec t1 8.703611, loss kl 0.272203, loss_trans 0.056712, loss flux 53.818275, loss flux t1 55.121284, binary loss 14.804658, binary loss t1 17.157345\n",
      "Epoch 6/10, Batch 661/1650, Loss 43.823494, Loss rec 5.305803, loss rec t1 7.181516, loss kl 0.385971, loss_trans 0.065427, loss flux 56.563324, loss flux t1 57.316132, binary loss 15.797884, binary loss t1 15.086894\n",
      "Epoch 6/10, Batch 671/1650, Loss 48.778576, Loss rec 6.379997, loss rec t1 7.734538, loss kl 0.233295, loss_trans 0.054022, loss flux 54.265972, loss flux t1 55.864609, binary loss 17.178755, binary loss t1 17.197968\n",
      "Epoch 6/10, Batch 681/1650, Loss 30.333153, Loss rec 2.360215, loss rec t1 2.576767, loss kl 0.234917, loss_trans 0.047535, loss flux 52.634502, loss flux t1 55.244453, binary loss 12.811860, binary loss t1 12.301859\n",
      "Epoch 6/10, Batch 691/1650, Loss 61.068157, Loss rec 10.088446, loss rec t1 10.293787, loss kl 0.473888, loss_trans 0.071573, loss flux 63.007065, loss flux t1 66.586189, binary loss 20.909559, binary loss t1 19.230902\n",
      "Epoch 6/10, Batch 701/1650, Loss 51.361137, Loss rec 15.408759, loss rec t1 14.608719, loss kl 0.397845, loss_trans 0.062896, loss flux 59.630257, loss flux t1 60.065598, binary loss 10.986994, binary loss t1 9.895924\n",
      "Epoch 6/10, Batch 711/1650, Loss 76.496902, Loss rec 14.625006, loss rec t1 14.816469, loss kl 0.566103, loss_trans 0.096957, loss flux 67.920082, loss flux t1 70.898674, binary loss 25.010748, binary loss t1 21.381624\n",
      "Epoch 6/10, Batch 721/1650, Loss 44.497631, Loss rec 8.186974, loss rec t1 9.286429, loss kl 0.395925, loss_trans 0.064115, loss flux 61.260166, loss flux t1 64.028244, binary loss 13.147409, binary loss t1 13.416778\n",
      "Epoch 6/10, Batch 731/1650, Loss 96.800934, Loss rec 12.421585, loss rec t1 12.275526, loss kl 0.285947, loss_trans 0.052797, loss flux 58.793465, loss flux t1 59.924976, binary loss 37.664864, binary loss t1 34.100212\n",
      "Epoch 6/10, Batch 741/1650, Loss 43.574089, Loss rec 6.654821, loss rec t1 6.080853, loss kl 0.263434, loss_trans 0.052706, loss flux 56.640316, loss flux t1 57.987900, binary loss 14.674246, binary loss t1 15.848025\n",
      "Epoch 6/10, Batch 751/1650, Loss 39.783859, Loss rec 3.893252, loss rec t1 4.801135, loss kl 0.334641, loss_trans 0.061342, loss flux 53.683308, loss flux t1 54.250439, binary loss 15.722916, binary loss t1 14.970570\n",
      "Epoch 6/10, Batch 761/1650, Loss 49.863350, Loss rec 4.916351, loss rec t1 7.079355, loss kl 0.402218, loss_trans 0.081094, loss flux 55.027142, loss flux t1 57.795738, binary loss 20.995932, binary loss t1 16.388403\n",
      "Epoch 6/10, Batch 771/1650, Loss 32.823399, Loss rec 5.598767, loss rec t1 5.806398, loss kl 0.236055, loss_trans 0.059605, loss flux 49.764439, loss flux t1 52.371517, binary loss 11.226650, binary loss t1 9.895924\n",
      "Epoch 6/10, Batch 781/1650, Loss 32.471592, Loss rec 4.591102, loss rec t1 5.216908, loss kl 0.235115, loss_trans 0.047448, loss flux 52.374275, loss flux t1 55.167049, binary loss 10.756784, binary loss t1 11.624235\n",
      "Epoch 6/10, Batch 791/1650, Loss 52.988514, Loss rec 3.667170, loss rec t1 4.685747, loss kl 0.217202, loss_trans 0.057558, loss flux 52.406498, loss flux t1 53.771301, binary loss 21.130493, binary loss t1 23.230341\n",
      "Epoch 6/10, Batch 801/1650, Loss 50.998184, Loss rec 7.295600, loss rec t1 8.224373, loss kl 0.374204, loss_trans 0.066254, loss flux 57.443291, loss flux t1 60.227268, binary loss 16.744387, binary loss t1 18.293365\n",
      "Epoch 6/10, Batch 811/1650, Loss 37.197887, Loss rec 4.702898, loss rec t1 5.954122, loss kl 0.459731, loss_trans 0.081908, loss flux 62.121845, loss flux t1 65.495094, binary loss 14.013639, binary loss t1 11.985588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Batch 821/1650, Loss 46.243797, Loss rec 3.656974, loss rec t1 3.964312, loss kl 0.276450, loss_trans 0.053167, loss flux 51.367542, loss flux t1 54.475719, binary loss 17.831306, binary loss t1 20.461590\n",
      "Epoch 6/10, Batch 831/1650, Loss 30.907427, Loss rec 4.517771, loss rec t1 5.137684, loss kl 0.482818, loss_trans 0.057829, loss flux 54.441368, loss flux t1 55.596409, binary loss 11.926172, binary loss t1 8.785152\n",
      "Epoch 6/10, Batch 841/1650, Loss 43.144341, Loss rec 3.278557, loss rec t1 4.149895, loss kl 0.166822, loss_trans 0.030779, loss flux 48.048771, loss flux t1 50.236317, binary loss 17.095001, binary loss t1 18.423290\n",
      "Epoch 6/10, Batch 851/1650, Loss 32.202492, Loss rec 2.759655, loss rec t1 3.217947, loss kl 0.296265, loss_trans 0.058900, loss flux 53.323715, loss flux t1 56.145790, binary loss 12.348825, binary loss t1 13.520899\n",
      "Epoch 6/10, Batch 861/1650, Loss 33.956512, Loss rec 3.317229, loss rec t1 2.910486, loss kl 0.392670, loss_trans 0.069007, loss flux 55.966557, loss flux t1 57.782940, binary loss 14.076649, binary loss t1 13.190474\n",
      "Epoch 6/10, Batch 871/1650, Loss 32.678425, Loss rec 3.048616, loss rec t1 2.848713, loss kl 0.353231, loss_trans 0.052042, loss flux 57.601707, loss flux t1 59.097569, binary loss 12.257574, binary loss t1 14.118250\n",
      "Epoch 6/10, Batch 881/1650, Loss 45.157898, Loss rec 2.889472, loss rec t1 4.144218, loss kl 0.283213, loss_trans 0.057618, loss flux 54.673103, loss flux t1 56.876129, binary loss 18.028143, binary loss t1 19.755236\n",
      "Epoch 6/10, Batch 891/1650, Loss 34.127712, Loss rec 2.430542, loss rec t1 2.330394, loss kl 0.259399, loss_trans 0.047711, loss flux 54.530354, loss flux t1 57.894138, binary loss 14.386153, binary loss t1 14.673513\n",
      "Epoch 6/10, Batch 901/1650, Loss 29.321514, Loss rec 2.598093, loss rec t1 3.106130, loss kl 0.436986, loss_trans 0.079574, loss flux 58.344456, loss flux t1 61.705181, binary loss 10.955819, binary loss t1 12.144910\n",
      "Epoch 6/10, Batch 911/1650, Loss 27.117729, Loss rec 1.720682, loss rec t1 1.634610, loss kl 0.237210, loss_trans 0.040582, loss flux 50.129166, loss flux t1 52.666054, binary loss 12.450264, binary loss t1 11.034383\n",
      "Epoch 6/10, Batch 921/1650, Loss 36.271957, Loss rec 2.159582, loss rec t1 2.517226, loss kl 0.277239, loss_trans 0.052322, loss flux 53.619125, loss flux t1 55.295490, binary loss 16.395723, binary loss t1 14.869865\n",
      "Epoch 6/10, Batch 931/1650, Loss 32.934208, Loss rec 2.855295, loss rec t1 3.012856, loss kl 0.302842, loss_trans 0.039464, loss flux 53.619358, loss flux t1 54.669525, binary loss 14.312406, binary loss t1 12.411348\n",
      "Epoch 6/10, Batch 941/1650, Loss 26.692785, Loss rec 2.757784, loss rec t1 2.927811, loss kl 0.367150, loss_trans 0.053823, loss flux 53.632431, loss flux t1 56.672493, binary loss 10.326809, binary loss t1 10.259407\n",
      "Epoch 6/10, Batch 951/1650, Loss 24.493973, Loss rec 3.603443, loss rec t1 2.671536, loss kl 0.235349, loss_trans 0.039785, loss flux 55.202572, loss flux t1 57.447369, binary loss 8.821693, binary loss t1 9.122167\n",
      "Epoch 6/10, Batch 961/1650, Loss 59.678452, Loss rec 3.937948, loss rec t1 4.288080, loss kl 0.196920, loss_trans 0.032046, loss flux 52.220345, loss flux t1 52.140175, binary loss 26.286942, binary loss t1 24.936512\n",
      "Epoch 6/10, Batch 971/1650, Loss 35.855827, Loss rec 3.765375, loss rec t1 4.200846, loss kl 0.241196, loss_trans 0.050437, loss flux 55.001534, loss flux t1 56.885815, binary loss 13.776355, binary loss t1 13.821616\n",
      "Epoch 6/10, Batch 981/1650, Loss 34.621563, Loss rec 5.506046, loss rec t1 7.210010, loss kl 0.214383, loss_trans 0.042440, loss flux 51.619541, loss flux t1 52.626518, binary loss 10.191337, binary loss t1 11.457348\n",
      "Epoch 6/10, Batch 991/1650, Loss 120.248512, Loss rec 5.870584, loss rec t1 7.773688, loss kl 0.211643, loss_trans 0.053061, loss flux 54.014153, loss flux t1 56.724487, binary loss 55.605415, binary loss t1 50.734123\n",
      "Epoch 6/10, Batch 1001/1650, Loss 58.239441, Loss rec 6.173009, loss rec t1 6.721942, loss kl 0.374152, loss_trans 0.062161, loss flux 58.893967, loss flux t1 60.833862, binary loss 23.559612, binary loss t1 21.348568\n",
      "Epoch 6/10, Batch 1011/1650, Loss 45.848457, Loss rec 3.607560, loss rec t1 4.979274, loss kl 0.235657, loss_trans 0.061113, loss flux 52.822739, loss flux t1 56.135918, binary loss 18.073162, binary loss t1 18.891691\n",
      "Epoch 6/10, Batch 1021/1650, Loss 35.586472, Loss rec 3.864276, loss rec t1 4.202820, loss kl 0.253376, loss_trans 0.044623, loss flux 52.741493, loss flux t1 54.685387, binary loss 13.255681, binary loss t1 13.965696\n",
      "Epoch 6/10, Batch 1031/1650, Loss 51.762318, Loss rec 4.682791, loss rec t1 4.966882, loss kl 0.418619, loss_trans 0.053508, loss flux 55.745995, loss flux t1 56.272793, binary loss 20.907364, binary loss t1 20.733154\n",
      "Epoch 6/10, Batch 1041/1650, Loss 30.198238, Loss rec 4.253564, loss rec t1 4.650094, loss kl 0.275783, loss_trans 0.036953, loss flux 52.982464, loss flux t1 53.658386, binary loss 10.878167, binary loss t1 10.103679\n",
      "Epoch 6/10, Batch 1051/1650, Loss 32.286037, Loss rec 4.413043, loss rec t1 4.358538, loss kl 0.215293, loss_trans 0.038556, loss flux 53.365128, loss flux t1 53.944775, binary loss 11.350719, binary loss t1 11.909887\n",
      "Epoch 6/10, Batch 1061/1650, Loss 56.620537, Loss rec 5.038138, loss rec t1 5.243933, loss kl 0.396501, loss_trans 0.073753, loss flux 59.565525, loss flux t1 62.467377, binary loss 23.654215, binary loss t1 22.213997\n",
      "Epoch 6/10, Batch 1071/1650, Loss 31.645008, Loss rec 2.989781, loss rec t1 2.931173, loss kl 0.402274, loss_trans 0.067955, loss flux 54.359966, loss flux t1 57.732265, binary loss 11.608372, binary loss t1 13.645453\n",
      "Epoch 6/10, Batch 1081/1650, Loss 35.750210, Loss rec 4.258529, loss rec t1 4.167222, loss kl 0.323914, loss_trans 0.054638, loss flux 56.822502, loss flux t1 56.780663, binary loss 13.651312, binary loss t1 13.294597\n",
      "Epoch 6/10, Batch 1091/1650, Loss 35.128704, Loss rec 2.119514, loss rec t1 2.442233, loss kl 0.174339, loss_trans 0.041939, loss flux 48.802814, loss flux t1 51.541302, binary loss 14.889321, binary loss t1 15.461358\n",
      "Epoch 6/10, Batch 1101/1650, Loss 49.946617, Loss rec 2.874066, loss rec t1 3.366328, loss kl 0.218480, loss_trans 0.042235, loss flux 51.074322, loss flux t1 52.227055, binary loss 24.367161, binary loss t1 19.078348\n",
      "Epoch 6/10, Batch 1111/1650, Loss 35.994854, Loss rec 2.646277, loss rec t1 3.516212, loss kl 0.215435, loss_trans 0.048237, loss flux 48.038704, loss flux t1 50.425541, binary loss 17.173141, binary loss t1 12.395552\n",
      "Epoch 6/10, Batch 1121/1650, Loss 36.178505, Loss rec 3.098884, loss rec t1 3.755779, loss kl 0.372269, loss_trans 0.075147, loss flux 55.764637, loss flux t1 57.996529, binary loss 14.338208, binary loss t1 14.538220\n",
      "Epoch 6/10, Batch 1131/1650, Loss 32.707512, Loss rec 4.878469, loss rec t1 5.521888, loss kl 0.523574, loss_trans 0.076344, loss flux 59.661011, loss flux t1 62.319931, binary loss 10.532434, binary loss t1 11.174802\n",
      "Epoch 6/10, Batch 1141/1650, Loss 75.204422, Loss rec 6.642165, loss rec t1 8.259075, loss kl 0.320683, loss_trans 0.062772, loss flux 57.487671, loss flux t1 59.323841, binary loss 30.645786, binary loss t1 29.273941\n",
      "Epoch 6/10, Batch 1151/1650, Loss 52.638355, Loss rec 5.341055, loss rec t1 7.035583, loss kl 0.401107, loss_trans 0.053860, loss flux 59.817280, loss flux t1 62.397354, binary loss 20.289400, binary loss t1 19.517351\n",
      "Epoch 6/10, Batch 1161/1650, Loss 34.949070, Loss rec 5.511373, loss rec t1 5.081785, loss kl 0.275805, loss_trans 0.051288, loss flux 55.770508, loss flux t1 58.730236, binary loss 11.227873, binary loss t1 12.800943\n",
      "Epoch 6/10, Batch 1171/1650, Loss 59.947468, Loss rec 7.304819, loss rec t1 8.556658, loss kl 0.267399, loss_trans 0.039306, loss flux 55.276245, loss flux t1 56.807571, binary loss 21.657026, binary loss t1 22.122257\n",
      "Epoch 6/10, Batch 1181/1650, Loss 41.126205, Loss rec 7.481135, loss rec t1 8.383681, loss kl 0.484750, loss_trans 0.067207, loss flux 59.907932, loss flux t1 63.611614, binary loss 11.589956, binary loss t1 13.119476\n",
      "Epoch 6/10, Batch 1191/1650, Loss 52.122082, Loss rec 6.613801, loss rec t1 8.725049, loss kl 0.377321, loss_trans 0.060550, loss flux 58.855938, loss flux t1 60.884197, binary loss 17.741274, binary loss t1 18.604086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Batch 1201/1650, Loss 35.269817, Loss rec 4.281492, loss rec t1 3.389435, loss kl 0.261204, loss_trans 0.054766, loss flux 51.174862, loss flux t1 50.503441, binary loss 14.851626, binary loss t1 12.431293\n",
      "Epoch 6/10, Batch 1211/1650, Loss 56.551460, Loss rec 8.488874, loss rec t1 9.848729, loss kl 0.336409, loss_trans 0.055328, loss flux 56.088585, loss flux t1 57.547089, binary loss 19.673256, binary loss t1 18.148863\n",
      "Epoch 6/10, Batch 1221/1650, Loss 49.565536, Loss rec 3.740512, loss rec t1 5.941850, loss kl 0.297708, loss_trans 0.058219, loss flux 54.307381, loss flux t1 57.413830, binary loss 20.727299, binary loss t1 18.799950\n",
      "Epoch 6/10, Batch 1231/1650, Loss 39.607773, Loss rec 2.350692, loss rec t1 2.928192, loss kl 0.271476, loss_trans 0.049853, loss flux 50.408218, loss flux t1 52.667931, binary loss 17.213276, binary loss t1 16.794283\n",
      "Epoch 6/10, Batch 1241/1650, Loss 40.631054, Loss rec 4.065179, loss rec t1 4.179461, loss kl 0.284025, loss_trans 0.046024, loss flux 52.385616, loss flux t1 56.787331, binary loss 16.459953, binary loss t1 15.596409\n",
      "Epoch 6/10, Batch 1251/1650, Loss 30.450630, Loss rec 4.527324, loss rec t1 4.404478, loss kl 0.235377, loss_trans 0.040958, loss flux 51.246262, loss flux t1 52.225662, binary loss 10.265018, binary loss t1 10.977474\n",
      "Epoch 6/10, Batch 1261/1650, Loss 33.819370, Loss rec 4.548928, loss rec t1 4.784015, loss kl 0.242909, loss_trans 0.045130, loss flux 54.930565, loss flux t1 54.626644, binary loss 12.331077, binary loss t1 11.867311\n",
      "Epoch 6/10, Batch 1271/1650, Loss 41.411354, Loss rec 4.720753, loss rec t1 4.052192, loss kl 0.304049, loss_trans 0.055596, loss flux 56.449635, loss flux t1 57.547550, binary loss 15.552856, binary loss t1 16.725904\n",
      "Epoch 6/10, Batch 1281/1650, Loss 34.532158, Loss rec 3.685731, loss rec t1 3.599129, loss kl 0.278997, loss_trans 0.044538, loss flux 51.058167, loss flux t1 51.666565, binary loss 15.331677, binary loss t1 11.592087\n",
      "Epoch 6/10, Batch 1291/1650, Loss 32.892025, Loss rec 2.094755, loss rec t1 2.763298, loss kl 0.189547, loss_trans 0.038388, loss flux 48.063095, loss flux t1 50.855061, binary loss 14.090251, binary loss t1 13.715784\n",
      "Epoch 6/10, Batch 1301/1650, Loss 39.431957, Loss rec 3.462653, loss rec t1 3.580437, loss kl 0.261900, loss_trans 0.036080, loss flux 50.280117, loss flux t1 51.200855, binary loss 16.875532, binary loss t1 15.215354\n",
      "Epoch 6/10, Batch 1311/1650, Loss 33.936279, Loss rec 2.621420, loss rec t1 2.684294, loss kl 0.231174, loss_trans 0.045168, loss flux 52.386181, loss flux t1 55.560658, binary loss 14.244514, binary loss t1 14.109708\n",
      "Epoch 6/10, Batch 1321/1650, Loss 27.039717, Loss rec 3.200210, loss rec t1 3.304731, loss kl 0.405891, loss_trans 0.067004, loss flux 56.272560, loss flux t1 60.243145, binary loss 10.197861, binary loss t1 9.864019\n",
      "Epoch 6/10, Batch 1331/1650, Loss 40.365524, Loss rec 3.694389, loss rec t1 4.448722, loss kl 0.224972, loss_trans 0.048375, loss flux 54.725792, loss flux t1 56.549675, binary loss 15.156980, binary loss t1 16.792088\n",
      "Epoch 6/10, Batch 1341/1650, Loss 29.582148, Loss rec 1.617954, loss rec t1 1.887859, loss kl 0.282415, loss_trans 0.049549, loss flux 48.673737, loss flux t1 53.013020, binary loss 13.314297, binary loss t1 12.430075\n",
      "Epoch 6/10, Batch 1351/1650, Loss 24.415430, Loss rec 1.580696, loss rec t1 1.868951, loss kl 0.189609, loss_trans 0.037161, loss flux 51.619686, loss flux t1 53.956074, binary loss 9.461310, binary loss t1 11.277703\n",
      "Epoch 6/10, Batch 1361/1650, Loss 32.108173, Loss rec 3.911306, loss rec t1 5.090076, loss kl 0.462155, loss_trans 0.066043, loss flux 58.076775, loss flux t1 58.767387, binary loss 12.570492, binary loss t1 10.008099\n",
      "Epoch 6/10, Batch 1371/1650, Loss 37.011814, Loss rec 2.496882, loss rec t1 3.169653, loss kl 0.222395, loss_trans 0.051518, loss flux 48.108948, loss flux t1 52.809776, binary loss 14.617515, binary loss t1 16.453854\n",
      "Epoch 6/10, Batch 1381/1650, Loss 53.032742, Loss rec 5.549584, loss rec t1 6.353189, loss kl 0.352807, loss_trans 0.049105, loss flux 58.100113, loss flux t1 59.982971, binary loss 20.883270, binary loss t1 19.844784\n",
      "Epoch 6/10, Batch 1391/1650, Loss 29.029121, Loss rec 6.816317, loss rec t1 7.749017, loss kl 0.404164, loss_trans 0.075864, loss flux 52.865658, loss flux t1 57.172737, binary loss 7.012800, binary loss t1 6.970956\n",
      "Epoch 6/10, Batch 1401/1650, Loss 49.359261, Loss rec 3.442687, loss rec t1 3.106378, loss kl 0.252902, loss_trans 0.048595, loss flux 55.341457, loss flux t1 57.985355, binary loss 19.428473, binary loss t1 23.080227\n",
      "Epoch 6/10, Batch 1411/1650, Loss 33.419231, Loss rec 6.422407, loss rec t1 7.187281, loss kl 0.293222, loss_trans 0.048553, loss flux 54.659222, loss flux t1 55.768829, binary loss 9.325108, binary loss t1 10.142659\n",
      "Epoch 6/10, Batch 1421/1650, Loss 38.897514, Loss rec 3.554577, loss rec t1 3.494119, loss kl 0.255065, loss_trans 0.047148, loss flux 52.645939, loss flux t1 53.887486, binary loss 15.244329, binary loss t1 16.302275\n",
      "Epoch 6/10, Batch 1431/1650, Loss 30.100798, Loss rec 3.111659, loss rec t1 2.954087, loss kl 0.289127, loss_trans 0.053704, loss flux 52.907543, loss flux t1 54.464279, binary loss 11.659977, binary loss t1 12.032246\n",
      "Epoch 6/10, Batch 1441/1650, Loss 34.609116, Loss rec 2.578656, loss rec t1 3.344386, loss kl 0.412588, loss_trans 0.071328, loss flux 54.412769, loss flux t1 58.684208, binary loss 14.268121, binary loss t1 13.934036\n",
      "Epoch 6/10, Batch 1451/1650, Loss 41.700665, Loss rec 5.428708, loss rec t1 5.362382, loss kl 0.294768, loss_trans 0.058989, loss flux 53.689354, loss flux t1 55.031036, binary loss 15.930248, binary loss t1 14.625568\n",
      "Epoch 6/10, Batch 1461/1650, Loss 29.139803, Loss rec 3.236355, loss rec t1 3.907948, loss kl 0.246322, loss_trans 0.052370, loss flux 52.430809, loss flux t1 53.137341, binary loss 10.488881, binary loss t1 11.207925\n",
      "Epoch 6/10, Batch 1471/1650, Loss 46.286545, Loss rec 3.818346, loss rec t1 4.660434, loss kl 0.332170, loss_trans 0.049170, loss flux 56.769695, loss flux t1 58.121967, binary loss 18.713333, binary loss t1 18.713091\n",
      "Epoch 6/10, Batch 1481/1650, Loss 25.152702, Loss rec 3.980627, loss rec t1 4.734909, loss kl 0.280727, loss_trans 0.045013, loss flux 54.855511, loss flux t1 57.115555, binary loss 7.909958, binary loss t1 8.201468\n",
      "Epoch 6/10, Batch 1491/1650, Loss 38.036480, Loss rec 4.591912, loss rec t1 4.136709, loss kl 0.424974, loss_trans 0.063680, loss flux 58.739803, loss flux t1 60.105080, binary loss 15.084940, binary loss t1 13.734266\n",
      "Epoch 6/10, Batch 1501/1650, Loss 36.408619, Loss rec 4.444308, loss rec t1 4.922131, loss kl 0.422583, loss_trans 0.061026, loss flux 58.371414, loss flux t1 61.365643, binary loss 13.630878, binary loss t1 12.927696\n",
      "Epoch 6/10, Batch 1511/1650, Loss 45.419029, Loss rec 4.339654, loss rec t1 3.986156, loss kl 0.223416, loss_trans 0.057020, loss flux 52.512745, loss flux t1 53.808750, binary loss 18.717970, binary loss t1 18.094816\n",
      "Epoch 6/10, Batch 1521/1650, Loss 24.200695, Loss rec 3.126033, loss rec t1 3.141967, loss kl 0.268737, loss_trans 0.042292, loss flux 51.912926, loss flux t1 55.510441, binary loss 8.611675, binary loss t1 9.009991\n",
      "Epoch 6/10, Batch 1531/1650, Loss 40.033257, Loss rec 4.123766, loss rec t1 4.221376, loss kl 0.256642, loss_trans 0.046700, loss flux 54.547558, loss flux t1 56.072384, binary loss 15.438972, binary loss t1 15.945803\n",
      "Epoch 6/10, Batch 1541/1650, Loss 30.720713, Loss rec 2.275390, loss rec t1 2.353518, loss kl 0.343203, loss_trans 0.069436, loss flux 53.823112, loss flux t1 56.589996, binary loss 12.650764, binary loss t1 13.028401\n",
      "Epoch 6/10, Batch 1551/1650, Loss 23.710161, Loss rec 2.702837, loss rec t1 3.227699, loss kl 0.170217, loss_trans 0.039346, loss flux 51.867580, loss flux t1 53.697159, binary loss 8.187557, binary loss t1 9.382504\n",
      "Epoch 6/10, Batch 1561/1650, Loss 43.477055, Loss rec 4.456406, loss rec t1 4.057557, loss kl 0.434320, loss_trans 0.068669, loss flux 58.051762, loss flux t1 59.863506, binary loss 17.320572, binary loss t1 17.139528\n",
      "Epoch 6/10, Batch 1571/1650, Loss 31.200586, Loss rec 2.132857, loss rec t1 3.453226, loss kl 0.406621, loss_trans 0.053541, loss flux 53.575336, loss flux t1 56.880234, binary loss 13.336439, binary loss t1 11.817902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Batch 1581/1650, Loss 24.539740, Loss rec 2.404891, loss rec t1 2.763324, loss kl 0.186001, loss_trans 0.030989, loss flux 48.692066, loss flux t1 49.053722, binary loss 10.221954, binary loss t1 8.932582\n",
      "Epoch 6/10, Batch 1591/1650, Loss 25.284468, Loss rec 2.005271, loss rec t1 2.055729, loss kl 0.315493, loss_trans 0.048244, loss flux 53.434387, loss flux t1 55.596230, binary loss 10.394699, binary loss t1 10.465031\n",
      "Epoch 6/10, Batch 1601/1650, Loss 29.594757, Loss rec 2.103969, loss rec t1 2.147486, loss kl 0.118459, loss_trans 0.032073, loss flux 48.808830, loss flux t1 48.808548, binary loss 11.899637, binary loss t1 13.293132\n",
      "Epoch 6/10, Batch 1611/1650, Loss 35.474651, Loss rec 1.731963, loss rec t1 1.808318, loss kl 0.141506, loss_trans 0.033621, loss flux 48.847504, loss flux t1 50.159878, binary loss 15.725845, binary loss t1 16.033396\n",
      "Epoch 6/10, Batch 1621/1650, Loss 29.992754, Loss rec 1.818176, loss rec t1 1.535117, loss kl 0.290901, loss_trans 0.052099, loss flux 50.937496, loss flux t1 53.554298, binary loss 13.978319, binary loss t1 12.318143\n",
      "Epoch 6/10, Batch 1631/1650, Loss 26.002382, Loss rec 3.076257, loss rec t1 3.867062, loss kl 0.195801, loss_trans 0.050798, loss flux 52.925945, loss flux t1 53.470425, binary loss 9.182492, binary loss t1 9.629972\n",
      "Epoch 6/10, Batch 1641/1650, Loss 36.376186, Loss rec 2.357240, loss rec t1 2.134701, loss kl 0.312968, loss_trans 0.064319, loss flux 55.603840, loss flux t1 58.830299, binary loss 15.709803, binary loss t1 15.797152\n",
      "Epoch 6/10, Train loss 30.942074, Eval loss 32.525982\n",
      "Epoch 7/10, Batch 1/1650, Loss 27.521975, Loss rec 1.802858, loss rec t1 2.271764, loss kl 0.321028, loss_trans 0.065305, loss flux 52.815712, loss flux t1 56.266399, binary loss 11.761660, binary loss t1 11.299357\n",
      "Epoch 7/10, Batch 11/1650, Loss 28.405489, Loss rec 3.614840, loss rec t1 3.152995, loss kl 0.328543, loss_trans 0.052466, loss flux 55.396656, loss flux t1 59.773434, binary loss 10.317601, binary loss t1 10.939046\n",
      "Epoch 7/10, Batch 21/1650, Loss 31.423218, Loss rec 3.464483, loss rec t1 3.199961, loss kl 0.226006, loss_trans 0.046842, loss flux 51.443165, loss flux t1 53.702915, binary loss 12.255621, binary loss t1 12.230306\n",
      "Epoch 7/10, Batch 31/1650, Loss 34.334118, Loss rec 2.068578, loss rec t1 2.720927, loss kl 0.177890, loss_trans 0.032383, loss flux 53.316429, loss flux t1 55.279903, binary loss 13.515042, binary loss t1 15.819296\n",
      "Epoch 7/10, Batch 41/1650, Loss 31.591263, Loss rec 2.464773, loss rec t1 2.963170, loss kl 0.222837, loss_trans 0.042092, loss flux 52.485916, loss flux t1 53.701866, binary loss 13.449102, binary loss t1 12.449288\n",
      "Epoch 7/10, Batch 51/1650, Loss 22.932760, Loss rec 2.678424, loss rec t1 2.938727, loss kl 0.194957, loss_trans 0.035036, loss flux 51.402340, loss flux t1 53.382812, binary loss 8.453996, binary loss t1 8.631621\n",
      "Epoch 7/10, Batch 61/1650, Loss 52.223660, Loss rec 5.885550, loss rec t1 5.998945, loss kl 0.383950, loss_trans 0.063931, loss flux 56.370571, loss flux t1 58.288494, binary loss 20.333130, binary loss t1 19.558153\n",
      "Epoch 7/10, Batch 71/1650, Loss 49.840961, Loss rec 3.827340, loss rec t1 3.856396, loss kl 0.401635, loss_trans 0.056210, loss flux 59.331776, loss flux t1 59.890068, binary loss 20.727541, binary loss t1 20.971840\n",
      "Epoch 7/10, Batch 81/1650, Loss 30.897461, Loss rec 3.574159, loss rec t1 3.851112, loss kl 0.195774, loss_trans 0.038506, loss flux 51.460621, loss flux t1 53.074909, binary loss 11.187426, binary loss t1 12.050485\n",
      "Epoch 7/10, Batch 91/1650, Loss 30.490429, Loss rec 3.247852, loss rec t1 3.882354, loss kl 0.229797, loss_trans 0.040924, loss flux 50.890251, loss flux t1 53.109493, binary loss 11.369201, binary loss t1 11.720304\n",
      "Epoch 7/10, Batch 101/1650, Loss 36.435364, Loss rec 3.016083, loss rec t1 3.571950, loss kl 0.178759, loss_trans 0.039555, loss flux 52.605793, loss flux t1 53.851189, binary loss 14.338450, binary loss t1 15.290565\n",
      "Epoch 7/10, Batch 111/1650, Loss 40.938148, Loss rec 3.908404, loss rec t1 4.122039, loss kl 0.376820, loss_trans 0.051865, loss flux 58.846237, loss flux t1 60.609177, binary loss 16.286966, binary loss t1 16.192053\n",
      "Epoch 7/10, Batch 121/1650, Loss 27.040241, Loss rec 3.371401, loss rec t1 3.656226, loss kl 0.354259, loss_trans 0.070490, loss flux 56.160751, loss flux t1 58.663555, binary loss 9.818515, binary loss t1 9.769350\n",
      "Epoch 7/10, Batch 131/1650, Loss 34.323334, Loss rec 2.136253, loss rec t1 2.421282, loss kl 0.128616, loss_trans 0.022562, loss flux 51.247410, loss flux t1 52.372021, binary loss 13.514797, binary loss t1 16.099823\n",
      "Epoch 7/10, Batch 141/1650, Loss 40.025593, Loss rec 4.877707, loss rec t1 5.139147, loss kl 0.185649, loss_trans 0.029625, loss flux 48.763596, loss flux t1 49.922573, binary loss 14.837961, binary loss t1 14.955503\n",
      "Epoch 7/10, Batch 151/1650, Loss 32.146984, Loss rec 5.401395, loss rec t1 5.751921, loss kl 0.389895, loss_trans 0.058851, loss flux 57.898212, loss flux t1 60.794868, binary loss 10.164314, binary loss t1 10.380611\n",
      "Epoch 7/10, Batch 161/1650, Loss 46.827522, Loss rec 4.647271, loss rec t1 4.629637, loss kl 0.419206, loss_trans 0.053404, loss flux 59.093025, loss flux t1 61.040283, binary loss 18.142273, binary loss t1 18.935732\n",
      "Epoch 7/10, Batch 171/1650, Loss 45.647709, Loss rec 5.538572, loss rec t1 5.851336, loss kl 0.440883, loss_trans 0.053655, loss flux 60.395119, loss flux t1 61.965481, binary loss 16.837347, binary loss t1 16.925915\n",
      "Epoch 7/10, Batch 181/1650, Loss 32.196232, Loss rec 2.947377, loss rec t1 2.983715, loss kl 0.182489, loss_trans 0.031705, loss flux 47.689674, loss flux t1 50.047626, binary loss 12.956605, binary loss t1 13.094340\n",
      "Epoch 7/10, Batch 191/1650, Loss 34.846310, Loss rec 6.112733, loss rec t1 5.840163, loss kl 0.385908, loss_trans 0.065671, loss flux 56.773293, loss flux t1 59.147816, binary loss 10.492786, binary loss t1 11.949047\n",
      "Epoch 7/10, Batch 201/1650, Loss 44.029972, Loss rec 4.196199, loss rec t1 4.260060, loss kl 0.231553, loss_trans 0.038464, loss flux 53.610611, loss flux t1 53.862652, binary loss 18.270489, binary loss t1 17.033211\n",
      "Epoch 7/10, Batch 211/1650, Loss 27.687527, Loss rec 6.482857, loss rec t1 6.961374, loss kl 0.152192, loss_trans 0.022553, loss flux 50.221985, loss flux t1 50.123020, binary loss 6.857626, binary loss t1 7.210925\n",
      "Epoch 7/10, Batch 221/1650, Loss 50.743931, Loss rec 4.727357, loss rec t1 5.514291, loss kl 0.268420, loss_trans 0.042766, loss flux 53.910488, loss flux t1 54.415619, binary loss 21.554613, binary loss t1 18.636480\n",
      "Epoch 7/10, Batch 231/1650, Loss 56.891224, Loss rec 4.480192, loss rec t1 5.011727, loss kl 0.353539, loss_trans 0.051651, loss flux 54.547009, loss flux t1 57.999603, binary loss 23.886621, binary loss t1 23.107494\n",
      "Epoch 7/10, Batch 241/1650, Loss 73.163635, Loss rec 11.967546, loss rec t1 13.966036, loss kl 0.255987, loss_trans 0.071522, loss flux 53.081573, loss flux t1 55.382019, binary loss 23.118410, binary loss t1 23.784142\n",
      "Epoch 7/10, Batch 251/1650, Loss 36.162270, Loss rec 4.222305, loss rec t1 4.989731, loss kl 0.345318, loss_trans 0.065130, loss flux 54.717720, loss flux t1 57.011993, binary loss 13.223043, binary loss t1 13.316738\n",
      "Epoch 7/10, Batch 261/1650, Loss 46.998844, Loss rec 6.514198, loss rec t1 8.579355, loss kl 0.195400, loss_trans 0.038288, loss flux 49.939213, loss flux t1 52.582825, binary loss 14.511263, binary loss t1 17.160337\n",
      "Epoch 7/10, Batch 271/1650, Loss 77.423447, Loss rec 8.442139, loss rec t1 8.286599, loss kl 0.346197, loss_trans 0.048947, loss flux 56.281258, loss flux t1 58.702568, binary loss 32.397457, binary loss t1 27.902105\n",
      "Epoch 7/10, Batch 281/1650, Loss 33.403072, Loss rec 6.088239, loss rec t1 7.073848, loss kl 0.260165, loss_trans 0.040750, loss flux 51.184277, loss flux t1 51.543125, binary loss 10.212015, binary loss t1 9.728059\n",
      "Epoch 7/10, Batch 291/1650, Loss 30.076265, Loss rec 2.804738, loss rec t1 2.808086, loss kl 0.356331, loss_trans 0.051892, loss flux 52.866848, loss flux t1 55.325150, binary loss 11.983570, binary loss t1 12.071650\n",
      "Epoch 7/10, Batch 301/1650, Loss 31.157480, Loss rec 2.700053, loss rec t1 3.009593, loss kl 0.202031, loss_trans 0.030405, loss flux 50.227535, loss flux t1 51.068596, binary loss 12.055609, binary loss t1 13.159790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Batch 311/1650, Loss 39.069553, Loss rec 2.079554, loss rec t1 2.938961, loss kl 0.262398, loss_trans 0.051668, loss flux 50.782173, loss flux t1 53.331791, binary loss 17.209618, binary loss t1 16.527357\n",
      "Epoch 7/10, Batch 321/1650, Loss 46.324215, Loss rec 5.417824, loss rec t1 5.600248, loss kl 0.279745, loss_trans 0.052015, loss flux 54.667511, loss flux t1 57.061066, binary loss 17.366631, binary loss t1 17.607754\n",
      "Epoch 7/10, Batch 331/1650, Loss 27.972700, Loss rec 3.255844, loss rec t1 3.381250, loss kl 0.209528, loss_trans 0.038334, loss flux 51.088219, loss flux t1 51.636410, binary loss 11.221770, binary loss t1 9.865973\n",
      "Epoch 7/10, Batch 341/1650, Loss 52.658142, Loss rec 7.231599, loss rec t1 7.596993, loss kl 0.324896, loss_trans 0.069866, loss flux 56.616245, loss flux t1 56.500721, binary loss 18.152279, binary loss t1 19.282509\n",
      "Epoch 7/10, Batch 351/1650, Loss 43.755695, Loss rec 4.992600, loss rec t1 4.937077, loss kl 0.388351, loss_trans 0.051243, loss flux 56.446808, loss flux t1 57.800079, binary loss 17.116234, binary loss t1 16.270193\n",
      "Epoch 7/10, Batch 361/1650, Loss 32.715530, Loss rec 2.445896, loss rec t1 2.981017, loss kl 0.249256, loss_trans 0.048682, loss flux 52.285873, loss flux t1 54.853424, binary loss 12.475333, binary loss t1 14.515345\n",
      "Epoch 7/10, Batch 371/1650, Loss 32.792656, Loss rec 3.814068, loss rec t1 3.934652, loss kl 0.436115, loss_trans 0.067603, loss flux 55.666840, loss flux t1 58.978058, binary loss 12.059757, binary loss t1 12.480459\n",
      "Epoch 7/10, Batch 381/1650, Loss 38.607819, Loss rec 4.042519, loss rec t1 4.718047, loss kl 0.302424, loss_trans 0.039217, loss flux 51.838352, loss flux t1 54.354076, binary loss 14.176378, binary loss t1 15.329237\n",
      "Epoch 7/10, Batch 391/1650, Loss 32.314121, Loss rec 6.008296, loss rec t1 6.146918, loss kl 0.304244, loss_trans 0.042804, loss flux 53.092495, loss flux t1 53.890270, binary loss 10.258251, binary loss t1 9.553606\n",
      "Epoch 7/10, Batch 401/1650, Loss 32.410290, Loss rec 4.193051, loss rec t1 3.776974, loss kl 0.213399, loss_trans 0.036593, loss flux 51.015816, loss flux t1 51.893059, binary loss 12.294048, binary loss t1 11.896221\n",
      "Epoch 7/10, Batch 411/1650, Loss 57.529888, Loss rec 9.739617, loss rec t1 11.046053, loss kl 0.403963, loss_trans 0.059419, loss flux 56.528366, loss flux t1 60.337822, binary loss 19.218830, binary loss t1 17.062008\n",
      "Epoch 7/10, Batch 421/1650, Loss 48.371910, Loss rec 8.639793, loss rec t1 9.454716, loss kl 0.376667, loss_trans 0.061698, loss flux 55.979004, loss flux t1 57.915775, binary loss 14.829971, binary loss t1 15.009064\n",
      "Epoch 7/10, Batch 431/1650, Loss 44.363640, Loss rec 4.711994, loss rec t1 5.017798, loss kl 0.313975, loss_trans 0.044655, loss flux 49.788082, loss flux t1 51.221653, binary loss 19.272745, binary loss t1 15.002474\n",
      "Epoch 7/10, Batch 441/1650, Loss 61.876133, Loss rec 5.589236, loss rec t1 5.652431, loss kl 0.312968, loss_trans 0.060773, loss flux 52.539677, loss flux t1 53.813225, binary loss 27.190201, binary loss t1 23.070528\n",
      "Epoch 7/10, Batch 451/1650, Loss 26.245419, Loss rec 4.316741, loss rec t1 5.333105, loss kl 0.232048, loss_trans 0.041417, loss flux 49.653816, loss flux t1 51.433105, binary loss 7.858841, binary loss t1 8.463269\n",
      "Epoch 7/10, Batch 461/1650, Loss 29.732779, Loss rec 3.189468, loss rec t1 3.431285, loss kl 0.229688, loss_trans 0.038102, loss flux 51.643742, loss flux t1 52.869801, binary loss 11.013950, binary loss t1 11.830281\n",
      "Epoch 7/10, Batch 471/1650, Loss 33.541302, Loss rec 2.060690, loss rec t1 2.572862, loss kl 0.255590, loss_trans 0.045833, loss flux 48.523884, loss flux t1 51.053642, binary loss 14.777879, binary loss t1 13.828448\n",
      "Epoch 7/10, Batch 481/1650, Loss 28.505594, Loss rec 2.283219, loss rec t1 2.509909, loss kl 0.218028, loss_trans 0.033642, loss flux 48.607037, loss flux t1 50.505695, binary loss 11.629539, binary loss t1 11.831259\n",
      "Epoch 7/10, Batch 491/1650, Loss 23.544996, Loss rec 3.259102, loss rec t1 3.337455, loss kl 0.145920, loss_trans 0.029334, loss flux 48.839134, loss flux t1 50.671852, binary loss 8.388301, binary loss t1 8.384885\n",
      "Epoch 7/10, Batch 501/1650, Loss 30.351198, Loss rec 3.177671, loss rec t1 3.236640, loss kl 0.284835, loss_trans 0.045220, loss flux 53.560242, loss flux t1 55.673519, binary loss 12.412814, binary loss t1 11.194016\n",
      "Epoch 7/10, Batch 511/1650, Loss 35.585365, Loss rec 3.061206, loss rec t1 2.986139, loss kl 0.259146, loss_trans 0.035305, loss flux 52.772079, loss flux t1 52.547482, binary loss 14.645024, binary loss t1 14.598545\n",
      "Epoch 7/10, Batch 521/1650, Loss 41.620716, Loss rec 2.986545, loss rec t1 2.270212, loss kl 0.361852, loss_trans 0.057993, loss flux 50.952599, loss flux t1 54.902058, binary loss 19.799034, binary loss t1 16.145082\n",
      "Epoch 7/10, Batch 531/1650, Loss 27.708191, Loss rec 2.603564, loss rec t1 3.285219, loss kl 0.179531, loss_trans 0.040489, loss flux 46.972744, loss flux t1 51.981846, binary loss 10.500041, binary loss t1 11.099346\n",
      "Epoch 7/10, Batch 541/1650, Loss 19.871756, Loss rec 3.789314, loss rec t1 5.038624, loss kl 0.210803, loss_trans 0.051516, loss flux 48.052105, loss flux t1 51.200439, binary loss 4.877452, binary loss t1 5.904047\n",
      "Epoch 7/10, Batch 551/1650, Loss 26.805311, Loss rec 3.074646, loss rec t1 3.021614, loss kl 0.289029, loss_trans 0.060289, loss flux 48.759983, loss flux t1 55.581463, binary loss 10.335106, binary loss t1 10.024628\n",
      "Epoch 7/10, Batch 561/1650, Loss 49.916042, Loss rec 3.544602, loss rec t1 5.244207, loss kl 0.240859, loss_trans 0.041266, loss flux 51.087696, loss flux t1 52.089046, binary loss 20.310013, binary loss t1 20.535095\n",
      "Epoch 7/10, Batch 571/1650, Loss 52.253960, Loss rec 7.059122, loss rec t1 7.051471, loss kl 0.253128, loss_trans 0.040916, loss flux 52.938408, loss flux t1 53.303040, binary loss 19.533325, binary loss t1 18.315994\n",
      "Epoch 7/10, Batch 581/1650, Loss 30.805117, Loss rec 7.781187, loss rec t1 7.873858, loss kl 0.234234, loss_trans 0.046326, loss flux 52.735188, loss flux t1 52.319439, binary loss 7.538178, binary loss t1 7.331333\n",
      "Epoch 7/10, Batch 591/1650, Loss 82.943321, Loss rec 3.637383, loss rec t1 4.763637, loss kl 0.196641, loss_trans 0.031064, loss flux 49.244705, loss flux t1 51.712814, binary loss 39.769588, binary loss t1 34.545006\n",
      "Epoch 7/10, Batch 601/1650, Loss 96.618774, Loss rec 17.879877, loss rec t1 17.663925, loss kl 0.290726, loss_trans 0.068142, loss flux 53.961746, loss flux t1 56.266865, binary loss 30.025070, binary loss t1 30.691042\n",
      "Epoch 7/10, Batch 611/1650, Loss 45.551479, Loss rec 13.025463, loss rec t1 13.846606, loss kl 0.271805, loss_trans 0.047308, loss flux 53.287540, loss flux t1 54.150566, binary loss 9.237580, binary loss t1 9.122720\n",
      "Epoch 7/10, Batch 621/1650, Loss 63.111748, Loss rec 5.136536, loss rec t1 4.937032, loss kl 0.375510, loss_trans 0.059808, loss flux 54.207382, loss flux t1 56.920895, binary loss 25.560398, binary loss t1 27.042465\n",
      "Epoch 7/10, Batch 631/1650, Loss 63.773685, Loss rec 4.627065, loss rec t1 5.545979, loss kl 0.379172, loss_trans 0.065298, loss flux 53.484261, loss flux t1 54.582947, binary loss 27.529591, binary loss t1 25.626581\n",
      "Epoch 7/10, Batch 641/1650, Loss 39.810337, Loss rec 5.470922, loss rec t1 5.579540, loss kl 0.323308, loss_trans 0.054828, loss flux 53.943939, loss flux t1 54.208050, binary loss 14.401463, binary loss t1 13.980272\n",
      "Epoch 7/10, Batch 651/1650, Loss 37.463867, Loss rec 5.804561, loss rec t1 6.337380, loss kl 0.306775, loss_trans 0.059355, loss flux 52.176384, loss flux t1 54.232754, binary loss 11.766539, binary loss t1 13.189253\n",
      "Epoch 7/10, Batch 661/1650, Loss 33.660938, Loss rec 4.079426, loss rec t1 4.118222, loss kl 0.392679, loss_trans 0.066138, loss flux 53.474472, loss flux t1 55.351871, binary loss 12.571712, binary loss t1 12.432758\n",
      "Epoch 7/10, Batch 671/1650, Loss 45.727364, Loss rec 4.142359, loss rec t1 4.654210, loss kl 0.254335, loss_trans 0.054900, loss flux 51.951359, loss flux t1 54.369347, binary loss 18.212360, binary loss t1 18.409199\n",
      "Epoch 7/10, Batch 681/1650, Loss 28.808603, Loss rec 2.158200, loss rec t1 2.758022, loss kl 0.247234, loss_trans 0.048507, loss flux 49.883308, loss flux t1 52.824306, binary loss 12.085561, binary loss t1 11.511083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Batch 691/1650, Loss 58.729736, Loss rec 6.889755, loss rec t1 7.742596, loss kl 0.471129, loss_trans 0.068328, loss flux 59.935280, loss flux t1 63.059288, binary loss 23.152025, binary loss t1 20.405903\n",
      "Epoch 7/10, Batch 701/1650, Loss 32.436157, Loss rec 6.186996, loss rec t1 5.138283, loss kl 0.433522, loss_trans 0.065093, loss flux 56.587765, loss flux t1 57.090355, binary loss 10.730248, binary loss t1 9.882013\n",
      "Epoch 7/10, Batch 711/1650, Loss 66.487846, Loss rec 5.725315, loss rec t1 6.292072, loss kl 0.596167, loss_trans 0.093509, loss flux 62.958138, loss flux t1 66.455032, binary loss 29.236734, binary loss t1 24.544052\n",
      "Epoch 7/10, Batch 721/1650, Loss 36.466202, Loss rec 4.162107, loss rec t1 5.944136, loss kl 0.378479, loss_trans 0.058996, loss flux 55.378643, loss flux t1 57.549332, binary loss 13.490948, binary loss t1 12.431538\n",
      "Epoch 7/10, Batch 731/1650, Loss 38.366165, Loss rec 3.411385, loss rec t1 3.519071, loss kl 0.271084, loss_trans 0.047263, loss flux 53.261829, loss flux t1 54.774113, binary loss 15.172047, binary loss t1 15.945315\n",
      "Epoch 7/10, Batch 741/1650, Loss 38.517078, Loss rec 3.627034, loss rec t1 4.068940, loss kl 0.264238, loss_trans 0.046795, loss flux 52.858437, loss flux t1 53.998192, binary loss 15.287395, binary loss t1 15.222675\n",
      "Epoch 7/10, Batch 751/1650, Loss 27.228466, Loss rec 2.404327, loss rec t1 2.835743, loss kl 0.309192, loss_trans 0.055231, loss flux 50.627361, loss flux t1 51.807236, binary loss 10.944594, binary loss t1 10.679377\n",
      "Epoch 7/10, Batch 761/1650, Loss 30.215965, Loss rec 3.242975, loss rec t1 3.338373, loss kl 0.385565, loss_trans 0.074882, loss flux 52.242630, loss flux t1 54.830963, binary loss 12.072870, binary loss t1 11.101298\n",
      "Epoch 7/10, Batch 771/1650, Loss 22.407564, Loss rec 2.129826, loss rec t1 2.477264, loss kl 0.234429, loss_trans 0.054181, loss flux 47.296688, loss flux t1 50.835270, binary loss 8.844990, binary loss t1 8.666876\n",
      "Epoch 7/10, Batch 781/1650, Loss 24.678474, Loss rec 2.489759, loss rec t1 3.076078, loss kl 0.237616, loss_trans 0.044563, loss flux 50.231220, loss flux t1 52.511410, binary loss 8.716286, binary loss t1 10.114173\n",
      "Epoch 7/10, Batch 791/1650, Loss 38.947834, Loss rec 2.823706, loss rec t1 2.910341, loss kl 0.217408, loss_trans 0.052623, loss flux 49.896378, loss flux t1 51.086033, binary loss 16.772629, binary loss t1 16.171129\n",
      "Epoch 7/10, Batch 801/1650, Loss 46.725796, Loss rec 4.900417, loss rec t1 6.139655, loss kl 0.325573, loss_trans 0.058891, loss flux 54.062504, loss flux t1 56.854046, binary loss 16.631721, binary loss t1 18.669538\n",
      "Epoch 7/10, Batch 811/1650, Loss 27.648155, Loss rec 3.536727, loss rec t1 3.888330, loss kl 0.418525, loss_trans 0.072141, loss flux 58.363712, loss flux t1 61.822090, binary loss 10.639729, binary loss t1 9.092703\n",
      "Epoch 7/10, Batch 821/1650, Loss 35.535114, Loss rec 2.784047, loss rec t1 3.510439, loss kl 0.263495, loss_trans 0.046969, loss flux 48.976677, loss flux t1 52.089355, binary loss 13.160522, binary loss t1 15.769642\n",
      "Epoch 7/10, Batch 831/1650, Loss 31.614315, Loss rec 2.753017, loss rec t1 2.633311, loss kl 0.437914, loss_trans 0.051311, loss flux 51.332645, loss flux t1 52.980316, binary loss 14.950380, binary loss t1 10.788379\n",
      "Epoch 7/10, Batch 841/1650, Loss 18.352863, Loss rec 1.725813, loss rec t1 1.710976, loss kl 0.167168, loss_trans 0.029156, loss flux 45.899033, loss flux t1 47.810421, binary loss 6.608627, binary loss t1 8.111125\n",
      "Epoch 7/10, Batch 851/1650, Loss 36.389790, Loss rec 2.797015, loss rec t1 3.633622, loss kl 0.285051, loss_trans 0.054354, loss flux 51.729908, loss flux t1 53.819153, binary loss 14.066889, binary loss t1 15.552855\n",
      "Epoch 7/10, Batch 861/1650, Loss 28.908361, Loss rec 1.950175, loss rec t1 2.746293, loss kl 0.359974, loss_trans 0.059967, loss flux 53.354790, loss flux t1 56.375103, binary loss 11.829794, binary loss t1 11.962158\n",
      "Epoch 7/10, Batch 871/1650, Loss 32.033001, Loss rec 2.562174, loss rec t1 2.506964, loss kl 0.318701, loss_trans 0.046520, loss flux 54.136322, loss flux t1 55.503868, binary loss 12.623009, binary loss t1 13.975635\n",
      "Epoch 7/10, Batch 881/1650, Loss 30.911427, Loss rec 2.106646, loss rec t1 2.899729, loss kl 0.259210, loss_trans 0.051587, loss flux 51.841232, loss flux t1 53.830147, binary loss 11.766539, binary loss t1 13.827717\n",
      "Epoch 7/10, Batch 891/1650, Loss 25.423948, Loss rec 1.952709, loss rec t1 2.255116, loss kl 0.230919, loss_trans 0.040568, loss flux 51.224823, loss flux t1 54.377918, binary loss 9.973997, binary loss t1 10.970640\n",
      "Epoch 7/10, Batch 901/1650, Loss 26.730564, Loss rec 2.541290, loss rec t1 3.174352, loss kl 0.383504, loss_trans 0.066547, loss flux 55.130066, loss flux t1 58.136112, binary loss 10.165290, binary loss t1 10.399581\n",
      "Epoch 7/10, Batch 911/1650, Loss 30.353710, Loss rec 2.210632, loss rec t1 2.330454, loss kl 0.216668, loss_trans 0.035312, loss flux 47.192543, loss flux t1 49.880260, binary loss 13.090679, binary loss t1 12.469965\n",
      "Epoch 7/10, Batch 921/1650, Loss 29.150055, Loss rec 2.462411, loss rec t1 2.585080, loss kl 0.261154, loss_trans 0.044756, loss flux 51.135708, loss flux t1 52.061359, binary loss 12.796063, binary loss t1 11.000591\n",
      "Epoch 7/10, Batch 931/1650, Loss 29.410622, Loss rec 2.775427, loss rec t1 2.433782, loss kl 0.272208, loss_trans 0.033306, loss flux 51.777790, loss flux t1 52.764923, binary loss 12.544202, binary loss t1 11.351695\n",
      "Epoch 7/10, Batch 941/1650, Loss 23.687984, Loss rec 2.562340, loss rec t1 2.348845, loss kl 0.329069, loss_trans 0.046516, loss flux 50.681419, loss flux t1 53.592945, binary loss 9.466923, binary loss t1 8.934291\n",
      "Epoch 7/10, Batch 951/1650, Loss 29.671846, Loss rec 2.146660, loss rec t1 1.931318, loss kl 0.214298, loss_trans 0.034911, loss flux 52.179546, loss flux t1 54.784973, binary loss 11.908912, binary loss t1 13.435747\n",
      "Epoch 7/10, Batch 961/1650, Loss 38.057022, Loss rec 3.378385, loss rec t1 3.820849, loss kl 0.177864, loss_trans 0.027061, loss flux 49.968410, loss flux t1 50.044186, binary loss 15.681561, binary loss t1 14.971303\n",
      "Epoch 7/10, Batch 971/1650, Loss 32.300972, Loss rec 3.246697, loss rec t1 3.910682, loss kl 0.214580, loss_trans 0.043549, loss flux 52.205212, loss flux t1 54.049683, binary loss 11.810580, binary loss t1 13.074883\n",
      "Epoch 7/10, Batch 981/1650, Loss 24.038998, Loss rec 2.673835, loss rec t1 3.066562, loss kl 0.209831, loss_trans 0.039391, loss flux 49.933907, loss flux t1 50.920620, binary loss 8.736719, binary loss t1 9.312660\n",
      "Epoch 7/10, Batch 991/1650, Loss 71.193108, Loss rec 4.079092, loss rec t1 4.978879, loss kl 0.195867, loss_trans 0.047424, loss flux 51.729855, loss flux t1 53.982555, binary loss 31.267475, binary loss t1 30.624372\n",
      "Epoch 7/10, Batch 1001/1650, Loss 35.623653, Loss rec 3.062281, loss rec t1 3.507443, loss kl 0.348871, loss_trans 0.055666, loss flux 56.316414, loss flux t1 58.290596, binary loss 14.599035, binary loss t1 14.050359\n",
      "Epoch 7/10, Batch 1011/1650, Loss 31.009460, Loss rec 3.271657, loss rec t1 2.899584, loss kl 0.206448, loss_trans 0.051907, loss flux 50.232361, loss flux t1 53.208981, binary loss 12.191390, binary loss t1 12.388474\n",
      "Epoch 7/10, Batch 1021/1650, Loss 35.038010, Loss rec 2.599573, loss rec t1 2.725441, loss kl 0.223035, loss_trans 0.036613, loss flux 50.478928, loss flux t1 52.602261, binary loss 14.382492, binary loss t1 15.070852\n",
      "Epoch 7/10, Batch 1031/1650, Loss 38.482193, Loss rec 4.286616, loss rec t1 4.001441, loss kl 0.383446, loss_trans 0.046199, loss flux 54.232132, loss flux t1 55.118355, binary loss 14.550112, binary loss t1 15.214378\n",
      "Epoch 7/10, Batch 1041/1650, Loss 20.704685, Loss rec 2.376402, loss rec t1 2.988870, loss kl 0.230760, loss_trans 0.029013, loss flux 51.311272, loss flux t1 51.964611, binary loss 7.672430, binary loss t1 7.407211\n",
      "Epoch 7/10, Batch 1051/1650, Loss 23.671026, Loss rec 2.203685, loss rec t1 2.754398, loss kl 0.185250, loss_trans 0.032542, loss flux 50.418221, loss flux t1 51.145721, binary loss 8.601669, binary loss t1 9.893482\n",
      "Epoch 7/10, Batch 1061/1650, Loss 53.610130, Loss rec 7.525589, loss rec t1 7.496053, loss kl 0.363517, loss_trans 0.063710, loss flux 58.461361, loss flux t1 60.575516, binary loss 19.401449, binary loss t1 18.759815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Batch 1071/1650, Loss 31.424910, Loss rec 4.096276, loss rec t1 2.983554, loss kl 0.342895, loss_trans 0.058164, loss flux 51.358440, loss flux t1 54.980556, binary loss 11.584277, binary loss t1 12.359744\n",
      "Epoch 7/10, Batch 1081/1650, Loss 55.501472, Loss rec 11.418213, loss rec t1 9.956240, loss kl 0.298882, loss_trans 0.048098, loss flux 54.213299, loss flux t1 54.414558, binary loss 17.699186, binary loss t1 16.080853\n",
      "Epoch 7/10, Batch 1091/1650, Loss 32.573471, Loss rec 2.474497, loss rec t1 3.007646, loss kl 0.145022, loss_trans 0.035233, loss flux 46.409508, loss flux t1 48.507370, binary loss 13.290935, binary loss t1 13.620139\n",
      "Epoch 7/10, Batch 1101/1650, Loss 49.008018, Loss rec 2.546051, loss rec t1 3.041553, loss kl 0.205569, loss_trans 0.039925, loss flux 47.995869, loss flux t1 48.923229, binary loss 24.717773, binary loss t1 18.457146\n",
      "Epoch 7/10, Batch 1111/1650, Loss 30.520454, Loss rec 2.110642, loss rec t1 2.810096, loss kl 0.195313, loss_trans 0.044014, loss flux 45.439091, loss flux t1 48.434940, binary loss 12.801611, binary loss t1 12.558779\n",
      "Epoch 7/10, Batch 1121/1650, Loss 25.359793, Loss rec 2.948648, loss rec t1 3.970397, loss kl 0.332952, loss_trans 0.063541, loss flux 52.919399, loss flux t1 54.886978, binary loss 9.065924, binary loss t1 8.978331\n",
      "Epoch 7/10, Batch 1131/1650, Loss 28.856794, Loss rec 3.380164, loss rec t1 3.747414, loss kl 0.485144, loss_trans 0.062946, loss flux 56.577049, loss flux t1 58.518250, binary loss 10.701029, binary loss t1 10.480097\n",
      "Epoch 7/10, Batch 1141/1650, Loss 50.735313, Loss rec 3.511842, loss rec t1 3.924787, loss kl 0.287222, loss_trans 0.053327, loss flux 54.176918, loss flux t1 56.476196, binary loss 21.224920, binary loss t1 21.733215\n",
      "Epoch 7/10, Batch 1151/1650, Loss 30.235249, Loss rec 3.073182, loss rec t1 2.762331, loss kl 0.368021, loss_trans 0.047491, loss flux 56.980415, loss flux t1 59.415268, binary loss 12.371214, binary loss t1 11.613010\n",
      "Epoch 7/10, Batch 1161/1650, Loss 37.042309, Loss rec 4.834591, loss rec t1 4.762690, loss kl 0.265925, loss_trans 0.048429, loss flux 53.590305, loss flux t1 56.243053, binary loss 13.045973, binary loss t1 14.084702\n",
      "Epoch 7/10, Batch 1171/1650, Loss 44.522579, Loss rec 4.128187, loss rec t1 4.564424, loss kl 0.245855, loss_trans 0.035878, loss flux 52.690765, loss flux t1 53.769318, binary loss 17.784580, binary loss t1 17.763659\n",
      "Epoch 7/10, Batch 1181/1650, Loss 30.161568, Loss rec 3.309544, loss rec t1 4.154038, loss kl 0.447958, loss_trans 0.058105, loss flux 57.751804, loss flux t1 60.902939, binary loss 10.378657, binary loss t1 11.813265\n",
      "Epoch 7/10, Batch 1191/1650, Loss 35.757195, Loss rec 3.163468, loss rec t1 3.947721, loss kl 0.329802, loss_trans 0.050058, loss flux 56.379871, loss flux t1 58.608696, binary loss 13.756899, binary loss t1 14.509245\n",
      "Epoch 7/10, Batch 1201/1650, Loss 31.748365, Loss rec 3.219555, loss rec t1 2.595908, loss kl 0.247300, loss_trans 0.050478, loss flux 48.691490, loss flux t1 48.237518, binary loss 14.359617, binary loss t1 11.275506\n",
      "Epoch 7/10, Batch 1211/1650, Loss 36.905117, Loss rec 5.917855, loss rec t1 6.488728, loss kl 0.307038, loss_trans 0.048311, loss flux 53.982456, loss flux t1 55.201214, binary loss 11.959296, binary loss t1 12.183890\n",
      "Epoch 7/10, Batch 1221/1650, Loss 39.581951, Loss rec 2.214324, loss rec t1 3.287339, loss kl 0.269243, loss_trans 0.049489, loss flux 51.125740, loss flux t1 53.687363, binary loss 18.518446, binary loss t1 15.243110\n",
      "Epoch 7/10, Batch 1231/1650, Loss 29.154835, Loss rec 1.993364, loss rec t1 2.938728, loss kl 0.260438, loss_trans 0.046948, loss flux 48.920986, loss flux t1 51.178761, binary loss 11.367249, binary loss t1 12.548107\n",
      "Epoch 7/10, Batch 1241/1650, Loss 34.309601, Loss rec 2.677358, loss rec t1 2.788757, loss kl 0.262623, loss_trans 0.041695, loss flux 49.019447, loss flux t1 53.735401, binary loss 14.601717, binary loss t1 13.937450\n",
      "Epoch 7/10, Batch 1251/1650, Loss 38.661510, Loss rec 3.881924, loss rec t1 4.889122, loss kl 0.217534, loss_trans 0.034949, loss flux 49.153481, loss flux t1 50.689705, binary loss 14.531631, binary loss t1 15.106350\n",
      "Epoch 7/10, Batch 1261/1650, Loss 41.720654, Loss rec 5.726574, loss rec t1 6.335812, loss kl 0.226684, loss_trans 0.039848, loss flux 52.928387, loss flux t1 52.699993, binary loss 14.263240, binary loss t1 15.128494\n",
      "Epoch 7/10, Batch 1271/1650, Loss 27.703209, Loss rec 4.612987, loss rec t1 4.051948, loss kl 0.272692, loss_trans 0.047788, loss flux 53.557198, loss flux t1 54.313465, binary loss 9.073245, binary loss t1 9.644548\n",
      "Epoch 7/10, Batch 1281/1650, Loss 39.398472, Loss rec 2.714411, loss rec t1 2.592246, loss kl 0.249251, loss_trans 0.042097, loss flux 48.758781, loss flux t1 49.608463, binary loss 18.650078, binary loss t1 15.150393\n",
      "Epoch 7/10, Batch 1291/1650, Loss 19.422531, Loss rec 3.009399, loss rec t1 3.335290, loss kl 0.176472, loss_trans 0.034906, loss flux 45.872536, loss flux t1 48.472267, binary loss 6.666579, binary loss t1 6.199884\n",
      "Epoch 7/10, Batch 1301/1650, Loss 31.473370, Loss rec 3.927062, loss rec t1 3.599931, loss kl 0.242322, loss_trans 0.030624, loss flux 48.151722, loss flux t1 49.367676, binary loss 12.136124, binary loss t1 11.537309\n",
      "Epoch 7/10, Batch 1311/1650, Loss 38.948360, Loss rec 4.423453, loss rec t1 5.257074, loss kl 0.206436, loss_trans 0.040957, loss flux 50.005627, loss flux t1 52.897892, binary loss 13.935253, binary loss t1 15.085186\n",
      "Epoch 7/10, Batch 1321/1650, Loss 23.220110, Loss rec 3.880906, loss rec t1 3.719732, loss kl 0.354039, loss_trans 0.057267, loss flux 52.491337, loss flux t1 55.871712, binary loss 7.969552, binary loss t1 7.238615\n",
      "Epoch 7/10, Batch 1331/1650, Loss 32.252289, Loss rec 2.968747, loss rec t1 3.797622, loss kl 0.196977, loss_trans 0.040664, loss flux 52.311054, loss flux t1 53.858299, binary loss 11.527613, binary loss t1 13.720667\n",
      "Epoch 7/10, Batch 1341/1650, Loss 23.210712, Loss rec 1.901504, loss rec t1 2.173664, loss kl 0.260478, loss_trans 0.047051, loss flux 46.884281, loss flux t1 51.691837, binary loss 9.271305, binary loss t1 9.556712\n",
      "Epoch 7/10, Batch 1351/1650, Loss 28.111515, Loss rec 2.445163, loss rec t1 2.802931, loss kl 0.169949, loss_trans 0.032235, loss flux 49.065369, loss flux t1 51.835072, binary loss 10.190294, binary loss t1 12.470942\n",
      "Epoch 7/10, Batch 1361/1650, Loss 35.965389, Loss rec 3.122522, loss rec t1 3.847024, loss kl 0.411772, loss_trans 0.059722, loss flux 55.198967, loss flux t1 56.242897, binary loss 14.956724, binary loss t1 13.567623\n",
      "Epoch 7/10, Batch 1371/1650, Loss 29.239399, Loss rec 1.884271, loss rec t1 2.158813, loss kl 0.204440, loss_trans 0.048773, loss flux 45.704704, loss flux t1 50.292583, binary loss 12.317654, binary loss t1 12.625448\n",
      "Epoch 7/10, Batch 1381/1650, Loss 47.256779, Loss rec 5.480994, loss rec t1 5.607507, loss kl 0.311414, loss_trans 0.041450, loss flux 55.132854, loss flux t1 56.505947, binary loss 18.383156, binary loss t1 17.432259\n",
      "Epoch 7/10, Batch 1391/1650, Loss 23.618017, Loss rec 4.967015, loss rec t1 5.141537, loss kl 0.370793, loss_trans 0.068113, loss flux 50.081284, loss flux t1 53.831596, binary loss 6.858048, binary loss t1 6.212508\n",
      "Epoch 7/10, Batch 1401/1650, Loss 33.921658, Loss rec 2.174580, loss rec t1 1.811209, loss kl 0.227585, loss_trans 0.040841, loss flux 52.163181, loss flux t1 54.991669, binary loss 13.450566, binary loss t1 16.216877\n",
      "Epoch 7/10, Batch 1411/1650, Loss 28.780209, Loss rec 4.697786, loss rec t1 5.122554, loss kl 0.266291, loss_trans 0.040925, loss flux 51.609867, loss flux t1 52.669941, binary loss 9.173772, binary loss t1 9.478882\n",
      "Epoch 7/10, Batch 1421/1650, Loss 38.190998, Loss rec 3.891045, loss rec t1 4.100288, loss kl 0.232906, loss_trans 0.040864, loss flux 50.351616, loss flux t1 51.465973, binary loss 14.209746, binary loss t1 15.716148\n",
      "Epoch 7/10, Batch 1431/1650, Loss 27.424997, Loss rec 2.362046, loss rec t1 2.533027, loss kl 0.271560, loss_trans 0.046496, loss flux 51.418594, loss flux t1 52.269009, binary loss 11.061895, binary loss t1 11.149975\n",
      "Epoch 7/10, Batch 1441/1650, Loss 25.402006, Loss rec 2.196292, loss rec t1 2.192788, loss kl 0.365162, loss_trans 0.061792, loss flux 50.774517, loss flux t1 54.844234, binary loss 10.259407, binary loss t1 10.326565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Batch 1451/1650, Loss 37.267178, Loss rec 3.800910, loss rec t1 4.075470, loss kl 0.275651, loss_trans 0.050419, loss flux 51.695751, loss flux t1 52.626274, binary loss 15.239695, binary loss t1 13.825033\n",
      "Epoch 7/10, Batch 1461/1650, Loss 24.496216, Loss rec 2.733725, loss rec t1 2.877149, loss kl 0.224603, loss_trans 0.045846, loss flux 50.857590, loss flux t1 51.092125, binary loss 9.583248, binary loss t1 9.031646\n",
      "Epoch 7/10, Batch 1471/1650, Loss 31.370176, Loss rec 2.357168, loss rec t1 2.651561, loss kl 0.294871, loss_trans 0.041678, loss flux 53.737820, loss flux t1 54.960613, binary loss 13.002110, binary loss t1 13.022789\n",
      "Epoch 7/10, Batch 1481/1650, Loss 24.687712, Loss rec 3.180969, loss rec t1 3.380606, loss kl 0.253729, loss_trans 0.037793, loss flux 53.058067, loss flux t1 54.959599, binary loss 9.328279, binary loss t1 8.506334\n",
      "Epoch 7/10, Batch 1491/1650, Loss 23.085260, Loss rec 3.113299, loss rec t1 2.621373, loss kl 0.367315, loss_trans 0.052229, loss flux 54.972145, loss flux t1 56.217697, binary loss 9.130887, binary loss t1 7.800159\n",
      "Epoch 7/10, Batch 1501/1650, Loss 34.860619, Loss rec 4.059986, loss rec t1 4.199016, loss kl 0.388627, loss_trans 0.054749, loss flux 56.137871, loss flux t1 57.849957, binary loss 12.978016, binary loss t1 13.180225\n",
      "Epoch 7/10, Batch 1511/1650, Loss 33.242218, Loss rec 3.106194, loss rec t1 3.107641, loss kl 0.215242, loss_trans 0.051203, loss flux 50.524456, loss flux t1 51.815086, binary loss 13.161743, binary loss t1 13.600192\n",
      "Epoch 7/10, Batch 1521/1650, Loss 22.283855, Loss rec 1.682937, loss rec t1 1.680107, loss kl 0.243364, loss_trans 0.036576, loss flux 49.542713, loss flux t1 52.894440, binary loss 9.621675, binary loss t1 9.019199\n",
      "Epoch 7/10, Batch 1531/1650, Loss 44.449554, Loss rec 5.120667, loss rec t1 5.100059, loss kl 0.240259, loss_trans 0.041405, loss flux 52.303917, loss flux t1 53.375587, binary loss 17.449520, binary loss t1 16.497648\n",
      "Epoch 7/10, Batch 1541/1650, Loss 22.569141, Loss rec 2.274948, loss rec t1 2.720650, loss kl 0.324486, loss_trans 0.061515, loss flux 51.590542, loss flux t1 53.995747, binary loss 8.094595, binary loss t1 9.092947\n",
      "Epoch 7/10, Batch 1551/1650, Loss 24.155579, Loss rec 3.350768, loss rec t1 4.044585, loss kl 0.158597, loss_trans 0.035955, loss flux 49.908482, loss flux t1 51.076473, binary loss 8.174444, binary loss t1 8.391230\n",
      "Epoch 7/10, Batch 1561/1650, Loss 39.393940, Loss rec 3.152343, loss rec t1 3.660875, loss kl 0.404293, loss_trans 0.062184, loss flux 54.929581, loss flux t1 56.798428, binary loss 16.745605, binary loss t1 15.368642\n",
      "Epoch 7/10, Batch 1571/1650, Loss 26.179237, Loss rec 2.946142, loss rec t1 4.326731, loss kl 0.367470, loss_trans 0.049777, loss flux 51.028500, loss flux t1 54.523201, binary loss 9.360117, binary loss t1 9.128999\n",
      "Epoch 7/10, Batch 1581/1650, Loss 25.580475, Loss rec 1.687815, loss rec t1 2.281634, loss kl 0.180792, loss_trans 0.029395, loss flux 46.848862, loss flux t1 47.155277, binary loss 11.342422, binary loss t1 10.058417\n",
      "Epoch 7/10, Batch 1591/1650, Loss 30.980843, Loss rec 2.272945, loss rec t1 2.272128, loss kl 0.283243, loss_trans 0.041922, loss flux 51.477337, loss flux t1 53.488869, binary loss 13.164915, binary loss t1 12.945690\n",
      "Epoch 7/10, Batch 1601/1650, Loss 31.286531, Loss rec 2.757409, loss rec t1 2.682456, loss kl 0.114162, loss_trans 0.029979, loss flux 47.367249, loss flux t1 47.397953, binary loss 11.944653, binary loss t1 13.757873\n",
      "Epoch 7/10, Batch 1611/1650, Loss 31.597193, Loss rec 1.939018, loss rec t1 1.934634, loss kl 0.141716, loss_trans 0.033511, loss flux 46.547733, loss flux t1 48.028339, binary loss 13.420859, binary loss t1 14.127457\n",
      "Epoch 7/10, Batch 1621/1650, Loss 22.790455, Loss rec 1.708650, loss rec t1 1.915671, loss kl 0.277279, loss_trans 0.047905, loss flux 48.909004, loss flux t1 51.072590, binary loss 9.496387, binary loss t1 9.344564\n",
      "Epoch 7/10, Batch 1631/1650, Loss 32.388813, Loss rec 3.647693, loss rec t1 3.504771, loss kl 0.184383, loss_trans 0.046584, loss flux 51.401253, loss flux t1 51.887508, binary loss 12.292339, binary loss t1 12.713041\n",
      "Epoch 7/10, Batch 1641/1650, Loss 24.260132, Loss rec 2.204935, loss rec t1 2.517219, loss kl 0.292442, loss_trans 0.059339, loss flux 52.524368, loss flux t1 56.127361, binary loss 9.717566, binary loss t1 9.468632\n",
      "Epoch 7/10, Train loss 23.049236, Eval loss 40.311115\n",
      "Epoch 8/10, Batch 1/1650, Loss 39.454365, Loss rec 3.361014, loss rec t1 3.457277, loss kl 0.306396, loss_trans 0.061652, loss flux 50.931835, loss flux t1 54.762928, binary loss 17.139774, binary loss t1 15.128250\n",
      "Epoch 8/10, Batch 11/1650, Loss 30.871037, Loss rec 2.322472, loss rec t1 2.366023, loss kl 0.315044, loss_trans 0.048891, loss flux 52.760162, loss flux t1 56.232559, binary loss 11.723475, binary loss t1 14.095131\n",
      "Epoch 8/10, Batch 21/1650, Loss 29.828320, Loss rec 4.999629, loss rec t1 5.644780, loss kl 0.210558, loss_trans 0.040595, loss flux 49.854301, loss flux t1 51.973743, binary loss 9.999622, binary loss t1 8.933136\n",
      "Epoch 8/10, Batch 31/1650, Loss 47.580627, Loss rec 4.449259, loss rec t1 5.367315, loss kl 0.172074, loss_trans 0.030264, loss flux 51.050621, loss flux t1 52.632408, binary loss 19.069805, binary loss t1 18.491911\n",
      "Epoch 8/10, Batch 41/1650, Loss 64.148926, Loss rec 5.199989, loss rec t1 6.275549, loss kl 0.211351, loss_trans 0.038990, loss flux 50.575050, loss flux t1 52.035332, binary loss 26.620785, binary loss t1 25.802258\n",
      "Epoch 8/10, Batch 51/1650, Loss 27.485874, Loss rec 3.877952, loss rec t1 3.690407, loss kl 0.184271, loss_trans 0.032963, loss flux 48.717129, loss flux t1 50.781052, binary loss 9.972777, binary loss t1 9.727506\n",
      "Epoch 8/10, Batch 61/1650, Loss 58.548061, Loss rec 9.096091, loss rec t1 9.217439, loss kl 0.369488, loss_trans 0.058910, loss flux 53.373642, loss flux t1 55.386555, binary loss 20.313431, binary loss t1 19.492702\n",
      "Epoch 8/10, Batch 71/1650, Loss 104.942818, Loss rec 13.738466, loss rec t1 13.802671, loss kl 0.401711, loss_trans 0.055812, loss flux 56.463451, loss flux t1 56.462105, binary loss 39.634544, binary loss t1 37.309612\n",
      "Epoch 8/10, Batch 81/1650, Loss 39.095997, Loss rec 6.562526, loss rec t1 6.792298, loss kl 0.200198, loss_trans 0.036996, loss flux 50.297356, loss flux t1 51.907494, binary loss 12.299173, binary loss t1 13.204807\n",
      "Epoch 8/10, Batch 91/1650, Loss 46.835144, Loss rec 4.346535, loss rec t1 4.901719, loss kl 0.248610, loss_trans 0.042270, loss flux 50.010174, loss flux t1 52.129181, binary loss 19.779331, binary loss t1 17.516678\n",
      "Epoch 8/10, Batch 101/1650, Loss 38.571247, Loss rec 3.736328, loss rec t1 4.338278, loss kl 0.171787, loss_trans 0.034007, loss flux 50.264660, loss flux t1 51.586739, binary loss 14.713161, binary loss t1 15.577682\n",
      "Epoch 8/10, Batch 111/1650, Loss 42.150478, Loss rec 7.622340, loss rec t1 7.324271, loss kl 0.359287, loss_trans 0.050493, loss flux 55.868420, loss flux t1 57.554897, binary loss 13.143749, binary loss t1 13.650336\n",
      "Epoch 8/10, Batch 121/1650, Loss 37.084480, Loss rec 6.962831, loss rec t1 9.175755, loss kl 0.355494, loss_trans 0.069396, loss flux 53.615746, loss flux t1 56.564655, binary loss 10.194199, binary loss t1 10.326809\n",
      "Epoch 8/10, Batch 131/1650, Loss 40.165176, Loss rec 7.846629, loss rec t1 8.382230, loss kl 0.116497, loss_trans 0.020971, loss flux 50.604168, loss flux t1 52.087631, binary loss 12.180473, binary loss t1 11.618378\n",
      "Epoch 8/10, Batch 141/1650, Loss 33.805931, Loss rec 3.432143, loss rec t1 5.154968, loss kl 0.190899, loss_trans 0.029310, loss flux 47.418095, loss flux t1 47.657948, binary loss 12.164611, binary loss t1 12.834002\n",
      "Epoch 8/10, Batch 151/1650, Loss 34.768311, Loss rec 3.443651, loss rec t1 4.174545, loss kl 0.380252, loss_trans 0.056045, loss flux 55.416359, loss flux t1 57.979557, binary loss 13.479300, binary loss t1 13.234515\n",
      "Epoch 8/10, Batch 161/1650, Loss 34.549767, Loss rec 3.774328, loss rec t1 4.518473, loss kl 0.424597, loss_trans 0.053476, loss flux 57.100918, loss flux t1 58.476349, binary loss 12.536148, binary loss t1 13.242746\n",
      "Epoch 8/10, Batch 171/1650, Loss 31.193871, Loss rec 3.732562, loss rec t1 4.254115, loss kl 0.436780, loss_trans 0.050979, loss flux 57.127098, loss flux t1 59.379547, binary loss 11.238056, binary loss t1 11.481376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Batch 181/1650, Loss 28.413101, Loss rec 1.774356, loss rec t1 1.845666, loss kl 0.196276, loss_trans 0.030850, loss flux 44.642498, loss flux t1 47.240074, binary loss 12.536149, binary loss t1 12.029805\n",
      "Epoch 8/10, Batch 191/1650, Loss 40.865334, Loss rec 4.706980, loss rec t1 5.311940, loss kl 0.373604, loss_trans 0.058630, loss flux 55.518814, loss flux t1 57.445713, binary loss 14.643805, binary loss t1 15.770372\n",
      "Epoch 8/10, Batch 201/1650, Loss 28.788042, Loss rec 2.953885, loss rec t1 2.801533, loss kl 0.221946, loss_trans 0.034094, loss flux 50.903751, loss flux t1 50.639160, binary loss 11.323452, binary loss t1 11.453133\n",
      "Epoch 8/10, Batch 211/1650, Loss 47.220402, Loss rec 4.242413, loss rec t1 4.852014, loss kl 0.151590, loss_trans 0.021914, loss flux 48.399330, loss flux t1 47.914173, binary loss 18.666122, binary loss t1 19.286348\n",
      "Epoch 8/10, Batch 221/1650, Loss 20.218149, Loss rec 2.785394, loss rec t1 2.415201, loss kl 0.249586, loss_trans 0.038698, loss flux 51.212391, loss flux t1 51.240993, binary loss 7.521827, binary loss t1 7.207444\n",
      "Epoch 8/10, Batch 231/1650, Loss 26.698484, Loss rec 3.386735, loss rec t1 3.127660, loss kl 0.336312, loss_trans 0.049651, loss flux 51.649139, loss flux t1 55.018139, binary loss 10.439716, binary loss t1 9.358409\n",
      "Epoch 8/10, Batch 241/1650, Loss 35.817898, Loss rec 3.584618, loss rec t1 3.558276, loss kl 0.233730, loss_trans 0.066799, loss flux 49.732533, loss flux t1 52.069813, binary loss 13.985884, binary loss t1 14.388594\n",
      "Epoch 8/10, Batch 251/1650, Loss 36.915157, Loss rec 3.836000, loss rec t1 3.766776, loss kl 0.331101, loss_trans 0.059105, loss flux 52.095608, loss flux t1 53.977051, binary loss 14.404391, binary loss t1 14.517785\n",
      "Epoch 8/10, Batch 261/1650, Loss 24.137926, Loss rec 2.718440, loss rec t1 2.805470, loss kl 0.200902, loss_trans 0.036480, loss flux 48.004780, loss flux t1 50.738136, binary loss 8.555922, binary loss t1 9.820711\n",
      "Epoch 8/10, Batch 271/1650, Loss 27.982313, Loss rec 2.565139, loss rec t1 2.878453, loss kl 0.300702, loss_trans 0.039817, loss flux 52.507130, loss flux t1 54.489368, binary loss 10.855537, binary loss t1 11.342665\n",
      "Epoch 8/10, Batch 281/1650, Loss 45.406788, Loss rec 3.823314, loss rec t1 4.915108, loss kl 0.260724, loss_trans 0.041115, loss flux 50.424126, loss flux t1 50.733456, binary loss 19.468121, binary loss t1 16.898407\n",
      "Epoch 8/10, Batch 291/1650, Loss 24.640976, Loss rec 2.509097, loss rec t1 2.957325, loss kl 0.313713, loss_trans 0.043563, loss flux 49.417946, loss flux t1 51.268185, binary loss 9.086114, binary loss t1 9.731166\n",
      "Epoch 8/10, Batch 301/1650, Loss 24.031317, Loss rec 2.851373, loss rec t1 3.130480, loss kl 0.187692, loss_trans 0.026492, loss flux 48.535892, loss flux t1 49.241371, binary loss 8.873477, binary loss t1 8.961802\n",
      "Epoch 8/10, Batch 311/1650, Loss 39.244167, Loss rec 2.435502, loss rec t1 3.440183, loss kl 0.219018, loss_trans 0.041499, loss flux 48.091774, loss flux t1 50.609379, binary loss 16.476240, binary loss t1 16.631723\n",
      "Epoch 8/10, Batch 321/1650, Loss 31.934046, Loss rec 2.666165, loss rec t1 3.040989, loss kl 0.264312, loss_trans 0.046926, loss flux 53.708401, loss flux t1 56.311684, binary loss 12.802831, binary loss t1 13.112822\n",
      "Epoch 8/10, Batch 331/1650, Loss 40.675175, Loss rec 9.626590, loss rec t1 11.149906, loss kl 0.173307, loss_trans 0.030372, loss flux 48.045345, loss flux t1 48.881542, binary loss 10.204336, binary loss t1 9.490662\n",
      "Epoch 8/10, Batch 341/1650, Loss 69.736603, Loss rec 12.297825, loss rec t1 13.366106, loss kl 0.325462, loss_trans 0.062956, loss flux 55.664284, loss flux t1 54.964588, binary loss 21.189421, binary loss t1 22.494835\n",
      "Epoch 8/10, Batch 351/1650, Loss 33.482491, Loss rec 5.101869, loss rec t1 4.285957, loss kl 0.381681, loss_trans 0.046562, loss flux 54.923439, loss flux t1 56.197556, binary loss 11.767759, binary loss t1 11.898662\n",
      "Epoch 8/10, Batch 361/1650, Loss 35.286591, Loss rec 4.634221, loss rec t1 5.176283, loss kl 0.240142, loss_trans 0.045000, loss flux 51.147552, loss flux t1 53.607800, binary loss 12.228420, binary loss t1 12.962527\n",
      "Epoch 8/10, Batch 371/1650, Loss 43.143547, Loss rec 4.433083, loss rec t1 4.410461, loss kl 0.400011, loss_trans 0.060604, loss flux 52.481853, loss flux t1 55.265942, binary loss 16.854609, binary loss t1 16.984779\n",
      "Epoch 8/10, Batch 381/1650, Loss 30.917948, Loss rec 3.224850, loss rec t1 3.824394, loss kl 0.299633, loss_trans 0.035991, loss flux 50.752262, loss flux t1 52.496956, binary loss 11.476738, binary loss t1 12.056341\n",
      "Epoch 8/10, Batch 391/1650, Loss 28.733032, Loss rec 4.215108, loss rec t1 3.991798, loss kl 0.290322, loss_trans 0.040276, loss flux 51.118931, loss flux t1 51.676235, binary loss 10.252882, binary loss t1 9.942647\n",
      "Epoch 8/10, Batch 401/1650, Loss 27.886330, Loss rec 4.283397, loss rec t1 4.419867, loss kl 0.192358, loss_trans 0.032458, loss flux 48.291996, loss flux t1 49.214462, binary loss 9.144308, binary loss t1 9.813943\n",
      "Epoch 8/10, Batch 411/1650, Loss 44.464405, Loss rec 5.549019, loss rec t1 5.511370, loss kl 0.392032, loss_trans 0.056576, loss flux 53.891659, loss flux t1 57.348164, binary loss 17.298674, binary loss t1 15.656734\n",
      "Epoch 8/10, Batch 421/1650, Loss 37.396538, Loss rec 5.143856, loss rec t1 5.073298, loss kl 0.348557, loss_trans 0.052362, loss flux 52.781998, loss flux t1 54.674549, binary loss 13.488262, binary loss t1 13.290203\n",
      "Epoch 8/10, Batch 431/1650, Loss 21.630617, Loss rec 2.678966, loss rec t1 2.824793, loss kl 0.275724, loss_trans 0.040801, loss flux 46.359962, loss flux t1 48.422901, binary loss 8.933558, binary loss t1 6.876774\n",
      "Epoch 8/10, Batch 441/1650, Loss 50.241817, Loss rec 4.325312, loss rec t1 4.412329, loss kl 0.282518, loss_trans 0.052959, loss flux 49.869663, loss flux t1 51.180027, binary loss 22.744194, binary loss t1 18.424509\n",
      "Epoch 8/10, Batch 451/1650, Loss 29.318045, Loss rec 3.236933, loss rec t1 3.195885, loss kl 0.208507, loss_trans 0.037382, loss flux 48.657623, loss flux t1 49.800869, binary loss 10.411961, binary loss t1 12.227377\n",
      "Epoch 8/10, Batch 461/1650, Loss 30.438120, Loss rec 4.080779, loss rec t1 3.843100, loss kl 0.215819, loss_trans 0.034037, loss flux 49.576488, loss flux t1 51.233994, binary loss 10.677668, binary loss t1 11.586719\n",
      "Epoch 8/10, Batch 471/1650, Loss 24.163328, Loss rec 2.961731, loss rec t1 3.752227, loss kl 0.222439, loss_trans 0.039632, loss flux 45.778072, loss flux t1 47.910389, binary loss 8.491690, binary loss t1 8.695608\n",
      "Epoch 8/10, Batch 481/1650, Loss 28.392191, Loss rec 2.087545, loss rec t1 2.005273, loss kl 0.209804, loss_trans 0.030931, loss flux 46.934444, loss flux t1 47.935547, binary loss 12.182850, binary loss t1 11.875787\n",
      "Epoch 8/10, Batch 491/1650, Loss 39.228878, Loss rec 2.760672, loss rec t1 3.603918, loss kl 0.139616, loss_trans 0.027654, loss flux 46.630939, loss flux t1 48.684010, binary loss 17.036383, binary loss t1 15.660639\n",
      "Epoch 8/10, Batch 501/1650, Loss 38.906509, Loss rec 4.090523, loss rec t1 5.259212, loss kl 0.269709, loss_trans 0.039282, loss flux 51.755478, loss flux t1 53.531712, binary loss 15.144112, binary loss t1 14.103672\n",
      "Epoch 8/10, Batch 511/1650, Loss 30.136848, Loss rec 4.940664, loss rec t1 5.420707, loss kl 0.252112, loss_trans 0.032966, loss flux 50.272919, loss flux t1 50.099720, binary loss 10.099352, binary loss t1 9.391046\n",
      "Epoch 8/10, Batch 521/1650, Loss 24.588018, Loss rec 2.754752, loss rec t1 1.832453, loss kl 0.343382, loss_trans 0.053771, loss flux 49.276905, loss flux t1 53.062424, binary loss 10.522429, binary loss t1 9.081232\n",
      "Epoch 8/10, Batch 531/1650, Loss 21.334263, Loss rec 2.893351, loss rec t1 3.001720, loss kl 0.171954, loss_trans 0.036751, loss flux 43.977230, loss flux t1 48.299370, binary loss 7.448567, binary loss t1 7.781920\n",
      "Epoch 8/10, Batch 541/1650, Loss 22.805775, Loss rec 1.731527, loss rec t1 1.918686, loss kl 0.205981, loss_trans 0.044952, loss flux 45.859135, loss flux t1 49.100597, binary loss 8.997301, binary loss t1 9.907327\n",
      "Epoch 8/10, Batch 551/1650, Loss 37.748199, Loss rec 1.392705, loss rec t1 1.773950, loss kl 0.276442, loss_trans 0.053244, loss flux 46.529778, loss flux t1 53.716496, binary loss 17.144409, binary loss t1 17.107447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Batch 561/1650, Loss 23.769119, Loss rec 2.106693, loss rec t1 2.696150, loss kl 0.219025, loss_trans 0.033607, loss flux 48.543159, loss flux t1 49.881393, binary loss 8.516029, binary loss t1 10.197616\n",
      "Epoch 8/10, Batch 571/1650, Loss 27.645510, Loss rec 2.259836, loss rec t1 2.458953, loss kl 0.252601, loss_trans 0.036489, loss flux 50.778332, loss flux t1 50.979267, binary loss 11.870419, binary loss t1 10.767212\n",
      "Epoch 8/10, Batch 581/1650, Loss 38.249416, Loss rec 3.381472, loss rec t1 3.608052, loss kl 0.207826, loss_trans 0.039561, loss flux 51.101604, loss flux t1 49.975868, binary loss 15.617331, binary loss t1 15.395175\n",
      "Epoch 8/10, Batch 591/1650, Loss 25.275873, Loss rec 2.239357, loss rec t1 3.133905, loss kl 0.180832, loss_trans 0.026558, loss flux 46.337860, loss flux t1 48.192657, binary loss 8.935266, binary loss t1 10.759956\n",
      "Epoch 8/10, Batch 601/1650, Loss 28.371872, Loss rec 4.971870, loss rec t1 5.718167, loss kl 0.223917, loss_trans 0.048644, loss flux 50.730347, loss flux t1 51.924484, binary loss 9.234097, binary loss t1 8.175177\n",
      "Epoch 8/10, Batch 611/1650, Loss 37.466946, Loss rec 4.114558, loss rec t1 3.550994, loss kl 0.235670, loss_trans 0.033817, loss flux 51.345184, loss flux t1 50.719391, binary loss 15.000277, binary loss t1 14.531631\n",
      "Epoch 8/10, Batch 621/1650, Loss 32.725800, Loss rec 6.822469, loss rec t1 7.719949, loss kl 0.265133, loss_trans 0.035092, loss flux 51.636757, loss flux t1 52.750816, binary loss 8.642538, binary loss t1 9.240621\n",
      "Epoch 8/10, Batch 631/1650, Loss 25.853485, Loss rec 3.446474, loss rec t1 4.000968, loss kl 0.302999, loss_trans 0.050979, loss flux 51.113762, loss flux t1 51.001675, binary loss 9.621919, binary loss t1 8.430145\n",
      "Epoch 8/10, Batch 641/1650, Loss 52.003708, Loss rec 6.119244, loss rec t1 8.433441, loss kl 0.245919, loss_trans 0.040906, loss flux 50.481621, loss flux t1 51.038059, binary loss 18.769089, binary loss t1 18.395111\n",
      "Epoch 8/10, Batch 651/1650, Loss 70.535782, Loss rec 5.229091, loss rec t1 6.318148, loss kl 0.267241, loss_trans 0.052458, loss flux 51.550480, loss flux t1 53.414593, binary loss 31.602289, binary loss t1 27.066555\n",
      "Epoch 8/10, Batch 661/1650, Loss 49.344505, Loss rec 14.685917, loss rec t1 14.974506, loss kl 0.297725, loss_trans 0.046362, loss flux 50.040737, loss flux t1 51.840057, binary loss 10.359575, binary loss t1 8.980414\n",
      "Epoch 8/10, Batch 671/1650, Loss 67.521606, Loss rec 11.769752, loss rec t1 14.323021, loss kl 0.235358, loss_trans 0.051739, loss flux 52.216908, loss flux t1 55.582603, binary loss 19.494900, binary loss t1 21.646843\n",
      "Epoch 8/10, Batch 681/1650, Loss 34.321930, Loss rec 3.643690, loss rec t1 3.888859, loss kl 0.216358, loss_trans 0.043182, loss flux 48.152901, loss flux t1 51.119087, binary loss 12.922082, binary loss t1 13.607759\n",
      "Epoch 8/10, Batch 691/1650, Loss 50.585438, Loss rec 8.937349, loss rec t1 7.629316, loss kl 0.419421, loss_trans 0.061594, loss flux 55.606674, loss flux t1 58.579338, binary loss 18.223587, binary loss t1 15.314174\n",
      "Epoch 8/10, Batch 701/1650, Loss 44.615967, Loss rec 6.020780, loss rec t1 5.922806, loss kl 0.414182, loss_trans 0.049526, loss flux 54.279686, loss flux t1 54.227699, binary loss 17.188694, binary loss t1 15.019979\n",
      "Epoch 8/10, Batch 711/1650, Loss 31.755896, Loss rec 7.486093, loss rec t1 7.434827, loss kl 0.544981, loss_trans 0.079507, loss flux 60.722740, loss flux t1 63.968555, binary loss 8.006580, binary loss t1 8.203908\n",
      "Epoch 8/10, Batch 721/1650, Loss 85.309174, Loss rec 6.834696, loss rec t1 8.121908, loss kl 0.367508, loss_trans 0.051454, loss flux 53.425911, loss flux t1 56.277519, binary loss 38.288990, binary loss t1 31.644623\n",
      "Epoch 8/10, Batch 731/1650, Loss 48.641613, Loss rec 3.849296, loss rec t1 3.751829, loss kl 0.257602, loss_trans 0.045560, loss flux 52.152176, loss flux t1 53.375027, binary loss 21.067730, binary loss t1 19.669596\n",
      "Epoch 8/10, Batch 741/1650, Loss 28.907467, Loss rec 5.827554, loss rec t1 5.932085, loss kl 0.230800, loss_trans 0.042095, loss flux 50.193657, loss flux t1 51.614384, binary loss 8.349874, binary loss t1 8.525059\n",
      "Epoch 8/10, Batch 751/1650, Loss 46.006489, Loss rec 4.003655, loss rec t1 4.183670, loss kl 0.289260, loss_trans 0.048459, loss flux 49.383965, loss flux t1 50.607426, binary loss 20.026312, binary loss t1 17.455132\n",
      "Epoch 8/10, Batch 761/1650, Loss 40.206619, Loss rec 4.705818, loss rec t1 5.040400, loss kl 0.357095, loss_trans 0.069452, loss flux 49.162674, loss flux t1 52.547726, binary loss 15.770861, binary loss t1 14.262997\n",
      "Epoch 8/10, Batch 771/1650, Loss 27.542025, Loss rec 3.562561, loss rec t1 3.217805, loss kl 0.215429, loss_trans 0.046324, loss flux 45.167892, loss flux t1 48.314533, binary loss 10.165778, binary loss t1 10.334129\n",
      "Epoch 8/10, Batch 781/1650, Loss 54.856167, Loss rec 4.797063, loss rec t1 4.634601, loss kl 0.231821, loss_trans 0.043513, loss flux 48.099041, loss flux t1 49.908680, binary loss 22.851484, binary loss t1 22.297686\n",
      "Epoch 8/10, Batch 791/1650, Loss 24.724638, Loss rec 3.182367, loss rec t1 4.079110, loss kl 0.209378, loss_trans 0.049712, loss flux 48.724113, loss flux t1 50.210987, binary loss 8.159558, binary loss t1 9.044514\n",
      "Epoch 8/10, Batch 801/1650, Loss 39.426743, Loss rec 4.570217, loss rec t1 7.732754, loss kl 0.315130, loss_trans 0.053893, loss flux 51.533031, loss flux t1 53.735008, binary loss 12.863955, binary loss t1 13.890793\n",
      "Epoch 8/10, Batch 811/1650, Loss 84.406456, Loss rec 8.834375, loss rec t1 11.600375, loss kl 0.399535, loss_trans 0.066629, loss flux 56.037582, loss flux t1 58.420448, binary loss 34.388058, binary loss t1 29.117485\n",
      "Epoch 8/10, Batch 821/1650, Loss 29.199741, Loss rec 3.823199, loss rec t1 3.294997, loss kl 0.261260, loss_trans 0.046200, loss flux 47.791142, loss flux t1 50.610794, binary loss 10.277400, binary loss t1 11.496685\n",
      "Epoch 8/10, Batch 831/1650, Loss 25.803770, Loss rec 2.682650, loss rec t1 3.137793, loss kl 0.430112, loss_trans 0.049529, loss flux 49.955032, loss flux t1 51.203548, binary loss 10.968445, binary loss t1 8.535243\n",
      "Epoch 8/10, Batch 841/1650, Loss 24.614567, Loss rec 3.120985, loss rec t1 3.558602, loss kl 0.159669, loss_trans 0.028600, loss flux 45.073387, loss flux t1 46.441727, binary loss 8.654495, binary loss t1 9.092215\n",
      "Epoch 8/10, Batch 851/1650, Loss 30.835394, Loss rec 3.800225, loss rec t1 5.258729, loss kl 0.285964, loss_trans 0.051323, loss flux 49.407761, loss flux t1 51.530304, binary loss 10.474060, binary loss t1 10.965094\n",
      "Epoch 8/10, Batch 861/1650, Loss 47.371143, Loss rec 4.225554, loss rec t1 4.872170, loss kl 0.364208, loss_trans 0.057696, loss flux 51.763725, loss flux t1 55.033592, binary loss 18.826483, binary loss t1 19.025032\n",
      "Epoch 8/10, Batch 871/1650, Loss 32.685707, Loss rec 3.318414, loss rec t1 3.020864, loss kl 0.322496, loss_trans 0.046249, loss flux 53.088120, loss flux t1 54.238251, binary loss 12.336136, binary loss t1 13.641550\n",
      "Epoch 8/10, Batch 881/1650, Loss 28.066481, Loss rec 3.306762, loss rec t1 3.928551, loss kl 0.266412, loss_trans 0.050759, loss flux 49.450062, loss flux t1 51.802048, binary loss 9.602950, binary loss t1 10.911047\n",
      "Epoch 8/10, Batch 891/1650, Loss 25.612289, Loss rec 2.095349, loss rec t1 2.641101, loss kl 0.235540, loss_trans 0.038954, loss flux 49.450848, loss flux t1 53.000290, binary loss 9.756237, binary loss t1 10.845109\n",
      "Epoch 8/10, Batch 901/1650, Loss 23.640621, Loss rec 2.582348, loss rec t1 2.729800, loss kl 0.384392, loss_trans 0.065251, loss flux 52.735191, loss flux t1 55.570347, binary loss 8.855484, binary loss t1 9.023348\n",
      "Epoch 8/10, Batch 911/1650, Loss 23.675417, Loss rec 1.580925, loss rec t1 1.774361, loss kl 0.217217, loss_trans 0.034997, loss flux 45.348003, loss flux t1 47.810261, binary loss 9.813147, binary loss t1 10.254769\n",
      "Epoch 8/10, Batch 921/1650, Loss 26.375214, Loss rec 1.622947, loss rec t1 1.925467, loss kl 0.250153, loss_trans 0.041185, loss flux 48.931744, loss flux t1 49.995319, binary loss 12.252205, binary loss t1 10.283257\n",
      "Epoch 8/10, Batch 931/1650, Loss 18.013674, Loss rec 2.605527, loss rec t1 2.463552, loss kl 0.271536, loss_trans 0.032477, loss flux 48.930206, loss flux t1 50.427299, binary loss 6.606919, binary loss t1 6.033663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Batch 941/1650, Loss 28.748957, Loss rec 2.562178, loss rec t1 2.708359, loss kl 0.331574, loss_trans 0.045939, loss flux 48.761166, loss flux t1 51.445274, binary loss 11.740493, binary loss t1 11.360415\n",
      "Epoch 8/10, Batch 951/1650, Loss 32.052975, Loss rec 2.153718, loss rec t1 2.057660, loss kl 0.204811, loss_trans 0.032958, loss flux 49.681026, loss flux t1 52.352188, binary loss 12.784348, binary loss t1 14.819478\n",
      "Epoch 8/10, Batch 961/1650, Loss 21.421299, Loss rec 2.794295, loss rec t1 2.945829, loss kl 0.177193, loss_trans 0.025231, loss flux 47.788151, loss flux t1 47.104874, binary loss 7.860793, binary loss t1 7.617960\n",
      "Epoch 8/10, Batch 971/1650, Loss 33.877556, Loss rec 4.002579, loss rec t1 4.545768, loss kl 0.215541, loss_trans 0.043015, loss flux 51.263546, loss flux t1 52.116962, binary loss 12.036640, binary loss t1 13.034015\n",
      "Epoch 8/10, Batch 981/1650, Loss 45.484386, Loss rec 3.645599, loss rec t1 3.969720, loss kl 0.204384, loss_trans 0.038493, loss flux 48.342464, loss flux t1 49.642937, binary loss 17.917191, binary loss t1 19.709000\n",
      "Epoch 8/10, Batch 991/1650, Loss 25.178469, Loss rec 4.530570, loss rec t1 5.667661, loss kl 0.185216, loss_trans 0.044098, loss flux 48.542103, loss flux t1 50.532978, binary loss 6.413253, binary loss t1 8.337671\n",
      "Epoch 8/10, Batch 1001/1650, Loss 90.008049, Loss rec 19.309000, loss rec t1 25.199036, loss kl 0.396764, loss_trans 0.064799, loss flux 55.670998, loss flux t1 57.588737, binary loss 23.338612, binary loss t1 21.699846\n",
      "Epoch 8/10, Batch 1011/1650, Loss 72.763130, Loss rec 15.701982, loss rec t1 14.581932, loss kl 0.214358, loss_trans 0.050706, loss flux 48.292385, loss flux t1 50.596737, binary loss 21.705282, binary loss t1 20.508871\n",
      "Epoch 8/10, Batch 1021/1650, Loss 56.569454, Loss rec 4.529119, loss rec t1 5.027938, loss kl 0.259811, loss_trans 0.043698, loss flux 49.148907, loss flux t1 50.459000, binary loss 21.949999, binary loss t1 24.758888\n",
      "Epoch 8/10, Batch 1031/1650, Loss 34.297371, Loss rec 4.698092, loss rec t1 4.160883, loss kl 0.451616, loss_trans 0.053194, loss flux 52.961323, loss flux t1 53.641590, binary loss 12.400366, binary loss t1 12.533218\n",
      "Epoch 8/10, Batch 1041/1650, Loss 22.469906, Loss rec 2.413698, loss rec t1 3.018838, loss kl 0.276991, loss_trans 0.032519, loss flux 49.209694, loss flux t1 49.933834, binary loss 7.997973, binary loss t1 8.729886\n",
      "Epoch 8/10, Batch 1051/1650, Loss 32.216640, Loss rec 8.131665, loss rec t1 9.945175, loss kl 0.187669, loss_trans 0.032056, loss flux 47.826588, loss flux t1 48.791859, binary loss 7.005545, binary loss t1 6.914536\n",
      "Epoch 8/10, Batch 1061/1650, Loss 35.657581, Loss rec 3.895071, loss rec t1 3.851377, loss kl 0.382421, loss_trans 0.070539, loss flux 55.913170, loss flux t1 57.627693, binary loss 13.971552, binary loss t1 13.486620\n",
      "Epoch 8/10, Batch 1071/1650, Loss 47.064137, Loss rec 5.865738, loss rec t1 6.990814, loss kl 0.408394, loss_trans 0.066126, loss flux 50.907478, loss flux t1 55.080696, binary loss 15.813925, binary loss t1 17.919142\n",
      "Epoch 8/10, Batch 1081/1650, Loss 40.515659, Loss rec 4.961866, loss rec t1 5.031201, loss kl 0.303678, loss_trans 0.051228, loss flux 51.198463, loss flux t1 51.555382, binary loss 16.303005, binary loss t1 13.864679\n",
      "Epoch 8/10, Batch 1091/1650, Loss 26.311054, Loss rec 3.024307, loss rec t1 3.519773, loss kl 0.161531, loss_trans 0.036726, loss flux 44.593300, loss flux t1 47.559513, binary loss 9.188349, binary loss t1 10.380367\n",
      "Epoch 8/10, Batch 1101/1650, Loss 31.885162, Loss rec 2.443516, loss rec t1 2.667195, loss kl 0.223326, loss_trans 0.040562, loss flux 46.936008, loss flux t1 47.168236, binary loss 14.306305, binary loss t1 12.204258\n",
      "Epoch 8/10, Batch 1111/1650, Loss 44.932430, Loss rec 2.839810, loss rec t1 3.862944, loss kl 0.204985, loss_trans 0.043735, loss flux 43.656532, loss flux t1 46.663338, binary loss 21.481110, binary loss t1 16.499846\n",
      "Epoch 8/10, Batch 1121/1650, Loss 35.736904, Loss rec 3.865041, loss rec t1 3.879066, loss kl 0.345500, loss_trans 0.068539, loss flux 52.011982, loss flux t1 53.620056, binary loss 13.224753, binary loss t1 14.354004\n",
      "Epoch 8/10, Batch 1131/1650, Loss 42.148609, Loss rec 6.128555, loss rec t1 6.457817, loss kl 0.507492, loss_trans 0.065653, loss flux 55.075203, loss flux t1 57.385830, binary loss 14.780807, binary loss t1 14.208282\n",
      "Epoch 8/10, Batch 1141/1650, Loss 42.088280, Loss rec 5.885936, loss rec t1 5.504099, loss kl 0.291706, loss_trans 0.052063, loss flux 52.270245, loss flux t1 53.923168, binary loss 14.735125, binary loss t1 15.619349\n",
      "Epoch 8/10, Batch 1151/1650, Loss 23.095095, Loss rec 2.078701, loss rec t1 2.424329, loss kl 0.388423, loss_trans 0.048676, loss flux 54.775597, loss flux t1 57.346638, binary loss 8.843769, binary loss t1 9.311197\n",
      "Epoch 8/10, Batch 1161/1650, Loss 31.681492, Loss rec 4.009535, loss rec t1 4.562744, loss kl 0.271227, loss_trans 0.047802, loss flux 50.672977, loss flux t1 53.394028, binary loss 10.985461, binary loss t1 11.804723\n",
      "Epoch 8/10, Batch 1171/1650, Loss 29.721312, Loss rec 2.142844, loss rec t1 2.663305, loss kl 0.243301, loss_trans 0.036065, loss flux 49.183949, loss flux t1 50.674809, binary loss 12.249764, binary loss t1 12.386034\n",
      "Epoch 8/10, Batch 1181/1650, Loss 29.191395, Loss rec 3.870774, loss rec t1 3.793882, loss kl 0.458619, loss_trans 0.062600, loss flux 54.218155, loss flux t1 57.551659, binary loss 10.182795, binary loss t1 10.822723\n",
      "Epoch 8/10, Batch 1191/1650, Loss 29.872862, Loss rec 3.368515, loss rec t1 3.666478, loss kl 0.345849, loss_trans 0.049520, loss flux 53.729645, loss flux t1 55.755157, binary loss 11.233175, binary loss t1 11.209325\n",
      "Epoch 8/10, Batch 1201/1650, Loss 20.044960, Loss rec 1.892040, loss rec t1 1.913816, loss kl 0.251133, loss_trans 0.048445, loss flux 46.868542, loss flux t1 46.262596, binary loss 8.890983, binary loss t1 7.048542\n",
      "Epoch 8/10, Batch 1211/1650, Loss 31.182743, Loss rec 3.415588, loss rec t1 3.530631, loss kl 0.326836, loss_trans 0.049355, loss flux 51.975964, loss flux t1 53.721527, binary loss 12.561218, binary loss t1 11.299114\n",
      "Epoch 8/10, Batch 1221/1650, Loss 50.451061, Loss rec 2.681496, loss rec t1 3.688778, loss kl 0.270500, loss_trans 0.046559, loss flux 48.622009, loss flux t1 51.185303, binary loss 24.007271, binary loss t1 19.756458\n",
      "Epoch 8/10, Batch 1231/1650, Loss 28.521372, Loss rec 2.057195, loss rec t1 2.370382, loss kl 0.263291, loss_trans 0.043676, loss flux 46.566158, loss flux t1 49.433495, binary loss 11.937088, binary loss t1 11.849739\n",
      "Epoch 8/10, Batch 1241/1650, Loss 19.700708, Loss rec 2.644703, loss rec t1 3.507717, loss kl 0.261521, loss_trans 0.040961, loss flux 47.290245, loss flux t1 51.017616, binary loss 6.685548, binary loss t1 6.560260\n",
      "Epoch 8/10, Batch 1251/1650, Loss 32.996986, Loss rec 3.505578, loss rec t1 3.833173, loss kl 0.214611, loss_trans 0.034980, loss flux 47.209190, loss flux t1 47.339657, binary loss 12.703100, binary loss t1 12.705542\n",
      "Epoch 8/10, Batch 1261/1650, Loss 40.651871, Loss rec 4.891896, loss rec t1 4.500226, loss kl 0.226132, loss_trans 0.038616, loss flux 51.484310, loss flux t1 51.140450, binary loss 15.684733, binary loss t1 15.310267\n",
      "Epoch 8/10, Batch 1271/1650, Loss 30.689585, Loss rec 4.090583, loss rec t1 3.643918, loss kl 0.285828, loss_trans 0.048157, loss flux 52.210793, loss flux t1 52.977711, binary loss 11.233907, binary loss t1 11.387194\n",
      "Epoch 8/10, Batch 1281/1650, Loss 27.802174, Loss rec 4.083264, loss rec t1 4.980473, loss kl 0.251311, loss_trans 0.040588, loss flux 47.091301, loss flux t1 47.254341, binary loss 9.740439, binary loss t1 8.706100\n",
      "Epoch 8/10, Batch 1291/1650, Loss 21.664591, Loss rec 1.967965, loss rec t1 2.097788, loss kl 0.180984, loss_trans 0.033716, loss flux 43.749317, loss flux t1 45.913052, binary loss 8.915320, binary loss t1 8.468817\n",
      "Epoch 8/10, Batch 1301/1650, Loss 22.982847, Loss rec 3.321568, loss rec t1 2.797869, loss kl 0.235409, loss_trans 0.030797, loss flux 47.593098, loss flux t1 48.415520, binary loss 8.110392, binary loss t1 8.486810\n",
      "Epoch 8/10, Batch 1311/1650, Loss 27.119463, Loss rec 2.385106, loss rec t1 2.181815, loss kl 0.216250, loss_trans 0.041956, loss flux 48.298298, loss flux t1 50.863762, binary loss 10.990343, binary loss t1 11.303993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Batch 1321/1650, Loss 24.464516, Loss rec 2.124259, loss rec t1 2.468059, loss kl 0.383759, loss_trans 0.056790, loss flux 51.394604, loss flux t1 54.789001, binary loss 9.727261, binary loss t1 9.704388\n",
      "Epoch 8/10, Batch 1331/1650, Loss 23.952063, Loss rec 2.967715, loss rec t1 3.481813, loss kl 0.209680, loss_trans 0.040529, loss flux 50.521225, loss flux t1 52.158665, binary loss 8.235258, binary loss t1 9.017068\n",
      "Epoch 8/10, Batch 1341/1650, Loss 20.872927, Loss rec 1.397178, loss rec t1 1.899916, loss kl 0.263668, loss_trans 0.043864, loss flux 43.749470, loss flux t1 48.523125, binary loss 7.935939, binary loss t1 9.332362\n",
      "Epoch 8/10, Batch 1351/1650, Loss 23.602661, Loss rec 1.221194, loss rec t1 1.704188, loss kl 0.168854, loss_trans 0.030969, loss flux 46.763348, loss flux t1 49.472481, binary loss 8.933314, binary loss t1 11.544142\n",
      "Epoch 8/10, Batch 1361/1650, Loss 33.993401, Loss rec 2.843448, loss rec t1 2.971127, loss kl 0.408322, loss_trans 0.056211, loss flux 53.223930, loss flux t1 53.680157, binary loss 14.906096, binary loss t1 12.808200\n",
      "Epoch 8/10, Batch 1371/1650, Loss 24.064281, Loss rec 1.435828, loss rec t1 1.605115, loss kl 0.214308, loss_trans 0.048119, loss flux 44.162716, loss flux t1 48.929626, binary loss 9.793932, binary loss t1 10.966980\n",
      "Epoch 8/10, Batch 1381/1650, Loss 31.319859, Loss rec 2.235568, loss rec t1 2.174895, loss kl 0.312111, loss_trans 0.037067, loss flux 52.906784, loss flux t1 54.081673, binary loss 13.732803, binary loss t1 12.827414\n",
      "Epoch 8/10, Batch 1391/1650, Loss 20.398579, Loss rec 2.951200, loss rec t1 2.916925, loss kl 0.383410, loss_trans 0.065023, loss flux 48.002106, loss flux t1 52.765488, binary loss 7.075565, binary loss t1 7.006455\n",
      "Epoch 8/10, Batch 1401/1650, Loss 22.981161, Loss rec 2.331203, loss rec t1 1.840454, loss kl 0.233687, loss_trans 0.040528, loss flux 50.226955, loss flux t1 52.877213, binary loss 7.916727, binary loss t1 10.618563\n",
      "Epoch 8/10, Batch 1411/1650, Loss 24.259634, Loss rec 2.853929, loss rec t1 2.893995, loss kl 0.273918, loss_trans 0.038785, loss flux 50.132385, loss flux t1 51.440994, binary loss 8.646930, binary loss t1 9.552076\n",
      "Epoch 8/10, Batch 1421/1650, Loss 26.636570, Loss rec 2.151181, loss rec t1 2.027087, loss kl 0.233590, loss_trans 0.039134, loss flux 47.952805, loss flux t1 49.305462, binary loss 10.750927, binary loss t1 11.434650\n",
      "Epoch 8/10, Batch 1431/1650, Loss 27.736952, Loss rec 2.029446, loss rec t1 2.069416, loss kl 0.261538, loss_trans 0.043238, loss flux 49.696419, loss flux t1 51.028732, binary loss 11.323208, binary loss t1 12.010105\n",
      "Epoch 8/10, Batch 1441/1650, Loss 31.320770, Loss rec 2.017994, loss rec t1 2.585793, loss kl 0.367360, loss_trans 0.058044, loss flux 49.059490, loss flux t1 53.790909, binary loss 12.892375, binary loss t1 13.399205\n",
      "Epoch 8/10, Batch 1451/1650, Loss 28.113253, Loss rec 2.483388, loss rec t1 2.375543, loss kl 0.264439, loss_trans 0.048298, loss flux 49.377125, loss flux t1 50.398026, binary loss 11.878959, binary loss t1 11.062626\n",
      "Epoch 8/10, Batch 1461/1650, Loss 24.230534, Loss rec 1.404689, loss rec t1 1.677864, loss kl 0.206206, loss_trans 0.042394, loss flux 48.246063, loss flux t1 48.726002, binary loss 10.347976, binary loss t1 10.551404\n",
      "Epoch 8/10, Batch 1471/1650, Loss 24.118305, Loss rec 1.979591, loss rec t1 1.949411, loss kl 0.275964, loss_trans 0.036162, loss flux 51.881573, loss flux t1 52.678925, binary loss 9.796372, binary loss t1 10.080805\n",
      "Epoch 8/10, Batch 1481/1650, Loss 21.641108, Loss rec 1.626339, loss rec t1 1.672658, loss kl 0.246020, loss_trans 0.034819, loss flux 50.235424, loss flux t1 52.210163, binary loss 8.687066, binary loss t1 9.374207\n",
      "Epoch 8/10, Batch 1491/1650, Loss 19.573572, Loss rec 1.957525, loss rec t1 1.990539, loss kl 0.367198, loss_trans 0.046550, loss flux 52.280708, loss flux t1 53.766979, binary loss 7.759290, binary loss t1 7.452471\n",
      "Epoch 8/10, Batch 1501/1650, Loss 32.361389, Loss rec 3.058077, loss rec t1 3.947532, loss kl 0.404681, loss_trans 0.052034, loss flux 54.603043, loss flux t1 56.890179, binary loss 12.958070, binary loss t1 11.940994\n",
      "Epoch 8/10, Batch 1511/1650, Loss 32.281322, Loss rec 3.018588, loss rec t1 3.457505, loss kl 0.201486, loss_trans 0.046450, loss flux 49.053024, loss flux t1 50.372795, binary loss 12.125207, binary loss t1 13.432085\n",
      "Epoch 8/10, Batch 1521/1650, Loss 27.617521, Loss rec 1.533157, loss rec t1 1.458251, loss kl 0.243337, loss_trans 0.035558, loss flux 47.753300, loss flux t1 51.167274, binary loss 12.385057, binary loss t1 11.962160\n",
      "Epoch 8/10, Batch 1531/1650, Loss 26.180607, Loss rec 2.497676, loss rec t1 2.569749, loss kl 0.226549, loss_trans 0.036177, loss flux 49.874359, loss flux t1 51.396774, binary loss 10.303690, binary loss t1 10.546766\n",
      "Epoch 8/10, Batch 1541/1650, Loss 25.574825, Loss rec 2.510095, loss rec t1 2.325211, loss kl 0.313531, loss_trans 0.058026, loss flux 49.472012, loss flux t1 52.084549, binary loss 9.574706, binary loss t1 10.793259\n",
      "Epoch 8/10, Batch 1551/1650, Loss 23.548025, Loss rec 2.268860, loss rec t1 2.654077, loss kl 0.160471, loss_trans 0.034428, loss flux 47.835087, loss flux t1 49.158020, binary loss 9.514380, binary loss t1 8.915810\n",
      "Epoch 8/10, Batch 1561/1650, Loss 25.477413, Loss rec 2.202328, loss rec t1 2.475128, loss kl 0.376502, loss_trans 0.054024, loss flux 52.106075, loss flux t1 53.399525, binary loss 10.352368, binary loss t1 10.017062\n",
      "Epoch 8/10, Batch 1571/1650, Loss 23.073746, Loss rec 1.652923, loss rec t1 1.818393, loss kl 0.364401, loss_trans 0.045065, loss flux 48.709141, loss flux t1 52.188068, binary loss 10.147718, binary loss t1 9.045246\n",
      "Epoch 8/10, Batch 1581/1650, Loss 24.095715, Loss rec 1.758207, loss rec t1 1.706569, loss kl 0.168473, loss_trans 0.026365, loss flux 45.506313, loss flux t1 45.936909, binary loss 10.707130, binary loss t1 9.728970\n",
      "Epoch 8/10, Batch 1591/1650, Loss 20.598444, Loss rec 1.592726, loss rec t1 1.504189, loss kl 0.279784, loss_trans 0.038108, loss flux 48.711941, loss flux t1 50.914978, binary loss 8.668829, binary loss t1 8.514809\n",
      "Epoch 8/10, Batch 1601/1650, Loss 23.462088, Loss rec 2.845049, loss rec t1 3.683814, loss kl 0.106105, loss_trans 0.027400, loss flux 46.063503, loss flux t1 46.852467, binary loss 7.854692, binary loss t1 8.945028\n",
      "Epoch 8/10, Batch 1611/1650, Loss 29.138802, Loss rec 1.776096, loss rec t1 2.454699, loss kl 0.139231, loss_trans 0.032382, loss flux 45.085381, loss flux t1 46.683598, binary loss 12.778071, binary loss t1 11.958321\n",
      "Epoch 8/10, Batch 1621/1650, Loss 32.971905, Loss rec 2.812483, loss rec t1 2.158179, loss kl 0.265130, loss_trans 0.044450, loss flux 46.703121, loss flux t1 48.846573, binary loss 14.268365, binary loss t1 13.423299\n",
      "Epoch 8/10, Batch 1631/1650, Loss 26.928080, Loss rec 4.124615, loss rec t1 6.405750, loss kl 0.167959, loss_trans 0.041166, loss flux 49.179089, loss flux t1 49.077591, binary loss 7.269787, binary loss t1 8.918802\n",
      "Epoch 8/10, Batch 1641/1650, Loss 32.563633, Loss rec 3.563621, loss rec t1 3.231035, loss kl 0.288064, loss_trans 0.054275, loss flux 50.554298, loss flux t1 53.630951, binary loss 13.057133, binary loss t1 12.369504\n",
      "Epoch 8/10, Train loss 26.078552, Eval loss 35.410835\n",
      "Epoch 9/10, Batch 1/1650, Loss 28.770088, Loss rec 2.189333, loss rec t1 2.100727, loss kl 0.286175, loss_trans 0.057320, loss flux 48.581875, loss flux t1 51.724186, binary loss 12.544445, binary loss t1 11.592087\n",
      "Epoch 9/10, Batch 11/1650, Loss 31.877110, Loss rec 2.605649, loss rec t1 3.273212, loss kl 0.305204, loss_trans 0.045227, loss flux 49.656330, loss flux t1 53.823231, binary loss 12.414765, binary loss t1 13.233050\n",
      "Epoch 9/10, Batch 21/1650, Loss 28.438450, Loss rec 3.743742, loss rec t1 4.400624, loss kl 0.207276, loss_trans 0.039505, loss flux 48.342697, loss flux t1 50.645592, binary loss 10.290577, binary loss t1 9.756725\n",
      "Epoch 9/10, Batch 31/1650, Loss 47.717232, Loss rec 2.830014, loss rec t1 3.549472, loss kl 0.160797, loss_trans 0.026973, loss flux 48.631363, loss flux t1 50.418713, binary loss 20.352591, binary loss t1 20.797384\n",
      "Epoch 9/10, Batch 41/1650, Loss 36.682121, Loss rec 3.235660, loss rec t1 4.085100, loss kl 0.201449, loss_trans 0.034130, loss flux 48.263771, loss flux t1 49.406574, binary loss 14.353028, binary loss t1 14.772754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Batch 51/1650, Loss 36.985413, Loss rec 2.367162, loss rec t1 3.261704, loss kl 0.183588, loss_trans 0.032234, loss flux 47.469620, loss flux t1 49.483837, binary loss 15.303923, binary loss t1 15.836801\n",
      "Epoch 9/10, Batch 61/1650, Loss 37.221073, Loss rec 7.595109, loss rec t1 7.242710, loss kl 0.315519, loss_trans 0.049708, loss flux 50.517296, loss flux t1 51.379025, binary loss 11.497726, binary loss t1 10.520297\n",
      "Epoch 9/10, Batch 71/1650, Loss 56.151817, Loss rec 4.828153, loss rec t1 5.242312, loss kl 0.353488, loss_trans 0.047035, loss flux 53.441830, loss flux t1 54.161343, binary loss 23.249557, binary loss t1 22.431271\n",
      "Epoch 9/10, Batch 81/1650, Loss 22.172981, Loss rec 3.056413, loss rec t1 3.243574, loss kl 0.184805, loss_trans 0.034073, loss flux 47.522522, loss flux t1 48.140358, binary loss 7.850788, binary loss t1 7.803330\n",
      "Epoch 9/10, Batch 91/1650, Loss 31.859533, Loss rec 5.514713, loss rec t1 6.830896, loss kl 0.221312, loss_trans 0.033333, loss flux 47.696568, loss flux t1 48.935909, binary loss 9.393486, binary loss t1 9.865793\n",
      "Epoch 9/10, Batch 101/1650, Loss 34.358234, Loss rec 4.130679, loss rec t1 4.555192, loss kl 0.167904, loss_trans 0.033962, loss flux 48.957138, loss flux t1 50.414757, binary loss 11.671934, binary loss t1 13.798562\n",
      "Epoch 9/10, Batch 111/1650, Loss 38.037086, Loss rec 2.970170, loss rec t1 3.390191, loss kl 0.370370, loss_trans 0.045893, loss flux 54.372768, loss flux t1 56.674950, binary loss 14.999300, binary loss t1 16.261162\n",
      "Epoch 9/10, Batch 121/1650, Loss 38.429337, Loss rec 5.627299, loss rec t1 6.560098, loss kl 0.339454, loss_trans 0.058319, loss flux 50.830830, loss flux t1 53.990742, binary loss 12.832783, binary loss t1 13.011385\n",
      "Epoch 9/10, Batch 131/1650, Loss 35.610947, Loss rec 3.663453, loss rec t1 4.209518, loss kl 0.130152, loss_trans 0.020035, loss flux 48.981670, loss flux t1 49.979385, binary loss 14.027241, binary loss t1 13.560547\n",
      "Epoch 9/10, Batch 141/1650, Loss 25.403351, Loss rec 2.809487, loss rec t1 3.382850, loss kl 0.182558, loss_trans 0.027206, loss flux 45.797173, loss flux t1 45.815762, binary loss 9.155713, binary loss t1 9.845537\n",
      "Epoch 9/10, Batch 151/1650, Loss 37.562855, Loss rec 3.334433, loss rec t1 3.582789, loss kl 0.358319, loss_trans 0.051735, loss flux 52.533463, loss flux t1 54.429924, binary loss 14.909513, binary loss t1 15.326066\n",
      "Epoch 9/10, Batch 161/1650, Loss 28.500849, Loss rec 4.055104, loss rec t1 3.828594, loss kl 0.401854, loss_trans 0.046857, loss flux 54.974995, loss flux t1 56.283386, binary loss 10.085196, binary loss t1 10.083245\n",
      "Epoch 9/10, Batch 171/1650, Loss 34.171696, Loss rec 4.082561, loss rec t1 4.745379, loss kl 0.405229, loss_trans 0.042637, loss flux 54.213318, loss flux t1 56.098347, binary loss 12.580677, binary loss t1 12.315214\n",
      "Epoch 9/10, Batch 181/1650, Loss 21.774181, Loss rec 1.731581, loss rec t1 1.923542, loss kl 0.186914, loss_trans 0.028796, loss flux 43.316322, loss flux t1 45.215237, binary loss 9.128446, binary loss t1 8.774902\n",
      "Epoch 9/10, Batch 191/1650, Loss 34.056820, Loss rec 2.976408, loss rec t1 3.943488, loss kl 0.334877, loss_trans 0.050539, loss flux 52.906090, loss flux t1 54.902580, binary loss 12.942272, binary loss t1 13.809234\n",
      "Epoch 9/10, Batch 201/1650, Loss 27.850962, Loss rec 2.250780, loss rec t1 2.054875, loss kl 0.212612, loss_trans 0.029577, loss flux 48.950565, loss flux t1 49.029144, binary loss 11.785754, binary loss t1 11.517364\n",
      "Epoch 9/10, Batch 211/1650, Loss 20.570456, Loss rec 2.519002, loss rec t1 2.570490, loss kl 0.150303, loss_trans 0.019660, loss flux 47.136581, loss flux t1 46.118855, binary loss 6.958265, binary loss t1 8.352736\n",
      "Epoch 9/10, Batch 221/1650, Loss 24.065256, Loss rec 2.192002, loss rec t1 2.094737, loss kl 0.233350, loss_trans 0.034159, loss flux 48.984718, loss flux t1 49.800137, binary loss 9.713172, binary loss t1 9.797836\n",
      "Epoch 9/10, Batch 231/1650, Loss 22.147314, Loss rec 1.694085, loss rec t1 1.626906, loss kl 0.301625, loss_trans 0.041262, loss flux 49.049961, loss flux t1 52.432137, binary loss 9.329434, binary loss t1 9.154004\n",
      "Epoch 9/10, Batch 241/1650, Loss 26.856293, Loss rec 2.786301, loss rec t1 2.902552, loss kl 0.205004, loss_trans 0.055980, loss flux 47.676197, loss flux t1 49.374523, binary loss 10.528528, binary loss t1 10.377927\n",
      "Epoch 9/10, Batch 251/1650, Loss 30.993385, Loss rec 3.375372, loss rec t1 2.856069, loss kl 0.300656, loss_trans 0.050086, loss flux 50.604954, loss flux t1 51.713074, binary loss 12.449044, binary loss t1 11.962158\n",
      "Epoch 9/10, Batch 261/1650, Loss 21.864210, Loss rec 3.423778, loss rec t1 4.825118, loss kl 0.174880, loss_trans 0.030845, loss flux 45.957970, loss flux t1 47.790661, binary loss 5.738558, binary loss t1 7.671031\n",
      "Epoch 9/10, Batch 271/1650, Loss 29.911669, Loss rec 3.381798, loss rec t1 4.550614, loss kl 0.288078, loss_trans 0.034329, loss flux 51.613926, loss flux t1 53.502415, binary loss 10.730982, binary loss t1 10.925867\n",
      "Epoch 9/10, Batch 281/1650, Loss 30.754488, Loss rec 3.026112, loss rec t1 2.757230, loss kl 0.228284, loss_trans 0.033071, loss flux 47.953304, loss flux t1 48.516754, binary loss 12.300638, binary loss t1 12.409153\n",
      "Epoch 9/10, Batch 291/1650, Loss 21.998674, Loss rec 2.542750, loss rec t1 3.147958, loss kl 0.289515, loss_trans 0.039457, loss flux 47.288090, loss flux t1 49.589527, binary loss 7.987301, binary loss t1 7.991693\n",
      "Epoch 9/10, Batch 301/1650, Loss 19.934731, Loss rec 2.662937, loss rec t1 3.057848, loss kl 0.177676, loss_trans 0.025245, loss flux 45.901230, loss flux t1 47.612347, binary loss 7.016705, binary loss t1 6.994319\n",
      "Epoch 9/10, Batch 311/1650, Loss 74.739571, Loss rec 3.678243, loss rec t1 5.010968, loss kl 0.224216, loss_trans 0.040922, loss flux 48.210720, loss flux t1 50.353729, binary loss 35.118267, binary loss t1 30.666952\n",
      "Epoch 9/10, Batch 321/1650, Loss 57.290966, Loss rec 5.675932, loss rec t1 5.799096, loss kl 0.247081, loss_trans 0.042049, loss flux 50.242321, loss flux t1 52.548790, binary loss 23.892412, binary loss t1 21.634398\n",
      "Epoch 9/10, Batch 331/1650, Loss 44.915333, Loss rec 12.588715, loss rec t1 15.593803, loss kl 0.169988, loss_trans 0.029772, loss flux 47.032249, loss flux t1 48.138142, binary loss 8.101071, binary loss t1 8.431984\n",
      "Epoch 9/10, Batch 341/1650, Loss 84.385971, Loss rec 25.450905, loss rec t1 28.284084, loss kl 0.294960, loss_trans 0.055225, loss flux 53.576214, loss flux t1 52.410072, binary loss 14.682121, binary loss t1 15.618682\n",
      "Epoch 9/10, Batch 351/1650, Loss 75.678734, Loss rec 9.214055, loss rec t1 8.705057, loss kl 0.406326, loss_trans 0.044881, loss flux 55.857403, loss flux t1 57.616814, binary loss 30.825605, binary loss t1 26.482807\n",
      "Epoch 9/10, Batch 361/1650, Loss 40.866203, Loss rec 6.750972, loss rec t1 7.282567, loss kl 0.231681, loss_trans 0.044180, loss flux 48.322121, loss flux t1 50.320431, binary loss 12.292828, binary loss t1 14.263972\n",
      "Epoch 9/10, Batch 371/1650, Loss 41.214813, Loss rec 9.126717, loss rec t1 7.603015, loss kl 0.425657, loss_trans 0.062333, loss flux 53.131142, loss flux t1 55.767994, binary loss 12.125207, binary loss t1 11.871881\n",
      "Epoch 9/10, Batch 381/1650, Loss 26.446465, Loss rec 4.148729, loss rec t1 5.403109, loss kl 0.271737, loss_trans 0.031659, loss flux 48.076069, loss flux t1 50.539898, binary loss 8.283691, binary loss t1 8.307542\n",
      "Epoch 9/10, Batch 391/1650, Loss 32.916248, Loss rec 2.427748, loss rec t1 2.785166, loss kl 0.286955, loss_trans 0.039830, loss flux 48.844967, loss flux t1 49.909565, binary loss 14.993934, binary loss t1 12.382617\n",
      "Epoch 9/10, Batch 401/1650, Loss 23.662876, Loss rec 3.384984, loss rec t1 3.419651, loss kl 0.195770, loss_trans 0.033607, loss flux 46.390347, loss flux t1 47.259632, binary loss 8.446674, binary loss t1 8.182189\n",
      "Epoch 9/10, Batch 411/1650, Loss 34.564468, Loss rec 4.392900, loss rec t1 4.056663, loss kl 0.389311, loss_trans 0.054236, loss flux 52.298813, loss flux t1 56.176868, binary loss 13.002357, binary loss t1 12.669002\n",
      "Epoch 9/10, Batch 421/1650, Loss 31.116636, Loss rec 4.610390, loss rec t1 4.832783, loss kl 0.345513, loss_trans 0.054106, loss flux 49.598297, loss flux t1 52.439293, binary loss 10.281793, binary loss t1 10.992051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Batch 431/1650, Loss 29.659853, Loss rec 1.746582, loss rec t1 2.638480, loss kl 0.274365, loss_trans 0.040972, loss flux 45.041870, loss flux t1 45.873020, binary loss 14.537000, binary loss t1 10.422454\n",
      "Epoch 9/10, Batch 441/1650, Loss 29.374830, Loss rec 2.911602, loss rec t1 2.926035, loss kl 0.276580, loss_trans 0.051122, loss flux 48.046181, loss flux t1 49.884823, binary loss 12.193099, binary loss t1 11.016390\n",
      "Epoch 9/10, Batch 451/1650, Loss 18.835464, Loss rec 1.844545, loss rec t1 1.925365, loss kl 0.201442, loss_trans 0.035354, loss flux 46.026642, loss flux t1 47.218346, binary loss 7.115458, binary loss t1 7.713298\n",
      "Epoch 9/10, Batch 461/1650, Loss 24.176706, Loss rec 2.355170, loss rec t1 2.269545, loss kl 0.204421, loss_trans 0.032731, loss flux 47.504852, loss flux t1 49.259521, binary loss 9.170290, binary loss t1 10.144547\n",
      "Epoch 9/10, Batch 471/1650, Loss 19.458735, Loss rec 1.665297, loss rec t1 1.712432, loss kl 0.212071, loss_trans 0.037435, loss flux 43.929302, loss flux t1 45.506931, binary loss 7.803818, binary loss t1 8.027681\n",
      "Epoch 9/10, Batch 481/1650, Loss 19.651806, Loss rec 1.846083, loss rec t1 2.193145, loss kl 0.203508, loss_trans 0.029865, loss flux 45.448219, loss flux t1 45.820721, binary loss 8.118202, binary loss t1 7.261002\n",
      "Epoch 9/10, Batch 491/1650, Loss 27.193514, Loss rec 1.903103, loss rec t1 1.952609, loss kl 0.136368, loss_trans 0.025072, loss flux 45.130836, loss flux t1 47.484379, binary loss 11.522975, binary loss t1 11.653387\n",
      "Epoch 9/10, Batch 501/1650, Loss 32.244984, Loss rec 2.405497, loss rec t1 2.948342, loss kl 0.264234, loss_trans 0.037960, loss flux 49.300636, loss flux t1 51.184345, binary loss 13.782701, binary loss t1 12.806248\n",
      "Epoch 9/10, Batch 511/1650, Loss 26.346144, Loss rec 2.695411, loss rec t1 3.189658, loss kl 0.237007, loss_trans 0.032021, loss flux 48.868931, loss flux t1 48.811676, binary loss 9.817294, binary loss t1 10.374754\n",
      "Epoch 9/10, Batch 521/1650, Loss 20.245619, Loss rec 3.020820, loss rec t1 3.056853, loss kl 0.311111, loss_trans 0.047289, loss flux 47.077885, loss flux t1 50.187038, binary loss 6.973885, binary loss t1 6.835663\n",
      "Epoch 9/10, Batch 531/1650, Loss 17.850210, Loss rec 2.125000, loss rec t1 2.465377, loss kl 0.173012, loss_trans 0.037008, loss flux 43.302689, loss flux t1 47.157024, binary loss 6.514202, binary loss t1 6.535612\n",
      "Epoch 9/10, Batch 541/1650, Loss 22.420387, Loss rec 2.132709, loss rec t1 3.244979, loss kl 0.197758, loss_trans 0.043270, loss flux 44.728291, loss flux t1 47.518982, binary loss 7.966623, binary loss t1 8.835050\n",
      "Epoch 9/10, Batch 551/1650, Loss 24.646338, Loss rec 2.392927, loss rec t1 2.269156, loss kl 0.264673, loss_trans 0.049850, loss flux 44.561184, loss flux t1 50.570095, binary loss 9.834133, binary loss t1 9.835597\n",
      "Epoch 9/10, Batch 561/1650, Loss 28.191994, Loss rec 2.384870, loss rec t1 2.750602, loss kl 0.210183, loss_trans 0.031817, loss flux 47.098408, loss flux t1 48.193939, binary loss 10.965272, binary loss t1 11.849251\n",
      "Epoch 9/10, Batch 571/1650, Loss 24.633747, Loss rec 2.571017, loss rec t1 2.965963, loss kl 0.232584, loss_trans 0.033305, loss flux 48.644505, loss flux t1 48.708210, binary loss 9.437217, binary loss t1 9.393663\n",
      "Epoch 9/10, Batch 581/1650, Loss 27.195221, Loss rec 3.234618, loss rec t1 3.694731, loss kl 0.210384, loss_trans 0.038314, loss flux 49.983829, loss flux t1 48.715611, binary loss 9.831449, binary loss t1 10.185724\n",
      "Epoch 9/10, Batch 591/1650, Loss 41.387211, Loss rec 3.116005, loss rec t1 3.296325, loss kl 0.179366, loss_trans 0.025181, loss flux 45.091793, loss flux t1 47.388092, binary loss 17.738588, binary loss t1 17.031748\n",
      "Epoch 9/10, Batch 601/1650, Loss 38.813213, Loss rec 5.941092, loss rec t1 6.163014, loss kl 0.228358, loss_trans 0.049481, loss flux 48.728294, loss flux t1 49.699238, binary loss 13.114041, binary loss t1 13.317225\n",
      "Epoch 9/10, Batch 611/1650, Loss 32.033611, Loss rec 5.616851, loss rec t1 6.210333, loss kl 0.220939, loss_trans 0.030772, loss flux 50.170063, loss flux t1 50.066566, binary loss 9.577944, binary loss t1 10.376772\n",
      "Epoch 9/10, Batch 621/1650, Loss 23.766016, Loss rec 2.325401, loss rec t1 2.409858, loss kl 0.278200, loss_trans 0.035738, loss flux 48.931244, loss flux t1 50.049492, binary loss 8.803634, binary loss t1 9.913184\n",
      "Epoch 9/10, Batch 631/1650, Loss 29.227127, Loss rec 2.273308, loss rec t1 2.842340, loss kl 0.303778, loss_trans 0.050027, loss flux 48.959438, loss flux t1 50.076378, binary loss 12.831318, binary loss t1 10.926356\n",
      "Epoch 9/10, Batch 641/1650, Loss 34.129982, Loss rec 3.072802, loss rec t1 3.688490, loss kl 0.251699, loss_trans 0.039207, loss flux 50.366791, loss flux t1 50.748230, binary loss 13.316737, binary loss t1 13.761045\n",
      "Epoch 9/10, Batch 651/1650, Loss 35.521996, Loss rec 3.108747, loss rec t1 3.779285, loss kl 0.255474, loss_trans 0.045923, loss flux 48.294167, loss flux t1 50.209087, binary loss 13.843513, binary loss t1 14.489055\n",
      "Epoch 9/10, Batch 661/1650, Loss 23.617538, Loss rec 3.992986, loss rec t1 4.383328, loss kl 0.308583, loss_trans 0.043673, loss flux 48.557484, loss flux t1 50.452927, binary loss 7.314315, binary loss t1 7.574653\n",
      "Epoch 9/10, Batch 671/1650, Loss 31.832476, Loss rec 2.511740, loss rec t1 2.714579, loss kl 0.217852, loss_trans 0.045362, loss flux 49.393379, loss flux t1 51.516590, binary loss 13.162230, binary loss t1 13.180713\n",
      "Epoch 9/10, Batch 681/1650, Loss 24.514027, Loss rec 1.424503, loss rec t1 1.861473, loss kl 0.210059, loss_trans 0.037789, loss flux 45.813297, loss flux t1 48.599064, binary loss 10.692309, binary loss t1 10.287893\n",
      "Epoch 9/10, Batch 691/1650, Loss 30.446966, Loss rec 2.688804, loss rec t1 3.067151, loss kl 0.379003, loss_trans 0.048480, loss flux 52.781567, loss flux t1 55.321095, binary loss 12.520595, binary loss t1 11.742934\n",
      "Epoch 9/10, Batch 701/1650, Loss 30.462368, Loss rec 3.295102, loss rec t1 3.631837, loss kl 0.356527, loss_trans 0.042674, loss flux 51.503624, loss flux t1 51.262550, binary loss 12.143445, binary loss t1 10.992784\n",
      "Epoch 9/10, Batch 711/1650, Loss 28.001604, Loss rec 4.306285, loss rec t1 4.002649, loss kl 0.487669, loss_trans 0.066747, loss flux 56.649063, loss flux t1 59.993031, binary loss 9.826568, binary loss t1 9.311684\n",
      "Epoch 9/10, Batch 721/1650, Loss 40.216278, Loss rec 2.503692, loss rec t1 3.127091, loss kl 0.315523, loss_trans 0.041717, loss flux 51.076736, loss flux t1 53.086544, binary loss 17.699675, binary loss t1 16.528578\n",
      "Epoch 9/10, Batch 731/1650, Loss 27.382257, Loss rec 2.992800, loss rec t1 3.375093, loss kl 0.224441, loss_trans 0.037489, loss flux 49.409939, loss flux t1 50.485298, binary loss 9.888113, binary loss t1 10.864323\n",
      "Epoch 9/10, Batch 741/1650, Loss 21.478617, Loss rec 2.792624, loss rec t1 2.822786, loss kl 0.213880, loss_trans 0.036076, loss flux 47.915150, loss flux t1 49.021690, binary loss 7.762462, binary loss t1 7.850788\n",
      "Epoch 9/10, Batch 751/1650, Loss 29.586390, Loss rec 2.067183, loss rec t1 2.783512, loss kl 0.261604, loss_trans 0.042456, loss flux 47.240795, loss flux t1 48.261978, binary loss 12.824728, binary loss t1 11.606908\n",
      "Epoch 9/10, Batch 761/1650, Loss 30.803308, Loss rec 2.518514, loss rec t1 2.580209, loss kl 0.329985, loss_trans 0.059473, loss flux 47.314415, loss flux t1 50.346992, binary loss 13.177539, binary loss t1 12.137589\n",
      "Epoch 9/10, Batch 771/1650, Loss 21.134773, Loss rec 1.671249, loss rec t1 2.247157, loss kl 0.196383, loss_trans 0.039776, loss flux 43.617310, loss flux t1 47.350548, binary loss 8.048359, binary loss t1 8.931850\n",
      "Epoch 9/10, Batch 781/1650, Loss 25.859587, Loss rec 1.970304, loss rec t1 2.202506, loss kl 0.211374, loss_trans 0.037111, loss flux 46.507526, loss flux t1 48.157902, binary loss 10.254525, binary loss t1 11.183766\n",
      "Epoch 9/10, Batch 791/1650, Loss 20.330799, Loss rec 1.913487, loss rec t1 2.456963, loss kl 0.191233, loss_trans 0.045155, loss flux 46.596008, loss flux t1 47.978683, binary loss 7.807235, binary loss t1 7.916726\n",
      "Epoch 9/10, Batch 801/1650, Loss 28.834505, Loss rec 2.591750, loss rec t1 3.942775, loss kl 0.275369, loss_trans 0.042395, loss flux 49.810036, loss flux t1 51.419483, binary loss 10.759468, binary loss t1 11.222748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Batch 811/1650, Loss 49.461594, Loss rec 3.100374, loss rec t1 3.952073, loss kl 0.342505, loss_trans 0.055319, loss flux 53.096420, loss flux t1 56.120438, binary loss 22.301346, binary loss t1 19.709976\n",
      "Epoch 9/10, Batch 821/1650, Loss 26.677654, Loss rec 2.255885, loss rec t1 2.698296, loss kl 0.223996, loss_trans 0.038557, loss flux 45.187595, loss flux t1 48.412579, binary loss 9.568604, binary loss t1 11.892317\n",
      "Epoch 9/10, Batch 831/1650, Loss 22.976606, Loss rec 1.917172, loss rec t1 1.842899, loss kl 0.366514, loss_trans 0.037134, loss flux 47.213623, loss flux t1 48.152023, binary loss 10.411473, binary loss t1 8.401414\n",
      "Epoch 9/10, Batch 841/1650, Loss 20.403502, Loss rec 1.604702, loss rec t1 1.765980, loss kl 0.142576, loss_trans 0.024407, loss flux 44.146362, loss flux t1 45.428230, binary loss 7.803818, binary loss t1 9.062018\n",
      "Epoch 9/10, Batch 851/1650, Loss 22.232407, Loss rec 2.961205, loss rec t1 3.433698, loss kl 0.250532, loss_trans 0.042280, loss flux 47.558403, loss flux t1 49.422203, binary loss 7.349570, binary loss t1 8.195122\n",
      "Epoch 9/10, Batch 861/1650, Loss 30.003448, Loss rec 2.155041, loss rec t1 2.614614, loss kl 0.325392, loss_trans 0.049472, loss flux 49.181400, loss flux t1 51.856453, binary loss 11.786486, binary loss t1 13.072442\n",
      "Epoch 9/10, Batch 871/1650, Loss 36.058151, Loss rec 3.055529, loss rec t1 3.299489, loss kl 0.276906, loss_trans 0.035713, loss flux 50.750637, loss flux t1 51.801720, binary loss 14.086347, binary loss t1 15.304166\n",
      "Epoch 9/10, Batch 881/1650, Loss 22.193598, Loss rec 2.654369, loss rec t1 2.910690, loss kl 0.237465, loss_trans 0.044446, loss flux 47.368664, loss flux t1 49.690727, binary loss 7.632050, binary loss t1 8.714577\n",
      "Epoch 9/10, Batch 891/1650, Loss 21.108860, Loss rec 1.649270, loss rec t1 1.838120, loss kl 0.205471, loss_trans 0.032837, loss flux 46.797928, loss flux t1 50.263706, binary loss 8.092888, binary loss t1 9.290274\n",
      "Epoch 9/10, Batch 901/1650, Loss 20.052181, Loss rec 2.096845, loss rec t1 2.562231, loss kl 0.337313, loss_trans 0.051543, loss flux 50.188526, loss flux t1 52.732861, binary loss 7.438139, binary loss t1 7.566111\n",
      "Epoch 9/10, Batch 911/1650, Loss 17.919056, Loss rec 1.095564, loss rec t1 1.613974, loss kl 0.194187, loss_trans 0.030117, loss flux 43.064007, loss flux t1 45.313278, binary loss 7.449055, binary loss t1 7.536160\n",
      "Epoch 9/10, Batch 921/1650, Loss 19.440491, Loss rec 1.458692, loss rec t1 1.734856, loss kl 0.226146, loss_trans 0.035279, loss flux 46.781307, loss flux t1 47.499977, binary loss 7.981688, binary loss t1 8.003830\n",
      "Epoch 9/10, Batch 931/1650, Loss 21.482611, Loss rec 1.835713, loss rec t1 1.541987, loss kl 0.239951, loss_trans 0.027551, loss flux 47.280941, loss flux t1 48.719501, binary loss 9.705118, binary loss t1 8.132291\n",
      "Epoch 9/10, Batch 941/1650, Loss 19.365303, Loss rec 1.923686, loss rec t1 1.690526, loss kl 0.286000, loss_trans 0.037763, loss flux 46.675411, loss flux t1 49.050987, binary loss 7.469733, binary loss t1 7.957594\n",
      "Epoch 9/10, Batch 951/1650, Loss 25.009161, Loss rec 1.387280, loss rec t1 1.506272, loss kl 0.186317, loss_trans 0.027661, loss flux 48.006306, loss flux t1 50.661934, binary loss 10.176450, binary loss t1 11.725183\n",
      "Epoch 9/10, Batch 961/1650, Loss 23.450676, Loss rec 1.594829, loss rec t1 1.512121, loss kl 0.155008, loss_trans 0.022472, loss flux 45.500534, loss flux t1 45.299679, binary loss 10.173278, binary loss t1 9.992968\n",
      "Epoch 9/10, Batch 971/1650, Loss 23.978794, Loss rec 2.944924, loss rec t1 3.375624, loss kl 0.182590, loss_trans 0.036494, loss flux 48.516949, loss flux t1 50.002651, binary loss 8.410200, binary loss t1 9.028960\n",
      "Epoch 9/10, Batch 981/1650, Loss 26.259216, Loss rec 3.158318, loss rec t1 3.323781, loss kl 0.180700, loss_trans 0.031185, loss flux 46.122215, loss flux t1 46.653790, binary loss 9.550367, binary loss t1 10.014866\n",
      "Epoch 9/10, Batch 991/1650, Loss 22.741804, Loss rec 3.346550, loss rec t1 3.807791, loss kl 0.165728, loss_trans 0.037473, loss flux 47.803204, loss flux t1 49.265251, binary loss 6.939053, binary loss t1 8.445210\n",
      "Epoch 9/10, Batch 1001/1650, Loss 45.823009, Loss rec 5.671326, loss rec t1 7.264295, loss kl 0.312028, loss_trans 0.045048, loss flux 51.204224, loss flux t1 52.896313, binary loss 16.962879, binary loss t1 15.567432\n",
      "Epoch 9/10, Batch 1011/1650, Loss 28.197317, Loss rec 5.239359, loss rec t1 6.172243, loss kl 0.195885, loss_trans 0.044347, loss flux 45.902641, loss flux t1 48.186111, binary loss 7.684144, binary loss t1 8.861341\n",
      "Epoch 9/10, Batch 1021/1650, Loss 33.431919, Loss rec 2.911167, loss rec t1 3.428769, loss kl 0.210152, loss_trans 0.030835, loss flux 46.581127, loss flux t1 48.684589, binary loss 12.472896, binary loss t1 14.378100\n",
      "Epoch 9/10, Batch 1031/1650, Loss 26.642973, Loss rec 3.669412, loss rec t1 2.827948, loss kl 0.346025, loss_trans 0.036299, loss flux 50.012848, loss flux t1 49.800251, binary loss 10.080559, binary loss t1 9.682733\n",
      "Epoch 9/10, Batch 1041/1650, Loss 20.935070, Loss rec 2.011242, loss rec t1 2.585257, loss kl 0.224209, loss_trans 0.023747, loss flux 47.232323, loss flux t1 47.959782, binary loss 8.487054, binary loss t1 7.603562\n",
      "Epoch 9/10, Batch 1051/1650, Loss 25.730194, Loss rec 3.616417, loss rec t1 4.370283, loss kl 0.162802, loss_trans 0.026250, loss flux 46.242455, loss flux t1 47.188580, binary loss 7.757582, binary loss t1 9.796860\n",
      "Epoch 9/10, Batch 1061/1650, Loss 36.292732, Loss rec 6.274723, loss rec t1 5.832848, loss kl 0.318421, loss_trans 0.051782, loss flux 53.890854, loss flux t1 54.710510, binary loss 12.361761, binary loss t1 11.453198\n",
      "Epoch 9/10, Batch 1071/1650, Loss 28.809084, Loss rec 2.765844, loss rec t1 2.949274, loss kl 0.329159, loss_trans 0.052387, loss flux 48.448151, loss flux t1 51.798431, binary loss 10.558724, binary loss t1 12.153694\n",
      "Epoch 9/10, Batch 1081/1650, Loss 31.257730, Loss rec 5.564447, loss rec t1 4.840825, loss kl 0.270280, loss_trans 0.041226, loss flux 49.649017, loss flux t1 50.144409, binary loss 10.592516, binary loss t1 9.948439\n",
      "Epoch 9/10, Batch 1091/1650, Loss 20.601849, Loss rec 2.470444, loss rec t1 2.372916, loss kl 0.145537, loss_trans 0.033493, loss flux 43.414295, loss flux t1 46.376362, binary loss 8.058852, binary loss t1 7.520607\n",
      "Epoch 9/10, Batch 1101/1650, Loss 21.741051, Loss rec 1.671817, loss rec t1 1.548898, loss kl 0.197756, loss_trans 0.036468, loss flux 44.951527, loss flux t1 45.720551, binary loss 9.773743, binary loss t1 8.512368\n",
      "Epoch 9/10, Batch 1111/1650, Loss 41.122475, Loss rec 2.146145, loss rec t1 4.397054, loss kl 0.203076, loss_trans 0.043028, loss flux 42.733948, loss flux t1 44.531902, binary loss 16.596712, binary loss t1 17.736458\n",
      "Epoch 9/10, Batch 1121/1650, Loss 32.614151, Loss rec 3.718492, loss rec t1 4.306645, loss kl 0.289817, loss_trans 0.051957, loss flux 48.826393, loss flux t1 50.633614, binary loss 12.101845, binary loss t1 12.145397\n",
      "Epoch 9/10, Batch 1131/1650, Loss 34.036701, Loss rec 3.660058, loss rec t1 3.619241, loss kl 0.413594, loss_trans 0.045885, loss flux 51.705597, loss flux t1 53.681438, binary loss 13.024252, binary loss t1 13.273673\n",
      "Epoch 9/10, Batch 1141/1650, Loss 25.266661, Loss rec 3.377751, loss rec t1 3.232545, loss kl 0.260123, loss_trans 0.043637, loss flux 49.517090, loss flux t1 51.073769, binary loss 8.855240, binary loss t1 9.497364\n",
      "Epoch 9/10, Batch 1151/1650, Loss 35.179516, Loss rec 2.687062, loss rec t1 2.679129, loss kl 0.345987, loss_trans 0.037423, loss flux 52.106331, loss flux t1 54.262260, binary loss 15.300995, binary loss t1 14.128922\n",
      "Epoch 9/10, Batch 1161/1650, Loss 29.588799, Loss rec 3.155672, loss rec t1 3.740509, loss kl 0.242960, loss_trans 0.040951, loss flux 48.392025, loss flux t1 51.368057, binary loss 11.081840, binary loss t1 11.326868\n",
      "Epoch 9/10, Batch 1171/1650, Loss 22.446390, Loss rec 2.997871, loss rec t1 3.885201, loss kl 0.214219, loss_trans 0.029734, loss flux 46.604122, loss flux t1 48.005352, binary loss 7.149069, binary loss t1 8.170296\n",
      "Epoch 9/10, Batch 1181/1650, Loss 33.556408, Loss rec 3.620461, loss rec t1 4.231273, loss kl 0.411548, loss_trans 0.051433, loss flux 52.795807, loss flux t1 56.100533, binary loss 12.036152, binary loss t1 13.205539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Batch 1191/1650, Loss 23.147591, Loss rec 3.025235, loss rec t1 3.557039, loss kl 0.292351, loss_trans 0.038026, loss flux 51.188896, loss flux t1 52.877483, binary loss 8.494619, binary loss t1 7.740320\n",
      "Epoch 9/10, Batch 1201/1650, Loss 23.844223, Loss rec 2.394020, loss rec t1 3.610294, loss kl 0.211816, loss_trans 0.041080, loss flux 43.743145, loss flux t1 43.985474, binary loss 8.529386, binary loss t1 9.057627\n",
      "Epoch 9/10, Batch 1211/1650, Loss 28.444521, Loss rec 3.224831, loss rec t1 3.651728, loss kl 0.294673, loss_trans 0.042022, loss flux 49.368805, loss flux t1 51.143818, binary loss 11.058234, binary loss t1 10.173034\n",
      "Epoch 9/10, Batch 1221/1650, Loss 36.525150, Loss rec 2.089379, loss rec t1 3.217432, loss kl 0.251936, loss_trans 0.041734, loss flux 47.020264, loss flux t1 49.394283, binary loss 16.236824, binary loss t1 14.687847\n",
      "Epoch 9/10, Batch 1231/1650, Loss 26.778893, Loss rec 1.727004, loss rec t1 1.643399, loss kl 0.226740, loss_trans 0.037533, loss flux 43.850861, loss flux t1 46.474529, binary loss 11.893047, binary loss t1 11.251168\n",
      "Epoch 9/10, Batch 1241/1650, Loss 23.691631, Loss rec 2.184840, loss rec t1 1.957414, loss kl 0.241980, loss_trans 0.033673, loss flux 45.281815, loss flux t1 49.058865, binary loss 9.882501, binary loss t1 9.391224\n",
      "Epoch 9/10, Batch 1251/1650, Loss 21.236702, Loss rec 2.671732, loss rec t1 2.796673, loss kl 0.183096, loss_trans 0.029834, loss flux 44.323425, loss flux t1 45.488102, binary loss 7.722571, binary loss t1 7.832794\n",
      "Epoch 9/10, Batch 1261/1650, Loss 25.539963, Loss rec 4.217034, loss rec t1 5.552282, loss kl 0.195755, loss_trans 0.031597, loss flux 49.045456, loss flux t1 48.028564, binary loss 7.757892, binary loss t1 7.785402\n",
      "Epoch 9/10, Batch 1271/1650, Loss 29.607002, Loss rec 2.713336, loss rec t1 2.537981, loss kl 0.254857, loss_trans 0.040239, loss flux 50.429546, loss flux t1 50.709061, binary loss 11.764345, binary loss t1 12.296244\n",
      "Epoch 9/10, Batch 1281/1650, Loss 23.613455, Loss rec 2.594972, loss rec t1 3.012640, loss kl 0.230947, loss_trans 0.035508, loss flux 44.371376, loss flux t1 44.894627, binary loss 9.842365, binary loss t1 7.897024\n",
      "Epoch 9/10, Batch 1291/1650, Loss 32.918980, Loss rec 2.444669, loss rec t1 3.174498, loss kl 0.164131, loss_trans 0.028989, loss flux 41.523727, loss flux t1 43.940601, binary loss 12.180408, binary loss t1 14.926286\n",
      "Epoch 9/10, Batch 1301/1650, Loss 23.120659, Loss rec 3.285001, loss rec t1 3.425205, loss kl 0.202263, loss_trans 0.025345, loss flux 44.743511, loss flux t1 45.560753, binary loss 7.934719, binary loss t1 8.248127\n",
      "Epoch 9/10, Batch 1311/1650, Loss 21.495110, Loss rec 1.760666, loss rec t1 2.342155, loss kl 0.198332, loss_trans 0.037342, loss flux 46.589199, loss flux t1 49.463352, binary loss 8.376587, binary loss t1 8.780027\n",
      "Epoch 9/10, Batch 1321/1650, Loss 27.997499, Loss rec 2.563242, loss rec t1 3.107928, loss kl 0.347803, loss_trans 0.048713, loss flux 49.000671, loss flux t1 52.456715, binary loss 11.253365, binary loss t1 10.676447\n",
      "Epoch 9/10, Batch 1331/1650, Loss 28.612267, Loss rec 2.947255, loss rec t1 3.243075, loss kl 0.182721, loss_trans 0.036065, loss flux 48.321342, loss flux t1 50.057346, binary loss 10.736107, binary loss t1 11.467043\n",
      "Epoch 9/10, Batch 1341/1650, Loss 31.596533, Loss rec 1.729790, loss rec t1 2.782044, loss kl 0.230368, loss_trans 0.035974, loss flux 41.419064, loss flux t1 46.452065, binary loss 12.843943, binary loss t1 13.974414\n",
      "Epoch 9/10, Batch 1351/1650, Loss 19.321877, Loss rec 1.198019, loss rec t1 1.671397, loss kl 0.157910, loss_trans 0.027285, loss flux 44.844135, loss flux t1 47.503025, binary loss 7.114970, binary loss t1 9.152296\n",
      "Epoch 9/10, Batch 1361/1650, Loss 41.359921, Loss rec 3.432875, loss rec t1 3.702070, loss kl 0.372736, loss_trans 0.049573, loss flux 50.879612, loss flux t1 51.631802, binary loss 18.560045, binary loss t1 15.242622\n",
      "Epoch 9/10, Batch 1371/1650, Loss 23.044306, Loss rec 1.423835, loss rec t1 2.090379, loss kl 0.192286, loss_trans 0.042916, loss flux 41.740089, loss flux t1 46.299004, binary loss 9.149856, binary loss t1 10.145035\n",
      "Epoch 9/10, Batch 1381/1650, Loss 27.026651, Loss rec 2.342711, loss rec t1 3.009182, loss kl 0.267593, loss_trans 0.032064, loss flux 49.578846, loss flux t1 51.296173, binary loss 10.597396, binary loss t1 10.777707\n",
      "Epoch 9/10, Batch 1391/1650, Loss 18.627045, Loss rec 1.966375, loss rec t1 2.150588, loss kl 0.353537, loss_trans 0.057750, loss flux 46.066788, loss flux t1 51.054348, binary loss 6.805956, binary loss t1 7.292840\n",
      "Epoch 9/10, Batch 1401/1650, Loss 24.448294, Loss rec 2.228751, loss rec t1 2.004493, loss kl 0.216290, loss_trans 0.036188, loss flux 48.729645, loss flux t1 51.030216, binary loss 9.017734, binary loss t1 10.944838\n",
      "Epoch 9/10, Batch 1411/1650, Loss 24.268040, Loss rec 2.903178, loss rec t1 3.043715, loss kl 0.247216, loss_trans 0.034312, loss flux 48.008652, loss flux t1 49.361626, binary loss 8.775635, binary loss t1 9.263984\n",
      "Epoch 9/10, Batch 1421/1650, Loss 25.493141, Loss rec 2.014670, loss rec t1 1.932218, loss kl 0.211811, loss_trans 0.035282, loss flux 46.544983, loss flux t1 48.665394, binary loss 10.661139, binary loss t1 10.638020\n",
      "Epoch 9/10, Batch 1431/1650, Loss 23.971264, Loss rec 2.560905, loss rec t1 2.247312, loss kl 0.243350, loss_trans 0.038367, loss flux 47.716137, loss flux t1 49.306126, binary loss 9.564034, binary loss t1 9.317297\n",
      "Epoch 9/10, Batch 1441/1650, Loss 34.606339, Loss rec 2.539453, loss rec t1 2.774223, loss kl 0.336283, loss_trans 0.052751, loss flux 47.208477, loss flux t1 51.975731, binary loss 13.998755, binary loss t1 14.904875\n",
      "Epoch 9/10, Batch 1451/1650, Loss 23.469061, Loss rec 2.468504, loss rec t1 2.674551, loss kl 0.246441, loss_trans 0.043539, loss flux 47.542072, loss flux t1 48.446877, binary loss 9.071293, binary loss t1 8.964730\n",
      "Epoch 9/10, Batch 1461/1650, Loss 22.222902, Loss rec 1.847387, loss rec t1 1.900103, loss kl 0.200648, loss_trans 0.039282, loss flux 46.008011, loss flux t1 46.470501, binary loss 9.327238, binary loss t1 8.908244\n",
      "Epoch 9/10, Batch 1471/1650, Loss 30.216797, Loss rec 2.235537, loss rec t1 2.830073, loss kl 0.265180, loss_trans 0.033424, loss flux 50.607750, loss flux t1 51.488071, binary loss 12.184068, binary loss t1 12.668514\n",
      "Epoch 9/10, Batch 1481/1650, Loss 17.028772, Loss rec 1.789875, loss rec t1 1.978722, loss kl 0.225592, loss_trans 0.030451, loss flux 47.812279, loss flux t1 49.598419, binary loss 6.324684, binary loss t1 6.679447\n",
      "Epoch 9/10, Batch 1491/1650, Loss 26.093981, Loss rec 3.008862, loss rec t1 2.495049, loss kl 0.341304, loss_trans 0.043118, loss flux 50.533901, loss flux t1 51.704121, binary loss 10.257210, binary loss t1 9.948439\n",
      "Epoch 9/10, Batch 1501/1650, Loss 28.141167, Loss rec 2.886457, loss rec t1 3.605078, loss kl 0.359953, loss_trans 0.044503, loss flux 52.144268, loss flux t1 54.548340, binary loss 11.175046, binary loss t1 10.070132\n",
      "Epoch 9/10, Batch 1511/1650, Loss 34.745228, Loss rec 3.058557, loss rec t1 3.239511, loss kl 0.183466, loss_trans 0.041106, loss flux 47.273125, loss flux t1 48.342033, binary loss 13.558105, binary loss t1 14.664483\n",
      "Epoch 9/10, Batch 1521/1650, Loss 20.757967, Loss rec 1.628102, loss rec t1 1.736165, loss kl 0.223669, loss_trans 0.031652, loss flux 45.475372, loss flux t1 48.546879, binary loss 8.358594, binary loss t1 8.779783\n",
      "Epoch 9/10, Batch 1531/1650, Loss 25.189125, Loss rec 2.203803, loss rec t1 2.275947, loss kl 0.210952, loss_trans 0.032924, loss flux 47.022469, loss flux t1 48.848549, binary loss 9.634543, binary loss t1 10.830955\n",
      "Epoch 9/10, Batch 1541/1650, Loss 21.864969, Loss rec 2.060801, loss rec t1 2.101764, loss kl 0.288510, loss_trans 0.052145, loss flux 46.828152, loss flux t1 49.454353, binary loss 8.515297, binary loss t1 8.846454\n",
      "Epoch 9/10, Batch 1551/1650, Loss 21.752136, Loss rec 1.933201, loss rec t1 2.218069, loss kl 0.152542, loss_trans 0.031372, loss flux 46.025143, loss flux t1 47.727501, binary loss 9.128689, binary loss t1 8.288262\n",
      "Epoch 9/10, Batch 1561/1650, Loss 23.408596, Loss rec 2.505835, loss rec t1 2.443149, loss kl 0.349112, loss_trans 0.046787, loss flux 49.303780, loss flux t1 50.887764, binary loss 9.310464, binary loss t1 8.753249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Batch 1571/1650, Loss 23.064871, Loss rec 2.002920, loss rec t1 2.188213, loss kl 0.334594, loss_trans 0.039908, loss flux 46.562943, loss flux t1 49.740726, binary loss 9.193896, binary loss t1 9.305340\n",
      "Epoch 9/10, Batch 1581/1650, Loss 21.297260, Loss rec 2.413028, loss rec t1 2.659765, loss kl 0.161081, loss_trans 0.024003, loss flux 43.862202, loss flux t1 44.541283, binary loss 8.528963, binary loss t1 7.510422\n",
      "Epoch 9/10, Batch 1591/1650, Loss 23.026283, Loss rec 2.150162, loss rec t1 1.930486, loss kl 0.259304, loss_trans 0.033808, loss flux 46.763641, loss flux t1 48.450169, binary loss 9.547684, binary loss t1 9.104839\n",
      "Epoch 9/10, Batch 1601/1650, Loss 25.106018, Loss rec 4.048600, loss rec t1 5.687808, loss kl 0.103118, loss_trans 0.025201, loss flux 44.022938, loss flux t1 44.873569, binary loss 6.840787, binary loss t1 8.400503\n",
      "Epoch 9/10, Batch 1611/1650, Loss 35.057575, Loss rec 2.825616, loss rec t1 3.816493, loss kl 0.136778, loss_trans 0.030166, loss flux 43.023407, loss flux t1 45.236328, binary loss 13.538713, binary loss t1 14.709808\n",
      "Epoch 9/10, Batch 1621/1650, Loss 45.124950, Loss rec 3.147851, loss rec t1 2.502900, loss kl 0.253615, loss_trans 0.042242, loss flux 45.056995, loss flux t1 47.095741, binary loss 20.886196, binary loss t1 18.292145\n",
      "Epoch 9/10, Batch 1631/1650, Loss 25.874044, Loss rec 3.028507, loss rec t1 3.545496, loss kl 0.163147, loss_trans 0.040483, loss flux 47.307720, loss flux t1 47.823635, binary loss 8.805099, binary loss t1 10.291310\n",
      "Epoch 9/10, Batch 1641/1650, Loss 23.886370, Loss rec 2.757347, loss rec t1 2.720125, loss kl 0.283470, loss_trans 0.050002, loss flux 48.872856, loss flux t1 52.080154, binary loss 9.823639, binary loss t1 8.251787\n",
      "Epoch 9/10, Train loss 24.281994, Eval loss 33.479401\n",
      "Epoch 10/10, Batch 1/1650, Loss 26.212784, Loss rec 2.140368, loss rec t1 2.112926, loss kl 0.279515, loss_trans 0.052589, loss flux 46.617020, loss flux t1 49.534256, binary loss 11.457037, binary loss t1 10.170349\n",
      "Epoch 10/10, Batch 11/1650, Loss 33.553726, Loss rec 2.986763, loss rec t1 3.829131, loss kl 0.288125, loss_trans 0.042465, loss flux 47.945766, loss flux t1 52.307995, binary loss 12.439347, binary loss t1 13.967892\n",
      "Epoch 10/10, Batch 21/1650, Loss 29.041786, Loss rec 3.801040, loss rec t1 3.953562, loss kl 0.197967, loss_trans 0.036731, loss flux 46.527527, loss flux t1 48.719746, binary loss 10.783319, binary loss t1 10.269167\n",
      "Epoch 10/10, Batch 31/1650, Loss 60.563927, Loss rec 3.331533, loss rec t1 4.651854, loss kl 0.161691, loss_trans 0.026737, loss flux 46.816708, loss flux t1 48.916801, binary loss 26.284258, binary loss t1 26.107853\n",
      "Epoch 10/10, Batch 41/1650, Loss 41.788647, Loss rec 3.745003, loss rec t1 5.375259, loss kl 0.202917, loss_trans 0.033907, loss flux 46.945911, loss flux t1 48.536919, binary loss 15.859919, binary loss t1 16.571640\n",
      "Epoch 10/10, Batch 51/1650, Loss 38.575966, Loss rec 3.426615, loss rec t1 4.080042, loss kl 0.186195, loss_trans 0.030484, loss flux 45.925518, loss flux t1 48.228043, binary loss 15.769153, binary loss t1 15.083477\n",
      "Epoch 10/10, Batch 61/1650, Loss 35.152512, Loss rec 7.729289, loss rec t1 7.072222, loss kl 0.313015, loss_trans 0.045642, loss flux 48.930672, loss flux t1 49.982353, binary loss 10.537802, binary loss t1 9.454542\n",
      "Epoch 10/10, Batch 71/1650, Loss 60.426819, Loss rec 6.037040, loss rec t1 6.466440, loss kl 0.357530, loss_trans 0.047906, loss flux 51.346954, loss flux t1 52.023571, binary loss 24.179531, binary loss t1 23.338371\n",
      "Epoch 10/10, Batch 81/1650, Loss 22.233328, Loss rec 2.749375, loss rec t1 3.022057, loss kl 0.180851, loss_trans 0.032507, loss flux 45.898434, loss flux t1 46.780739, binary loss 7.691887, binary loss t1 8.556653\n",
      "Epoch 10/10, Batch 91/1650, Loss 30.334805, Loss rec 5.414962, loss rec t1 5.784899, loss kl 0.223649, loss_trans 0.033069, loss flux 46.291149, loss flux t1 47.413136, binary loss 9.214883, binary loss t1 9.663342\n",
      "Epoch 10/10, Batch 101/1650, Loss 33.293739, Loss rec 4.910210, loss rec t1 5.013968, loss kl 0.162345, loss_trans 0.031943, loss flux 47.109150, loss flux t1 48.402321, binary loss 11.653210, binary loss t1 11.522065\n",
      "Epoch 10/10, Batch 111/1650, Loss 35.563461, Loss rec 3.620555, loss rec t1 3.219810, loss kl 0.349339, loss_trans 0.043385, loss flux 52.089424, loss flux t1 54.393589, binary loss 13.469049, binary loss t1 14.861324\n",
      "Epoch 10/10, Batch 121/1650, Loss 41.273735, Loss rec 6.516408, loss rec t1 8.332258, loss kl 0.330980, loss_trans 0.054793, loss flux 48.805321, loss flux t1 52.093391, binary loss 12.896524, binary loss t1 13.142773\n",
      "Epoch 10/10, Batch 131/1650, Loss 29.020092, Loss rec 3.150782, loss rec t1 3.812696, loss kl 0.122244, loss_trans 0.019134, loss flux 46.216339, loss flux t1 47.616291, binary loss 10.836567, binary loss t1 11.078668\n",
      "Epoch 10/10, Batch 141/1650, Loss 25.473448, Loss rec 2.732168, loss rec t1 3.192127, loss kl 0.182912, loss_trans 0.025846, loss flux 44.489792, loss flux t1 44.290680, binary loss 9.570069, binary loss t1 9.770326\n",
      "Epoch 10/10, Batch 151/1650, Loss 31.290600, Loss rec 3.123461, loss rec t1 2.946441, loss kl 0.335354, loss_trans 0.046360, loss flux 49.842773, loss flux t1 52.010391, binary loss 12.587997, binary loss t1 12.250984\n",
      "Epoch 10/10, Batch 161/1650, Loss 32.280582, Loss rec 4.511647, loss rec t1 4.808959, loss kl 0.382430, loss_trans 0.044280, loss flux 52.536125, loss flux t1 54.119812, binary loss 10.901529, binary loss t1 11.631736\n",
      "Epoch 10/10, Batch 171/1650, Loss 35.202251, Loss rec 4.003129, loss rec t1 5.022585, loss kl 0.400459, loss_trans 0.042931, loss flux 52.334637, loss flux t1 54.760307, binary loss 12.844187, binary loss t1 12.888960\n",
      "Epoch 10/10, Batch 181/1650, Loss 26.012020, Loss rec 1.953501, loss rec t1 2.480302, loss kl 0.188688, loss_trans 0.027360, loss flux 42.270634, loss flux t1 44.441902, binary loss 11.191088, binary loss t1 10.171082\n",
      "Epoch 10/10, Batch 191/1650, Loss 37.979271, Loss rec 3.175254, loss rec t1 3.780926, loss kl 0.331417, loss_trans 0.048018, loss flux 50.939548, loss flux t1 53.027660, binary loss 15.001253, binary loss t1 15.642403\n",
      "Epoch 10/10, Batch 201/1650, Loss 24.786833, Loss rec 2.900344, loss rec t1 2.983385, loss kl 0.208422, loss_trans 0.028738, loss flux 46.662510, loss flux t1 46.940182, binary loss 9.666447, binary loss t1 8.999496\n",
      "Epoch 10/10, Batch 211/1650, Loss 23.922647, Loss rec 2.199234, loss rec t1 2.951215, loss kl 0.144774, loss_trans 0.019430, loss flux 45.352760, loss flux t1 44.667953, binary loss 8.684870, binary loss t1 9.923124\n",
      "Epoch 10/10, Batch 221/1650, Loss 23.026241, Loss rec 1.832505, loss rec t1 1.594219, loss kl 0.228254, loss_trans 0.032511, loss flux 47.525814, loss flux t1 48.138268, binary loss 9.471805, binary loss t1 9.866947\n",
      "Epoch 10/10, Batch 231/1650, Loss 30.097969, Loss rec 2.383993, loss rec t1 2.669549, loss kl 0.303215, loss_trans 0.041184, loss flux 47.561638, loss flux t1 50.509415, binary loss 12.492108, binary loss t1 12.207919\n",
      "Epoch 10/10, Batch 241/1650, Loss 24.708942, Loss rec 2.470814, loss rec t1 2.520181, loss kl 0.211153, loss_trans 0.056110, loss flux 46.584332, loss flux t1 47.970818, binary loss 10.067448, binary loss t1 9.383236\n",
      "Epoch 10/10, Batch 251/1650, Loss 26.679140, Loss rec 2.843318, loss rec t1 2.718339, loss kl 0.299649, loss_trans 0.049357, loss flux 48.578953, loss flux t1 50.119427, binary loss 10.239460, binary loss t1 10.529017\n",
      "Epoch 10/10, Batch 261/1650, Loss 19.366703, Loss rec 1.255721, loss rec t1 1.416036, loss kl 0.175500, loss_trans 0.030760, loss flux 44.109581, loss flux t1 46.916428, binary loss 7.602098, binary loss t1 8.886589\n",
      "Epoch 10/10, Batch 271/1650, Loss 26.366711, Loss rec 1.968261, loss rec t1 2.487002, loss kl 0.275091, loss_trans 0.032085, loss flux 49.605362, loss flux t1 51.197758, binary loss 10.416111, binary loss t1 11.188159\n",
      "Epoch 10/10, Batch 281/1650, Loss 24.900570, Loss rec 1.653590, loss rec t1 1.933532, loss kl 0.232138, loss_trans 0.031575, loss flux 46.983994, loss flux t1 46.866142, binary loss 10.879632, binary loss t1 10.170105\n",
      "Epoch 10/10, Batch 291/1650, Loss 23.096056, Loss rec 2.401575, loss rec t1 2.453667, loss kl 0.283979, loss_trans 0.035983, loss flux 45.519108, loss flux t1 47.740242, binary loss 8.772706, binary loss t1 9.148148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Batch 301/1650, Loss 19.419838, Loss rec 2.991775, loss rec t1 3.470415, loss kl 0.177502, loss_trans 0.023663, loss flux 44.713478, loss flux t1 46.093834, binary loss 6.600152, binary loss t1 6.156332\n",
      "Epoch 10/10, Batch 311/1650, Loss 44.031250, Loss rec 2.981250, loss rec t1 3.936551, loss kl 0.208498, loss_trans 0.037208, loss flux 45.368931, loss flux t1 47.468262, binary loss 17.958303, binary loss t1 18.909441\n",
      "Epoch 10/10, Batch 321/1650, Loss 43.782967, Loss rec 3.748236, loss rec t1 4.546251, loss kl 0.238307, loss_trans 0.038939, loss flux 49.153862, loss flux t1 51.111305, binary loss 17.494781, binary loss t1 17.716448\n",
      "Epoch 10/10, Batch 331/1650, Loss 27.653946, Loss rec 5.172676, loss rec t1 6.237511, loss kl 0.167707, loss_trans 0.027817, loss flux 44.978233, loss flux t1 46.069195, binary loss 8.103691, binary loss t1 7.944546\n",
      "Epoch 10/10, Batch 341/1650, Loss 46.496628, Loss rec 7.114451, loss rec t1 7.646308, loss kl 0.285967, loss_trans 0.054810, loss flux 51.127434, loss flux t1 50.140553, binary loss 14.744089, binary loss t1 16.651001\n",
      "Epoch 10/10, Batch 351/1650, Loss 40.725609, Loss rec 4.392150, loss rec t1 4.504960, loss kl 0.343036, loss_trans 0.036946, loss flux 50.714684, loss flux t1 52.290550, binary loss 16.079876, binary loss t1 15.368642\n",
      "Epoch 10/10, Batch 361/1650, Loss 26.697205, Loss rec 2.038903, loss rec t1 2.157152, loss kl 0.213104, loss_trans 0.037261, loss flux 46.336285, loss flux t1 48.339314, binary loss 10.661870, binary loss t1 11.588915\n",
      "Epoch 10/10, Batch 371/1650, Loss 27.049713, Loss rec 2.362233, loss rec t1 2.092778, loss kl 0.361638, loss_trans 0.048703, loss flux 48.740902, loss flux t1 51.019611, binary loss 11.215915, binary loss t1 10.968445\n",
      "Epoch 10/10, Batch 381/1650, Loss 21.235619, Loss rec 2.012818, loss rec t1 2.213672, loss kl 0.254115, loss_trans 0.027886, loss flux 46.004715, loss flux t1 47.139973, binary loss 8.442038, binary loss t1 8.285089\n",
      "Epoch 10/10, Batch 391/1650, Loss 23.091257, Loss rec 1.779081, loss rec t1 1.519332, loss kl 0.260753, loss_trans 0.032065, loss flux 47.209675, loss flux t1 48.346085, binary loss 9.593431, binary loss t1 9.906595\n",
      "Epoch 10/10, Batch 401/1650, Loss 20.964842, Loss rec 2.086960, loss rec t1 1.902796, loss kl 0.169155, loss_trans 0.028173, loss flux 44.954857, loss flux t1 45.506054, binary loss 8.797533, binary loss t1 7.980224\n",
      "Epoch 10/10, Batch 411/1650, Loss 27.878923, Loss rec 2.435852, loss rec t1 2.278481, loss kl 0.347677, loss_trans 0.045455, loss flux 49.944099, loss flux t1 53.732918, binary loss 11.652656, binary loss t1 11.118803\n",
      "Epoch 10/10, Batch 421/1650, Loss 24.173962, Loss rec 2.252545, loss rec t1 2.250209, loss kl 0.300823, loss_trans 0.042858, loss flux 48.208004, loss flux t1 49.813519, binary loss 9.640401, binary loss t1 9.687126\n",
      "Epoch 10/10, Batch 431/1650, Loss 19.084909, Loss rec 1.871110, loss rec t1 2.424930, loss kl 0.237765, loss_trans 0.035205, loss flux 42.453819, loss flux t1 43.988224, binary loss 8.098012, binary loss t1 6.417889\n",
      "Epoch 10/10, Batch 441/1650, Loss 33.574829, Loss rec 2.931069, loss rec t1 2.485301, loss kl 0.254864, loss_trans 0.043825, loss flux 45.717659, loss flux t1 47.776752, binary loss 14.372486, binary loss t1 13.487287\n",
      "Epoch 10/10, Batch 451/1650, Loss 25.002512, Loss rec 1.941405, loss rec t1 2.315254, loss kl 0.185797, loss_trans 0.030570, loss flux 44.360779, loss flux t1 46.160343, binary loss 9.567629, binary loss t1 10.961856\n",
      "Epoch 10/10, Batch 461/1650, Loss 19.441545, Loss rec 2.427238, loss rec t1 2.029678, loss kl 0.192494, loss_trans 0.027853, loss flux 46.345943, loss flux t1 47.632034, binary loss 7.294548, binary loss t1 7.469733\n",
      "Epoch 10/10, Batch 471/1650, Loss 21.008064, Loss rec 1.266186, loss rec t1 2.189890, loss kl 0.194763, loss_trans 0.032745, loss flux 41.928631, loss flux t1 43.822414, binary loss 8.396290, binary loss t1 8.928189\n",
      "Epoch 10/10, Batch 481/1650, Loss 20.151520, Loss rec 1.555493, loss rec t1 1.830672, loss kl 0.175818, loss_trans 0.025150, loss flux 43.015717, loss flux t1 43.527164, binary loss 8.401414, binary loss t1 8.162974\n",
      "Epoch 10/10, Batch 491/1650, Loss 24.027418, Loss rec 1.792500, loss rec t1 2.418178, loss kl 0.126558, loss_trans 0.023024, loss flux 43.048283, loss flux t1 45.626034, binary loss 9.258126, binary loss t1 10.409032\n",
      "Epoch 10/10, Batch 501/1650, Loss 27.034294, Loss rec 2.103863, loss rec t1 3.033259, loss kl 0.238547, loss_trans 0.033125, loss flux 48.547607, loss flux t1 50.209560, binary loss 11.023466, binary loss t1 10.602034\n",
      "Epoch 10/10, Batch 511/1650, Loss 21.163462, Loss rec 2.081578, loss rec t1 2.117862, loss kl 0.222343, loss_trans 0.028394, loss flux 46.486572, loss flux t1 46.980076, binary loss 8.134975, binary loss t1 8.578307\n",
      "Epoch 10/10, Batch 521/1650, Loss 21.133383, Loss rec 1.672262, loss rec t1 1.454921, loss kl 0.301796, loss_trans 0.043644, loss flux 45.372726, loss flux t1 48.102940, binary loss 9.219211, binary loss t1 8.441549\n",
      "Epoch 10/10, Batch 531/1650, Loss 16.736269, Loss rec 1.692622, loss rec t1 1.775802, loss kl 0.154976, loss_trans 0.033837, loss flux 41.825691, loss flux t1 45.316463, binary loss 6.406176, binary loss t1 6.672857\n",
      "Epoch 10/10, Batch 541/1650, Loss 16.156136, Loss rec 1.125795, loss rec t1 1.301389, loss kl 0.181469, loss_trans 0.038964, loss flux 42.273182, loss flux t1 45.099377, binary loss 6.519570, binary loss t1 6.988949\n",
      "Epoch 10/10, Batch 551/1650, Loss 18.448038, Loss rec 1.150035, loss rec t1 1.152568, loss kl 0.240443, loss_trans 0.045494, loss flux 42.791019, loss flux t1 48.742535, binary loss 7.383849, binary loss t1 8.475650\n",
      "Epoch 10/10, Batch 561/1650, Loss 21.054382, Loss rec 1.235417, loss rec t1 1.515513, loss kl 0.191897, loss_trans 0.028140, loss flux 44.978970, loss flux t1 46.127743, binary loss 8.444234, binary loss t1 9.639180\n",
      "Epoch 10/10, Batch 571/1650, Loss 23.576332, Loss rec 2.414242, loss rec t1 2.584620, loss kl 0.217693, loss_trans 0.030845, loss flux 47.058945, loss flux t1 47.321011, binary loss 9.373718, binary loss t1 8.955213\n",
      "Epoch 10/10, Batch 581/1650, Loss 21.111578, Loss rec 2.184617, loss rec t1 2.289325, loss kl 0.184567, loss_trans 0.032693, loss flux 47.948532, loss flux t1 47.009716, binary loss 8.210676, binary loss t1 8.209700\n",
      "Epoch 10/10, Batch 591/1650, Loss 23.642979, Loss rec 1.658138, loss rec t1 1.814959, loss kl 0.148118, loss_trans 0.021496, loss flux 42.565258, loss flux t1 45.179550, binary loss 9.877376, binary loss t1 10.122891\n",
      "Epoch 10/10, Batch 601/1650, Loss 34.803677, Loss rec 4.319987, loss rec t1 4.799319, loss kl 0.200503, loss_trans 0.042898, loss flux 47.290848, loss flux t1 48.209415, binary loss 12.740064, binary loss t1 12.700906\n",
      "Epoch 10/10, Batch 611/1650, Loss 24.324251, Loss rec 3.640203, loss rec t1 4.357546, loss kl 0.198247, loss_trans 0.026526, loss flux 48.084064, loss flux t1 47.822426, binary loss 7.605825, binary loss t1 8.495905\n",
      "Epoch 10/10, Batch 621/1650, Loss 29.665573, Loss rec 2.451120, loss rec t1 3.013491, loss kl 0.250033, loss_trans 0.030202, loss flux 46.885864, loss flux t1 48.438160, binary loss 11.571898, binary loss t1 12.348827\n",
      "Epoch 10/10, Batch 631/1650, Loss 33.229473, Loss rec 2.218909, loss rec t1 3.217693, loss kl 0.268438, loss_trans 0.044675, loss flux 46.680511, loss flux t1 47.144474, binary loss 15.090066, binary loss t1 12.389694\n",
      "Epoch 10/10, Batch 641/1650, Loss 26.453491, Loss rec 3.357068, loss rec t1 3.959997, loss kl 0.228865, loss_trans 0.034038, loss flux 47.928196, loss flux t1 48.345188, binary loss 9.423371, binary loss t1 9.450150\n",
      "Epoch 10/10, Batch 651/1650, Loss 34.813904, Loss rec 3.076476, loss rec t1 4.453591, loss kl 0.228825, loss_trans 0.041702, loss flux 46.599117, loss flux t1 47.925095, binary loss 13.957642, binary loss t1 13.055669\n",
      "Epoch 10/10, Batch 661/1650, Loss 27.998081, Loss rec 4.343685, loss rec t1 4.669905, loss kl 0.278690, loss_trans 0.038571, loss flux 46.381531, loss flux t1 48.497917, binary loss 9.101976, binary loss t1 9.565254\n",
      "Epoch 10/10, Batch 671/1650, Loss 35.045403, Loss rec 4.185635, loss rec t1 4.783182, loss kl 0.199266, loss_trans 0.041207, loss flux 47.852348, loss flux t1 49.577564, binary loss 12.500160, binary loss t1 13.335952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Batch 681/1650, Loss 25.966505, Loss rec 1.793184, loss rec t1 2.476514, loss kl 0.187392, loss_trans 0.033364, loss flux 44.253761, loss flux t1 46.761341, binary loss 10.594224, binary loss t1 10.881828\n",
      "Epoch 10/10, Batch 691/1650, Loss 30.396088, Loss rec 2.893751, loss rec t1 3.284925, loss kl 0.338326, loss_trans 0.040341, loss flux 51.320744, loss flux t1 53.161373, binary loss 12.240067, binary loss t1 11.598677\n",
      "Epoch 10/10, Batch 701/1650, Loss 28.204744, Loss rec 2.990904, loss rec t1 3.233868, loss kl 0.317570, loss_trans 0.035994, loss flux 48.966656, loss flux t1 49.252121, binary loss 11.124416, binary loss t1 10.501994\n",
      "Epoch 10/10, Batch 711/1650, Loss 24.319387, Loss rec 4.231067, loss rec t1 4.727338, loss kl 0.443621, loss_trans 0.057124, loss flux 54.310509, loss flux t1 56.846996, binary loss 7.263197, binary loss t1 7.597039\n",
      "Epoch 10/10, Batch 721/1650, Loss 33.844528, Loss rec 2.492548, loss rec t1 3.251204, loss kl 0.286484, loss_trans 0.037231, loss flux 48.629143, loss flux t1 50.979893, binary loss 14.950868, binary loss t1 12.826194\n",
      "Epoch 10/10, Batch 731/1650, Loss 27.548788, Loss rec 3.008070, loss rec t1 3.175211, loss kl 0.211603, loss_trans 0.034569, loss flux 47.505096, loss flux t1 48.369541, binary loss 9.996140, binary loss t1 11.123196\n",
      "Epoch 10/10, Batch 741/1650, Loss 21.953011, Loss rec 2.718577, loss rec t1 2.694703, loss kl 0.198540, loss_trans 0.031528, loss flux 46.291767, loss flux t1 47.478634, binary loss 7.788265, binary loss t1 8.521399\n",
      "Epoch 10/10, Batch 751/1650, Loss 34.071007, Loss rec 2.306632, loss rec t1 2.707009, loss kl 0.248202, loss_trans 0.038386, loss flux 45.779308, loss flux t1 46.393738, binary loss 15.326553, binary loss t1 13.444222\n",
      "Epoch 10/10, Batch 761/1650, Loss 25.445827, Loss rec 2.487377, loss rec t1 2.918943, loss kl 0.294646, loss_trans 0.051658, loss flux 45.374241, loss flux t1 48.122063, binary loss 10.013401, binary loss t1 9.679804\n",
      "Epoch 10/10, Batch 771/1650, Loss 18.621014, Loss rec 1.886240, loss rec t1 1.870981, loss kl 0.186360, loss_trans 0.036243, loss flux 41.982368, loss flux t1 45.318886, binary loss 6.809615, binary loss t1 7.831573\n",
      "Epoch 10/10, Batch 781/1650, Loss 23.868793, Loss rec 2.519133, loss rec t1 3.002342, loss kl 0.187444, loss_trans 0.033151, loss flux 45.021023, loss flux t1 46.130264, binary loss 8.731595, binary loss t1 9.395128\n",
      "Epoch 10/10, Batch 791/1650, Loss 18.608002, Loss rec 2.688968, loss rec t1 2.821382, loss kl 0.177757, loss_trans 0.040563, loss flux 45.486328, loss flux t1 46.821423, binary loss 6.596980, binary loss t1 6.282351\n",
      "Epoch 10/10, Batch 801/1650, Loss 28.417795, Loss rec 3.186296, loss rec t1 4.058481, loss kl 0.241699, loss_trans 0.038709, loss flux 47.493610, loss flux t1 48.837944, binary loss 10.225859, binary loss t1 10.666751\n",
      "Epoch 10/10, Batch 811/1650, Loss 39.737507, Loss rec 3.697247, loss rec t1 4.092909, loss kl 0.319409, loss_trans 0.051144, loss flux 50.510616, loss flux t1 53.486153, binary loss 17.417925, binary loss t1 14.158874\n",
      "Epoch 10/10, Batch 821/1650, Loss 26.159710, Loss rec 2.607116, loss rec t1 2.473034, loss kl 0.199617, loss_trans 0.033147, loss flux 43.142670, loss flux t1 46.431095, binary loss 9.861091, binary loss t1 10.985707\n",
      "Epoch 10/10, Batch 831/1650, Loss 21.157282, Loss rec 2.088216, loss rec t1 2.557313, loss kl 0.339092, loss_trans 0.033124, loss flux 45.652637, loss flux t1 45.986397, binary loss 8.619663, binary loss t1 7.519875\n",
      "Epoch 10/10, Batch 841/1650, Loss 25.161308, Loss rec 1.493530, loss rec t1 2.068807, loss kl 0.134022, loss_trans 0.022754, loss flux 42.537739, loss flux t1 43.883553, binary loss 9.968629, binary loss t1 11.473566\n",
      "Epoch 10/10, Batch 851/1650, Loss 26.510216, Loss rec 5.026648, loss rec t1 6.664099, loss kl 0.220355, loss_trans 0.038375, loss flux 45.254662, loss flux t1 46.860283, binary loss 7.133760, binary loss t1 7.426979\n",
      "Epoch 10/10, Batch 861/1650, Loss 54.197418, Loss rec 3.736850, loss rec t1 4.373777, loss kl 0.306586, loss_trans 0.046068, loss flux 48.552402, loss flux t1 51.196941, binary loss 23.432064, binary loss t1 22.302076\n",
      "Epoch 10/10, Batch 871/1650, Loss 29.195772, Loss rec 6.089921, loss rec t1 7.338007, loss kl 0.257776, loss_trans 0.032536, loss flux 48.423859, loss flux t1 48.840668, binary loss 7.216717, binary loss t1 8.260817\n",
      "Epoch 10/10, Batch 881/1650, Loss 25.189558, Loss rec 3.467246, loss rec t1 4.960285, loss kl 0.227957, loss_trans 0.042696, loss flux 46.220680, loss flux t1 48.357216, binary loss 7.712565, binary loss t1 8.778808\n",
      "Epoch 10/10, Batch 891/1650, Loss 28.282301, Loss rec 2.545904, loss rec t1 3.060497, loss kl 0.192312, loss_trans 0.030108, loss flux 44.068737, loss flux t1 47.184078, binary loss 10.395676, binary loss t1 12.057804\n",
      "Epoch 10/10, Batch 901/1650, Loss 23.651495, Loss rec 2.314938, loss rec t1 3.133976, loss kl 0.319991, loss_trans 0.047798, loss flux 48.754734, loss flux t1 51.336426, binary loss 8.896839, binary loss t1 8.937952\n",
      "Epoch 10/10, Batch 911/1650, Loss 17.224451, Loss rec 1.620722, loss rec t1 2.170223, loss kl 0.192970, loss_trans 0.030358, loss flux 41.426601, loss flux t1 44.288830, binary loss 6.272590, binary loss t1 6.937589\n",
      "Epoch 10/10, Batch 921/1650, Loss 17.908415, Loss rec 1.867473, loss rec t1 2.214382, loss kl 0.221847, loss_trans 0.034159, loss flux 44.817844, loss flux t1 46.090504, binary loss 6.588194, binary loss t1 6.982361\n",
      "Epoch 10/10, Batch 931/1650, Loss 39.528477, Loss rec 2.950085, loss rec t1 2.538766, loss kl 0.238396, loss_trans 0.026075, loss flux 46.267448, loss flux t1 47.645454, binary loss 18.183140, binary loss t1 15.592014\n",
      "Epoch 10/10, Batch 941/1650, Loss 22.422930, Loss rec 2.673943, loss rec t1 3.745845, loss kl 0.277384, loss_trans 0.034922, loss flux 44.640972, loss flux t1 46.942944, binary loss 7.225681, binary loss t1 8.465156\n",
      "Epoch 10/10, Batch 951/1650, Loss 24.426542, Loss rec 2.263292, loss rec t1 2.478559, loss kl 0.187342, loss_trans 0.026297, loss flux 46.206516, loss flux t1 48.073151, binary loss 9.348648, binary loss t1 10.122404\n",
      "Epoch 10/10, Batch 961/1650, Loss 18.131260, Loss rec 1.602638, loss rec t1 1.828648, loss kl 0.152044, loss_trans 0.021845, loss flux 43.805302, loss flux t1 43.730072, binary loss 7.430573, binary loss t1 7.095512\n",
      "Epoch 10/10, Batch 971/1650, Loss 23.096125, Loss rec 2.310823, loss rec t1 2.704968, loss kl 0.183034, loss_trans 0.035795, loss flux 46.821571, loss flux t1 48.239338, binary loss 8.555922, binary loss t1 9.305583\n",
      "Epoch 10/10, Batch 981/1650, Loss 20.359348, Loss rec 2.541880, loss rec t1 2.895206, loss kl 0.177405, loss_trans 0.031872, loss flux 44.276440, loss flux t1 45.085964, binary loss 6.923499, binary loss t1 7.789485\n",
      "Epoch 10/10, Batch 991/1650, Loss 20.099863, Loss rec 1.882849, loss rec t1 2.189274, loss kl 0.164253, loss_trans 0.036378, loss flux 44.748371, loss flux t1 47.229523, binary loss 7.292840, binary loss t1 8.534267\n",
      "Epoch 10/10, Batch 1001/1650, Loss 40.437920, Loss rec 2.750932, loss rec t1 3.333165, loss kl 0.293798, loss_trans 0.042033, loss flux 49.290653, loss flux t1 51.434654, binary loss 17.717422, binary loss t1 16.300568\n",
      "Epoch 10/10, Batch 1011/1650, Loss 20.618097, Loss rec 2.871552, loss rec t1 3.850927, loss kl 0.187445, loss_trans 0.042150, loss flux 44.074558, loss flux t1 46.715866, binary loss 6.729344, binary loss t1 6.936678\n",
      "Epoch 10/10, Batch 1021/1650, Loss 21.385258, Loss rec 1.653233, loss rec t1 1.761596, loss kl 0.196870, loss_trans 0.027646, loss flux 44.568146, loss flux t1 46.578003, binary loss 8.064889, binary loss t1 9.681025\n",
      "Epoch 10/10, Batch 1031/1650, Loss 20.349398, Loss rec 2.099957, loss rec t1 1.961029, loss kl 0.317392, loss_trans 0.032713, loss flux 48.248173, loss flux t1 48.440887, binary loss 7.824496, binary loss t1 8.113810\n",
      "Epoch 10/10, Batch 1041/1650, Loss 20.027159, Loss rec 1.628254, loss rec t1 1.957141, loss kl 0.204222, loss_trans 0.021149, loss flux 45.348385, loss flux t1 46.435928, binary loss 7.930570, binary loss t1 8.285822\n",
      "Epoch 10/10, Batch 1051/1650, Loss 24.800465, Loss rec 2.200893, loss rec t1 2.397128, loss kl 0.155331, loss_trans 0.024947, loss flux 44.303253, loss flux t1 45.204472, binary loss 9.789539, binary loss t1 10.232628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Batch 1061/1650, Loss 31.732777, Loss rec 6.119087, loss rec t1 6.694645, loss kl 0.283970, loss_trans 0.044811, loss flux 51.159588, loss flux t1 52.576092, binary loss 9.259722, binary loss t1 9.330542\n",
      "Epoch 10/10, Batch 1071/1650, Loss 30.933632, Loss rec 3.378658, loss rec t1 4.086647, loss kl 0.307067, loss_trans 0.046130, loss flux 46.469769, loss flux t1 49.911594, binary loss 11.049026, binary loss t1 12.066102\n",
      "Epoch 10/10, Batch 1081/1650, Loss 28.568359, Loss rec 5.669531, loss rec t1 5.901770, loss kl 0.235097, loss_trans 0.036658, loss flux 47.609249, loss flux t1 48.170361, binary loss 8.794426, binary loss t1 7.930880\n",
      "Epoch 10/10, Batch 1091/1650, Loss 29.487293, Loss rec 3.207216, loss rec t1 3.433768, loss kl 0.147853, loss_trans 0.030807, loss flux 42.918709, loss flux t1 45.259674, binary loss 11.158516, binary loss t1 11.509131\n",
      "Epoch 10/10, Batch 1101/1650, Loss 28.828339, Loss rec 2.312356, loss rec t1 2.611082, loss kl 0.190459, loss_trans 0.034176, loss flux 44.496887, loss flux t1 45.222759, binary loss 12.073603, binary loss t1 11.606664\n",
      "Epoch 10/10, Batch 1111/1650, Loss 22.422985, Loss rec 2.444582, loss rec t1 3.678469, loss kl 0.186388, loss_trans 0.040061, loss flux 40.817612, loss flux t1 42.945610, binary loss 9.059156, binary loss t1 7.014329\n",
      "Epoch 10/10, Batch 1121/1650, Loss 34.044323, Loss rec 2.853880, loss rec t1 2.989156, loss kl 0.278343, loss_trans 0.049014, loss flux 47.184650, loss flux t1 49.231510, binary loss 13.848395, binary loss t1 14.025534\n",
      "Epoch 10/10, Batch 1131/1650, Loss 31.036446, Loss rec 3.338942, loss rec t1 2.926633, loss kl 0.382499, loss_trans 0.045305, loss flux 49.958611, loss flux t1 52.095821, binary loss 12.580432, binary loss t1 11.762636\n",
      "Epoch 10/10, Batch 1141/1650, Loss 23.581289, Loss rec 2.342148, loss rec t1 2.765381, loss kl 0.242800, loss_trans 0.039696, loss flux 48.012627, loss flux t1 49.557091, binary loss 8.853776, binary loss t1 9.337488\n",
      "Epoch 10/10, Batch 1151/1650, Loss 25.731812, Loss rec 1.975129, loss rec t1 2.144660, loss kl 0.308092, loss_trans 0.032529, loss flux 49.422882, loss flux t1 51.357269, binary loss 11.078912, binary loss t1 10.192491\n",
      "Epoch 10/10, Batch 1161/1650, Loss 26.971420, Loss rec 3.131656, loss rec t1 3.355670, loss kl 0.220997, loss_trans 0.035794, loss flux 46.904091, loss flux t1 49.005730, binary loss 10.059638, binary loss t1 10.167665\n",
      "Epoch 10/10, Batch 1171/1650, Loss 26.476315, Loss rec 2.244444, loss rec t1 3.312657, loss kl 0.207416, loss_trans 0.028718, loss flux 45.733067, loss flux t1 46.916321, binary loss 9.997116, binary loss t1 10.685965\n",
      "Epoch 10/10, Batch 1181/1650, Loss 31.980722, Loss rec 3.022595, loss rec t1 3.447488, loss kl 0.380718, loss_trans 0.044690, loss flux 50.130611, loss flux t1 52.830280, binary loss 11.721279, binary loss t1 13.363951\n",
      "Epoch 10/10, Batch 1191/1650, Loss 30.456343, Loss rec 4.360401, loss rec t1 5.098393, loss kl 0.285295, loss_trans 0.038201, loss flux 49.519798, loss flux t1 52.048210, binary loss 10.481805, binary loss t1 10.192247\n",
      "Epoch 10/10, Batch 1201/1650, Loss 27.375729, Loss rec 4.353689, loss rec t1 3.113535, loss kl 0.199395, loss_trans 0.038780, loss flux 41.642319, loss flux t1 41.980804, binary loss 10.190783, binary loss t1 9.479548\n",
      "Epoch 10/10, Batch 1211/1650, Loss 52.202660, Loss rec 5.563236, loss rec t1 7.427870, loss kl 0.296470, loss_trans 0.042099, loss flux 49.912769, loss flux t1 51.629665, binary loss 19.779819, binary loss t1 19.093168\n",
      "Epoch 10/10, Batch 1221/1650, Loss 24.576151, Loss rec 2.807158, loss rec t1 3.097589, loss kl 0.263776, loss_trans 0.045819, loss flux 45.734116, loss flux t1 48.442627, binary loss 9.444781, binary loss t1 8.917028\n",
      "Epoch 10/10, Batch 1231/1650, Loss 64.917328, Loss rec 5.307595, loss rec t1 4.847005, loss kl 0.228717, loss_trans 0.038149, loss flux 44.383713, loss flux t1 46.854374, binary loss 28.034710, binary loss t1 26.461151\n",
      "Epoch 10/10, Batch 1241/1650, Loss 31.988094, Loss rec 3.173813, loss rec t1 2.693113, loss kl 0.262787, loss_trans 0.033984, loss flux 43.783375, loss flux t1 48.061718, binary loss 13.533278, binary loss t1 12.291119\n",
      "Epoch 10/10, Batch 1251/1650, Loss 23.651850, Loss rec 3.691164, loss rec t1 4.059919, loss kl 0.210159, loss_trans 0.032098, loss flux 43.925064, loss flux t1 44.940678, binary loss 7.095756, binary loss t1 8.562755\n",
      "Epoch 10/10, Batch 1261/1650, Loss 32.366520, Loss rec 7.083522, loss rec t1 8.470322, loss kl 0.207678, loss_trans 0.032179, loss flux 47.483353, loss flux t1 46.058590, binary loss 8.607348, binary loss t1 7.965469\n",
      "Epoch 10/10, Batch 1271/1650, Loss 31.292387, Loss rec 3.340513, loss rec t1 3.326321, loss kl 0.289297, loss_trans 0.043021, loss flux 50.067989, loss flux t1 50.423939, binary loss 11.813021, binary loss t1 12.480215\n",
      "Epoch 10/10, Batch 1281/1650, Loss 29.100882, Loss rec 2.376323, loss rec t1 2.344494, loss kl 0.263518, loss_trans 0.038942, loss flux 45.217831, loss flux t1 44.781345, binary loss 13.267084, binary loss t1 10.810520\n",
      "Epoch 10/10, Batch 1291/1650, Loss 20.444029, Loss rec 1.922327, loss rec t1 2.152161, loss kl 0.183610, loss_trans 0.032061, loss flux 40.658253, loss flux t1 43.053310, binary loss 7.025424, binary loss t1 9.128446\n",
      "Epoch 10/10, Batch 1301/1650, Loss 21.036512, Loss rec 2.574586, loss rec t1 2.524234, loss kl 0.222178, loss_trans 0.024921, loss flux 43.466370, loss flux t1 45.080025, binary loss 7.867072, binary loss t1 7.823520\n",
      "Epoch 10/10, Batch 1311/1650, Loss 23.778860, Loss rec 2.050210, loss rec t1 2.051915, loss kl 0.205646, loss_trans 0.037000, loss flux 44.920338, loss flux t1 47.775612, binary loss 9.572266, binary loss t1 9.861823\n",
      "Epoch 10/10, Batch 1321/1650, Loss 24.623985, Loss rec 2.706630, loss rec t1 3.298255, loss kl 0.358996, loss_trans 0.047741, loss flux 48.211296, loss flux t1 51.596500, binary loss 9.592700, binary loss t1 8.619663\n",
      "Epoch 10/10, Batch 1331/1650, Loss 29.739798, Loss rec 2.072917, loss rec t1 2.324537, loss kl 0.192339, loss_trans 0.036775, loss flux 46.751637, loss flux t1 48.690792, binary loss 11.858282, binary loss t1 13.254948\n",
      "Epoch 10/10, Batch 1341/1650, Loss 25.208790, Loss rec 1.522979, loss rec t1 1.744634, loss kl 0.240604, loss_trans 0.036714, loss flux 40.288994, loss flux t1 44.795792, binary loss 10.676446, binary loss t1 10.987414\n",
      "Epoch 10/10, Batch 1351/1650, Loss 18.058083, Loss rec 1.238390, loss rec t1 1.780717, loss kl 0.162704, loss_trans 0.027084, loss flux 43.666115, loss flux t1 46.124908, binary loss 6.495720, binary loss t1 8.353468\n",
      "Epoch 10/10, Batch 1361/1650, Loss 33.884018, Loss rec 2.454223, loss rec t1 2.597792, loss kl 0.382693, loss_trans 0.049339, loss flux 49.354034, loss flux t1 49.929302, binary loss 15.460872, binary loss t1 12.939100\n",
      "Epoch 10/10, Batch 1371/1650, Loss 21.284237, Loss rec 1.308011, loss rec t1 1.688679, loss kl 0.200679, loss_trans 0.042615, loss flux 41.267162, loss flux t1 45.933517, binary loss 8.557140, binary loss t1 9.487113\n",
      "Epoch 10/10, Batch 1381/1650, Loss 31.442383, Loss rec 2.290503, loss rec t1 2.736568, loss kl 0.277675, loss_trans 0.033378, loss flux 47.968906, loss flux t1 49.984634, binary loss 13.382188, binary loss t1 12.722071\n",
      "Epoch 10/10, Batch 1391/1650, Loss 22.253893, Loss rec 3.858378, loss rec t1 3.696616, loss kl 0.347705, loss_trans 0.054826, loss flux 44.183113, loss flux t1 49.351990, binary loss 7.004015, binary loss t1 7.292352\n",
      "Epoch 10/10, Batch 1401/1650, Loss 21.848753, Loss rec 1.912446, loss rec t1 1.602662, loss kl 0.214507, loss_trans 0.033949, loss flux 46.884293, loss flux t1 49.483784, binary loss 8.366403, binary loss t1 9.718785\n",
      "Epoch 10/10, Batch 1411/1650, Loss 24.960413, Loss rec 2.522062, loss rec t1 2.345171, loss kl 0.249504, loss_trans 0.035119, loss flux 46.326759, loss flux t1 47.948318, binary loss 9.881524, binary loss t1 9.927030\n",
      "Epoch 10/10, Batch 1421/1650, Loss 22.958633, Loss rec 1.960365, loss rec t1 2.003735, loss kl 0.210062, loss_trans 0.034840, loss flux 45.172207, loss flux t1 46.576908, binary loss 9.286613, binary loss t1 9.463019\n",
      "Epoch 10/10, Batch 1431/1650, Loss 19.940605, Loss rec 2.191832, loss rec t1 2.080534, loss kl 0.243096, loss_trans 0.038929, loss flux 45.497749, loss flux t1 46.764042, binary loss 7.915994, binary loss t1 7.470222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Batch 1441/1650, Loss 28.391697, Loss rec 2.100214, loss rec t1 2.684272, loss kl 0.339705, loss_trans 0.050030, loss flux 46.276672, loss flux t1 50.148605, binary loss 12.097208, binary loss t1 11.120268\n",
      "Epoch 10/10, Batch 1451/1650, Loss 21.815285, Loss rec 2.658785, loss rec t1 2.638445, loss kl 0.241684, loss_trans 0.042897, loss flux 46.146160, loss flux t1 46.905964, binary loss 8.626740, binary loss t1 7.606735\n",
      "Epoch 10/10, Batch 1461/1650, Loss 21.119450, Loss rec 1.481739, loss rec t1 1.447634, loss kl 0.202139, loss_trans 0.037621, loss flux 44.691841, loss flux t1 45.481277, binary loss 8.864203, binary loss t1 9.086114\n",
      "Epoch 10/10, Batch 1471/1650, Loss 30.843189, Loss rec 2.220883, loss rec t1 2.481616, loss kl 0.260002, loss_trans 0.032680, loss flux 48.475510, loss flux t1 49.480202, binary loss 13.135208, binary loss t1 12.712798\n",
      "Epoch 10/10, Batch 1481/1650, Loss 17.801043, Loss rec 2.783973, loss rec t1 2.847620, loss kl 0.223592, loss_trans 0.029069, loss flux 45.995281, loss flux t1 47.475548, binary loss 6.094054, binary loss t1 5.822734\n",
      "Epoch 10/10, Batch 1491/1650, Loss 28.122433, Loss rec 2.978791, loss rec t1 2.484816, loss kl 0.332663, loss_trans 0.040611, loss flux 49.184704, loss flux t1 49.505539, binary loss 11.563110, binary loss t1 10.722441\n",
      "Epoch 10/10, Batch 1501/1650, Loss 25.668474, Loss rec 2.358549, loss rec t1 2.934942, loss kl 0.358159, loss_trans 0.045222, loss flux 50.357777, loss flux t1 52.485542, binary loss 10.283501, binary loss t1 9.688102\n",
      "Epoch 10/10, Batch 1511/1650, Loss 29.709553, Loss rec 2.996380, loss rec t1 3.869099, loss kl 0.181881, loss_trans 0.038896, loss flux 45.760323, loss flux t1 46.628365, binary loss 10.814181, binary loss t1 11.809115\n",
      "Epoch 10/10, Batch 1521/1650, Loss 17.001869, Loss rec 1.267231, loss rec t1 1.537378, loss kl 0.220559, loss_trans 0.030461, loss flux 44.137402, loss flux t1 47.415096, binary loss 6.873114, binary loss t1 7.073126\n",
      "Epoch 10/10, Batch 1531/1650, Loss 24.759592, Loss rec 2.351045, loss rec t1 1.876930, loss kl 0.208361, loss_trans 0.032941, loss flux 45.483803, loss flux t1 46.833946, binary loss 9.968385, binary loss t1 10.321928\n",
      "Epoch 10/10, Batch 1541/1650, Loss 23.696701, Loss rec 1.705410, loss rec t1 1.863353, loss kl 0.287620, loss_trans 0.049027, loss flux 45.565449, loss flux t1 48.303017, binary loss 10.129726, binary loss t1 9.661567\n",
      "Epoch 10/10, Batch 1551/1650, Loss 17.235664, Loss rec 1.625917, loss rec t1 1.789111, loss kl 0.151506, loss_trans 0.029710, loss flux 44.405907, loss flux t1 45.771973, binary loss 7.163891, binary loss t1 6.475530\n",
      "Epoch 10/10, Batch 1561/1650, Loss 27.132523, Loss rec 2.298377, loss rec t1 2.305524, loss kl 0.349895, loss_trans 0.045730, loss flux 47.857323, loss flux t1 49.047386, binary loss 11.388659, binary loss t1 10.744338\n",
      "Epoch 10/10, Batch 1571/1650, Loss 18.430901, Loss rec 1.675112, loss rec t1 1.807911, loss kl 0.326518, loss_trans 0.037876, loss flux 44.371143, loss flux t1 47.704990, binary loss 7.422520, binary loss t1 7.160963\n",
      "Epoch 10/10, Batch 1581/1650, Loss 16.321598, Loss rec 1.678759, loss rec t1 1.860055, loss kl 0.164676, loss_trans 0.022966, loss flux 42.381611, loss flux t1 43.073135, binary loss 6.664138, binary loss t1 5.931005\n",
      "Epoch 10/10, Batch 1591/1650, Loss 17.711184, Loss rec 1.418390, loss rec t1 1.214717, loss kl 0.254871, loss_trans 0.032388, loss flux 45.293251, loss flux t1 46.722610, binary loss 7.605759, binary loss t1 7.185057\n",
      "Epoch 10/10, Batch 1601/1650, Loss 22.432665, Loss rec 2.236856, loss rec t1 2.601222, loss kl 0.100840, loss_trans 0.023969, loss flux 43.169144, loss flux t1 43.719807, binary loss 8.025728, binary loss t1 9.444050\n",
      "Epoch 10/10, Batch 1611/1650, Loss 17.555187, Loss rec 1.394196, loss rec t1 1.590073, loss kl 0.134256, loss_trans 0.029032, loss flux 41.261864, loss flux t1 43.847340, binary loss 6.994562, binary loss t1 7.413068\n",
      "Epoch 10/10, Batch 1621/1650, Loss 30.887259, Loss rec 1.900510, loss rec t1 1.808881, loss kl 0.250077, loss_trans 0.038370, loss flux 43.380753, loss flux t1 45.335384, binary loss 14.464960, binary loss t1 12.424461\n",
      "Epoch 10/10, Batch 1631/1650, Loss 25.459911, Loss rec 2.857732, loss rec t1 3.871893, loss kl 0.153661, loss_trans 0.037923, loss flux 46.412689, loss flux t1 46.466351, binary loss 8.934535, binary loss t1 9.604169\n",
      "Epoch 10/10, Batch 1641/1650, Loss 22.371813, Loss rec 2.763567, loss rec t1 3.178711, loss kl 0.265179, loss_trans 0.046893, loss flux 47.016987, loss flux t1 50.165138, binary loss 8.634793, binary loss t1 7.482667\n",
      "Epoch 10/10, Train loss 22.496527, Eval loss 31.274147\n"
     ]
    }
   ],
   "source": [
    "# Optimization\n",
    "opt = Adam(lr=learning_rate)\n",
    "\n",
    "trainable_weights = encoder.trainable_weights + decoder.trainable_weights + transition.trainable_weights\n",
    "\n",
    "updates = opt.get_updates(loss, trainable_weights)\n",
    "\n",
    "iterate = K.function([xt, ut, xt1, m_tf], [loss, loss_rec_t, loss_rec_t1, loss_kl, loss_trans, loss_flux_t, loss_flux_t1, binary_sat_loss_t, binary_sat_loss_t1], updates=updates)\n",
    "\n",
    "eval_loss = K.function([xt, ut, xt1, m_tf], [loss])\n",
    "\n",
    "num_batch = int(num_train/batch_size)\n",
    "\n",
    "for e in range(epoch):\n",
    "    for ib in range(num_batch):\n",
    "        ind0 = ib * batch_size\n",
    "        state_t_batch = state_t_train[ind0:ind0+batch_size, ...]\n",
    "        state_t1_batch = state_t1_train[ind0:ind0 + batch_size, ...]\n",
    "        bhp_batch = bhp_train[ind0:ind0 + batch_size, ...]\n",
    "        m_batch = m[ind0:ind0 + batch_size, ...]\n",
    "\n",
    "        output = iterate([state_t_batch, bhp_batch, state_t1_batch, m_batch])\n",
    "\n",
    "        # tf.session.run(feed_dict={xt: sat_t_batch, ut: bhp_batch, xt1: sat_t1_batch}, ...\n",
    "        #                fetches= [loss, loss_rec_t, loss_rec_t1, loss_kl, loss_trans, updates])\n",
    "        # But output tensor for the updates operation is not returned\n",
    "\n",
    "        if ib % 10 == 0:\n",
    "            print('Epoch %d/%d, Batch %d/%d, Loss %f, Loss rec %f, loss rec t1 %f, loss kl %f, loss_trans %f, loss flux %f, loss flux t1 %f, binary loss %f, binary loss t1 %f'\n",
    "                  % (e+1, epoch, ib+1, num_batch, output[0], output[1], output[2], output[3], output[4], output[5], output[6], output[7], output[8]))\n",
    "    eval_loss_val = eval_loss([state_t_eval, bhp_eval, state_t1_eval, m_eval])\n",
    "\n",
    "    print('Epoch %d/%d, Train loss %f, Eval loss %f' % (e + 1, epoch, output[0], eval_loss_val[0]))\n",
    "\n",
    "\n",
    "encoder.save_weights(output_dir + 'e2c_encoder_' + case_name + case_suffix + train_suffix + model_suffix + '_nt%d_l%d_lr%.0e_ep%d.h5' \\\n",
    "                     % (num_train, latent_dim, learning_rate, epoch))\n",
    "decoder.save_weights(output_dir + 'e2c_decoder_' + case_name + case_suffix + train_suffix + model_suffix + '_nt%d_l%d_lr%.0e_ep%d.h5' \\\n",
    "                     % (num_train, latent_dim, learning_rate, epoch))\n",
    "transition.save_weights(output_dir + 'e2c_transition_' + case_name + case_suffix + train_suffix + model_suffix + '_nt%d_l%d_lr%.0e_ep%d.h5' \\\n",
    "                        % (num_train, latent_dim, learning_rate, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
