{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "import e2c as e2c_util\n",
    "\n",
    "# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "# The GPU id to use, usually either \"0\" or \"1\"\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras import losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruction_loss(x, t_decoded):\n",
    "    '''Reconstruction loss for the plain VAE'''\n",
    "    v = 0.1\n",
    "    # return K.mean(K.sum((K.batch_flatten(x) - K.batch_flatten(t_decoded)) ** 2 / (2*v) + 0.5*K.log(2*np.pi*v), axis=-1))\n",
    "    return K.mean(K.sum((K.batch_flatten(x) - K.batch_flatten(t_decoded)) ** 2 / (2*v), axis=-1))\n",
    "    # return K.sum((K.batch_flatten(x) - K.batch_flatten(t_decoded)) ** 2, axis=-1)\n",
    "\n",
    "\n",
    "def kl_normal_loss(qm, q_logv, pm, p_logv):\n",
    "    # 0.5 * (torch.log(pv) - torch.log(qv) + qv / pv + (qm - pm).pow(2) / pv - 1)\n",
    "    # -0.5 * K.sum(1 + t_log_var - K.square(t_mean) - K.exp(t_log_var), axis=-1)\n",
    "    kl = -0.5 * (1 - p_logv + q_logv - K.exp(q_logv) / K.exp(p_logv) - K.square(qm - pm) / K.exp(p_logv))\n",
    "    return K.mean(K.sum(kl, axis=-1))\n",
    "\n",
    "\n",
    "def get_flux_loss(m, state, state_pred):\n",
    "    # state, state_pred shape (batch_size, 60, 60, 2)\n",
    "    # p, p_pred shape (batch_size, 60, 60, 1)\n",
    "    # k shape (batch_size, 60, 60, 1)\n",
    "    \n",
    "    # Only consider discrepancies in total flux, not in phases (saturation not used) \n",
    "    \n",
    "    perm = K.exp(m)\n",
    "    p = K.expand_dims(state[:, :, :, 1], -1)\n",
    "    p_pred = K.expand_dims(state_pred[:, :, :, 1], -1)\n",
    "\n",
    "    #print(K.in_shape(xxx))\n",
    "    \n",
    "    tran_x = 1./perm[:, 1:, ...] + 1./perm[:, :-1, ...]\n",
    "    tran_y = 1./perm[:, :, 1:, ...] + 1./perm[:, :, :-1, ...]\n",
    "    flux_x = (p[:, 1:, ...] - p[:, :-1, ...]) / tran_x\n",
    "    flux_y = (p[:, :, 1:, :] - p[:, :, :-1, :]) / tran_y\n",
    "    flux_x_pred = (p_pred[:, 1:, ...] - p_pred[:, :-1, ...]) / tran_x\n",
    "    flux_y_pred = (p_pred[:, :, 1:, :] - p_pred[:, :, :-1, :]) / tran_y\n",
    "\n",
    "    loss_x = K.sum(K.abs(K.batch_flatten(flux_x) - K.batch_flatten(flux_x_pred)), axis=-1)\n",
    "    loss_y = K.sum(K.abs(K.batch_flatten(flux_y) - K.batch_flatten(flux_y_pred)), axis=-1)\n",
    "\n",
    "    loss_flux = K.mean(loss_x + loss_y)\n",
    "    return loss_flux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_sat_loss(state, state_pred):\n",
    "    \n",
    "    sat_threshold = 0.105\n",
    "    sat = K.expand_dims(state[:, :, :, 0], -1)\n",
    "    sat_pred = K.expand_dims(state_pred[:, :, :, 0], -1)\n",
    "    \n",
    "    \n",
    "    sat_bool = K.greater_equal(sat, sat_threshold) #will return boolean values\n",
    "    sat_bin = K.cast(sat_bool, dtype=K.floatx()) #will convert bool to 0 and 1  \n",
    "    \n",
    "    sat_pred_bool = K.greater_equal(sat_pred, sat_threshold) #will return boolean values\n",
    "    sat_pred_bin = K.cast(sat_pred_bool, dtype=K.floatx()) #will convert bool to 0 and 1  \n",
    "    \n",
    "#     binary_loss = K.sum(K.abs(K.batch_flatten(sat_bin) - K.batch_flatten(sat_pred_bin)), axis=-1)\n",
    "    \n",
    "    binary_loss = losses.binary_crossentropy(sat_bin, sat_pred_bin)\n",
    "    return K.mean(binary_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_e2c(latent_dim, u_dim, input_shape):\n",
    "    '''\n",
    "    Creates a E2C.\n",
    "\n",
    "    Args:\n",
    "        latent_dim: dimensionality of latent space\n",
    "        return_kl_loss_op: whether to return the operation for\n",
    "                           computing the KL divergence loss.\n",
    "\n",
    "    Returns:\n",
    "        The VAE model. If return_kl_loss_op is True, then the\n",
    "        operation for computing the KL divergence loss is\n",
    "        additionally returned.\n",
    "    '''\n",
    "\n",
    "    encoder_ = e2c_util.create_encoder(latent_dim, input_shape)\n",
    "    decoder_ = e2c_util.create_decoder(latent_dim, input_shape)\n",
    "    transition_ = e2c_util.create_trans(latent_dim, u_dim)\n",
    "    sampler_ = e2c_util.create_sampler()\n",
    "\n",
    "    return encoder_, decoder_, transition_, sampler_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m shape is  (60, 60, 1)\n",
      "m_eval shape is  (2200, 60, 60, 1)\n",
      "m shape is  (6600, 60, 60, 1)\n"
     ]
    }
   ],
   "source": [
    "# Create plain E2C model and associated loss operations\n",
    "\n",
    "################### case specification ######################\n",
    "\n",
    "#     data_dir = '/data/cees/zjin/lstm_rom/datasets/9W_BHP/'\n",
    "data_dir = '/data/cees/zjin/lstm_rom/datasets/9W_MS_BHP_RATE/'\n",
    "output_dir = '/data3/Astro/lstm_rom/e2c_larry/saved_models/'\n",
    "\n",
    "#     case_name = '9w_bhp'\n",
    "# case_name = '9w_bhp_rate'\n",
    "case_name = '9w_ms_bhp_rate'\n",
    "\n",
    "#     case_suffix = '_single_out_rel_2'\n",
    "case_suffix = '_fix_wl_rel_1'\n",
    "#     case_suffix = '_single_out_rel_3'\n",
    "train_suffix = '_with_p'\n",
    "model_suffix = '_flux_loss'\n",
    "\n",
    "\n",
    "train_file = case_name + '_e2c_train' + case_suffix + train_suffix + '_n6900_dt20day_nt23_nrun300.mat'\n",
    "eval_file = case_name + '_e2c_eval' + case_suffix + train_suffix +'_n2300_dt20day_nt23_nrun100.mat'\n",
    "\n",
    "#################### model specification ##################\n",
    "epoch = 10\n",
    "batch_size = 4\n",
    "learning_rate = 1e-4\n",
    "latent_dim = 50\n",
    "u_dim = 9*2 # control dimension\n",
    "\n",
    "# load data\n",
    "hf_r = h5py.File(data_dir + train_file, 'r')\n",
    "state_t_train = np.array(hf_r.get('state_t'))\n",
    "state_t1_train = np.array(hf_r.get('state_t1'))\n",
    "bhp_train = np.array(hf_r.get('bhp'))\n",
    "hf_r.close()\n",
    "\n",
    "num_train = state_t_train.shape[0]\n",
    "\n",
    "hf_r = h5py.File(data_dir + eval_file, 'r')\n",
    "state_t_eval = np.array(hf_r.get('state_t'))\n",
    "state_t1_eval = np.array(hf_r.get('state_t1'))\n",
    "bhp_eval = np.array(hf_r.get('bhp'))\n",
    "hf_r.close()\n",
    "\n",
    "m = np.loadtxt(\"/data/cees/zjin/lstm_rom/sim_runs/case6_9w_bhp_rate_ms_h5/template/logk1.dat\")\n",
    "m = m.reshape(60,60,1)\n",
    "print('m shape is ', m.shape)\n",
    "#     m_tf = K.placeholder((batch_size, 60, 60 ,1))\n",
    "m_tf = Input(shape=(60, 60, 1))\n",
    "\n",
    "\n",
    "\n",
    "m_eval = np.repeat(np.expand_dims(m, axis = 0), state_t_eval.shape[0], axis = 0)\n",
    "print(\"m_eval shape is \", m_eval.shape)\n",
    "m = np.repeat(np.expand_dims(m,axis = 0), state_t_train.shape[0], axis = 0)\n",
    "print(\"m shape is \", m.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Construct E2C\n",
    "input_shape = (60, 60, 2)\n",
    "encoder, decoder, transition, sampler = create_e2c(latent_dim, u_dim, input_shape)\n",
    "\n",
    "xt = Input(shape=input_shape)\n",
    "xt1 = Input(shape=input_shape)\n",
    "ut = Input(shape=(u_dim, ))\n",
    "\n",
    "zt_mean, zt_logvar = encoder(xt)\n",
    "zt = sampler([zt_mean, zt_logvar])\n",
    "xt_rec = decoder(zt)\n",
    "\n",
    "zt1_mean, zt1_logvar = encoder(xt1)\n",
    "\n",
    "# zt1_pred, zt1_mean_pred, zt1_logvar_pred = transition([zt, ut])\n",
    "zt1_pred, zt1_mean_pred = transition([zt, zt_mean, ut])\n",
    "xt1_pred = decoder(zt1_pred)\n",
    "\n",
    "# Compute loss\n",
    "loss_rec_t = reconstruction_loss(xt, xt_rec)\n",
    "loss_rec_t1 = reconstruction_loss(xt1, xt1_pred)\n",
    "\n",
    "loss_flux_t = get_flux_loss(m_tf, xt, xt_rec) / 1000.\n",
    "loss_flux_t1 = get_flux_loss(m_tf, xt1, xt1_pred) / 1000.\n",
    "\n",
    "binary_sat_loss_t = get_binary_sat_loss(xt, xt_rec) * 1\n",
    "binary_sat_loss_t1 = get_binary_sat_loss(xt1, xt1_pred) * 1\n",
    "\n",
    "\n",
    "loss_kl = kl_normal_loss(zt_mean, zt_logvar, 0., 0.)  # log(1.) = 0.\n",
    "loss_bound = loss_rec_t + loss_rec_t1 + loss_kl  + loss_flux_t + loss_flux_t1\n",
    "# loss_bound = loss_rec_t + loss_rec_t1 + loss_kl + binary_sat_loss_t + binary_sat_loss_t1\n",
    "\n",
    "# loss_trans = kl_normal_loss(zt1_mean_pred, zt1_logvar_pred, zt1_mean, zt1_logvar)\n",
    "\n",
    "# Use zt_logvar to approximate zt1_logvar_pred\n",
    "loss_trans = kl_normal_loss(zt1_mean_pred, zt_logvar, zt1_mean, zt1_logvar)\n",
    "\n",
    "\n",
    "trans_loss_weight = 1.0 # lambda in E2C paper Eq. (11)\n",
    "loss = loss_bound + trans_loss_weight * loss_trans\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Batch 1/1650, Loss 5473.817871, Loss rec 2449.146484, loss rec t1 2935.941406, loss kl 0.011339, loss_trans 0.007562, loss flux 43.008205, loss flux t1 45.702984, binary loss 7.239711, binary loss t1 8.713845\n",
      "Epoch 1/10, Batch 11/1650, Loss 1892.093140, Loss rec 807.189636, loss rec t1 947.972290, loss kl 2.134185, loss_trans 2.230043, loss flux 69.375496, loss flux t1 63.191536, binary loss 10.198698, binary loss t1 8.492787\n",
      "Epoch 1/10, Batch 21/1650, Loss 1722.424561, Loss rec 763.721130, loss rec t1 564.635498, loss kl 5.849187, loss_trans 5.125171, loss flux 168.219940, loss flux t1 214.873566, binary loss 5.955356, binary loss t1 5.185890\n",
      "Epoch 1/10, Batch 31/1650, Loss 995.683289, Loss rec 340.264954, loss rec t1 322.177765, loss kl 3.007895, loss_trans 2.150449, loss flux 174.745514, loss flux t1 153.336700, binary loss 8.438710, binary loss t1 7.112660\n",
      "Epoch 1/10, Batch 41/1650, Loss 858.768494, Loss rec 278.871643, loss rec t1 300.319885, loss kl 1.907560, loss_trans 1.551727, loss flux 135.066666, loss flux t1 141.051102, binary loss 6.867163, binary loss t1 5.725915\n",
      "Epoch 1/10, Batch 51/1650, Loss 733.078796, Loss rec 267.106079, loss rec t1 227.146057, loss kl 1.449588, loss_trans 1.189945, loss flux 114.319565, loss flux t1 121.867546, binary loss 6.354461, binary loss t1 4.967423\n",
      "Epoch 1/10, Batch 61/1650, Loss 721.093079, Loss rec 220.492401, loss rec t1 310.221039, loss kl 1.142444, loss_trans 0.820998, loss flux 92.812256, loss flux t1 95.603912, binary loss 7.239188, binary loss t1 5.690439\n",
      "Epoch 1/10, Batch 71/1650, Loss 598.630676, Loss rec 197.895874, loss rec t1 211.355591, loss kl 1.088602, loss_trans 0.942330, loss flux 88.864693, loss flux t1 98.483612, binary loss 6.099000, binary loss t1 5.228811\n",
      "Epoch 1/10, Batch 81/1650, Loss 611.405090, Loss rec 210.037857, loss rec t1 230.467575, loss kl 1.091648, loss_trans 0.792916, loss flux 82.235550, loss flux t1 86.779518, binary loss 7.234614, binary loss t1 5.800857\n",
      "Epoch 1/10, Batch 91/1650, Loss 566.408142, Loss rec 173.851852, loss rec t1 212.410309, loss kl 1.266916, loss_trans 0.883907, loss flux 83.163788, loss flux t1 94.831398, binary loss 4.086517, binary loss t1 3.886106\n",
      "Epoch 1/10, Batch 101/1650, Loss 472.146088, Loss rec 160.882751, loss rec t1 162.589371, loss kl 0.831764, loss_trans 0.540238, loss flux 73.542213, loss flux t1 73.759766, binary loss 4.579800, binary loss t1 4.262243\n",
      "Epoch 1/10, Batch 111/1650, Loss 487.891052, Loss rec 177.295273, loss rec t1 169.095459, loss kl 1.084023, loss_trans 0.630380, loss flux 70.150116, loss flux t1 69.635811, binary loss 4.183723, binary loss t1 3.577308\n",
      "Epoch 1/10, Batch 121/1650, Loss 523.423584, Loss rec 201.209808, loss rec t1 194.681519, loss kl 0.746287, loss_trans 0.521038, loss flux 61.023331, loss flux t1 65.241562, binary loss 5.308681, binary loss t1 4.383952\n",
      "Epoch 1/10, Batch 131/1650, Loss 454.704132, Loss rec 156.170364, loss rec t1 180.770355, loss kl 0.836507, loss_trans 0.488334, loss flux 58.893517, loss flux t1 57.545002, binary loss 4.846773, binary loss t1 3.260211\n",
      "Epoch 1/10, Batch 141/1650, Loss 586.089233, Loss rec 219.342407, loss rec t1 243.872314, loss kl 1.039640, loss_trans 0.586720, loss flux 64.517151, loss flux t1 56.731007, binary loss 6.284542, binary loss t1 4.367015\n",
      "Epoch 1/10, Batch 151/1650, Loss 347.164337, Loss rec 118.657249, loss rec t1 127.389046, loss kl 0.660875, loss_trans 0.414591, loss flux 51.341633, loss flux t1 48.700966, binary loss 5.723018, binary loss t1 5.390010\n",
      "Epoch 1/10, Batch 161/1650, Loss 388.595978, Loss rec 151.032043, loss rec t1 135.884354, loss kl 0.904605, loss_trans 0.416964, loss flux 54.459576, loss flux t1 45.898468, binary loss 4.780249, binary loss t1 3.158332\n",
      "Epoch 1/10, Batch 171/1650, Loss 379.048920, Loss rec 138.217041, loss rec t1 147.663712, loss kl 0.750437, loss_trans 0.542878, loss flux 46.789165, loss flux t1 45.085712, binary loss 4.562596, binary loss t1 4.006949\n",
      "Epoch 1/10, Batch 181/1650, Loss 385.173615, Loss rec 135.436737, loss rec t1 142.015839, loss kl 0.867471, loss_trans 0.486615, loss flux 53.831284, loss flux t1 52.535690, binary loss 5.733470, binary loss t1 4.978580\n",
      "Epoch 1/10, Batch 191/1650, Loss 427.349213, Loss rec 152.925049, loss rec t1 178.946991, loss kl 0.876019, loss_trans 0.413045, loss flux 51.942558, loss flux t1 42.245541, binary loss 3.598608, binary loss t1 3.220538\n",
      "Epoch 1/10, Batch 201/1650, Loss 273.012970, Loss rec 78.605743, loss rec t1 110.659103, loss kl 0.487631, loss_trans 0.258415, loss flux 45.377094, loss flux t1 37.624985, binary loss 7.082232, binary loss t1 5.982884\n",
      "Epoch 1/10, Batch 211/1650, Loss 347.011047, Loss rec 116.619133, loss rec t1 146.716888, loss kl 0.808088, loss_trans 0.501514, loss flux 41.679668, loss flux t1 40.685768, binary loss 3.149170, binary loss t1 3.368109\n",
      "Epoch 1/10, Batch 221/1650, Loss 381.088165, Loss rec 126.333084, loss rec t1 170.727783, loss kl 1.108681, loss_trans 0.500472, loss flux 42.329689, loss flux t1 40.088512, binary loss 3.096078, binary loss t1 2.979929\n",
      "Epoch 1/10, Batch 231/1650, Loss 231.011078, Loss rec 79.635384, loss rec t1 85.060814, loss kl 0.550711, loss_trans 0.265864, loss flux 35.505230, loss flux t1 29.993073, binary loss 2.927370, binary loss t1 3.891626\n",
      "Epoch 1/10, Batch 241/1650, Loss 260.348053, Loss rec 99.148743, loss rec t1 80.006927, loss kl 1.492741, loss_trans 0.263817, loss flux 46.258072, loss flux t1 33.177753, binary loss 8.501498, binary loss t1 6.260744\n",
      "Epoch 1/10, Batch 251/1650, Loss 224.170715, Loss rec 72.630096, loss rec t1 95.206650, loss kl 0.332322, loss_trans 0.213115, loss flux 28.918976, loss flux t1 26.869549, binary loss 8.266876, binary loss t1 6.595152\n",
      "Epoch 1/10, Batch 261/1650, Loss 310.065674, Loss rec 143.520264, loss rec t1 93.418053, loss kl 1.275412, loss_trans 0.298590, loss flux 40.080338, loss flux t1 31.473036, binary loss 7.754308, binary loss t1 5.690692\n",
      "Epoch 1/10, Batch 271/1650, Loss 214.555115, Loss rec 65.579842, loss rec t1 88.875610, loss kl 0.482930, loss_trans 0.273070, loss flux 29.614012, loss flux t1 29.729658, binary loss 4.472823, binary loss t1 4.471715\n",
      "Epoch 1/10, Batch 281/1650, Loss 257.154144, Loss rec 86.443542, loss rec t1 105.933792, loss kl 0.933773, loss_trans 0.355527, loss flux 34.144512, loss flux t1 29.342981, binary loss 5.991850, binary loss t1 5.030977\n",
      "Epoch 1/10, Batch 291/1650, Loss 242.155823, Loss rec 79.760574, loss rec t1 101.726410, loss kl 0.875904, loss_trans 0.344605, loss flux 30.605549, loss flux t1 28.842796, binary loss 4.528751, binary loss t1 3.943941\n",
      "Epoch 1/10, Batch 301/1650, Loss 213.544769, Loss rec 69.951324, loss rec t1 79.895180, loss kl 0.889715, loss_trans 0.262295, loss flux 32.307255, loss flux t1 30.239014, binary loss 3.307096, binary loss t1 3.130130\n",
      "Epoch 1/10, Batch 311/1650, Loss 261.227112, Loss rec 92.204094, loss rec t1 107.428719, loss kl 0.989813, loss_trans 0.358486, loss flux 30.409384, loss flux t1 29.836615, binary loss 2.200340, binary loss t1 2.411798\n",
      "Epoch 1/10, Batch 321/1650, Loss 190.024475, Loss rec 64.588501, loss rec t1 69.983223, loss kl 0.657579, loss_trans 0.151310, loss flux 30.809654, loss flux t1 23.834221, binary loss 3.711131, binary loss t1 4.379910\n",
      "Epoch 1/10, Batch 331/1650, Loss 237.631622, Loss rec 81.345856, loss rec t1 98.423615, loss kl 0.865020, loss_trans 0.342126, loss flux 29.605392, loss flux t1 27.049606, binary loss 4.518324, binary loss t1 3.600676\n",
      "Epoch 1/10, Batch 341/1650, Loss 264.219696, Loss rec 97.256149, loss rec t1 108.817039, loss kl 0.600897, loss_trans 0.288193, loss flux 29.425863, loss flux t1 27.831551, binary loss 3.890434, binary loss t1 3.715632\n",
      "Epoch 1/10, Batch 351/1650, Loss 264.561157, Loss rec 89.233505, loss rec t1 117.096756, loss kl 0.765939, loss_trans 0.290222, loss flux 29.349718, loss flux t1 27.825012, binary loss 1.995781, binary loss t1 1.881968\n",
      "Epoch 1/10, Batch 361/1650, Loss 279.226990, Loss rec 142.841461, loss rec t1 81.938942, loss kl 1.020556, loss_trans 0.238838, loss flux 28.436167, loss flux t1 24.751051, binary loss 3.333655, binary loss t1 2.896529\n",
      "Epoch 1/10, Batch 371/1650, Loss 219.207138, Loss rec 71.204552, loss rec t1 84.832687, loss kl 0.926221, loss_trans 0.282395, loss flux 32.735359, loss flux t1 29.225922, binary loss 2.606760, binary loss t1 2.418368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Batch 381/1650, Loss 280.065338, Loss rec 105.345245, loss rec t1 113.211731, loss kl 1.258834, loss_trans 0.375491, loss flux 30.950527, loss flux t1 28.923508, binary loss 3.499990, binary loss t1 3.154669\n",
      "Epoch 1/10, Batch 391/1650, Loss 296.369965, Loss rec 97.486359, loss rec t1 137.663635, loss kl 0.937136, loss_trans 0.300370, loss flux 31.686790, loss flux t1 28.295650, binary loss 4.306915, binary loss t1 3.898610\n",
      "Epoch 1/10, Batch 401/1650, Loss 282.723663, Loss rec 140.346634, loss rec t1 79.576828, loss kl 1.456538, loss_trans 0.280880, loss flux 30.766171, loss flux t1 30.296602, binary loss 1.767277, binary loss t1 1.932505\n",
      "Epoch 1/10, Batch 411/1650, Loss 263.492310, Loss rec 90.252975, loss rec t1 106.864563, loss kl 1.221031, loss_trans 0.339836, loss flux 32.595997, loss flux t1 32.217918, binary loss 4.928866, binary loss t1 4.127343\n",
      "Epoch 1/10, Batch 421/1650, Loss 198.936508, Loss rec 67.374084, loss rec t1 80.752449, loss kl 0.468106, loss_trans 0.173267, loss flux 26.178373, loss flux t1 23.990240, binary loss 4.972116, binary loss t1 4.733090\n",
      "Epoch 1/10, Batch 431/1650, Loss 173.392899, Loss rec 59.451012, loss rec t1 58.999481, loss kl 0.804280, loss_trans 0.295943, loss flux 27.854946, loss flux t1 25.987221, binary loss 3.053568, binary loss t1 3.279370\n",
      "Epoch 1/10, Batch 441/1650, Loss 213.302307, Loss rec 75.162666, loss rec t1 76.386887, loss kl 1.042646, loss_trans 0.264528, loss flux 32.447636, loss flux t1 27.997934, binary loss 2.405180, binary loss t1 2.461997\n",
      "Epoch 1/10, Batch 451/1650, Loss 166.572205, Loss rec 51.586586, loss rec t1 58.807072, loss kl 1.437443, loss_trans 0.234016, loss flux 29.421923, loss flux t1 25.085157, binary loss 2.478905, binary loss t1 2.533263\n",
      "Epoch 1/10, Batch 461/1650, Loss 214.838409, Loss rec 75.737976, loss rec t1 79.941605, loss kl 1.067775, loss_trans 0.337862, loss flux 29.513699, loss flux t1 28.239485, binary loss 3.461180, binary loss t1 3.010745\n",
      "Epoch 1/10, Batch 471/1650, Loss 154.353699, Loss rec 45.676682, loss rec t1 59.659012, loss kl 0.668440, loss_trans 0.175440, loss flux 26.006708, loss flux t1 22.167404, binary loss 3.390007, binary loss t1 3.572779\n",
      "Epoch 1/10, Batch 481/1650, Loss 173.572998, Loss rec 54.770676, loss rec t1 70.299858, loss kl 0.928950, loss_trans 0.253280, loss flux 23.786732, loss flux t1 23.533508, binary loss 5.001960, binary loss t1 4.245901\n",
      "Epoch 1/10, Batch 491/1650, Loss 135.861633, Loss rec 40.177292, loss rec t1 47.923847, loss kl 0.760702, loss_trans 0.235575, loss flux 23.934456, loss flux t1 22.829760, binary loss 3.563824, binary loss t1 3.259369\n",
      "Epoch 1/10, Batch 501/1650, Loss 159.576721, Loss rec 49.886276, loss rec t1 59.052044, loss kl 0.820626, loss_trans 0.197588, loss flux 26.779150, loss flux t1 22.841028, binary loss 2.927321, binary loss t1 3.725620\n",
      "Epoch 1/10, Batch 511/1650, Loss 144.286301, Loss rec 47.413101, loss rec t1 45.217522, loss kl 1.388758, loss_trans 0.166758, loss flux 26.966337, loss flux t1 23.133821, binary loss 6.941592, binary loss t1 5.148086\n",
      "Epoch 1/10, Batch 521/1650, Loss 138.891541, Loss rec 42.289726, loss rec t1 52.880478, loss kl 0.492742, loss_trans 0.127061, loss flux 23.133106, loss flux t1 19.968428, binary loss 2.840881, binary loss t1 2.797826\n",
      "Epoch 1/10, Batch 531/1650, Loss 146.595230, Loss rec 47.875942, loss rec t1 47.991936, loss kl 1.023112, loss_trans 0.207467, loss flux 25.681087, loss flux t1 23.815691, binary loss 2.424974, binary loss t1 2.091612\n",
      "Epoch 1/10, Batch 541/1650, Loss 146.418716, Loss rec 43.308647, loss rec t1 55.640625, loss kl 1.376458, loss_trans 0.145103, loss flux 24.751841, loss flux t1 21.196045, binary loss 5.600992, binary loss t1 4.503882\n",
      "Epoch 1/10, Batch 551/1650, Loss 132.286362, Loss rec 38.653923, loss rec t1 41.189602, loss kl 1.538588, loss_trans 0.181671, loss flux 26.455544, loss flux t1 24.267031, binary loss 4.338862, binary loss t1 3.294955\n",
      "Epoch 1/10, Batch 561/1650, Loss 148.363464, Loss rec 44.420666, loss rec t1 56.291603, loss kl 0.757532, loss_trans 0.163465, loss flux 24.367361, loss flux t1 22.362844, binary loss 2.696993, binary loss t1 2.736861\n",
      "Epoch 1/10, Batch 571/1650, Loss 133.577057, Loss rec 34.837029, loss rec t1 54.227837, loss kl 0.531527, loss_trans 0.139124, loss flux 21.476709, loss flux t1 22.364826, binary loss 3.094434, binary loss t1 2.848680\n",
      "Epoch 1/10, Batch 581/1650, Loss 165.705841, Loss rec 50.543381, loss rec t1 66.841545, loss kl 1.302614, loss_trans 0.177829, loss flux 25.692324, loss flux t1 21.148146, binary loss 3.257179, binary loss t1 3.060150\n",
      "Epoch 1/10, Batch 591/1650, Loss 145.519318, Loss rec 45.881111, loss rec t1 52.243382, loss kl 0.912213, loss_trans 0.209990, loss flux 24.072603, loss flux t1 22.200020, binary loss 3.558300, binary loss t1 3.127623\n",
      "Epoch 1/10, Batch 601/1650, Loss 183.984528, Loss rec 61.303478, loss rec t1 71.849289, loss kl 0.538085, loss_trans 0.161038, loss flux 25.047989, loss flux t1 25.084635, binary loss 1.590200, binary loss t1 1.618061\n",
      "Epoch 1/10, Batch 611/1650, Loss 170.030670, Loss rec 45.432301, loss rec t1 72.717331, loss kl 1.474062, loss_trans 0.207083, loss flux 27.135757, loss flux t1 23.064150, binary loss 4.087536, binary loss t1 2.070869\n",
      "Epoch 1/10, Batch 621/1650, Loss 137.585312, Loss rec 41.484802, loss rec t1 47.240532, loss kl 0.779606, loss_trans 0.181168, loss flux 25.700153, loss flux t1 22.199047, binary loss 5.883231, binary loss t1 4.441860\n",
      "Epoch 1/10, Batch 631/1650, Loss 128.099258, Loss rec 38.831764, loss rec t1 44.930874, loss kl 0.788411, loss_trans 0.190087, loss flux 22.875471, loss flux t1 20.482647, binary loss 2.919474, binary loss t1 2.797716\n",
      "Epoch 1/10, Batch 641/1650, Loss 134.443741, Loss rec 43.650364, loss rec t1 45.167122, loss kl 0.859836, loss_trans 0.171263, loss flux 21.756435, loss flux t1 22.838713, binary loss 2.504356, binary loss t1 2.330515\n",
      "Epoch 1/10, Batch 651/1650, Loss 142.527710, Loss rec 45.100533, loss rec t1 51.091183, loss kl 0.663462, loss_trans 0.143179, loss flux 23.714119, loss flux t1 21.815250, binary loss 4.482726, binary loss t1 3.930339\n",
      "Epoch 1/10, Batch 661/1650, Loss 121.531113, Loss rec 36.716389, loss rec t1 43.817772, loss kl 0.435677, loss_trans 0.084999, loss flux 20.464966, loss flux t1 20.011305, binary loss 7.582609, binary loss t1 6.033762\n",
      "Epoch 1/10, Batch 671/1650, Loss 188.868698, Loss rec 66.934242, loss rec t1 69.231125, loss kl 0.872687, loss_trans 0.160464, loss flux 27.050365, loss flux t1 24.619816, binary loss 4.075333, binary loss t1 3.497495\n",
      "Epoch 1/10, Batch 681/1650, Loss 118.998260, Loss rec 33.047203, loss rec t1 43.953781, loss kl 0.557546, loss_trans 0.159330, loss flux 20.770039, loss flux t1 20.510357, binary loss 4.648828, binary loss t1 4.137295\n",
      "Epoch 1/10, Batch 691/1650, Loss 139.736786, Loss rec 44.202072, loss rec t1 51.578762, loss kl 0.968613, loss_trans 0.159937, loss flux 21.776030, loss flux t1 21.051361, binary loss 2.343874, binary loss t1 2.088205\n",
      "Epoch 1/10, Batch 701/1650, Loss 140.852768, Loss rec 50.361549, loss rec t1 48.149166, loss kl 0.740232, loss_trans 0.125289, loss flux 21.265028, loss flux t1 20.211502, binary loss 5.222262, binary loss t1 4.421822\n",
      "Epoch 1/10, Batch 711/1650, Loss 140.183044, Loss rec 45.282604, loss rec t1 44.151634, loss kl 1.159455, loss_trans 0.155907, loss flux 25.994576, loss flux t1 23.438864, binary loss 1.840139, binary loss t1 1.728321\n",
      "Epoch 1/10, Batch 721/1650, Loss 127.943130, Loss rec 38.332527, loss rec t1 47.415653, loss kl 0.647776, loss_trans 0.135370, loss flux 21.009609, loss flux t1 20.402199, binary loss 4.253712, binary loss t1 3.634703\n",
      "Epoch 1/10, Batch 731/1650, Loss 130.906265, Loss rec 40.178772, loss rec t1 44.127007, loss kl 0.858418, loss_trans 0.185914, loss flux 23.374252, loss flux t1 22.181902, binary loss 2.518749, binary loss t1 2.447906\n",
      "Epoch 1/10, Batch 741/1650, Loss 146.348236, Loss rec 45.030216, loss rec t1 56.905785, loss kl 0.716409, loss_trans 0.130339, loss flux 22.125982, loss flux t1 21.439501, binary loss 2.155678, binary loss t1 1.702918\n",
      "Epoch 1/10, Batch 751/1650, Loss 117.711662, Loss rec 34.968178, loss rec t1 40.967754, loss kl 0.579118, loss_trans 0.107821, loss flux 21.557610, loss flux t1 19.531187, binary loss 2.466678, binary loss t1 2.423610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Batch 761/1650, Loss 127.992722, Loss rec 39.412071, loss rec t1 44.294060, loss kl 0.500482, loss_trans 0.080873, loss flux 22.855536, loss flux t1 20.849701, binary loss 3.504015, binary loss t1 3.392197\n",
      "Epoch 1/10, Batch 771/1650, Loss 139.851410, Loss rec 45.538761, loss rec t1 49.583900, loss kl 1.002228, loss_trans 0.154895, loss flux 23.006504, loss flux t1 20.565130, binary loss 1.789480, binary loss t1 1.928927\n",
      "Epoch 1/10, Batch 781/1650, Loss 129.382187, Loss rec 40.720596, loss rec t1 43.922573, loss kl 0.977702, loss_trans 0.145339, loss flux 23.045853, loss flux t1 20.570118, binary loss 2.306427, binary loss t1 2.067243\n",
      "Epoch 1/10, Batch 791/1650, Loss 125.667389, Loss rec 36.134045, loss rec t1 45.963387, loss kl 0.754573, loss_trans 0.138612, loss flux 21.677567, loss flux t1 20.999214, binary loss 2.690424, binary loss t1 2.436908\n",
      "Epoch 1/10, Batch 801/1650, Loss 112.246353, Loss rec 32.317200, loss rec t1 39.646416, loss kl 0.677024, loss_trans 0.114637, loss flux 19.215485, loss flux t1 20.275587, binary loss 3.381151, binary loss t1 3.175216\n",
      "Epoch 1/10, Batch 811/1650, Loss 111.602737, Loss rec 34.277809, loss rec t1 34.796158, loss kl 0.920372, loss_trans 0.072708, loss flux 21.801102, loss flux t1 19.734591, binary loss 5.357306, binary loss t1 3.587037\n",
      "Epoch 1/10, Batch 821/1650, Loss 168.668411, Loss rec 57.700905, loss rec t1 69.347458, loss kl 0.716432, loss_trans 0.093634, loss flux 21.437803, loss flux t1 19.372194, binary loss 1.096625, binary loss t1 1.191775\n",
      "Epoch 1/10, Batch 831/1650, Loss 164.366516, Loss rec 49.991482, loss rec t1 74.524529, loss kl 0.502659, loss_trans 0.106213, loss flux 20.803968, loss flux t1 18.437674, binary loss 1.932066, binary loss t1 1.494138\n",
      "Epoch 1/10, Batch 841/1650, Loss 138.481934, Loss rec 45.132168, loss rec t1 49.460266, loss kl 0.649780, loss_trans 0.125443, loss flux 21.955267, loss flux t1 21.159000, binary loss 4.977567, binary loss t1 4.678647\n",
      "Epoch 1/10, Batch 851/1650, Loss 118.677414, Loss rec 37.549538, loss rec t1 41.414360, loss kl 0.401417, loss_trans 0.090645, loss flux 21.540689, loss flux t1 17.680763, binary loss 6.505439, binary loss t1 5.097184\n",
      "Epoch 1/10, Batch 861/1650, Loss 125.442291, Loss rec 34.982368, loss rec t1 42.192307, loss kl 1.017837, loss_trans 0.099781, loss flux 26.707804, loss flux t1 20.442198, binary loss 3.923757, binary loss t1 3.909535\n",
      "Epoch 1/10, Batch 871/1650, Loss 123.137283, Loss rec 36.412491, loss rec t1 42.178745, loss kl 0.748345, loss_trans 0.112493, loss flux 22.786741, loss flux t1 20.898470, binary loss 2.881954, binary loss t1 2.515513\n",
      "Epoch 1/10, Batch 881/1650, Loss 128.045990, Loss rec 38.526520, loss rec t1 48.621704, loss kl 0.510451, loss_trans 0.121093, loss flux 19.567158, loss flux t1 20.699064, binary loss 3.044577, binary loss t1 3.005828\n",
      "Epoch 1/10, Batch 891/1650, Loss 111.711128, Loss rec 33.340591, loss rec t1 40.355171, loss kl 0.636467, loss_trans 0.078606, loss flux 19.666368, loss flux t1 17.633928, binary loss 2.778932, binary loss t1 2.209938\n",
      "Epoch 1/10, Batch 901/1650, Loss 112.142578, Loss rec 28.671318, loss rec t1 46.676144, loss kl 0.450436, loss_trans 0.067732, loss flux 18.313505, loss flux t1 17.963438, binary loss 5.805686, binary loss t1 5.118169\n",
      "Epoch 1/10, Batch 911/1650, Loss 104.092270, Loss rec 30.463430, loss rec t1 34.291710, loss kl 0.604967, loss_trans 0.081163, loss flux 19.894381, loss flux t1 18.756622, binary loss 2.044869, binary loss t1 2.058179\n",
      "Epoch 1/10, Batch 921/1650, Loss 112.384369, Loss rec 35.578957, loss rec t1 36.615288, loss kl 0.866985, loss_trans 0.111546, loss flux 20.289543, loss flux t1 18.922045, binary loss 2.923963, binary loss t1 2.651700\n",
      "Epoch 1/10, Batch 931/1650, Loss 131.713455, Loss rec 37.940483, loss rec t1 48.846664, loss kl 0.931390, loss_trans 0.150082, loss flux 22.533052, loss flux t1 21.311781, binary loss 3.055697, binary loss t1 2.843144\n",
      "Epoch 1/10, Batch 941/1650, Loss 103.407364, Loss rec 29.475677, loss rec t1 35.423882, loss kl 0.482562, loss_trans 0.093525, loss flux 18.760212, loss flux t1 19.171511, binary loss 5.728188, binary loss t1 4.975353\n",
      "Epoch 1/10, Batch 951/1650, Loss 105.797829, Loss rec 26.976658, loss rec t1 38.073135, loss kl 0.532639, loss_trans 0.081519, loss flux 20.925493, loss flux t1 19.208391, binary loss 1.452614, binary loss t1 1.584458\n",
      "Epoch 1/10, Batch 961/1650, Loss 112.294991, Loss rec 35.582340, loss rec t1 36.461262, loss kl 0.776868, loss_trans 0.078365, loss flux 20.299023, loss flux t1 19.097136, binary loss 4.094142, binary loss t1 3.599227\n",
      "Epoch 1/10, Batch 971/1650, Loss 82.920166, Loss rec 21.273914, loss rec t1 27.632389, loss kl 0.456303, loss_trans 0.053580, loss flux 16.682676, loss flux t1 16.821304, binary loss 3.766401, binary loss t1 3.773031\n",
      "Epoch 1/10, Batch 981/1650, Loss 99.208832, Loss rec 25.769684, loss rec t1 31.860037, loss kl 0.531567, loss_trans 0.095141, loss flux 21.718700, loss flux t1 19.233700, binary loss 2.529783, binary loss t1 2.296146\n",
      "Epoch 1/10, Batch 991/1650, Loss 101.141449, Loss rec 28.627861, loss rec t1 34.887825, loss kl 0.622778, loss_trans 0.120128, loss flux 18.504051, loss flux t1 18.378809, binary loss 3.478552, binary loss t1 3.191823\n",
      "Epoch 1/10, Batch 1001/1650, Loss 94.706276, Loss rec 27.233799, loss rec t1 29.938311, loss kl 0.418302, loss_trans 0.067171, loss flux 18.874056, loss flux t1 18.174637, binary loss 2.886236, binary loss t1 2.494319\n",
      "Epoch 1/10, Batch 1011/1650, Loss 104.003517, Loss rec 31.930107, loss rec t1 33.560158, loss kl 0.507114, loss_trans 0.074160, loss flux 20.100224, loss flux t1 17.831762, binary loss 3.344628, binary loss t1 3.032387\n",
      "Epoch 1/10, Batch 1021/1650, Loss 110.931274, Loss rec 32.860405, loss rec t1 35.735512, loss kl 1.118505, loss_trans 0.105683, loss flux 20.977837, loss flux t1 20.133329, binary loss 2.557510, binary loss t1 2.198891\n",
      "Epoch 1/10, Batch 1031/1650, Loss 86.640228, Loss rec 23.625736, loss rec t1 29.332645, loss kl 0.577315, loss_trans 0.079867, loss flux 16.346361, loss flux t1 16.678305, binary loss 3.266011, binary loss t1 3.330273\n",
      "Epoch 1/10, Batch 1041/1650, Loss 96.961166, Loss rec 28.713614, loss rec t1 31.167007, loss kl 0.608196, loss_trans 0.085971, loss flux 18.501591, loss flux t1 17.884790, binary loss 2.871844, binary loss t1 2.577377\n",
      "Epoch 1/10, Batch 1051/1650, Loss 91.652412, Loss rec 25.701948, loss rec t1 29.640965, loss kl 0.699181, loss_trans 0.051229, loss flux 18.404703, loss flux t1 17.154388, binary loss 6.743408, binary loss t1 3.866077\n",
      "Epoch 1/10, Batch 1061/1650, Loss 88.286819, Loss rec 22.350372, loss rec t1 30.574917, loss kl 0.410580, loss_trans 0.060937, loss flux 17.109673, loss flux t1 17.780344, binary loss 2.789929, binary loss t1 2.713527\n",
      "Epoch 1/10, Batch 1071/1650, Loss 108.431641, Loss rec 31.470718, loss rec t1 37.859936, loss kl 1.052035, loss_trans 0.070358, loss flux 19.715319, loss flux t1 18.263279, binary loss 3.873778, binary loss t1 3.175253\n",
      "Epoch 1/10, Batch 1081/1650, Loss 103.822319, Loss rec 28.342148, loss rec t1 36.220707, loss kl 0.521855, loss_trans 0.084210, loss flux 20.283413, loss flux t1 18.369989, binary loss 3.061196, binary loss t1 2.742324\n",
      "Epoch 1/10, Batch 1091/1650, Loss 118.058052, Loss rec 36.777229, loss rec t1 38.689968, loss kl 0.817497, loss_trans 0.075063, loss flux 21.832922, loss flux t1 19.865374, binary loss 2.931639, binary loss t1 2.260719\n",
      "Epoch 1/10, Batch 1101/1650, Loss 95.521805, Loss rec 27.370951, loss rec t1 29.312456, loss kl 0.573755, loss_trans 0.079641, loss flux 20.142477, loss flux t1 18.042528, binary loss 2.889557, binary loss t1 2.473284\n",
      "Epoch 1/10, Batch 1111/1650, Loss 96.021400, Loss rec 29.178654, loss rec t1 32.912308, loss kl 0.678978, loss_trans 0.085319, loss flux 17.298584, loss flux t1 15.867556, binary loss 2.394728, binary loss t1 2.259673\n",
      "Epoch 1/10, Batch 1121/1650, Loss 98.722366, Loss rec 27.309738, loss rec t1 34.138626, loss kl 0.602789, loss_trans 0.075635, loss flux 19.513582, loss flux t1 17.081991, binary loss 2.509867, binary loss t1 2.388085\n",
      "Epoch 1/10, Batch 1131/1650, Loss 95.131058, Loss rec 28.268497, loss rec t1 29.141972, loss kl 0.562373, loss_trans 0.046872, loss flux 19.988605, loss flux t1 17.122738, binary loss 1.854605, binary loss t1 1.732871\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Batch 1141/1650, Loss 83.724617, Loss rec 22.351004, loss rec t1 25.539413, loss kl 0.481227, loss_trans 0.079049, loss flux 18.789696, loss flux t1 16.484224, binary loss 3.145300, binary loss t1 3.190753\n",
      "Epoch 1/10, Batch 1151/1650, Loss 100.813477, Loss rec 29.047863, loss rec t1 32.102661, loss kl 0.578331, loss_trans 0.081961, loss flux 19.025589, loss flux t1 19.977076, binary loss 3.488528, binary loss t1 3.226167\n",
      "Epoch 1/10, Batch 1161/1650, Loss 95.192932, Loss rec 29.588448, loss rec t1 28.521118, loss kl 0.614647, loss_trans 0.083781, loss flux 19.540733, loss flux t1 16.844210, binary loss 3.067814, binary loss t1 2.732347\n",
      "Epoch 1/10, Batch 1171/1650, Loss 74.538689, Loss rec 19.412073, loss rec t1 23.843678, loss kl 0.323610, loss_trans 0.049387, loss flux 15.739193, loss flux t1 15.170751, binary loss 3.336830, binary loss t1 3.050088\n",
      "Epoch 1/10, Batch 1181/1650, Loss 95.887863, Loss rec 29.576256, loss rec t1 27.481579, loss kl 0.579080, loss_trans 0.079792, loss flux 20.748240, loss flux t1 17.422915, binary loss 2.520914, binary loss t1 2.163403\n",
      "Epoch 1/10, Batch 1191/1650, Loss 87.385933, Loss rec 27.468624, loss rec t1 27.020645, loss kl 0.498478, loss_trans 0.062443, loss flux 16.993929, loss flux t1 15.341811, binary loss 2.254247, binary loss t1 2.168975\n",
      "Epoch 1/10, Batch 1201/1650, Loss 122.700211, Loss rec 40.259300, loss rec t1 39.270874, loss kl 0.895617, loss_trans 0.082085, loss flux 21.771029, loss flux t1 20.421310, binary loss 1.725231, binary loss t1 1.589142\n",
      "Epoch 1/10, Batch 1211/1650, Loss 98.485718, Loss rec 29.551939, loss rec t1 29.891056, loss kl 0.690413, loss_trans 0.058107, loss flux 20.512545, loss flux t1 17.781666, binary loss 2.133401, binary loss t1 1.981752\n",
      "Epoch 1/10, Batch 1221/1650, Loss 76.010124, Loss rec 20.224621, loss rec t1 23.379530, loss kl 0.332998, loss_trans 0.050680, loss flux 16.409492, loss flux t1 15.612802, binary loss 2.052582, binary loss t1 1.903147\n",
      "Epoch 1/10, Batch 1231/1650, Loss 85.524223, Loss rec 23.356083, loss rec t1 28.421297, loss kl 0.407466, loss_trans 0.048176, loss flux 17.173653, loss flux t1 16.117540, binary loss 2.494355, binary loss t1 2.639448\n",
      "Epoch 1/10, Batch 1241/1650, Loss 110.290733, Loss rec 39.043568, loss rec t1 37.349075, loss kl 0.519216, loss_trans 0.082579, loss flux 17.138220, loss flux t1 16.158075, binary loss 1.733030, binary loss t1 1.578959\n",
      "Epoch 1/10, Batch 1251/1650, Loss 110.597954, Loss rec 34.312080, loss rec t1 45.986488, loss kl 0.552439, loss_trans 0.042459, loss flux 15.386001, loss flux t1 14.318486, binary loss 5.337390, binary loss t1 4.353218\n",
      "Epoch 1/10, Batch 1261/1650, Loss 98.643669, Loss rec 31.901796, loss rec t1 34.495277, loss kl 0.410364, loss_trans 0.052015, loss flux 16.521025, loss flux t1 15.263191, binary loss 2.346076, binary loss t1 2.218746\n",
      "Epoch 1/10, Batch 1271/1650, Loss 125.747627, Loss rec 41.253044, loss rec t1 47.975025, loss kl 0.389947, loss_trans 0.065453, loss flux 18.649618, loss flux t1 17.414537, binary loss 0.675096, binary loss t1 0.990867\n",
      "Epoch 1/10, Batch 1281/1650, Loss 90.222038, Loss rec 23.686695, loss rec t1 29.629738, loss kl 0.386871, loss_trans 0.058630, loss flux 19.536013, loss flux t1 16.924084, binary loss 7.375641, binary loss t1 6.075905\n",
      "Epoch 1/10, Batch 1291/1650, Loss 87.678566, Loss rec 25.704281, loss rec t1 27.031214, loss kl 0.602582, loss_trans 0.056668, loss flux 18.011312, loss flux t1 16.272505, binary loss 2.147794, binary loss t1 2.115700\n",
      "Epoch 1/10, Batch 1301/1650, Loss 105.418884, Loss rec 35.638504, loss rec t1 34.177330, loss kl 0.556232, loss_trans 0.061580, loss flux 18.603853, loss flux t1 16.381392, binary loss 1.712882, binary loss t1 1.720657\n",
      "Epoch 1/10, Batch 1311/1650, Loss 74.555244, Loss rec 20.524490, loss rec t1 21.468861, loss kl 0.758768, loss_trans 0.065332, loss flux 16.748322, loss flux t1 14.989478, binary loss 5.803471, binary loss t1 3.463052\n",
      "Epoch 1/10, Batch 1321/1650, Loss 84.519295, Loss rec 25.333139, loss rec t1 24.632875, loss kl 1.016986, loss_trans 0.069224, loss flux 17.650782, loss flux t1 15.816289, binary loss 4.683088, binary loss t1 2.879606\n",
      "Epoch 1/10, Batch 1331/1650, Loss 106.594360, Loss rec 32.988098, loss rec t1 39.687004, loss kl 0.385589, loss_trans 0.034719, loss flux 17.628849, loss flux t1 15.870096, binary loss 7.652345, binary loss t1 5.912041\n",
      "Epoch 1/10, Batch 1341/1650, Loss 99.419220, Loss rec 33.252861, loss rec t1 29.968111, loss kl 0.610970, loss_trans 0.070515, loss flux 19.122677, loss flux t1 16.394079, binary loss 2.480097, binary loss t1 2.234416\n",
      "Epoch 1/10, Batch 1351/1650, Loss 112.555901, Loss rec 36.885838, loss rec t1 41.122665, loss kl 0.477953, loss_trans 0.068003, loss flux 18.302408, loss flux t1 15.699041, binary loss 1.713456, binary loss t1 1.446569\n",
      "Epoch 1/10, Batch 1361/1650, Loss 111.292870, Loss rec 37.869057, loss rec t1 36.621330, loss kl 0.470279, loss_trans 0.044215, loss flux 18.264595, loss flux t1 18.023403, binary loss 3.255013, binary loss t1 2.990341\n",
      "Epoch 1/10, Batch 1371/1650, Loss 89.111084, Loss rec 28.025585, loss rec t1 27.203800, loss kl 0.500321, loss_trans 0.050094, loss flux 16.573729, loss flux t1 16.757551, binary loss 2.308325, binary loss t1 2.212152\n",
      "Epoch 1/10, Batch 1381/1650, Loss 111.650406, Loss rec 33.904274, loss rec t1 37.666630, loss kl 0.807289, loss_trans 0.081288, loss flux 20.641005, loss flux t1 18.549913, binary loss 3.330212, binary loss t1 2.851952\n",
      "Epoch 1/10, Batch 1391/1650, Loss 77.971458, Loss rec 21.288614, loss rec t1 22.469465, loss kl 0.520603, loss_trans 0.044893, loss flux 17.433624, loss flux t1 16.214260, binary loss 1.789114, binary loss t1 1.783677\n",
      "Epoch 1/10, Batch 1401/1650, Loss 105.238998, Loss rec 31.370461, loss rec t1 39.023567, loss kl 0.467147, loss_trans 0.063758, loss flux 18.934843, loss flux t1 15.379219, binary loss 4.784930, binary loss t1 4.400763\n",
      "Epoch 1/10, Batch 1411/1650, Loss 81.870186, Loss rec 21.947279, loss rec t1 28.471004, loss kl 0.330423, loss_trans 0.038999, loss flux 15.631903, loss flux t1 15.450575, binary loss 2.046049, binary loss t1 1.861174\n",
      "Epoch 1/10, Batch 1421/1650, Loss 86.486168, Loss rec 26.388374, loss rec t1 27.765596, loss kl 0.422404, loss_trans 0.037587, loss flux 16.486399, loss flux t1 15.385805, binary loss 3.060125, binary loss t1 2.762276\n",
      "Epoch 1/10, Batch 1431/1650, Loss 85.016472, Loss rec 22.976349, loss rec t1 28.726828, loss kl 1.109940, loss_trans 0.056551, loss flux 16.593485, loss flux t1 15.553322, binary loss 1.169169, binary loss t1 1.839068\n",
      "Epoch 1/10, Batch 1441/1650, Loss 87.868454, Loss rec 26.019257, loss rec t1 26.179699, loss kl 0.689238, loss_trans 0.061342, loss flux 18.119833, loss flux t1 16.799091, binary loss 3.008043, binary loss t1 2.490049\n",
      "Epoch 1/10, Batch 1451/1650, Loss 84.789474, Loss rec 23.666267, loss rec t1 25.705856, loss kl 0.509533, loss_trans 0.065620, loss flux 17.947220, loss flux t1 16.894979, binary loss 1.548859, binary loss t1 1.486898\n",
      "Epoch 1/10, Batch 1461/1650, Loss 86.537247, Loss rec 25.672697, loss rec t1 27.538479, loss kl 0.424705, loss_trans 0.042546, loss flux 17.710825, loss flux t1 15.147998, binary loss 6.256279, binary loss t1 4.886784\n",
      "Epoch 1/10, Batch 1471/1650, Loss 87.244904, Loss rec 25.388870, loss rec t1 26.196014, loss kl 0.529124, loss_trans 0.053716, loss flux 19.462343, loss flux t1 15.614828, binary loss 3.351222, binary loss t1 3.184049\n",
      "Epoch 1/10, Batch 1481/1650, Loss 80.406044, Loss rec 22.678905, loss rec t1 27.442320, loss kl 0.441545, loss_trans 0.046345, loss flux 15.317393, loss flux t1 14.479537, binary loss 2.021595, binary loss t1 1.879983\n",
      "Epoch 1/10, Batch 1491/1650, Loss 87.249893, Loss rec 25.457279, loss rec t1 27.865704, loss kl 0.587984, loss_trans 0.045369, loss flux 17.033661, loss flux t1 16.259893, binary loss 2.033834, binary loss t1 1.887745\n",
      "Epoch 1/10, Batch 1501/1650, Loss 76.824852, Loss rec 18.331951, loss rec t1 27.009808, loss kl 0.442934, loss_trans 0.063502, loss flux 15.979528, loss flux t1 14.997134, binary loss 2.565186, binary loss t1 2.039297\n",
      "Epoch 1/10, Batch 1511/1650, Loss 73.688797, Loss rec 17.749496, loss rec t1 25.137150, loss kl 0.463240, loss_trans 0.047887, loss flux 14.590622, loss flux t1 15.700398, binary loss 4.151724, binary loss t1 3.851648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Batch 1521/1650, Loss 63.954430, Loss rec 15.249386, loss rec t1 18.808584, loss kl 0.951796, loss_trans 0.032691, loss flux 15.442858, loss flux t1 13.469114, binary loss 2.176640, binary loss t1 2.021681\n",
      "Epoch 1/10, Batch 1531/1650, Loss 80.527496, Loss rec 23.319836, loss rec t1 24.294247, loss kl 0.793335, loss_trans 0.049255, loss flux 16.997555, loss flux t1 15.073273, binary loss 1.876601, binary loss t1 1.711678\n",
      "Epoch 1/10, Batch 1541/1650, Loss 77.983597, Loss rec 20.983543, loss rec t1 23.851444, loss kl 0.547309, loss_trans 0.052435, loss flux 16.842873, loss flux t1 15.705993, binary loss 2.298422, binary loss t1 1.940801\n",
      "Epoch 1/10, Batch 1551/1650, Loss 80.058281, Loss rec 22.107311, loss rec t1 22.797729, loss kl 0.790607, loss_trans 0.064455, loss flux 19.013325, loss flux t1 15.284861, binary loss 1.874350, binary loss t1 1.904290\n",
      "Epoch 1/10, Batch 1561/1650, Loss 66.240593, Loss rec 17.937336, loss rec t1 17.308882, loss kl 0.463288, loss_trans 0.041249, loss flux 17.479816, loss flux t1 13.010021, binary loss 2.506497, binary loss t1 2.805417\n",
      "Epoch 1/10, Batch 1571/1650, Loss 68.131310, Loss rec 17.873468, loss rec t1 18.211203, loss kl 0.770469, loss_trans 0.040301, loss flux 16.653969, loss flux t1 14.581899, binary loss 3.670070, binary loss t1 3.077803\n",
      "Epoch 1/10, Batch 1581/1650, Loss 83.324135, Loss rec 24.455162, loss rec t1 26.020172, loss kl 0.665934, loss_trans 0.047161, loss flux 16.597601, loss flux t1 15.538111, binary loss 2.922795, binary loss t1 2.677065\n",
      "Epoch 1/10, Batch 1591/1650, Loss 72.547760, Loss rec 18.059071, loss rec t1 22.551188, loss kl 0.535285, loss_trans 0.036609, loss flux 15.215425, loss flux t1 16.150181, binary loss 2.487701, binary loss t1 2.336039\n",
      "Epoch 1/10, Batch 1601/1650, Loss 64.722588, Loss rec 16.600288, loss rec t1 18.927532, loss kl 0.754011, loss_trans 0.031540, loss flux 15.456275, loss flux t1 12.952940, binary loss 3.233881, binary loss t1 2.570746\n",
      "Epoch 1/10, Batch 1611/1650, Loss 68.824806, Loss rec 19.180357, loss rec t1 17.957340, loss kl 0.489165, loss_trans 0.048786, loss flux 17.284048, loss flux t1 13.865108, binary loss 2.344859, binary loss t1 2.178792\n",
      "Epoch 1/10, Batch 1621/1650, Loss 74.561913, Loss rec 22.499525, loss rec t1 23.807381, loss kl 0.523225, loss_trans 0.037199, loss flux 14.745673, loss flux t1 12.948907, binary loss 1.826805, binary loss t1 1.561074\n",
      "Epoch 1/10, Batch 1631/1650, Loss 77.224281, Loss rec 23.388266, loss rec t1 22.025661, loss kl 0.633157, loss_trans 0.030300, loss flux 16.730690, loss flux t1 14.416218, binary loss 2.561962, binary loss t1 2.359337\n",
      "Epoch 1/10, Batch 1641/1650, Loss 86.464600, Loss rec 27.242561, loss rec t1 25.039312, loss kl 0.662187, loss_trans 0.048383, loss flux 17.971693, loss flux t1 15.500462, binary loss 1.420544, binary loss t1 1.313228\n",
      "Epoch 1/10, Train loss 77.584106, Eval loss 68.814140\n",
      "Epoch 2/10, Batch 1/1650, Loss 73.088356, Loss rec 19.659798, loss rec t1 22.077711, loss kl 0.474012, loss_trans 0.034346, loss flux 15.953250, loss flux t1 14.889232, binary loss 2.678099, binary loss t1 2.567437\n",
      "Epoch 2/10, Batch 11/1650, Loss 68.364082, Loss rec 17.283026, loss rec t1 21.648197, loss kl 0.336178, loss_trans 0.042648, loss flux 16.155293, loss flux t1 12.898745, binary loss 4.365359, binary loss t1 3.613681\n",
      "Epoch 2/10, Batch 21/1650, Loss 77.541893, Loss rec 23.934582, loss rec t1 23.583122, loss kl 0.589343, loss_trans 0.040504, loss flux 15.600646, loss flux t1 13.793694, binary loss 2.684754, binary loss t1 2.383620\n",
      "Epoch 2/10, Batch 31/1650, Loss 70.628365, Loss rec 18.927652, loss rec t1 23.924828, loss kl 0.351388, loss_trans 0.043265, loss flux 14.528543, loss flux t1 12.852693, binary loss 2.382513, binary loss t1 2.080370\n",
      "Epoch 2/10, Batch 41/1650, Loss 68.433144, Loss rec 19.514065, loss rec t1 20.457230, loss kl 0.446328, loss_trans 0.040084, loss flux 15.222272, loss flux t1 12.753168, binary loss 3.904802, binary loss t1 3.518554\n",
      "Epoch 2/10, Batch 51/1650, Loss 69.724648, Loss rec 18.578093, loss rec t1 20.490362, loss kl 0.476561, loss_trans 0.044920, loss flux 16.033659, loss flux t1 14.101053, binary loss 3.230559, binary loss t1 2.431251\n",
      "Epoch 2/10, Batch 61/1650, Loss 84.329315, Loss rec 20.476725, loss rec t1 28.092070, loss kl 0.467199, loss_trans 0.047301, loss flux 17.893787, loss flux t1 17.352236, binary loss 2.216715, binary loss t1 1.833960\n",
      "Epoch 2/10, Batch 71/1650, Loss 67.297966, Loss rec 18.542816, loss rec t1 19.021345, loss kl 0.456389, loss_trans 0.027110, loss flux 15.039060, loss flux t1 14.211245, binary loss 2.145701, binary loss t1 1.836732\n",
      "Epoch 2/10, Batch 81/1650, Loss 67.135284, Loss rec 20.251690, loss rec t1 20.398941, loss kl 0.402591, loss_trans 0.030475, loss flux 13.689798, loss flux t1 12.361797, binary loss 3.427637, binary loss t1 2.978126\n",
      "Epoch 2/10, Batch 91/1650, Loss 70.303291, Loss rec 18.901232, loss rec t1 20.988976, loss kl 0.624334, loss_trans 0.029849, loss flux 15.597434, loss flux t1 14.161471, binary loss 2.457809, binary loss t1 2.414644\n",
      "Epoch 2/10, Batch 101/1650, Loss 61.162598, Loss rec 16.343365, loss rec t1 19.131332, loss kl 0.408964, loss_trans 0.036439, loss flux 12.726508, loss flux t1 12.515992, binary loss 2.802157, binary loss t1 2.586258\n",
      "Epoch 2/10, Batch 111/1650, Loss 84.250877, Loss rec 25.131510, loss rec t1 27.779213, loss kl 0.534529, loss_trans 0.042898, loss flux 16.600647, loss flux t1 14.162082, binary loss 2.207712, binary loss t1 1.943186\n",
      "Epoch 2/10, Batch 121/1650, Loss 66.462646, Loss rec 18.088461, loss rec t1 19.968534, loss kl 0.536176, loss_trans 0.033877, loss flux 14.661850, loss flux t1 13.173755, binary loss 2.649375, binary loss t1 2.357074\n",
      "Epoch 2/10, Batch 131/1650, Loss 68.593437, Loss rec 19.350166, loss rec t1 20.369963, loss kl 0.513837, loss_trans 0.030855, loss flux 14.363520, loss flux t1 13.965095, binary loss 2.733467, binary loss t1 2.404667\n",
      "Epoch 2/10, Batch 141/1650, Loss 77.883263, Loss rec 22.876400, loss rec t1 21.913731, loss kl 0.623821, loss_trans 0.044360, loss flux 17.801004, loss flux t1 14.623950, binary loss 2.249757, binary loss t1 1.677443\n",
      "Epoch 2/10, Batch 151/1650, Loss 68.099770, Loss rec 19.015448, loss rec t1 19.823750, loss kl 0.353034, loss_trans 0.034584, loss flux 15.978127, loss flux t1 12.894831, binary loss 2.221970, binary loss t1 2.082523\n",
      "Epoch 2/10, Batch 161/1650, Loss 67.217064, Loss rec 18.910892, loss rec t1 17.874252, loss kl 0.472734, loss_trans 0.041512, loss flux 16.160582, loss flux t1 13.757096, binary loss 2.660386, binary loss t1 2.191032\n",
      "Epoch 2/10, Batch 171/1650, Loss 58.032204, Loss rec 16.241596, loss rec t1 16.904686, loss kl 0.356925, loss_trans 0.027438, loss flux 12.716049, loss flux t1 11.785506, binary loss 3.469719, binary loss t1 2.849738\n",
      "Epoch 2/10, Batch 181/1650, Loss 66.615517, Loss rec 18.493519, loss rec t1 19.452209, loss kl 0.437638, loss_trans 0.020351, loss flux 15.232422, loss flux t1 12.979385, binary loss 1.800198, binary loss t1 1.667515\n",
      "Epoch 2/10, Batch 191/1650, Loss 68.370399, Loss rec 18.175714, loss rec t1 22.614822, loss kl 0.475078, loss_trans 0.041223, loss flux 14.418794, loss flux t1 12.644774, binary loss 2.881869, binary loss t1 2.355967\n",
      "Epoch 2/10, Batch 201/1650, Loss 50.780670, Loss rec 12.895119, loss rec t1 12.812512, loss kl 0.294520, loss_trans 0.034212, loss flux 13.501237, loss flux t1 11.243072, binary loss 6.626054, binary loss t1 4.844714\n",
      "Epoch 2/10, Batch 211/1650, Loss 71.259094, Loss rec 20.438150, loss rec t1 20.987560, loss kl 0.372876, loss_trans 0.058517, loss flux 16.102634, loss flux t1 13.299352, binary loss 1.929827, binary loss t1 2.054906\n",
      "Epoch 2/10, Batch 221/1650, Loss 69.421097, Loss rec 18.268669, loss rec t1 21.064680, loss kl 0.585189, loss_trans 0.036451, loss flux 15.619579, loss flux t1 13.846520, binary loss 1.366223, binary loss t1 1.282107\n",
      "Epoch 2/10, Batch 231/1650, Loss 54.033974, Loss rec 13.656897, loss rec t1 15.180001, loss kl 0.320013, loss_trans 0.024801, loss flux 13.195002, loss flux t1 11.657262, binary loss 4.158305, binary loss t1 3.560466\n",
      "Epoch 2/10, Batch 241/1650, Loss 54.341461, Loss rec 11.998104, loss rec t1 15.739638, loss kl 0.508348, loss_trans 0.026292, loss flux 13.084705, loss flux t1 12.984374, binary loss 3.140883, binary loss t1 3.122051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Batch 251/1650, Loss 46.650097, Loss rec 10.701261, loss rec t1 13.146071, loss kl 0.268756, loss_trans 0.023502, loss flux 11.974803, loss flux t1 10.535701, binary loss 3.835066, binary loss t1 3.361186\n",
      "Epoch 2/10, Batch 261/1650, Loss 58.757828, Loss rec 14.106119, loss rec t1 17.692526, loss kl 0.551731, loss_trans 0.032488, loss flux 14.204835, loss flux t1 12.170134, binary loss 2.551889, binary loss t1 2.506497\n",
      "Epoch 2/10, Batch 271/1650, Loss 49.526333, Loss rec 12.597317, loss rec t1 13.888938, loss kl 0.252344, loss_trans 0.021551, loss flux 11.925774, loss flux t1 10.840406, binary loss 3.398828, binary loss t1 2.658184\n",
      "Epoch 2/10, Batch 281/1650, Loss 62.384407, Loss rec 17.408031, loss rec t1 17.466717, loss kl 0.429783, loss_trans 0.035711, loss flux 15.386662, loss flux t1 11.657506, binary loss 2.515391, binary loss t1 2.102500\n",
      "Epoch 2/10, Batch 291/1650, Loss 62.788429, Loss rec 16.716106, loss rec t1 20.457047, loss kl 0.382184, loss_trans 0.031282, loss flux 12.524487, loss flux t1 12.677325, binary loss 2.488832, binary loss t1 1.801463\n",
      "Epoch 2/10, Batch 301/1650, Loss 97.305817, Loss rec 34.192543, loss rec t1 34.838730, loss kl 0.411720, loss_trans 0.022435, loss flux 14.890239, loss flux t1 12.950147, binary loss 0.892636, binary loss t1 0.860554\n",
      "Epoch 2/10, Batch 311/1650, Loss 101.131630, Loss rec 30.446865, loss rec t1 38.945984, loss kl 0.507222, loss_trans 0.046809, loss flux 15.219929, loss flux t1 15.964815, binary loss 0.788812, binary loss t1 0.722495\n",
      "Epoch 2/10, Batch 321/1650, Loss 58.002129, Loss rec 14.593571, loss rec t1 15.946562, loss kl 0.343201, loss_trans 0.025508, loss flux 15.092307, loss flux t1 12.000979, binary loss 2.992518, binary loss t1 2.990317\n",
      "Epoch 2/10, Batch 331/1650, Loss 82.667084, Loss rec 24.913342, loss rec t1 26.786171, loss kl 0.471904, loss_trans 0.047182, loss flux 15.388343, loss flux t1 15.060141, binary loss 2.309493, binary loss t1 2.017447\n",
      "Epoch 2/10, Batch 341/1650, Loss 81.513329, Loss rec 22.746086, loss rec t1 26.732635, loss kl 0.358998, loss_trans 0.036949, loss flux 16.341213, loss flux t1 15.297449, binary loss 6.447834, binary loss t1 5.292120\n",
      "Epoch 2/10, Batch 351/1650, Loss 75.538483, Loss rec 19.009869, loss rec t1 26.140244, loss kl 0.423094, loss_trans 0.042731, loss flux 14.420753, loss flux t1 15.501795, binary loss 1.018798, binary loss t1 1.131967\n",
      "Epoch 2/10, Batch 361/1650, Loss 63.195801, Loss rec 17.472397, loss rec t1 18.737457, loss kl 0.500369, loss_trans 0.021206, loss flux 13.636476, loss flux t1 12.827896, binary loss 1.765914, binary loss t1 2.206629\n",
      "Epoch 2/10, Batch 371/1650, Loss 67.732521, Loss rec 16.892975, loss rec t1 20.005814, loss kl 0.428496, loss_trans 0.042224, loss flux 15.907768, loss flux t1 14.455243, binary loss 2.697189, binary loss t1 2.112537\n",
      "Epoch 2/10, Batch 381/1650, Loss 84.086937, Loss rec 24.801388, loss rec t1 27.089439, loss kl 0.668281, loss_trans 0.052906, loss flux 16.022511, loss flux t1 15.452408, binary loss 1.675106, binary loss t1 1.534540\n",
      "Epoch 2/10, Batch 391/1650, Loss 70.457535, Loss rec 20.952780, loss rec t1 21.023956, loss kl 0.554107, loss_trans 0.035479, loss flux 15.093526, loss flux t1 12.797688, binary loss 3.067802, binary loss t1 2.788810\n",
      "Epoch 2/10, Batch 401/1650, Loss 71.906425, Loss rec 19.791885, loss rec t1 21.926340, loss kl 0.691052, loss_trans 0.025785, loss flux 14.907814, loss flux t1 14.563548, binary loss 0.887186, binary loss t1 0.996741\n",
      "Epoch 2/10, Batch 411/1650, Loss 65.653648, Loss rec 18.418552, loss rec t1 18.928921, loss kl 0.552706, loss_trans 0.022140, loss flux 14.448127, loss flux t1 13.283200, binary loss 1.974002, binary loss t1 1.691689\n",
      "Epoch 2/10, Batch 421/1650, Loss 69.562347, Loss rec 17.998440, loss rec t1 23.502659, loss kl 0.331543, loss_trans 0.042567, loss flux 13.147432, loss flux t1 14.539710, binary loss 3.695680, binary loss t1 3.056853\n",
      "Epoch 2/10, Batch 431/1650, Loss 63.481358, Loss rec 17.610044, loss rec t1 19.498219, loss kl 0.340173, loss_trans 0.028242, loss flux 14.044614, loss flux t1 11.960071, binary loss 2.250816, binary loss t1 1.862281\n",
      "Epoch 2/10, Batch 441/1650, Loss 70.513260, Loss rec 19.853992, loss rec t1 21.638338, loss kl 0.486415, loss_trans 0.027539, loss flux 15.501165, loss flux t1 13.005803, binary loss 1.182443, binary loss t1 1.020939\n",
      "Epoch 2/10, Batch 451/1650, Loss 72.786545, Loss rec 22.077435, loss rec t1 19.768478, loss kl 0.566514, loss_trans 0.036761, loss flux 17.315607, loss flux t1 13.021751, binary loss 2.100237, binary loss t1 2.048337\n",
      "Epoch 2/10, Batch 461/1650, Loss 82.707123, Loss rec 26.568289, loss rec t1 24.876932, loss kl 0.546600, loss_trans 0.033747, loss flux 16.019480, loss flux t1 14.662077, binary loss 3.280477, binary loss t1 2.772350\n",
      "Epoch 2/10, Batch 471/1650, Loss 57.901402, Loss rec 16.153301, loss rec t1 16.393047, loss kl 0.308809, loss_trans 0.025135, loss flux 13.668712, loss flux t1 11.352397, binary loss 6.189852, binary loss t1 5.257666\n",
      "Epoch 2/10, Batch 481/1650, Loss 63.211750, Loss rec 18.993299, loss rec t1 18.061966, loss kl 0.415450, loss_trans 0.019859, loss flux 13.233936, loss flux t1 12.487237, binary loss 1.999526, binary loss t1 1.702979\n",
      "Epoch 2/10, Batch 491/1650, Loss 60.113049, Loss rec 15.084037, loss rec t1 17.678862, loss kl 0.370577, loss_trans 0.022536, loss flux 14.458335, loss flux t1 12.498704, binary loss 2.425715, binary loss t1 2.244124\n",
      "Epoch 2/10, Batch 501/1650, Loss 54.982834, Loss rec 14.486031, loss rec t1 15.302389, loss kl 0.383524, loss_trans 0.034469, loss flux 13.706343, loss flux t1 11.070077, binary loss 4.577900, binary loss t1 3.856065\n",
      "Epoch 2/10, Batch 511/1650, Loss 54.186821, Loss rec 14.201555, loss rec t1 13.802125, loss kl 0.611802, loss_trans 0.017037, loss flux 13.925606, loss flux t1 11.628697, binary loss 1.200168, binary loss t1 1.318641\n",
      "Epoch 2/10, Batch 521/1650, Loss 53.655476, Loss rec 14.918327, loss rec t1 14.940161, loss kl 0.262800, loss_trans 0.016430, loss flux 12.830615, loss flux t1 10.687141, binary loss 2.080272, binary loss t1 1.693927\n",
      "Epoch 2/10, Batch 531/1650, Loss 63.557774, Loss rec 16.859011, loss rec t1 20.499882, loss kl 0.452398, loss_trans 0.023091, loss flux 13.563556, loss flux t1 12.159837, binary loss 3.773434, binary loss t1 3.471156\n",
      "Epoch 2/10, Batch 541/1650, Loss 53.022255, Loss rec 12.181994, loss rec t1 16.578613, loss kl 0.593129, loss_trans 0.026223, loss flux 12.135379, loss flux t1 11.506917, binary loss 5.568776, binary loss t1 3.486290\n",
      "Epoch 2/10, Batch 551/1650, Loss 51.849636, Loss rec 13.472848, loss rec t1 12.557246, loss kl 0.645442, loss_trans 0.020076, loss flux 12.742286, loss flux t1 12.411735, binary loss 1.275464, binary loss t1 1.338618\n",
      "Epoch 2/10, Batch 561/1650, Loss 64.046028, Loss rec 16.997444, loss rec t1 21.352583, loss kl 0.368498, loss_trans 0.031194, loss flux 13.723168, loss flux t1 11.573133, binary loss 1.161481, binary loss t1 1.108473\n",
      "Epoch 2/10, Batch 571/1650, Loss 60.352558, Loss rec 16.900108, loss rec t1 19.107605, loss kl 0.266842, loss_trans 0.022897, loss flux 11.189464, loss flux t1 12.865643, binary loss 1.769284, binary loss t1 2.179961\n",
      "Epoch 2/10, Batch 581/1650, Loss 65.789871, Loss rec 17.619556, loss rec t1 20.059311, loss kl 0.567919, loss_trans 0.036227, loss flux 14.743523, loss flux t1 12.763338, binary loss 3.314724, binary loss t1 2.900763\n",
      "Epoch 2/10, Batch 591/1650, Loss 61.888546, Loss rec 17.199602, loss rec t1 17.802927, loss kl 0.399000, loss_trans 0.026144, loss flux 14.798110, loss flux t1 11.662761, binary loss 2.619422, binary loss t1 2.233053\n",
      "Epoch 2/10, Batch 601/1650, Loss 59.087765, Loss rec 15.837440, loss rec t1 15.593198, loss kl 0.272709, loss_trans 0.030019, loss flux 14.754356, loss flux t1 12.600044, binary loss 1.774710, binary loss t1 1.690606\n",
      "Epoch 2/10, Batch 611/1650, Loss 60.647797, Loss rec 15.588377, loss rec t1 19.134115, loss kl 0.584211, loss_trans 0.023491, loss flux 13.367912, loss flux t1 11.949692, binary loss 2.722396, binary loss t1 2.173367\n",
      "Epoch 2/10, Batch 621/1650, Loss 51.206928, Loss rec 13.662735, loss rec t1 13.903326, loss kl 0.377193, loss_trans 0.021322, loss flux 12.525239, loss flux t1 10.717112, binary loss 3.578180, binary loss t1 3.001375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Batch 631/1650, Loss 55.102631, Loss rec 13.791058, loss rec t1 15.466652, loss kl 0.358638, loss_trans 0.022486, loss flux 13.616870, loss flux t1 11.846924, binary loss 3.262702, binary loss t1 1.939693\n",
      "Epoch 2/10, Batch 641/1650, Loss 60.189358, Loss rec 16.151917, loss rec t1 18.823719, loss kl 0.387077, loss_trans 0.039189, loss flux 12.337534, loss flux t1 12.449919, binary loss 2.733504, binary loss t1 2.384752\n",
      "Epoch 2/10, Batch 651/1650, Loss 71.857742, Loss rec 21.131611, loss rec t1 23.387577, loss kl 0.318390, loss_trans 0.023209, loss flux 13.934088, loss flux t1 13.062865, binary loss 3.924705, binary loss t1 3.588156\n",
      "Epoch 2/10, Batch 661/1650, Loss 46.396568, Loss rec 11.086922, loss rec t1 13.563880, loss kl 0.238146, loss_trans 0.014020, loss flux 10.789588, loss flux t1 10.704014, binary loss 2.506509, binary loss t1 2.026011\n",
      "Epoch 2/10, Batch 671/1650, Loss 69.328392, Loss rec 18.390032, loss rec t1 22.047009, loss kl 0.414008, loss_trans 0.026775, loss flux 15.367710, loss flux t1 13.082856, binary loss 1.985085, binary loss t1 1.735985\n",
      "Epoch 2/10, Batch 681/1650, Loss 57.666943, Loss rec 13.333138, loss rec t1 19.998154, loss kl 0.274705, loss_trans 0.039290, loss flux 12.791476, loss flux t1 11.230178, binary loss 2.846380, binary loss t1 2.916201\n",
      "Epoch 2/10, Batch 691/1650, Loss 62.798302, Loss rec 17.645779, loss rec t1 19.544785, loss kl 0.455839, loss_trans 0.027177, loss flux 12.665339, loss flux t1 12.459388, binary loss 2.364811, binary loss t1 2.057035\n",
      "Epoch 2/10, Batch 701/1650, Loss 53.750889, Loss rec 15.616318, loss rec t1 15.745066, loss kl 0.327883, loss_trans 0.022654, loss flux 11.426833, loss flux t1 10.612134, binary loss 3.492944, binary loss t1 3.064481\n",
      "Epoch 2/10, Batch 711/1650, Loss 52.928822, Loss rec 13.922297, loss rec t1 14.799667, loss kl 0.565670, loss_trans 0.019978, loss flux 12.474337, loss flux t1 11.146875, binary loss 2.677004, binary loss t1 1.848910\n",
      "Epoch 2/10, Batch 721/1650, Loss 52.362217, Loss rec 12.408107, loss rec t1 15.869135, loss kl 0.331433, loss_trans 0.022676, loss flux 12.285303, loss flux t1 11.445564, binary loss 1.732627, binary loss t1 1.655203\n",
      "Epoch 2/10, Batch 731/1650, Loss 53.891720, Loss rec 13.789572, loss rec t1 15.837787, loss kl 0.426309, loss_trans 0.036779, loss flux 12.343588, loss flux t1 11.457686, binary loss 2.660385, binary loss t1 2.420143\n",
      "Epoch 2/10, Batch 741/1650, Loss 61.288303, Loss rec 17.100882, loss rec t1 18.556662, loss kl 0.367075, loss_trans 0.030715, loss flux 12.848243, loss flux t1 12.384727, binary loss 3.417649, binary loss t1 3.039017\n",
      "Epoch 2/10, Batch 751/1650, Loss 58.130539, Loss rec 17.223217, loss rec t1 14.871767, loss kl 0.318321, loss_trans 0.022827, loss flux 13.787359, loss flux t1 11.907043, binary loss 4.221411, binary loss t1 3.465255\n",
      "Epoch 2/10, Batch 761/1650, Loss 51.220295, Loss rec 12.596506, loss rec t1 14.746138, loss kl 0.254131, loss_trans 0.016576, loss flux 12.712704, loss flux t1 10.894242, binary loss 3.020196, binary loss t1 2.866344\n",
      "Epoch 2/10, Batch 771/1650, Loss 60.507645, Loss rec 17.574650, loss rec t1 17.258390, loss kl 0.504004, loss_trans 0.033698, loss flux 13.390496, loss flux t1 11.746408, binary loss 1.330978, binary loss t1 1.406286\n",
      "Epoch 2/10, Batch 781/1650, Loss 61.665623, Loss rec 16.787655, loss rec t1 17.567673, loss kl 0.445315, loss_trans 0.021491, loss flux 14.697881, loss flux t1 12.145607, binary loss 1.613291, binary loss t1 1.427321\n",
      "Epoch 2/10, Batch 791/1650, Loss 54.283794, Loss rec 14.354672, loss rec t1 15.292529, loss kl 0.360666, loss_trans 0.028021, loss flux 12.722573, loss flux t1 11.525329, binary loss 2.176615, binary loss t1 1.669632\n",
      "Epoch 2/10, Batch 801/1650, Loss 54.551502, Loss rec 13.522730, loss rec t1 16.884378, loss kl 0.329099, loss_trans 0.026253, loss flux 11.817572, loss flux t1 11.971469, binary loss 1.661919, binary loss t1 1.612074\n",
      "Epoch 2/10, Batch 811/1650, Loss 53.822197, Loss rec 13.579215, loss rec t1 14.986925, loss kl 0.465107, loss_trans 0.022611, loss flux 13.501448, loss flux t1 11.266895, binary loss 1.736058, binary loss t1 1.857987\n",
      "Epoch 2/10, Batch 821/1650, Loss 73.742233, Loss rec 23.317400, loss rec t1 24.684652, loss kl 0.402686, loss_trans 0.015725, loss flux 13.933474, loss flux t1 11.388299, binary loss 0.583960, binary loss t1 0.663489\n",
      "Epoch 2/10, Batch 831/1650, Loss 63.522964, Loss rec 16.716545, loss rec t1 21.857124, loss kl 0.261975, loss_trans 0.020592, loss flux 13.464925, loss flux t1 11.201803, binary loss 1.579980, binary loss t1 1.287862\n",
      "Epoch 2/10, Batch 841/1650, Loss 67.257515, Loss rec 18.680168, loss rec t1 22.292933, loss kl 0.314562, loss_trans 0.024921, loss flux 14.283682, loss flux t1 11.661257, binary loss 5.239952, binary loss t1 4.657625\n",
      "Epoch 2/10, Batch 851/1650, Loss 57.062614, Loss rec 16.196838, loss rec t1 15.271976, loss kl 0.240944, loss_trans 0.021959, loss flux 14.256829, loss flux t1 11.074068, binary loss 2.042618, binary loss t1 1.475863\n",
      "Epoch 2/10, Batch 861/1650, Loss 101.315178, Loss rec 39.606781, loss rec t1 30.743692, loss kl 0.526089, loss_trans 0.031842, loss flux 16.483667, loss flux t1 13.923106, binary loss 8.939999, binary loss t1 6.395787\n",
      "Epoch 2/10, Batch 871/1650, Loss 72.967957, Loss rec 22.196054, loss rec t1 20.078850, loss kl 0.400279, loss_trans 0.022530, loss flux 16.136078, loss flux t1 14.134169, binary loss 0.992227, binary loss t1 0.953393\n",
      "Epoch 2/10, Batch 881/1650, Loss 60.457638, Loss rec 16.877876, loss rec t1 19.065601, loss kl 0.257323, loss_trans 0.029348, loss flux 11.690083, loss flux t1 12.537405, binary loss 1.442601, binary loss t1 1.524564\n",
      "Epoch 2/10, Batch 891/1650, Loss 61.484150, Loss rec 17.521875, loss rec t1 18.048866, loss kl 0.316514, loss_trans 0.014903, loss flux 13.956977, loss flux t1 11.625016, binary loss 1.875566, binary loss t1 1.927711\n",
      "Epoch 2/10, Batch 901/1650, Loss 58.509556, Loss rec 16.156048, loss rec t1 19.015728, loss kl 0.226938, loss_trans 0.015009, loss flux 11.202194, loss flux t1 11.893642, binary loss 1.865529, binary loss t1 1.838922\n",
      "Epoch 2/10, Batch 911/1650, Loss 56.143883, Loss rec 15.531945, loss rec t1 17.447269, loss kl 0.329655, loss_trans 0.020610, loss flux 12.025168, loss flux t1 10.789233, binary loss 1.717482, binary loss t1 1.764953\n",
      "Epoch 2/10, Batch 921/1650, Loss 61.755009, Loss rec 18.283020, loss rec t1 18.888210, loss kl 0.443355, loss_trans 0.020013, loss flux 12.799771, loss flux t1 11.320640, binary loss 2.204659, binary loss t1 1.767485\n",
      "Epoch 2/10, Batch 931/1650, Loss 61.194035, Loss rec 16.014687, loss rec t1 18.459583, loss kl 0.455563, loss_trans 0.032020, loss flux 13.679389, loss flux t1 12.552792, binary loss 1.544504, binary loss t1 1.387368\n",
      "Epoch 2/10, Batch 941/1650, Loss 50.277725, Loss rec 10.587311, loss rec t1 16.526052, loss kl 0.287584, loss_trans 0.032907, loss flux 10.973210, loss flux t1 11.870663, binary loss 5.627440, binary loss t1 4.239149\n",
      "Epoch 2/10, Batch 951/1650, Loss 46.855389, Loss rec 11.381987, loss rec t1 13.156336, loss kl 0.250374, loss_trans 0.015921, loss flux 12.148301, loss flux t1 9.902472, binary loss 2.243078, binary loss t1 2.120165\n",
      "Epoch 2/10, Batch 961/1650, Loss 54.023285, Loss rec 15.087186, loss rec t1 15.393005, loss kl 0.400802, loss_trans 0.021967, loss flux 11.315589, loss flux t1 11.804737, binary loss 1.261047, binary loss t1 1.345212\n",
      "Epoch 2/10, Batch 971/1650, Loss 42.314140, Loss rec 9.515678, loss rec t1 11.723564, loss kl 0.272406, loss_trans 0.012428, loss flux 10.490966, loss flux t1 10.299101, binary loss 5.267642, binary loss t1 4.788263\n",
      "Epoch 2/10, Batch 981/1650, Loss 52.440056, Loss rec 14.331736, loss rec t1 12.732731, loss kl 0.277594, loss_trans 0.033423, loss flux 14.263336, loss flux t1 10.801233, binary loss 2.092706, binary loss t1 2.205412\n",
      "Epoch 2/10, Batch 991/1650, Loss 51.568821, Loss rec 14.158711, loss rec t1 14.702798, loss kl 0.306357, loss_trans 0.032223, loss flux 11.517531, loss flux t1 10.851198, binary loss 2.686993, binary loss t1 2.495475\n",
      "Epoch 2/10, Batch 1001/1650, Loss 53.702240, Loss rec 13.832452, loss rec t1 15.190513, loss kl 0.223249, loss_trans 0.016399, loss flux 13.174973, loss flux t1 11.264653, binary loss 1.547752, binary loss t1 1.544419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Batch 1011/1650, Loss 56.981396, Loss rec 16.131771, loss rec t1 16.863419, loss kl 0.275294, loss_trans 0.015511, loss flux 12.644706, loss flux t1 11.050693, binary loss 3.816208, binary loss t1 3.361198\n",
      "Epoch 2/10, Batch 1021/1650, Loss 82.395607, Loss rec 25.085960, loss rec t1 31.301586, loss kl 0.601110, loss_trans 0.024814, loss flux 12.695351, loss flux t1 12.686791, binary loss 3.745402, binary loss t1 3.239429\n",
      "Epoch 2/10, Batch 1031/1650, Loss 61.694363, Loss rec 18.164351, loss rec t1 19.946224, loss kl 0.294780, loss_trans 0.020043, loss flux 12.194630, loss flux t1 11.074338, binary loss 4.500414, binary loss t1 4.079762\n",
      "Epoch 2/10, Batch 1041/1650, Loss 61.049850, Loss rec 18.381163, loss rec t1 19.440060, loss kl 0.337333, loss_trans 0.025884, loss flux 11.411492, loss flux t1 11.453922, binary loss 3.946860, binary loss t1 3.412126\n",
      "Epoch 2/10, Batch 1051/1650, Loss 53.830967, Loss rec 13.820701, loss rec t1 16.142210, loss kl 0.410203, loss_trans 0.020812, loss flux 12.618134, loss flux t1 10.818908, binary loss 5.388353, binary loss t1 2.178878\n",
      "Epoch 2/10, Batch 1061/1650, Loss 53.261791, Loss rec 13.551277, loss rec t1 18.295181, loss kl 0.221383, loss_trans 0.020709, loss flux 10.602313, loss flux t1 10.570927, binary loss 0.970170, binary loss t1 0.998796\n",
      "Epoch 2/10, Batch 1071/1650, Loss 69.261749, Loss rec 20.631512, loss rec t1 23.161247, loss kl 0.590883, loss_trans 0.019292, loss flux 12.868073, loss flux t1 11.990745, binary loss 0.649047, binary loss t1 0.850785\n",
      "Epoch 2/10, Batch 1081/1650, Loss 73.859993, Loss rec 21.201965, loss rec t1 26.307632, loss kl 0.281436, loss_trans 0.031525, loss flux 13.926057, loss flux t1 12.111381, binary loss 7.666737, binary loss t1 5.929694\n",
      "Epoch 2/10, Batch 1091/1650, Loss 66.800911, Loss rec 17.754276, loss rec t1 21.277397, loss kl 0.459229, loss_trans 0.027384, loss flux 15.013190, loss flux t1 12.269436, binary loss 2.615079, binary loss t1 2.235414\n",
      "Epoch 2/10, Batch 1101/1650, Loss 56.099712, Loss rec 14.950531, loss rec t1 15.414152, loss kl 0.338317, loss_trans 0.021258, loss flux 13.847836, loss flux t1 11.527619, binary loss 1.372963, binary loss t1 1.286608\n",
      "Epoch 2/10, Batch 1111/1650, Loss 94.195290, Loss rec 34.043007, loss rec t1 36.492996, loss kl 0.346094, loss_trans 0.030075, loss flux 12.097839, loss flux t1 11.185280, binary loss 0.797620, binary loss t1 0.753408\n",
      "Epoch 2/10, Batch 1121/1650, Loss 69.285110, Loss rec 20.085876, loss rec t1 24.035532, loss kl 0.326998, loss_trans 0.026542, loss flux 13.766652, loss flux t1 11.043509, binary loss 1.208113, binary loss t1 1.278981\n",
      "Epoch 2/10, Batch 1131/1650, Loss 54.873463, Loss rec 15.940027, loss rec t1 15.328367, loss kl 0.348003, loss_trans 0.016673, loss flux 12.661978, loss flux t1 10.578415, binary loss 2.568495, binary loss t1 2.389168\n",
      "Epoch 2/10, Batch 1141/1650, Loss 47.332306, Loss rec 12.184643, loss rec t1 12.427603, loss kl 0.290713, loss_trans 0.029635, loss flux 12.137807, loss flux t1 10.261903, binary loss 2.899546, binary loss t1 2.982664\n",
      "Epoch 2/10, Batch 1151/1650, Loss 58.420574, Loss rec 14.588583, loss rec t1 18.137032, loss kl 0.310122, loss_trans 0.026141, loss flux 11.991518, loss flux t1 13.367170, binary loss 3.101015, binary loss t1 2.784467\n",
      "Epoch 2/10, Batch 1161/1650, Loss 56.321644, Loss rec 15.337105, loss rec t1 16.276587, loss kl 0.352554, loss_trans 0.027216, loss flux 13.603543, loss flux t1 10.724637, binary loss 1.542302, binary loss t1 1.427138\n",
      "Epoch 2/10, Batch 1171/1650, Loss 40.614231, Loss rec 9.017431, loss rec t1 11.626013, loss kl 0.184089, loss_trans 0.016618, loss flux 10.105752, loss flux t1 9.664330, binary loss 3.147538, binary loss t1 3.037910\n",
      "Epoch 2/10, Batch 1181/1650, Loss 52.219112, Loss rec 13.987129, loss rec t1 13.788518, loss kl 0.308101, loss_trans 0.022475, loss flux 13.429579, loss flux t1 10.683309, binary loss 2.003967, binary loss t1 1.821501\n",
      "Epoch 2/10, Batch 1191/1650, Loss 46.603947, Loss rec 12.999233, loss rec t1 13.344103, loss kl 0.300853, loss_trans 0.018192, loss flux 10.335230, loss flux t1 9.606335, binary loss 2.723564, binary loss t1 2.571853\n",
      "Epoch 2/10, Batch 1201/1650, Loss 73.837715, Loss rec 23.840698, loss rec t1 22.347206, loss kl 0.548359, loss_trans 0.026633, loss flux 14.420294, loss flux t1 12.654530, binary loss 1.669522, binary loss t1 1.480206\n",
      "Epoch 2/10, Batch 1211/1650, Loss 63.041481, Loss rec 18.540436, loss rec t1 19.149616, loss kl 0.417158, loss_trans 0.019087, loss flux 14.078981, loss flux t1 10.836198, binary loss 5.041780, binary loss t1 4.460546\n",
      "Epoch 2/10, Batch 1221/1650, Loss 47.269196, Loss rec 12.845590, loss rec t1 13.629403, loss kl 0.193211, loss_trans 0.014701, loss flux 10.874909, loss flux t1 9.711381, binary loss 6.636054, binary loss t1 5.411566\n",
      "Epoch 2/10, Batch 1231/1650, Loss 46.552246, Loss rec 10.519409, loss rec t1 14.625666, loss kl 0.267609, loss_trans 0.017264, loss flux 11.052706, loss flux t1 10.069592, binary loss 1.386187, binary loss t1 1.373012\n",
      "Epoch 2/10, Batch 1241/1650, Loss 61.310444, Loss rec 18.863213, loss rec t1 17.789679, loss kl 0.319610, loss_trans 0.032095, loss flux 13.449252, loss flux t1 10.856590, binary loss 2.445655, binary loss t1 2.326136\n",
      "Epoch 2/10, Batch 1251/1650, Loss 56.582188, Loss rec 16.182673, loss rec t1 19.153725, loss kl 0.396547, loss_trans 0.018502, loss flux 11.148750, loss flux t1 9.681991, binary loss 2.561950, binary loss t1 2.055977\n",
      "Epoch 2/10, Batch 1261/1650, Loss 52.165810, Loss rec 13.887320, loss rec t1 17.148575, loss kl 0.231513, loss_trans 0.014159, loss flux 10.980274, loss flux t1 9.903968, binary loss 4.418537, binary loss t1 4.033288\n",
      "Epoch 2/10, Batch 1271/1650, Loss 45.686279, Loss rec 10.807914, loss rec t1 12.891148, loss kl 0.223744, loss_trans 0.018222, loss flux 11.574872, loss flux t1 10.170381, binary loss 1.780380, binary loss t1 2.007325\n",
      "Epoch 2/10, Batch 1281/1650, Loss 47.340855, Loss rec 10.534187, loss rec t1 13.906556, loss kl 0.228376, loss_trans 0.017894, loss flux 12.569608, loss flux t1 10.084231, binary loss 3.170946, binary loss t1 2.708113\n",
      "Epoch 2/10, Batch 1291/1650, Loss 50.685417, Loss rec 14.065844, loss rec t1 14.734020, loss kl 0.343816, loss_trans 0.014964, loss flux 11.672498, loss flux t1 9.854274, binary loss 2.580747, binary loss t1 2.352633\n",
      "Epoch 2/10, Batch 1301/1650, Loss 56.241936, Loss rec 16.944792, loss rec t1 16.616722, loss kl 0.312758, loss_trans 0.015874, loss flux 11.670356, loss flux t1 10.681430, binary loss 1.618766, binary loss t1 1.482542\n",
      "Epoch 2/10, Batch 1311/1650, Loss 40.666241, Loss rec 8.857985, loss rec t1 11.343424, loss kl 0.472118, loss_trans 0.021219, loss flux 10.878702, loss flux t1 9.092793, binary loss 2.125700, binary loss t1 2.466702\n",
      "Epoch 2/10, Batch 1321/1650, Loss 48.672291, Loss rec 12.857530, loss rec t1 13.642748, loss kl 0.598270, loss_trans 0.018748, loss flux 11.382717, loss flux t1 10.172274, binary loss 1.564493, binary loss t1 1.831246\n",
      "Epoch 2/10, Batch 1331/1650, Loss 42.211269, Loss rec 11.026455, loss rec t1 11.944387, loss kl 0.214252, loss_trans 0.012010, loss flux 9.604909, loss flux t1 9.409256, binary loss 1.918634, binary loss t1 1.766960\n",
      "Epoch 2/10, Batch 1341/1650, Loss 66.691597, Loss rec 22.218996, loss rec t1 19.921379, loss kl 0.326174, loss_trans 0.018996, loss flux 13.624108, loss flux t1 10.581945, binary loss 1.160520, binary loss t1 1.126358\n",
      "Epoch 2/10, Batch 1351/1650, Loss 52.116310, Loss rec 14.548973, loss rec t1 16.030018, loss kl 0.308511, loss_trans 0.030303, loss flux 11.292706, loss flux t1 9.905798, binary loss 1.664682, binary loss t1 1.414170\n",
      "Epoch 2/10, Batch 1361/1650, Loss 52.117130, Loss rec 13.894018, loss rec t1 16.538280, loss kl 0.255297, loss_trans 0.016340, loss flux 10.663512, loss flux t1 10.749685, binary loss 4.458381, binary loss t1 3.891565\n",
      "Epoch 2/10, Batch 1371/1650, Loss 51.849945, Loss rec 17.191750, loss rec t1 13.707298, loss kl 0.271914, loss_trans 0.014269, loss flux 10.197593, loss flux t1 10.467124, binary loss 1.587681, binary loss t1 1.463697\n",
      "Epoch 2/10, Batch 1381/1650, Loss 56.422470, Loss rec 15.413075, loss rec t1 16.486282, loss kl 0.421379, loss_trans 0.021996, loss flux 12.662049, loss flux t1 11.417692, binary loss 2.268481, binary loss t1 2.018323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Batch 1391/1650, Loss 46.967144, Loss rec 12.329274, loss rec t1 12.912690, loss kl 0.298875, loss_trans 0.014323, loss flux 10.977326, loss flux t1 10.434652, binary loss 1.597572, binary loss t1 1.646297\n",
      "Epoch 2/10, Batch 1401/1650, Loss 56.300869, Loss rec 15.940001, loss rec t1 15.934671, loss kl 0.250640, loss_trans 0.021002, loss flux 13.773847, loss flux t1 10.380708, binary loss 2.468868, binary loss t1 2.380323\n",
      "Epoch 2/10, Batch 1411/1650, Loss 58.105350, Loss rec 16.588423, loss rec t1 18.628447, loss kl 0.189754, loss_trans 0.017520, loss flux 11.952720, loss flux t1 10.728487, binary loss 2.493224, binary loss t1 2.355930\n",
      "Epoch 2/10, Batch 1421/1650, Loss 54.741737, Loss rec 14.748857, loss rec t1 16.127117, loss kl 0.249358, loss_trans 0.014632, loss flux 12.184126, loss flux t1 11.417647, binary loss 3.435363, binary loss t1 3.160824\n",
      "Epoch 2/10, Batch 1431/1650, Loss 64.001152, Loss rec 26.199242, loss rec t1 15.299490, loss kl 0.714293, loss_trans 0.020558, loss flux 11.469428, loss flux t1 10.298138, binary loss 6.702468, binary loss t1 3.549407\n",
      "Epoch 2/10, Batch 1441/1650, Loss 55.374931, Loss rec 13.773062, loss rec t1 15.344117, loss kl 0.425586, loss_trans 0.023253, loss flux 13.525233, loss flux t1 12.283674, binary loss 2.058130, binary loss t1 1.956483\n",
      "Epoch 2/10, Batch 1451/1650, Loss 67.482452, Loss rec 15.647413, loss rec t1 21.647261, loss kl 0.306582, loss_trans 0.032309, loss flux 15.271618, loss flux t1 14.577265, binary loss 3.236290, binary loss t1 2.845480\n",
      "Epoch 2/10, Batch 1461/1650, Loss 50.681194, Loss rec 14.609525, loss rec t1 13.197079, loss kl 0.267557, loss_trans 0.015805, loss flux 12.641346, loss flux t1 9.949883, binary loss 2.308422, binary loss t1 2.215449\n",
      "Epoch 2/10, Batch 1471/1650, Loss 55.186588, Loss rec 14.480037, loss rec t1 14.110815, loss kl 0.313552, loss_trans 0.021702, loss flux 15.219326, loss flux t1 11.041157, binary loss 1.915337, binary loss t1 1.828970\n",
      "Epoch 2/10, Batch 1481/1650, Loss 46.047348, Loss rec 11.848110, loss rec t1 13.302038, loss kl 0.259431, loss_trans 0.018655, loss flux 10.905532, loss flux t1 9.713581, binary loss 2.358193, binary loss t1 2.223211\n",
      "Epoch 2/10, Batch 1491/1650, Loss 69.323227, Loss rec 22.334618, loss rec t1 21.061367, loss kl 0.399540, loss_trans 0.019688, loss flux 13.226180, loss flux t1 12.281831, binary loss 2.127878, binary loss t1 1.820101\n",
      "Epoch 2/10, Batch 1501/1650, Loss 63.176945, Loss rec 19.194857, loss rec t1 19.812016, loss kl 0.276734, loss_trans 0.031970, loss flux 12.292065, loss flux t1 11.569300, binary loss 6.322706, binary loss t1 4.911140\n",
      "Epoch 2/10, Batch 1511/1650, Loss 57.129154, Loss rec 16.017868, loss rec t1 18.326332, loss kl 0.295574, loss_trans 0.020355, loss flux 10.909842, loss flux t1 11.559182, binary loss 4.334421, binary loss t1 3.793020\n",
      "Epoch 2/10, Batch 1521/1650, Loss 50.881195, Loss rec 17.467609, loss rec t1 10.797115, loss kl 0.776344, loss_trans 0.015730, loss flux 12.208427, loss flux t1 9.615966, binary loss 3.526170, binary loss t1 1.822328\n",
      "Epoch 2/10, Batch 1531/1650, Loss 65.649345, Loss rec 20.453182, loss rec t1 20.575476, loss kl 0.505951, loss_trans 0.019895, loss flux 12.660887, loss flux t1 11.433955, binary loss 3.205084, binary loss t1 2.695825\n",
      "Epoch 2/10, Batch 1541/1650, Loss 55.891987, Loss rec 15.184866, loss rec t1 16.898081, loss kl 0.344034, loss_trans 0.024146, loss flux 12.207370, loss flux t1 11.233486, binary loss 1.100797, binary loss t1 1.026669\n",
      "Epoch 2/10, Batch 1551/1650, Loss 70.778572, Loss rec 26.483624, loss rec t1 18.761681, loss kl 0.531923, loss_trans 0.027349, loss flux 14.580851, loss flux t1 10.393144, binary loss 1.230268, binary loss t1 1.133123\n",
      "Epoch 2/10, Batch 1561/1650, Loss 43.705608, Loss rec 10.919363, loss rec t1 10.576870, loss kl 0.315783, loss_trans 0.016060, loss flux 12.503323, loss flux t1 9.374211, binary loss 1.574359, binary loss t1 1.509003\n",
      "Epoch 2/10, Batch 1571/1650, Loss 51.579914, Loss rec 14.181826, loss rec t1 13.482666, loss kl 0.534445, loss_trans 0.017398, loss flux 13.303739, loss flux t1 10.059840, binary loss 4.627720, binary loss t1 2.927272\n",
      "Epoch 2/10, Batch 1581/1650, Loss 56.088444, Loss rec 15.601028, loss rec t1 17.682617, loss kl 0.433397, loss_trans 0.022020, loss flux 11.079571, loss flux t1 11.269809, binary loss 1.244453, binary loss t1 1.295416\n",
      "Epoch 2/10, Batch 1591/1650, Loss 47.218094, Loss rec 11.154257, loss rec t1 13.617958, loss kl 0.363728, loss_trans 0.017898, loss flux 11.018526, loss flux t1 11.045726, binary loss 2.059359, binary loss t1 2.042740\n",
      "Epoch 2/10, Batch 1601/1650, Loss 53.190289, Loss rec 16.832554, loss rec t1 13.799314, loss kl 0.571361, loss_trans 0.015394, loss flux 12.485987, loss flux t1 9.485678, binary loss 7.868231, binary loss t1 4.073058\n",
      "Epoch 2/10, Batch 1611/1650, Loss 50.502422, Loss rec 14.899393, loss rec t1 13.689470, loss kl 0.291050, loss_trans 0.021071, loss flux 11.581665, loss flux t1 10.019773, binary loss 1.678489, binary loss t1 1.491546\n",
      "Epoch 2/10, Batch 1621/1650, Loss 61.968063, Loss rec 18.568174, loss rec t1 20.977673, loss kl 0.308328, loss_trans 0.015362, loss flux 12.108100, loss flux t1 9.990428, binary loss 1.615579, binary loss t1 1.442747\n",
      "Epoch 2/10, Batch 1631/1650, Loss 49.172947, Loss rec 13.679296, loss rec t1 13.178787, loss kl 0.400193, loss_trans 0.010855, loss flux 11.820908, loss flux t1 10.082905, binary loss 1.683988, binary loss t1 1.651918\n",
      "Epoch 2/10, Batch 1641/1650, Loss 85.492210, Loss rec 31.348824, loss rec t1 27.482445, loss kl 0.409578, loss_trans 0.020131, loss flux 13.699101, loss flux t1 12.532127, binary loss 1.354044, binary loss t1 1.299784\n",
      "Epoch 2/10, Train loss 48.338718, Eval loss 49.111309\n",
      "Epoch 3/10, Batch 1/1650, Loss 50.093449, Loss rec 12.002808, loss rec t1 15.012110, loss kl 0.315336, loss_trans 0.016401, loss flux 11.691067, loss flux t1 11.055728, binary loss 1.754782, binary loss t1 1.829019\n",
      "Epoch 3/10, Batch 11/1650, Loss 45.343460, Loss rec 11.219358, loss rec t1 12.081514, loss kl 0.222750, loss_trans 0.023668, loss flux 12.548259, loss flux t1 9.247910, binary loss 2.662685, binary loss t1 2.298507\n",
      "Epoch 3/10, Batch 21/1650, Loss 50.132587, Loss rec 14.973475, loss rec t1 13.014187, loss kl 0.369749, loss_trans 0.019515, loss flux 11.670741, loss flux t1 10.084918, binary loss 2.937175, binary loss t1 2.574068\n",
      "Epoch 3/10, Batch 31/1650, Loss 44.953388, Loss rec 12.014698, loss rec t1 12.840103, loss kl 0.230788, loss_trans 0.019938, loss flux 10.634915, loss flux t1 9.212946, binary loss 4.554651, binary loss t1 3.990159\n",
      "Epoch 3/10, Batch 41/1650, Loss 45.848240, Loss rec 12.144753, loss rec t1 12.792985, loss kl 0.286685, loss_trans 0.021853, loss flux 11.468647, loss flux t1 9.133317, binary loss 1.576781, binary loss t1 1.604678\n",
      "Epoch 3/10, Batch 51/1650, Loss 45.032791, Loss rec 10.983850, loss rec t1 12.515404, loss kl 0.322248, loss_trans 0.021075, loss flux 11.651847, loss flux t1 9.538368, binary loss 1.407174, binary loss t1 1.392769\n",
      "Epoch 3/10, Batch 61/1650, Loss 57.756237, Loss rec 15.942981, loss rec t1 17.723637, loss kl 0.324472, loss_trans 0.022578, loss flux 12.224639, loss flux t1 11.517924, binary loss 3.215170, binary loss t1 2.999442\n",
      "Epoch 3/10, Batch 71/1650, Loss 48.418468, Loss rec 14.743383, loss rec t1 12.522022, loss kl 0.294554, loss_trans 0.013896, loss flux 11.023279, loss flux t1 9.821333, binary loss 5.385045, binary loss t1 4.345419\n",
      "Epoch 3/10, Batch 81/1650, Loss 45.826954, Loss rec 13.194000, loss rec t1 13.487791, loss kl 0.283727, loss_trans 0.015086, loss flux 10.084874, loss flux t1 8.761475, binary loss 1.783591, binary loss t1 1.517848\n",
      "Epoch 3/10, Batch 91/1650, Loss 43.853889, Loss rec 11.603096, loss rec t1 11.747563, loss kl 0.389463, loss_trans 0.011628, loss flux 11.004780, loss flux t1 9.097361, binary loss 1.530331, binary loss t1 1.480414\n",
      "Epoch 3/10, Batch 101/1650, Loss 41.793507, Loss rec 10.701356, loss rec t1 12.982993, loss kl 0.244241, loss_trans 0.017605, loss flux 9.200780, loss flux t1 8.646531, binary loss 1.921019, binary loss t1 1.829007\n",
      "Epoch 3/10, Batch 111/1650, Loss 51.227303, Loss rec 14.370337, loss rec t1 14.659679, loss kl 0.359894, loss_trans 0.020883, loss flux 12.084926, loss flux t1 9.731584, binary loss 1.910909, binary loss t1 1.755938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Batch 121/1650, Loss 43.166546, Loss rec 11.015108, loss rec t1 12.468396, loss kl 0.365456, loss_trans 0.013964, loss flux 10.175834, loss flux t1 9.127785, binary loss 2.447833, binary loss t1 2.143414\n",
      "Epoch 3/10, Batch 131/1650, Loss 43.866959, Loss rec 11.813451, loss rec t1 12.648504, loss kl 0.334697, loss_trans 0.013756, loss flux 9.688985, loss flux t1 9.367567, binary loss 2.063690, binary loss t1 1.964184\n",
      "Epoch 3/10, Batch 141/1650, Loss 51.715729, Loss rec 14.680821, loss rec t1 13.852435, loss kl 0.421236, loss_trans 0.022171, loss flux 12.659002, loss flux t1 10.080064, binary loss 1.925289, binary loss t1 1.577668\n",
      "Epoch 3/10, Batch 151/1650, Loss 41.700745, Loss rec 10.238933, loss rec t1 11.511577, loss kl 0.233835, loss_trans 0.015401, loss flux 10.567485, loss flux t1 9.133515, binary loss 1.563386, binary loss t1 1.461605\n",
      "Epoch 3/10, Batch 161/1650, Loss 42.853268, Loss rec 10.402483, loss rec t1 10.981138, loss kl 0.328637, loss_trans 0.020782, loss flux 11.305168, loss flux t1 9.815061, binary loss 2.874082, binary loss t1 2.142380\n",
      "Epoch 3/10, Batch 171/1650, Loss 38.267845, Loss rec 9.533232, loss rec t1 10.552234, loss kl 0.237218, loss_trans 0.014641, loss flux 9.588470, loss flux t1 8.342052, binary loss 3.163050, binary loss t1 2.753456\n",
      "Epoch 3/10, Batch 181/1650, Loss 38.820427, Loss rec 9.922581, loss rec t1 10.052066, loss kl 0.295437, loss_trans 0.008820, loss flux 9.586145, loss flux t1 8.955378, binary loss 1.661772, binary loss t1 1.634180\n",
      "Epoch 3/10, Batch 191/1650, Loss 43.137486, Loss rec 11.701895, loss rec t1 12.824768, loss kl 0.331134, loss_trans 0.016203, loss flux 9.922457, loss flux t1 8.341031, binary loss 2.760026, binary loss t1 2.340492\n",
      "Epoch 3/10, Batch 201/1650, Loss 37.369102, Loss rec 10.065891, loss rec t1 9.342921, loss kl 0.233327, loss_trans 0.020209, loss flux 9.675595, loss flux t1 8.031155, binary loss 6.488784, binary loss t1 5.792412\n",
      "Epoch 3/10, Batch 211/1650, Loss 43.589085, Loss rec 11.536566, loss rec t1 12.431298, loss kl 0.236471, loss_trans 0.024999, loss flux 9.843006, loss flux t1 9.516745, binary loss 2.168902, binary loss t1 2.072559\n",
      "Epoch 3/10, Batch 221/1650, Loss 51.221279, Loss rec 13.355974, loss rec t1 16.362259, loss kl 0.375778, loss_trans 0.013655, loss flux 11.228843, loss flux t1 9.884768, binary loss 1.151504, binary loss t1 1.069578\n",
      "Epoch 3/10, Batch 231/1650, Loss 36.909611, Loss rec 9.257393, loss rec t1 10.264193, loss kl 0.208762, loss_trans 0.016301, loss flux 9.271935, loss flux t1 7.891027, binary loss 1.947431, binary loss t1 1.663987\n",
      "Epoch 3/10, Batch 241/1650, Loss 36.825645, Loss rec 8.190995, loss rec t1 9.311705, loss kl 0.403374, loss_trans 0.012473, loss flux 9.781796, loss flux t1 9.125303, binary loss 2.918391, binary loss t1 2.394716\n",
      "Epoch 3/10, Batch 251/1650, Loss 32.635910, Loss rec 7.333408, loss rec t1 8.632687, loss kl 0.194070, loss_trans 0.012994, loss flux 8.880957, loss flux t1 7.581796, binary loss 0.909023, binary loss t1 1.079457\n",
      "Epoch 3/10, Batch 261/1650, Loss 43.992764, Loss rec 11.097867, loss rec t1 13.183884, loss kl 0.439925, loss_trans 0.015620, loss flux 9.999985, loss flux t1 9.255485, binary loss 1.152538, binary loss t1 1.321926\n",
      "Epoch 3/10, Batch 271/1650, Loss 35.641903, Loss rec 9.084724, loss rec t1 10.278605, loss kl 0.172472, loss_trans 0.013538, loss flux 8.188691, loss flux t1 7.903871, binary loss 1.744940, binary loss t1 1.545684\n",
      "Epoch 3/10, Batch 281/1650, Loss 45.683437, Loss rec 12.821772, loss rec t1 12.872639, loss kl 0.291416, loss_trans 0.018005, loss flux 11.241326, loss flux t1 8.438278, binary loss 2.486899, binary loss t1 1.815164\n",
      "Epoch 3/10, Batch 291/1650, Loss 49.825691, Loss rec 15.697387, loss rec t1 15.816378, loss kl 0.258790, loss_trans 0.020133, loss flux 8.874006, loss flux t1 9.158996, binary loss 1.706276, binary loss t1 1.440582\n",
      "Epoch 3/10, Batch 301/1650, Loss 94.032639, Loss rec 36.699512, loss rec t1 35.219940, loss kl 0.288090, loss_trans 0.012024, loss flux 11.834202, loss flux t1 9.978870, binary loss 0.584057, binary loss t1 0.578717\n",
      "Epoch 3/10, Batch 311/1650, Loss 86.626610, Loss rec 27.073425, loss rec t1 34.200130, loss kl 0.349466, loss_trans 0.028422, loss flux 11.808045, loss flux t1 13.167118, binary loss 0.583365, binary loss t1 0.588050\n",
      "Epoch 3/10, Batch 321/1650, Loss 50.394608, Loss rec 15.472480, loss rec t1 15.284281, loss kl 0.257626, loss_trans 0.016707, loss flux 10.536581, loss flux t1 8.826935, binary loss 11.157454, binary loss t1 9.632964\n",
      "Epoch 3/10, Batch 331/1650, Loss 61.388275, Loss rec 18.637959, loss rec t1 19.747328, loss kl 0.337935, loss_trans 0.024469, loss flux 11.087423, loss flux t1 11.553163, binary loss 4.633280, binary loss t1 3.675728\n",
      "Epoch 3/10, Batch 341/1650, Loss 55.039776, Loss rec 14.628103, loss rec t1 16.367134, loss kl 0.248634, loss_trans 0.019005, loss flux 12.441968, loss flux t1 11.334930, binary loss 4.254758, binary loss t1 3.387891\n",
      "Epoch 3/10, Batch 351/1650, Loss 55.251583, Loss rec 15.012130, loss rec t1 19.308441, loss kl 0.298921, loss_trans 0.026617, loss flux 10.004054, loss flux t1 10.601417, binary loss 2.019552, binary loss t1 1.937504\n",
      "Epoch 3/10, Batch 361/1650, Loss 40.265499, Loss rec 9.787858, loss rec t1 11.116148, loss kl 0.389069, loss_trans 0.011480, loss flux 9.937459, loss flux t1 9.023486, binary loss 1.865493, binary loss t1 1.872172\n",
      "Epoch 3/10, Batch 371/1650, Loss 43.516087, Loss rec 10.449548, loss rec t1 11.589808, loss kl 0.305938, loss_trans 0.026357, loss flux 10.784185, loss flux t1 10.360254, binary loss 2.308630, binary loss t1 2.078338\n",
      "Epoch 3/10, Batch 381/1650, Loss 60.913166, Loss rec 17.255470, loss rec t1 21.123350, loss kl 0.440771, loss_trans 0.023015, loss flux 11.251924, loss flux t1 10.818636, binary loss 1.025379, binary loss t1 0.904716\n",
      "Epoch 3/10, Batch 391/1650, Loss 43.675789, Loss rec 11.505205, loss rec t1 12.266729, loss kl 0.392367, loss_trans 0.017418, loss flux 10.148387, loss flux t1 9.345680, binary loss 1.480243, binary loss t1 1.450375\n",
      "Epoch 3/10, Batch 401/1650, Loss 47.710522, Loss rec 11.945696, loss rec t1 15.264389, loss kl 0.523597, loss_trans 0.015833, loss flux 9.853373, loss flux t1 10.107635, binary loss 0.587025, binary loss t1 0.658099\n",
      "Epoch 3/10, Batch 411/1650, Loss 43.355583, Loss rec 11.610077, loss rec t1 12.137373, loss kl 0.383807, loss_trans 0.010169, loss flux 10.003922, loss flux t1 9.210237, binary loss 1.266729, binary loss t1 1.017593\n",
      "Epoch 3/10, Batch 421/1650, Loss 50.173672, Loss rec 12.817117, loss rec t1 17.216625, loss kl 0.225077, loss_trans 0.023190, loss flux 9.762141, loss flux t1 10.129526, binary loss 3.359033, binary loss t1 3.365798\n",
      "Epoch 3/10, Batch 431/1650, Loss 39.107758, Loss rec 10.025425, loss rec t1 10.493908, loss kl 0.249685, loss_trans 0.013122, loss flux 10.004830, loss flux t1 8.320786, binary loss 2.049346, binary loss t1 1.872209\n",
      "Epoch 3/10, Batch 441/1650, Loss 38.645592, Loss rec 8.975067, loss rec t1 10.213182, loss kl 0.343939, loss_trans 0.012414, loss flux 10.232939, loss flux t1 8.868053, binary loss 1.157040, binary loss t1 1.061938\n",
      "Epoch 3/10, Batch 451/1650, Loss 42.793606, Loss rec 10.954838, loss rec t1 10.706115, loss kl 0.422016, loss_trans 0.017180, loss flux 12.043509, loss flux t1 8.649943, binary loss 1.578788, binary loss t1 1.840237\n",
      "Epoch 3/10, Batch 461/1650, Loss 49.923252, Loss rec 13.775090, loss rec t1 13.479523, loss kl 0.375735, loss_trans 0.015249, loss flux 11.643209, loss flux t1 10.634445, binary loss 2.433513, binary loss t1 2.150215\n",
      "Epoch 3/10, Batch 471/1650, Loss 37.259445, Loss rec 9.032616, loss rec t1 10.522047, loss kl 0.232694, loss_trans 0.013001, loss flux 9.665742, loss flux t1 7.793345, binary loss 3.091051, binary loss t1 2.920557\n",
      "Epoch 3/10, Batch 481/1650, Loss 44.646591, Loss rec 11.741664, loss rec t1 13.233406, loss kl 0.284429, loss_trans 0.010037, loss flux 10.288827, loss flux t1 9.088227, binary loss 1.107305, binary loss t1 0.977932\n",
      "Epoch 3/10, Batch 491/1650, Loss 35.137047, Loss rec 8.736805, loss rec t1 8.965191, loss kl 0.259395, loss_trans 0.009085, loss flux 8.863330, loss flux t1 8.303237, binary loss 1.720522, binary loss t1 1.503529\n",
      "Epoch 3/10, Batch 501/1650, Loss 35.900311, Loss rec 8.421646, loss rec t1 9.311028, loss kl 0.300165, loss_trans 0.018057, loss flux 9.859428, loss flux t1 7.989989, binary loss 4.102950, binary loss t1 3.082195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Batch 511/1650, Loss 35.331860, Loss rec 8.180453, loss rec t1 9.137079, loss kl 0.461877, loss_trans 0.008547, loss flux 9.649311, loss flux t1 7.894589, binary loss 4.273457, binary loss t1 2.889582\n",
      "Epoch 3/10, Batch 521/1650, Loss 34.802917, Loss rec 8.831610, loss rec t1 8.962569, loss kl 0.195832, loss_trans 0.007758, loss flux 9.229712, loss flux t1 7.575436, binary loss 2.011631, binary loss t1 1.821245\n",
      "Epoch 3/10, Batch 531/1650, Loss 42.342884, Loss rec 10.965227, loss rec t1 12.586584, loss kl 0.313374, loss_trans 0.012402, loss flux 9.771690, loss flux t1 8.693609, binary loss 1.169743, binary loss t1 1.046927\n",
      "Epoch 3/10, Batch 541/1650, Loss 34.426483, Loss rec 7.365934, loss rec t1 9.904995, loss kl 0.448637, loss_trans 0.013965, loss flux 8.617038, loss flux t1 8.075912, binary loss 1.686177, binary loss t1 1.628559\n",
      "Epoch 3/10, Batch 551/1650, Loss 39.719318, Loss rec 12.368046, loss rec t1 9.103391, loss kl 0.448346, loss_trans 0.010693, loss flux 8.890965, loss flux t1 8.897876, binary loss 1.385019, binary loss t1 1.557777\n",
      "Epoch 3/10, Batch 561/1650, Loss 38.274719, Loss rec 9.322835, loss rec t1 11.348711, loss kl 0.265586, loss_trans 0.018759, loss flux 9.173606, loss flux t1 8.145218, binary loss 2.633815, binary loss t1 2.427905\n",
      "Epoch 3/10, Batch 571/1650, Loss 41.912010, Loss rec 10.779778, loss rec t1 12.244890, loss kl 0.186115, loss_trans 0.012291, loss flux 8.817797, loss flux t1 9.871140, binary loss 0.965461, binary loss t1 1.301998\n",
      "Epoch 3/10, Batch 581/1650, Loss 49.431637, Loss rec 12.564061, loss rec t1 15.202523, loss kl 0.412559, loss_trans 0.022731, loss flux 11.584472, loss flux t1 9.645289, binary loss 3.603753, binary loss t1 2.740256\n",
      "Epoch 3/10, Batch 591/1650, Loss 45.909466, Loss rec 12.215330, loss rec t1 12.154211, loss kl 0.258839, loss_trans 0.013570, loss flux 11.695307, loss flux t1 9.572211, binary loss 2.479975, binary loss t1 2.170058\n",
      "Epoch 3/10, Batch 601/1650, Loss 45.363033, Loss rec 11.338251, loss rec t1 12.963704, loss kl 0.203753, loss_trans 0.017788, loss flux 11.009871, loss flux t1 9.829664, binary loss 1.248857, binary loss t1 1.289954\n",
      "Epoch 3/10, Batch 611/1650, Loss 50.047836, Loss rec 15.557260, loss rec t1 14.177872, loss kl 0.452540, loss_trans 0.015098, loss flux 10.671567, loss flux t1 9.173502, binary loss 1.584299, binary loss t1 1.469269\n",
      "Epoch 3/10, Batch 621/1650, Loss 41.234669, Loss rec 11.943077, loss rec t1 11.080011, loss kl 0.283027, loss_trans 0.010605, loss flux 9.670048, loss flux t1 8.247899, binary loss 4.048726, binary loss t1 3.013566\n",
      "Epoch 3/10, Batch 631/1650, Loss 45.433132, Loss rec 12.238131, loss rec t1 12.506411, loss kl 0.270891, loss_trans 0.014478, loss flux 11.045322, loss flux t1 9.357903, binary loss 1.996266, binary loss t1 1.365262\n",
      "Epoch 3/10, Batch 641/1650, Loss 64.417603, Loss rec 21.346718, loss rec t1 20.976562, loss kl 0.271160, loss_trans 0.027329, loss flux 11.395203, loss flux t1 10.400627, binary loss 1.988479, binary loss t1 1.769211\n",
      "Epoch 3/10, Batch 651/1650, Loss 50.509098, Loss rec 15.161409, loss rec t1 14.513023, loss kl 0.231298, loss_trans 0.014703, loss flux 10.661382, loss flux t1 9.927283, binary loss 2.692492, binary loss t1 2.436749\n",
      "Epoch 3/10, Batch 661/1650, Loss 34.123245, Loss rec 7.711009, loss rec t1 9.352994, loss kl 0.175760, loss_trans 0.009895, loss flux 8.465490, loss flux t1 8.408095, binary loss 3.791864, binary loss t1 3.213940\n",
      "Epoch 3/10, Batch 671/1650, Loss 42.819366, Loss rec 10.669929, loss rec t1 11.545891, loss kl 0.311681, loss_trans 0.016714, loss flux 10.706986, loss flux t1 9.568162, binary loss 1.747044, binary loss t1 1.586525\n",
      "Epoch 3/10, Batch 681/1650, Loss 37.333878, Loss rec 8.605800, loss rec t1 12.212732, loss kl 0.202337, loss_trans 0.022629, loss flux 8.161092, loss flux t1 8.129286, binary loss 3.237202, binary loss t1 3.013615\n",
      "Epoch 3/10, Batch 691/1650, Loss 42.602333, Loss rec 11.725356, loss rec t1 13.355453, loss kl 0.315754, loss_trans 0.016089, loss flux 8.648646, loss flux t1 8.541032, binary loss 2.039321, binary loss t1 1.779126\n",
      "Epoch 3/10, Batch 701/1650, Loss 36.415581, Loss rec 9.818823, loss rec t1 10.073318, loss kl 0.238380, loss_trans 0.015016, loss flux 8.165353, loss flux t1 8.104689, binary loss 2.326075, binary loss t1 2.019430\n",
      "Epoch 3/10, Batch 711/1650, Loss 37.286633, Loss rec 9.066292, loss rec t1 10.106428, loss kl 0.430694, loss_trans 0.010659, loss flux 9.231035, loss flux t1 8.441524, binary loss 2.383669, binary loss t1 1.665106\n",
      "Epoch 3/10, Batch 721/1650, Loss 35.315849, Loss rec 8.167205, loss rec t1 10.706045, loss kl 0.240230, loss_trans 0.013827, loss flux 8.431328, loss flux t1 7.757212, binary loss 1.833387, binary loss t1 1.848910\n",
      "Epoch 3/10, Batch 731/1650, Loss 36.864685, Loss rec 9.120125, loss rec t1 9.829016, loss kl 0.319218, loss_trans 0.018739, loss flux 9.179501, loss flux t1 8.398089, binary loss 1.945193, binary loss t1 1.896504\n",
      "Epoch 3/10, Batch 741/1650, Loss 40.964535, Loss rec 10.591983, loss rec t1 12.007668, loss kl 0.264811, loss_trans 0.018333, loss flux 9.067243, loss flux t1 9.014497, binary loss 2.214232, binary loss t1 1.983966\n",
      "Epoch 3/10, Batch 751/1650, Loss 35.833279, Loss rec 8.671303, loss rec t1 9.439748, loss kl 0.228591, loss_trans 0.009550, loss flux 9.278264, loss flux t1 8.205821, binary loss 3.236095, binary loss t1 2.619471\n",
      "Epoch 3/10, Batch 761/1650, Loss 33.511555, Loss rec 7.640402, loss rec t1 8.614230, loss kl 0.188489, loss_trans 0.009394, loss flux 9.142632, loss flux t1 7.916409, binary loss 2.188769, binary loss t1 2.078070\n",
      "Epoch 3/10, Batch 771/1650, Loss 42.974033, Loss rec 11.576984, loss rec t1 12.059586, loss kl 0.380500, loss_trans 0.018124, loss flux 10.383484, loss flux t1 8.555356, binary loss 0.961289, binary loss t1 1.023446\n",
      "Epoch 3/10, Batch 781/1650, Loss 42.049854, Loss rec 11.367502, loss rec t1 11.188212, loss kl 0.325008, loss_trans 0.009973, loss flux 10.234461, loss flux t1 8.924702, binary loss 1.582280, binary loss t1 1.426129\n",
      "Epoch 3/10, Batch 791/1650, Loss 36.473404, Loss rec 9.219999, loss rec t1 9.826295, loss kl 0.261173, loss_trans 0.015304, loss flux 8.825831, loss flux t1 8.324799, binary loss 1.930885, binary loss t1 1.580005\n",
      "Epoch 3/10, Batch 801/1650, Loss 35.662498, Loss rec 8.168815, loss rec t1 10.087374, loss kl 0.238457, loss_trans 0.015236, loss flux 8.502814, loss flux t1 8.649803, binary loss 1.655300, binary loss t1 1.642064\n",
      "Epoch 3/10, Batch 811/1650, Loss 32.926544, Loss rec 6.885101, loss rec t1 8.516668, loss kl 0.378226, loss_trans 0.012640, loss flux 9.244946, loss flux t1 7.888964, binary loss 2.384727, binary loss t1 2.078180\n",
      "Epoch 3/10, Batch 821/1650, Loss 41.420086, Loss rec 10.528091, loss rec t1 10.694936, loss kl 0.295878, loss_trans 0.008655, loss flux 10.760779, loss flux t1 9.131746, binary loss 0.869374, binary loss t1 0.882428\n",
      "Epoch 3/10, Batch 831/1650, Loss 42.340115, Loss rec 10.493079, loss rec t1 12.599222, loss kl 0.192285, loss_trans 0.010319, loss flux 10.140229, loss flux t1 8.904979, binary loss 1.450424, binary loss t1 1.223564\n",
      "Epoch 3/10, Batch 841/1650, Loss 46.729053, Loss rec 13.326390, loss rec t1 14.084583, loss kl 0.224716, loss_trans 0.011173, loss flux 10.101171, loss flux t1 8.981019, binary loss 3.877100, binary loss t1 3.658001\n",
      "Epoch 3/10, Batch 851/1650, Loss 49.313911, Loss rec 14.181835, loss rec t1 11.556574, loss kl 0.195459, loss_trans 0.013376, loss flux 12.326685, loss flux t1 11.039986, binary loss 1.437053, binary loss t1 1.119410\n",
      "Epoch 3/10, Batch 861/1650, Loss 75.354546, Loss rec 24.815556, loss rec t1 24.655479, loss kl 0.437322, loss_trans 0.017355, loss flux 13.853900, loss flux t1 11.574932, binary loss 8.859168, binary loss t1 5.426044\n",
      "Epoch 3/10, Batch 871/1650, Loss 46.288750, Loss rec 12.139256, loss rec t1 11.862600, loss kl 0.289171, loss_trans 0.011401, loss flux 11.569149, loss flux t1 10.417172, binary loss 1.355249, binary loss t1 1.298738\n",
      "Epoch 3/10, Batch 881/1650, Loss 50.056057, Loss rec 14.703834, loss rec t1 15.784508, loss kl 0.193986, loss_trans 0.019700, loss flux 9.351723, loss flux t1 10.002309, binary loss 1.289966, binary loss t1 1.166019\n",
      "Epoch 3/10, Batch 891/1650, Loss 44.393936, Loss rec 12.041846, loss rec t1 11.987265, loss kl 0.236223, loss_trans 0.010089, loss flux 10.821264, loss flux t1 9.297249, binary loss 1.397368, binary loss t1 1.323363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Batch 901/1650, Loss 54.903900, Loss rec 17.076481, loss rec t1 17.085552, loss kl 0.175036, loss_trans 0.010295, loss flux 9.663447, loss flux t1 10.893085, binary loss 1.217919, binary loss t1 1.105006\n",
      "Epoch 3/10, Batch 911/1650, Loss 46.994732, Loss rec 14.389044, loss rec t1 14.200155, loss kl 0.252555, loss_trans 0.012134, loss flux 9.274190, loss flux t1 8.866653, binary loss 1.389024, binary loss t1 1.405411\n",
      "Epoch 3/10, Batch 921/1650, Loss 47.619473, Loss rec 14.121099, loss rec t1 14.244595, loss kl 0.322262, loss_trans 0.010481, loss flux 9.693402, loss flux t1 9.227630, binary loss 2.884498, binary loss t1 2.483809\n",
      "Epoch 3/10, Batch 931/1650, Loss 48.075691, Loss rec 12.222837, loss rec t1 14.505239, loss kl 0.343224, loss_trans 0.019915, loss flux 10.816795, loss flux t1 10.167678, binary loss 1.367464, binary loss t1 1.151687\n",
      "Epoch 3/10, Batch 941/1650, Loss 36.961189, Loss rec 8.210620, loss rec t1 10.697557, loss kl 0.231441, loss_trans 0.024024, loss flux 8.732555, loss flux t1 9.064989, binary loss 3.450874, binary loss t1 2.654850\n",
      "Epoch 3/10, Batch 951/1650, Loss 34.592369, Loss rec 8.432468, loss rec t1 10.162989, loss kl 0.187595, loss_trans 0.008554, loss flux 8.249303, loss flux t1 7.551458, binary loss 2.724647, binary loss t1 2.456775\n",
      "Epoch 3/10, Batch 961/1650, Loss 38.804165, Loss rec 10.054545, loss rec t1 11.384179, loss kl 0.299868, loss_trans 0.013339, loss flux 8.265783, loss flux t1 8.786451, binary loss 1.404971, binary loss t1 1.509052\n",
      "Epoch 3/10, Batch 971/1650, Loss 31.157412, Loss rec 6.387335, loss rec t1 8.260538, loss kl 0.210368, loss_trans 0.007929, loss flux 8.108816, loss flux t1 8.182426, binary loss 3.663513, binary loss t1 3.194086\n",
      "Epoch 3/10, Batch 981/1650, Loss 36.711880, Loss rec 9.510736, loss rec t1 8.813599, loss kl 0.210842, loss_trans 0.022154, loss flux 10.219192, loss flux t1 7.935356, binary loss 2.832171, binary loss t1 2.709172\n",
      "Epoch 3/10, Batch 991/1650, Loss 37.067852, Loss rec 9.579292, loss rec t1 10.213853, loss kl 0.229666, loss_trans 0.019947, loss flux 8.870240, loss flux t1 8.154854, binary loss 2.057071, binary loss t1 1.938648\n",
      "Epoch 3/10, Batch 1001/1650, Loss 36.575253, Loss rec 8.877861, loss rec t1 10.136374, loss kl 0.167777, loss_trans 0.008218, loss flux 9.031378, loss flux t1 8.353647, binary loss 0.927795, binary loss t1 0.968746\n",
      "Epoch 3/10, Batch 1011/1650, Loss 39.176334, Loss rec 10.171502, loss rec t1 11.127106, loss kl 0.207641, loss_trans 0.009516, loss flux 9.283216, loss flux t1 8.377356, binary loss 4.384156, binary loss t1 3.747592\n",
      "Epoch 3/10, Batch 1021/1650, Loss 66.943382, Loss rec 20.167341, loss rec t1 24.644396, loss kl 0.460041, loss_trans 0.014524, loss flux 11.054282, loss flux t1 10.602793, binary loss 4.014393, binary loss t1 3.309152\n",
      "Epoch 3/10, Batch 1031/1650, Loss 51.156528, Loss rec 15.261501, loss rec t1 15.775852, loss kl 0.219453, loss_trans 0.014211, loss flux 10.193108, loss flux t1 9.692408, binary loss 4.840310, binary loss t1 4.318873\n",
      "Epoch 3/10, Batch 1041/1650, Loss 44.624287, Loss rec 12.279425, loss rec t1 13.749113, loss kl 0.256913, loss_trans 0.017231, loss flux 9.055094, loss flux t1 9.266511, binary loss 3.262666, binary loss t1 2.832012\n",
      "Epoch 3/10, Batch 1051/1650, Loss 40.280254, Loss rec 9.583153, loss rec t1 11.579222, loss kl 0.345119, loss_trans 0.012994, loss flux 10.087069, loss flux t1 8.672699, binary loss 5.215620, binary loss t1 2.148974\n",
      "Epoch 3/10, Batch 1061/1650, Loss 45.726585, Loss rec 11.841396, loss rec t1 17.034468, loss kl 0.183332, loss_trans 0.013121, loss flux 8.449602, loss flux t1 8.204667, binary loss 0.587366, binary loss t1 0.612842\n",
      "Epoch 3/10, Batch 1071/1650, Loss 58.805111, Loss rec 19.294682, loss rec t1 19.352348, loss kl 0.486004, loss_trans 0.012473, loss flux 10.004374, loss flux t1 9.655231, binary loss 0.437858, binary loss t1 0.529870\n",
      "Epoch 3/10, Batch 1081/1650, Loss 56.762096, Loss rec 15.396387, loss rec t1 18.974562, loss kl 0.238145, loss_trans 0.020068, loss flux 12.005102, loss flux t1 10.127829, binary loss 8.021049, binary loss t1 6.299480\n",
      "Epoch 3/10, Batch 1091/1650, Loss 62.506226, Loss rec 16.913689, loss rec t1 23.484737, loss kl 0.343091, loss_trans 0.014387, loss flux 11.521260, loss flux t1 10.229066, binary loss 1.821586, binary loss t1 1.568363\n",
      "Epoch 3/10, Batch 1101/1650, Loss 47.716057, Loss rec 13.402972, loss rec t1 13.281173, loss kl 0.264241, loss_trans 0.013777, loss flux 11.156689, loss flux t1 9.597205, binary loss 0.812900, binary loss t1 0.891492\n",
      "Epoch 3/10, Batch 1111/1650, Loss 54.017162, Loss rec 15.317705, loss rec t1 20.821564, loss kl 0.271797, loss_trans 0.018441, loss flux 8.741115, loss flux t1 8.846541, binary loss 1.140750, binary loss t1 1.138597\n",
      "Epoch 3/10, Batch 1121/1650, Loss 54.905003, Loss rec 15.197336, loss rec t1 18.228952, loss kl 0.250569, loss_trans 0.019410, loss flux 11.637510, loss flux t1 9.571223, binary loss 1.253346, binary loss t1 1.196884\n",
      "Epoch 3/10, Batch 1131/1650, Loss 39.581821, Loss rec 10.586479, loss rec t1 10.971402, loss kl 0.260574, loss_trans 0.010443, loss flux 9.539129, loss flux t1 8.213798, binary loss 1.588752, binary loss t1 1.535659\n",
      "Epoch 3/10, Batch 1141/1650, Loss 39.143253, Loss rec 9.685653, loss rec t1 11.732743, loss kl 0.238995, loss_trans 0.021049, loss flux 9.485989, loss flux t1 7.978826, binary loss 7.319300, binary loss t1 5.750586\n",
      "Epoch 3/10, Batch 1151/1650, Loss 43.972359, Loss rec 11.492593, loss rec t1 12.139624, loss kl 0.241371, loss_trans 0.017923, loss flux 9.593739, loss flux t1 10.487110, binary loss 1.810186, binary loss t1 1.826854\n",
      "Epoch 3/10, Batch 1161/1650, Loss 39.082275, Loss rec 10.908956, loss rec t1 10.953201, loss kl 0.264223, loss_trans 0.016343, loss flux 8.903701, loss flux t1 8.035855, binary loss 1.233516, binary loss t1 1.154850\n",
      "Epoch 3/10, Batch 1171/1650, Loss 29.784605, Loss rec 7.102666, loss rec t1 8.072087, loss kl 0.158593, loss_trans 0.010259, loss flux 7.273867, loss flux t1 7.167134, binary loss 3.004733, binary loss t1 2.681445\n",
      "Epoch 3/10, Batch 1181/1650, Loss 37.385708, Loss rec 9.213476, loss rec t1 10.063512, loss kl 0.232411, loss_trans 0.012729, loss flux 9.879163, loss flux t1 7.984418, binary loss 1.343156, binary loss t1 1.194962\n",
      "Epoch 3/10, Batch 1191/1650, Loss 35.299721, Loss rec 9.637756, loss rec t1 9.797395, loss kl 0.215722, loss_trans 0.011650, loss flux 8.072792, loss flux t1 7.564405, binary loss 1.894326, binary loss t1 1.910909\n",
      "Epoch 3/10, Batch 1201/1650, Loss 68.658165, Loss rec 25.387203, loss rec t1 20.921108, loss kl 0.428793, loss_trans 0.016331, loss flux 11.274374, loss flux t1 10.630363, binary loss 1.796876, binary loss t1 1.629691\n",
      "Epoch 3/10, Batch 1211/1650, Loss 49.197102, Loss rec 14.766550, loss rec t1 15.364180, loss kl 0.327984, loss_trans 0.011050, loss flux 9.949528, loss flux t1 8.777810, binary loss 5.599763, binary loss t1 4.741753\n",
      "Epoch 3/10, Batch 1221/1650, Loss 37.308594, Loss rec 8.749519, loss rec t1 11.948735, loss kl 0.151186, loss_trans 0.010825, loss flux 8.444714, loss flux t1 8.003615, binary loss 5.775867, binary loss t1 4.395447\n",
      "Epoch 3/10, Batch 1231/1650, Loss 37.853703, Loss rec 8.922705, loss rec t1 11.610609, loss kl 0.215313, loss_trans 0.011884, loss flux 8.695393, loss flux t1 8.397799, binary loss 1.352026, binary loss t1 1.263481\n",
      "Epoch 3/10, Batch 1241/1650, Loss 51.951591, Loss rec 17.013754, loss rec t1 13.709208, loss kl 0.245489, loss_trans 0.021457, loss flux 11.000048, loss flux t1 9.961636, binary loss 1.430508, binary loss t1 1.376309\n",
      "Epoch 3/10, Batch 1251/1650, Loss 43.117409, Loss rec 12.260223, loss rec t1 12.664732, loss kl 0.281221, loss_trans 0.013600, loss flux 9.640973, loss flux t1 8.256661, binary loss 2.159121, binary loss t1 1.891103\n",
      "Epoch 3/10, Batch 1261/1650, Loss 38.711136, Loss rec 10.942584, loss rec t1 12.005085, loss kl 0.191830, loss_trans 0.009302, loss flux 7.843422, loss flux t1 7.718909, binary loss 2.765634, binary loss t1 2.791146\n",
      "Epoch 3/10, Batch 1271/1650, Loss 34.227852, Loss rec 7.768390, loss rec t1 9.605739, loss kl 0.180903, loss_trans 0.011443, loss flux 8.601115, loss flux t1 8.060259, binary loss 3.512933, binary loss t1 3.408877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10, Batch 1281/1650, Loss 34.408077, Loss rec 7.356764, loss rec t1 10.003626, loss kl 0.193578, loss_trans 0.009964, loss flux 8.742144, loss flux t1 8.102000, binary loss 3.396784, binary loss t1 2.903001\n",
      "Epoch 3/10, Batch 1291/1650, Loss 35.566753, Loss rec 9.360869, loss rec t1 9.799307, loss kl 0.273624, loss_trans 0.008323, loss flux 8.353901, loss flux t1 7.770729, binary loss 2.674876, binary loss t1 2.302850\n",
      "Epoch 3/10, Batch 1301/1650, Loss 41.556900, Loss rec 12.295834, loss rec t1 11.596556, loss kl 0.246545, loss_trans 0.009432, loss flux 9.218755, loss flux t1 8.189777, binary loss 1.305795, binary loss t1 1.180594\n",
      "Epoch 3/10, Batch 1311/1650, Loss 30.014816, Loss rec 6.677777, loss rec t1 7.953671, loss kl 0.401405, loss_trans 0.014137, loss flux 7.928312, loss flux t1 7.039513, binary loss 1.507945, binary loss t1 2.020574\n",
      "Epoch 3/10, Batch 1321/1650, Loss 35.150585, Loss rec 8.447983, loss rec t1 9.719114, loss kl 0.492420, loss_trans 0.013667, loss flux 8.500442, loss flux t1 7.976959, binary loss 1.227932, binary loss t1 1.207006\n",
      "Epoch 3/10, Batch 1331/1650, Loss 30.563478, Loss rec 7.338403, loss rec t1 8.630318, loss kl 0.177974, loss_trans 0.008940, loss flux 7.389592, loss flux t1 7.018253, binary loss 1.689511, binary loss t1 1.635214\n",
      "Epoch 3/10, Batch 1341/1650, Loss 41.609669, Loss rec 12.917902, loss rec t1 11.118236, loss kl 0.252608, loss_trans 0.011149, loss flux 9.655731, loss flux t1 7.654046, binary loss 1.342074, binary loss t1 1.257946\n",
      "Epoch 3/10, Batch 1351/1650, Loss 40.085136, Loss rec 11.472810, loss rec t1 11.728592, loss kl 0.241086, loss_trans 0.020328, loss flux 8.956921, loss flux t1 7.665401, binary loss 0.767267, binary loss t1 0.771134\n",
      "Epoch 3/10, Batch 1361/1650, Loss 33.329712, Loss rec 7.700506, loss rec t1 9.557493, loss kl 0.211639, loss_trans 0.010919, loss flux 7.721057, loss flux t1 8.128098, binary loss 2.156675, binary loss t1 2.115700\n",
      "Epoch 3/10, Batch 1371/1650, Loss 41.781872, Loss rec 13.016489, loss rec t1 12.177574, loss kl 0.203882, loss_trans 0.010533, loss flux 8.286615, loss flux t1 8.086775, binary loss 1.466229, binary loss t1 1.272667\n",
      "Epoch 3/10, Batch 1381/1650, Loss 41.753719, Loss rec 11.221214, loss rec t1 12.280594, loss kl 0.328059, loss_trans 0.012815, loss flux 9.025901, loss flux t1 8.885141, binary loss 1.836744, binary loss t1 1.608704\n",
      "Epoch 3/10, Batch 1391/1650, Loss 36.404617, Loss rec 10.067207, loss rec t1 8.922054, loss kl 0.229989, loss_trans 0.008964, loss flux 8.876703, loss flux t1 8.299702, binary loss 0.915629, binary loss t1 0.948903\n",
      "Epoch 3/10, Batch 1401/1650, Loss 36.696186, Loss rec 9.239493, loss rec t1 9.430002, loss kl 0.203258, loss_trans 0.011441, loss flux 9.730300, loss flux t1 8.081694, binary loss 1.848971, binary loss t1 1.752580\n",
      "Epoch 3/10, Batch 1411/1650, Loss 45.310379, Loss rec 12.110654, loss rec t1 14.440140, loss kl 0.159374, loss_trans 0.012726, loss flux 9.430373, loss flux t1 9.157113, binary loss 3.282581, binary loss t1 3.000268\n",
      "Epoch 3/10, Batch 1421/1650, Loss 39.884533, Loss rec 10.203812, loss rec t1 10.616625, loss kl 0.201178, loss_trans 0.009965, loss flux 9.722773, loss flux t1 9.130181, binary loss 2.700241, binary loss t1 2.536438\n",
      "Epoch 3/10, Batch 1431/1650, Loss 41.555874, Loss rec 14.744442, loss rec t1 10.207228, loss kl 0.626585, loss_trans 0.013119, loss flux 8.143972, loss flux t1 7.820527, binary loss 2.229781, binary loss t1 2.161140\n",
      "Epoch 3/10, Batch 1441/1650, Loss 42.010380, Loss rec 10.352980, loss rec t1 11.447513, loss kl 0.343536, loss_trans 0.013721, loss flux 10.264167, loss flux t1 9.588461, binary loss 1.303154, binary loss t1 1.181433\n",
      "Epoch 3/10, Batch 1451/1650, Loss 45.019669, Loss rec 10.897845, loss rec t1 12.613181, loss kl 0.240276, loss_trans 0.021330, loss flux 11.110736, loss flux t1 10.136301, binary loss 2.783348, binary loss t1 2.481131\n",
      "Epoch 3/10, Batch 1461/1650, Loss 34.676617, Loss rec 9.239823, loss rec t1 8.046900, loss kl 0.237357, loss_trans 0.010108, loss flux 9.309115, loss flux t1 7.833310, binary loss 2.091355, binary loss t1 1.903134\n",
      "Epoch 3/10, Batch 1471/1650, Loss 36.124775, Loss rec 8.975389, loss rec t1 8.978487, loss kl 0.252801, loss_trans 0.010711, loss flux 10.219895, loss flux t1 7.687487, binary loss 2.226472, binary loss t1 2.103558\n",
      "Epoch 3/10, Batch 1481/1650, Loss 32.718777, Loss rec 7.929152, loss rec t1 9.990532, loss kl 0.205918, loss_trans 0.011851, loss flux 7.321861, loss flux t1 7.259463, binary loss 2.281839, binary loss t1 2.234270\n",
      "Epoch 3/10, Batch 1491/1650, Loss 45.616917, Loss rec 13.832156, loss rec t1 13.265352, loss kl 0.309135, loss_trans 0.013028, loss flux 9.337435, loss flux t1 8.859811, binary loss 2.021595, binary loss t1 1.673950\n",
      "Epoch 3/10, Batch 1501/1650, Loss 38.396725, Loss rec 9.843164, loss rec t1 11.430947, loss kl 0.226257, loss_trans 0.020409, loss flux 8.464639, loss flux t1 8.411309, binary loss 4.204804, binary loss t1 3.143085\n",
      "Epoch 3/10, Batch 1511/1650, Loss 38.754147, Loss rec 8.949282, loss rec t1 11.641886, loss kl 0.234111, loss_trans 0.013135, loss flux 8.560460, loss flux t1 9.355276, binary loss 3.799614, binary loss t1 3.605870\n",
      "Epoch 3/10, Batch 1521/1650, Loss 32.773273, Loss rec 7.079007, loss rec t1 8.823015, loss kl 0.612177, loss_trans 0.009314, loss flux 8.788411, loss flux t1 7.461353, binary loss 3.615870, binary loss t1 2.702602\n",
      "Epoch 3/10, Batch 1531/1650, Loss 46.139645, Loss rec 13.267670, loss rec t1 13.997036, loss kl 0.393396, loss_trans 0.011543, loss flux 9.511280, loss flux t1 8.958721, binary loss 2.719087, binary loss t1 2.235304\n",
      "Epoch 3/10, Batch 1541/1650, Loss 38.444946, Loss rec 9.914921, loss rec t1 11.074326, loss kl 0.261584, loss_trans 0.014641, loss flux 8.687718, loss flux t1 8.491756, binary loss 0.982458, binary loss t1 0.985865\n",
      "Epoch 3/10, Batch 1551/1650, Loss 51.136742, Loss rec 16.256208, loss rec t1 16.112082, loss kl 0.450096, loss_trans 0.013307, loss flux 10.258155, loss flux t1 8.046894, binary loss 0.807571, binary loss t1 0.868902\n",
      "Epoch 3/10, Batch 1561/1650, Loss 32.726475, Loss rec 7.611963, loss rec t1 8.189619, loss kl 0.256300, loss_trans 0.008785, loss flux 9.323981, loss flux t1 7.335827, binary loss 2.332852, binary loss t1 1.999453\n",
      "Epoch 3/10, Batch 1571/1650, Loss 35.911690, Loss rec 8.380979, loss rec t1 9.851305, loss kl 0.437495, loss_trans 0.009913, loss flux 9.516156, loss flux t1 7.715838, binary loss 1.575442, binary loss t1 1.572206\n",
      "Epoch 3/10, Batch 1581/1650, Loss 41.499203, Loss rec 11.146175, loss rec t1 12.884433, loss kl 0.328354, loss_trans 0.013020, loss flux 8.686888, loss flux t1 8.440331, binary loss 0.718710, binary loss t1 0.751911\n",
      "Epoch 3/10, Batch 1591/1650, Loss 38.714901, Loss rec 9.562994, loss rec t1 11.328465, loss kl 0.293434, loss_trans 0.010352, loss flux 8.664829, loss flux t1 8.854824, binary loss 1.217992, binary loss t1 1.266717\n",
      "Epoch 3/10, Batch 1601/1650, Loss 32.114563, Loss rec 6.503623, loss rec t1 8.802321, loss kl 0.457063, loss_trans 0.009412, loss flux 9.018541, loss flux t1 7.323604, binary loss 3.884862, binary loss t1 1.951884\n",
      "Epoch 3/10, Batch 1611/1650, Loss 36.427593, Loss rec 9.179649, loss rec t1 11.675776, loss kl 0.220568, loss_trans 0.014117, loss flux 7.797539, loss flux t1 7.539942, binary loss 1.471447, binary loss t1 1.305710\n",
      "Epoch 3/10, Batch 1621/1650, Loss 50.744469, Loss rec 16.107773, loss rec t1 17.996578, loss kl 0.241368, loss_trans 0.009442, loss flux 8.850267, loss flux t1 7.539043, binary loss 0.965062, binary loss t1 0.898720\n",
      "Epoch 3/10, Batch 1631/1650, Loss 38.237015, Loss rec 10.329351, loss rec t1 10.349900, loss kl 0.328553, loss_trans 0.007069, loss flux 9.010395, loss flux t1 8.211745, binary loss 1.331902, binary loss t1 1.209025\n",
      "Epoch 3/10, Batch 1641/1650, Loss 48.061802, Loss rec 13.458784, loss rec t1 14.851160, loss kl 0.333281, loss_trans 0.012844, loss flux 10.166090, loss flux t1 9.239641, binary loss 1.702833, binary loss t1 1.572170\n",
      "Epoch 3/10, Train loss 38.438393, Eval loss 41.100754\n",
      "Epoch 4/10, Batch 1/1650, Loss 40.683926, Loss rec 9.334295, loss rec t1 11.692628, loss kl 0.254449, loss_trans 0.011914, loss flux 10.257215, loss flux t1 9.133424, binary loss 3.662332, binary loss t1 3.414340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Batch 11/1650, Loss 40.726959, Loss rec 9.865139, loss rec t1 13.182739, loss kl 0.188016, loss_trans 0.014911, loss flux 9.622584, loss flux t1 7.853568, binary loss 3.739818, binary loss t1 3.177406\n",
      "Epoch 4/10, Batch 21/1650, Loss 34.575138, Loss rec 8.904928, loss rec t1 9.253562, loss kl 0.300344, loss_trans 0.011024, loss flux 8.485421, loss flux t1 7.619857, binary loss 2.610590, binary loss t1 2.274065\n",
      "Epoch 4/10, Batch 31/1650, Loss 33.474503, Loss rec 8.082411, loss rec t1 9.889053, loss kl 0.184020, loss_trans 0.013827, loss flux 7.866885, loss flux t1 7.438304, binary loss 4.223686, binary loss t1 3.948174\n",
      "Epoch 4/10, Batch 41/1650, Loss 38.197697, Loss rec 10.574042, loss rec t1 11.305220, loss kl 0.227363, loss_trans 0.012618, loss flux 8.684409, loss flux t1 7.394048, binary loss 1.250232, binary loss t1 1.170630\n",
      "Epoch 4/10, Batch 51/1650, Loss 35.903412, Loss rec 8.380598, loss rec t1 9.781490, loss kl 0.258662, loss_trans 0.013003, loss flux 9.427469, loss flux t1 8.042188, binary loss 2.068118, binary loss t1 1.609775\n",
      "Epoch 4/10, Batch 61/1650, Loss 38.417431, Loss rec 9.032269, loss rec t1 10.460650, loss kl 0.249413, loss_trans 0.014759, loss flux 9.378842, loss flux t1 9.281499, binary loss 2.327267, binary loss t1 2.155812\n",
      "Epoch 4/10, Batch 71/1650, Loss 35.748352, Loss rec 10.121186, loss rec t1 9.183529, loss kl 0.240718, loss_trans 0.008792, loss flux 8.791272, loss flux t1 7.402856, binary loss 2.171299, binary loss t1 1.997361\n",
      "Epoch 4/10, Batch 81/1650, Loss 34.438850, Loss rec 9.193832, loss rec t1 9.471054, loss kl 0.220171, loss_trans 0.009498, loss flux 8.289819, loss flux t1 7.254475, binary loss 1.330832, binary loss t1 1.192406\n",
      "Epoch 4/10, Batch 91/1650, Loss 30.904627, Loss rec 7.749291, loss rec t1 7.773726, loss kl 0.320497, loss_trans 0.006513, loss flux 7.593348, loss flux t1 7.461250, binary loss 1.475949, binary loss t1 1.458247\n",
      "Epoch 4/10, Batch 101/1650, Loss 33.953335, Loss rec 8.097094, loss rec t1 10.104845, loss kl 0.198414, loss_trans 0.010697, loss flux 7.900255, loss flux t1 7.642030, binary loss 2.483468, binary loss t1 2.276279\n",
      "Epoch 4/10, Batch 111/1650, Loss 52.960014, Loss rec 17.198786, loss rec t1 18.283794, loss kl 0.302547, loss_trans 0.014260, loss flux 9.002193, loss flux t1 8.158434, binary loss 3.838363, binary loss t1 3.140883\n",
      "Epoch 4/10, Batch 121/1650, Loss 40.153431, Loss rec 11.036720, loss rec t1 12.674749, loss kl 0.287566, loss_trans 0.008992, loss flux 8.280849, loss flux t1 7.864557, binary loss 2.626248, binary loss t1 2.268664\n",
      "Epoch 4/10, Batch 131/1650, Loss 35.265366, Loss rec 9.155786, loss rec t1 9.640152, loss kl 0.267261, loss_trans 0.009682, loss flux 8.321995, loss flux t1 7.870492, binary loss 1.290939, binary loss t1 1.157137\n",
      "Epoch 4/10, Batch 141/1650, Loss 65.749901, Loss rec 27.089470, loss rec t1 19.325436, loss kl 0.334750, loss_trans 0.015492, loss flux 10.628541, loss flux t1 8.356210, binary loss 0.939098, binary loss t1 0.925874\n",
      "Epoch 4/10, Batch 151/1650, Loss 46.328381, Loss rec 12.957178, loss rec t1 16.692360, loss kl 0.180082, loss_trans 0.010965, loss flux 8.570341, loss flux t1 7.917453, binary loss 0.686204, binary loss t1 0.760429\n",
      "Epoch 4/10, Batch 161/1650, Loss 35.204067, Loss rec 8.799280, loss rec t1 8.672644, loss kl 0.272446, loss_trans 0.016118, loss flux 9.413492, loss flux t1 8.030087, binary loss 3.066792, binary loss t1 2.202176\n",
      "Epoch 4/10, Batch 171/1650, Loss 33.652134, Loss rec 9.173204, loss rec t1 9.578428, loss kl 0.201046, loss_trans 0.011713, loss flux 7.841775, loss flux t1 6.845966, binary loss 3.037959, binary loss t1 2.602852\n",
      "Epoch 4/10, Batch 181/1650, Loss 33.838852, Loss rec 9.006071, loss rec t1 9.637443, loss kl 0.237032, loss_trans 0.006495, loss flux 7.674074, loss flux t1 7.277737, binary loss 1.113802, binary loss t1 1.128377\n",
      "Epoch 4/10, Batch 191/1650, Loss 46.864944, Loss rec 14.196893, loss rec t1 15.648738, loss kl 0.260541, loss_trans 0.010396, loss flux 9.130008, loss flux t1 7.618371, binary loss 0.931763, binary loss t1 0.970512\n",
      "Epoch 4/10, Batch 201/1650, Loss 28.499952, Loss rec 7.275270, loss rec t1 6.621199, loss kl 0.202585, loss_trans 0.017540, loss flux 7.725760, loss flux t1 6.657601, binary loss 7.361199, binary loss t1 5.832292\n",
      "Epoch 4/10, Batch 211/1650, Loss 38.067188, Loss rec 11.369225, loss rec t1 10.871096, loss kl 0.200708, loss_trans 0.019944, loss flux 7.842800, loss flux t1 7.763416, binary loss 2.812145, binary loss t1 2.516559\n",
      "Epoch 4/10, Batch 221/1650, Loss 48.655930, Loss rec 12.785330, loss rec t1 15.943109, loss kl 0.316312, loss_trans 0.009966, loss flux 10.011323, loss flux t1 9.589895, binary loss 0.705827, binary loss t1 0.645058\n",
      "Epoch 4/10, Batch 231/1650, Loss 29.565418, Loss rec 6.782366, loss rec t1 8.628164, loss kl 0.182685, loss_trans 0.012189, loss flux 7.645236, loss flux t1 6.314777, binary loss 2.255281, binary loss t1 1.987299\n",
      "Epoch 4/10, Batch 241/1650, Loss 28.698006, Loss rec 6.294381, loss rec t1 6.911144, loss kl 0.337421, loss_trans 0.008558, loss flux 7.916870, loss flux t1 7.229631, binary loss 1.263274, binary loss t1 1.630895\n",
      "Epoch 4/10, Batch 251/1650, Loss 25.076899, Loss rec 5.302250, loss rec t1 6.857125, loss kl 0.156489, loss_trans 0.009753, loss flux 6.631635, loss flux t1 6.119647, binary loss 1.316354, binary loss t1 1.553288\n",
      "Epoch 4/10, Batch 261/1650, Loss 32.145855, Loss rec 8.356120, loss rec t1 8.415162, loss kl 0.366184, loss_trans 0.009459, loss flux 7.955899, loss flux t1 7.043031, binary loss 1.468028, binary loss t1 1.481326\n",
      "Epoch 4/10, Batch 271/1650, Loss 25.827784, Loss rec 5.892875, loss rec t1 6.912425, loss kl 0.150818, loss_trans 0.010959, loss flux 6.557292, loss flux t1 6.303416, binary loss 1.448173, binary loss t1 1.387294\n",
      "Epoch 4/10, Batch 281/1650, Loss 31.578142, Loss rec 8.090609, loss rec t1 8.559881, loss kl 0.248736, loss_trans 0.013422, loss flux 8.043319, loss flux t1 6.622176, binary loss 1.154997, binary loss t1 1.107537\n",
      "Epoch 4/10, Batch 291/1650, Loss 30.321140, Loss rec 7.309344, loss rec t1 8.376529, loss kl 0.227123, loss_trans 0.013335, loss flux 7.080084, loss flux t1 7.314725, binary loss 1.679523, binary loss t1 1.441555\n",
      "Epoch 4/10, Batch 301/1650, Loss 40.712662, Loss rec 12.548654, loss rec t1 12.022222, loss kl 0.255288, loss_trans 0.006998, loss flux 8.341722, loss flux t1 7.537776, binary loss 0.873839, binary loss t1 0.866053\n",
      "Epoch 4/10, Batch 311/1650, Loss 46.753181, Loss rec 13.262934, loss rec t1 16.001865, loss kl 0.265359, loss_trans 0.016032, loss flux 8.291596, loss flux t1 8.915393, binary loss 0.630007, binary loss t1 0.611369\n",
      "Epoch 4/10, Batch 321/1650, Loss 26.863392, Loss rec 6.068667, loss rec t1 6.691121, loss kl 0.206629, loss_trans 0.009631, loss flux 7.771187, loss flux t1 6.116155, binary loss 2.176591, binary loss t1 2.029333\n",
      "Epoch 4/10, Batch 331/1650, Loss 38.075264, Loss rec 10.300165, loss rec t1 11.321363, loss kl 0.264991, loss_trans 0.015878, loss flux 7.708854, loss flux t1 8.464010, binary loss 1.865590, binary loss t1 1.538993\n",
      "Epoch 4/10, Batch 341/1650, Loss 40.239639, Loss rec 9.519396, loss rec t1 12.057951, loss kl 0.200132, loss_trans 0.011759, loss flux 9.530430, loss flux t1 8.919971, binary loss 4.781779, binary loss t1 3.963686\n",
      "Epoch 4/10, Batch 351/1650, Loss 39.911156, Loss rec 10.767305, loss rec t1 13.006000, loss kl 0.226671, loss_trans 0.016919, loss flux 7.800950, loss flux t1 8.093310, binary loss 0.755745, binary loss t1 0.702591\n",
      "Epoch 4/10, Batch 361/1650, Loss 36.287800, Loss rec 9.049320, loss rec t1 11.005249, loss kl 0.352320, loss_trans 0.008748, loss flux 8.315760, loss flux t1 7.556406, binary loss 1.023116, binary loss t1 1.209098\n",
      "Epoch 4/10, Batch 371/1650, Loss 35.521019, Loss rec 8.944292, loss rec t1 10.528930, loss kl 0.252866, loss_trans 0.018186, loss flux 7.938276, loss flux t1 7.838470, binary loss 1.351211, binary loss t1 1.205280\n",
      "Epoch 4/10, Batch 381/1650, Loss 44.281631, Loss rec 12.466059, loss rec t1 13.749500, loss kl 0.363254, loss_trans 0.016472, loss flux 8.877357, loss flux t1 8.808990, binary loss 1.293117, binary loss t1 1.166955\n",
      "Epoch 4/10, Batch 391/1650, Loss 32.532169, Loss rec 8.124739, loss rec t1 8.666574, loss kl 0.335342, loss_trans 0.011539, loss flux 7.735965, loss flux t1 7.658007, binary loss 1.720510, binary loss t1 1.571038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Batch 401/1650, Loss 34.867973, Loss rec 9.259502, loss rec t1 8.997012, loss kl 0.440279, loss_trans 0.010394, loss flux 8.162101, loss flux t1 7.998683, binary loss 5.314165, binary loss t1 3.134241\n",
      "Epoch 4/10, Batch 411/1650, Loss 34.046589, Loss rec 8.864054, loss rec t1 9.028164, loss kl 0.305645, loss_trans 0.006760, loss flux 8.150257, loss flux t1 7.691711, binary loss 1.180204, binary loss t1 1.003152\n",
      "Epoch 4/10, Batch 421/1650, Loss 36.400425, Loss rec 8.071696, loss rec t1 12.108252, loss kl 0.183963, loss_trans 0.016639, loss flux 7.776866, loss flux t1 8.243007, binary loss 1.505828, binary loss t1 1.592464\n",
      "Epoch 4/10, Batch 431/1650, Loss 30.733433, Loss rec 7.871313, loss rec t1 8.168056, loss kl 0.211793, loss_trans 0.008949, loss flux 7.659879, loss flux t1 6.813442, binary loss 1.249003, binary loss t1 1.179231\n",
      "Epoch 4/10, Batch 441/1650, Loss 33.119179, Loss rec 8.257761, loss rec t1 8.466639, loss kl 0.292935, loss_trans 0.009257, loss flux 8.532327, loss flux t1 7.560261, binary loss 1.419523, binary loss t1 1.149388\n",
      "Epoch 4/10, Batch 451/1650, Loss 32.965939, Loss rec 8.630096, loss rec t1 8.815245, loss kl 0.352693, loss_trans 0.011205, loss flux 8.469542, loss flux t1 6.687158, binary loss 3.944816, binary loss t1 1.821440\n",
      "Epoch 4/10, Batch 461/1650, Loss 41.103039, Loss rec 11.466374, loss rec t1 11.600218, loss kl 0.323435, loss_trans 0.010199, loss flux 9.074195, loss flux t1 8.628615, binary loss 2.814433, binary loss t1 2.334993\n",
      "Epoch 4/10, Batch 471/1650, Loss 28.048292, Loss rec 6.732112, loss rec t1 7.200324, loss kl 0.203634, loss_trans 0.008496, loss flux 7.456583, loss flux t1 6.447143, binary loss 1.680642, binary loss t1 1.604227\n",
      "Epoch 4/10, Batch 481/1650, Loss 33.788334, Loss rec 8.743771, loss rec t1 8.520543, loss kl 0.234094, loss_trans 0.006676, loss flux 8.707704, loss flux t1 7.575547, binary loss 1.214646, binary loss t1 1.093035\n",
      "Epoch 4/10, Batch 491/1650, Loss 29.034212, Loss rec 7.114282, loss rec t1 7.299375, loss kl 0.211771, loss_trans 0.006665, loss flux 7.425779, loss flux t1 6.976339, binary loss 1.179158, binary loss t1 1.023104\n",
      "Epoch 4/10, Batch 501/1650, Loss 27.452808, Loss rec 6.070876, loss rec t1 6.503215, loss kl 0.255488, loss_trans 0.014602, loss flux 7.975768, loss flux t1 6.632858, binary loss 1.330746, binary loss t1 1.140324\n",
      "Epoch 4/10, Batch 511/1650, Loss 30.088881, Loss rec 7.884803, loss rec t1 7.102913, loss kl 0.396585, loss_trans 0.006682, loss flux 8.009803, loss flux t1 6.688094, binary loss 0.741825, binary loss t1 0.842743\n",
      "Epoch 4/10, Batch 521/1650, Loss 27.489925, Loss rec 6.271982, loss rec t1 7.393508, loss kl 0.163270, loss_trans 0.006211, loss flux 7.486538, loss flux t1 6.168417, binary loss 1.253249, binary loss t1 1.210084\n",
      "Epoch 4/10, Batch 531/1650, Loss 43.878864, Loss rec 13.635067, loss rec t1 14.531858, loss kl 0.267011, loss_trans 0.007593, loss flux 7.838346, loss flux t1 7.598988, binary loss 4.280320, binary loss t1 3.916116\n",
      "Epoch 4/10, Batch 541/1650, Loss 31.632837, Loss rec 7.947068, loss rec t1 9.210066, loss kl 0.389250, loss_trans 0.010474, loss flux 7.236018, loss flux t1 6.839962, binary loss 7.415448, binary loss t1 4.587876\n",
      "Epoch 4/10, Batch 551/1650, Loss 36.204464, Loss rec 9.050254, loss rec t1 9.655939, loss kl 0.413550, loss_trans 0.009488, loss flux 8.526494, loss flux t1 8.548738, binary loss 7.014685, binary loss t1 4.384217\n",
      "Epoch 4/10, Batch 561/1650, Loss 33.683777, Loss rec 8.163551, loss rec t1 10.435549, loss kl 0.229365, loss_trans 0.013742, loss flux 7.936438, loss flux t1 6.905132, binary loss 1.863461, binary loss t1 1.762666\n",
      "Epoch 4/10, Batch 571/1650, Loss 30.748947, Loss rec 6.823400, loss rec t1 9.521787, loss kl 0.158952, loss_trans 0.008328, loss flux 6.759123, loss flux t1 7.477360, binary loss 3.222822, binary loss t1 3.562680\n",
      "Epoch 4/10, Batch 581/1650, Loss 40.965565, Loss rec 10.661318, loss rec t1 11.217258, loss kl 0.362038, loss_trans 0.019149, loss flux 10.746659, loss flux t1 7.959140, binary loss 4.998773, binary loss t1 3.209549\n",
      "Epoch 4/10, Batch 591/1650, Loss 39.860466, Loss rec 10.316332, loss rec t1 10.958029, loss kl 0.224949, loss_trans 0.010583, loss flux 9.994576, loss flux t1 8.356000, binary loss 1.339628, binary loss t1 1.171420\n",
      "Epoch 4/10, Batch 601/1650, Loss 36.635365, Loss rec 10.289771, loss rec t1 10.031950, loss kl 0.186200, loss_trans 0.014342, loss flux 8.442219, loss flux t1 7.670882, binary loss 2.936141, binary loss t1 2.469014\n",
      "Epoch 4/10, Batch 611/1650, Loss 71.031021, Loss rec 22.833900, loss rec t1 26.801571, loss kl 0.399973, loss_trans 0.011595, loss flux 11.745913, loss flux t1 9.238070, binary loss 8.032095, binary loss t1 6.382538\n",
      "Epoch 4/10, Batch 621/1650, Loss 67.949890, Loss rec 23.109167, loss rec t1 25.456440, loss kl 0.235829, loss_trans 0.008382, loss flux 10.281936, loss flux t1 8.858138, binary loss 0.457944, binary loss t1 0.512486\n",
      "Epoch 4/10, Batch 631/1650, Loss 44.840721, Loss rec 13.535799, loss rec t1 14.885674, loss kl 0.240535, loss_trans 0.014573, loss flux 8.478632, loss flux t1 7.685507, binary loss 2.015245, binary loss t1 1.418513\n",
      "Epoch 4/10, Batch 641/1650, Loss 46.574047, Loss rec 14.954140, loss rec t1 14.124579, loss kl 0.262014, loss_trans 0.019966, loss flux 9.015306, loss flux t1 8.198039, binary loss 4.801621, binary loss t1 3.877111\n",
      "Epoch 4/10, Batch 651/1650, Loss 40.195511, Loss rec 10.458067, loss rec t1 13.744606, loss kl 0.212768, loss_trans 0.010116, loss flux 7.903164, loss flux t1 7.866788, binary loss 3.126589, binary loss t1 2.921761\n",
      "Epoch 4/10, Batch 661/1650, Loss 30.607986, Loss rec 6.835967, loss rec t1 9.072482, loss kl 0.179346, loss_trans 0.009193, loss flux 7.298709, loss flux t1 7.212289, binary loss 3.253808, binary loss t1 2.364787\n",
      "Epoch 4/10, Batch 671/1650, Loss 37.458424, Loss rec 10.010994, loss rec t1 9.974986, loss kl 0.274058, loss_trans 0.013645, loss flux 8.893124, loss flux t1 8.291615, binary loss 2.174437, binary loss t1 1.880007\n",
      "Epoch 4/10, Batch 681/1650, Loss 31.312168, Loss rec 7.774441, loss rec t1 9.420729, loss kl 0.182618, loss_trans 0.016391, loss flux 6.910140, loss flux t1 7.007853, binary loss 2.334969, binary loss t1 2.246461\n",
      "Epoch 4/10, Batch 691/1650, Loss 48.575958, Loss rec 15.016163, loss rec t1 18.882595, loss kl 0.252371, loss_trans 0.012681, loss flux 7.467689, loss flux t1 6.944463, binary loss 0.928551, binary loss t1 0.808121\n",
      "Epoch 4/10, Batch 701/1650, Loss 34.008877, Loss rec 9.807070, loss rec t1 9.906597, loss kl 0.199724, loss_trans 0.014849, loss flux 7.115078, loss flux t1 6.965556, binary loss 1.165982, binary loss t1 1.004430\n",
      "Epoch 4/10, Batch 711/1650, Loss 33.364223, Loss rec 7.631623, loss rec t1 9.244295, loss kl 0.383917, loss_trans 0.009518, loss flux 8.396258, loss flux t1 7.698612, binary loss 1.575515, binary loss t1 0.992044\n",
      "Epoch 4/10, Batch 721/1650, Loss 31.215860, Loss rec 7.911380, loss rec t1 8.395650, loss kl 0.214496, loss_trans 0.012677, loss flux 7.741712, loss flux t1 6.939945, binary loss 2.936141, binary loss t1 2.702529\n",
      "Epoch 4/10, Batch 731/1650, Loss 34.168217, Loss rec 8.509906, loss rec t1 9.530144, loss kl 0.278533, loss_trans 0.013653, loss flux 8.456030, loss flux t1 7.379951, binary loss 0.804918, binary loss t1 0.847013\n",
      "Epoch 4/10, Batch 741/1650, Loss 36.799244, Loss rec 8.750218, loss rec t1 10.916135, loss kl 0.226526, loss_trans 0.015364, loss flux 8.482997, loss flux t1 8.408001, binary loss 1.513456, binary loss t1 1.389557\n",
      "Epoch 4/10, Batch 751/1650, Loss 29.995813, Loss rec 6.943986, loss rec t1 8.367368, loss kl 0.182841, loss_trans 0.007179, loss flux 7.574659, loss flux t1 6.919779, binary loss 1.359568, binary loss t1 1.335297\n",
      "Epoch 4/10, Batch 761/1650, Loss 28.503571, Loss rec 6.480855, loss rec t1 7.294794, loss kl 0.161227, loss_trans 0.007693, loss flux 7.783104, loss flux t1 6.775897, binary loss 1.647380, binary loss t1 1.603144\n",
      "Epoch 4/10, Batch 771/1650, Loss 35.509907, Loss rec 9.373505, loss rec t1 10.472193, loss kl 0.329857, loss_trans 0.013816, loss flux 8.216784, loss flux t1 7.103752, binary loss 1.044322, binary loss t1 1.056586\n",
      "Epoch 4/10, Batch 781/1650, Loss 37.472244, Loss rec 11.115736, loss rec t1 10.144878, loss kl 0.279739, loss_trans 0.008018, loss flux 8.353084, loss flux t1 7.570789, binary loss 1.451873, binary loss t1 1.277910\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Batch 791/1650, Loss 30.303831, Loss rec 7.401443, loss rec t1 7.983025, loss kl 0.227267, loss_trans 0.011968, loss flux 7.469013, loss flux t1 7.211117, binary loss 1.625384, binary loss t1 1.377440\n",
      "Epoch 4/10, Batch 801/1650, Loss 28.246508, Loss rec 6.449693, loss rec t1 8.071655, loss kl 0.208689, loss_trans 0.012525, loss flux 6.534839, loss flux t1 6.969104, binary loss 1.595577, binary loss t1 1.405142\n",
      "Epoch 4/10, Batch 811/1650, Loss 28.448889, Loss rec 5.483032, loss rec t1 8.114993, loss kl 0.348082, loss_trans 0.010176, loss flux 7.615616, loss flux t1 6.876989, binary loss 3.971228, binary loss t1 1.916615\n",
      "Epoch 4/10, Batch 821/1650, Loss 39.495800, Loss rec 11.418373, loss rec t1 12.363425, loss kl 0.245512, loss_trans 0.007007, loss flux 8.315748, loss flux t1 7.145735, binary loss 0.565261, binary loss t1 0.604022\n",
      "Epoch 4/10, Batch 831/1650, Loss 40.012878, Loss rec 11.553127, loss rec t1 13.933119, loss kl 0.165833, loss_trans 0.009812, loss flux 7.526591, loss flux t1 6.824399, binary loss 1.059056, binary loss t1 0.971729\n",
      "Epoch 4/10, Batch 841/1650, Loss 31.516001, Loss rec 7.779542, loss rec t1 8.782735, loss kl 0.198020, loss_trans 0.009255, loss flux 7.753392, loss flux t1 6.993059, binary loss 2.718004, binary loss t1 2.560941\n",
      "Epoch 4/10, Batch 851/1650, Loss 31.084078, Loss rec 8.617604, loss rec t1 7.931521, loss kl 0.171525, loss_trans 0.012504, loss flux 7.818837, loss flux t1 6.532088, binary loss 2.306171, binary loss t1 1.414060\n",
      "Epoch 4/10, Batch 861/1650, Loss 57.390133, Loss rec 19.143499, loss rec t1 17.136021, loss kl 0.359619, loss_trans 0.012173, loss flux 10.972761, loss flux t1 9.766059, binary loss 2.072184, binary loss t1 2.157602\n",
      "Epoch 4/10, Batch 871/1650, Loss 37.490555, Loss rec 9.381279, loss rec t1 10.450529, loss kl 0.245585, loss_trans 0.007735, loss flux 9.011127, loss flux t1 8.394298, binary loss 1.560016, binary loss t1 1.395008\n",
      "Epoch 4/10, Batch 881/1650, Loss 32.414593, Loss rec 7.779454, loss rec t1 9.876743, loss kl 0.170545, loss_trans 0.014155, loss flux 7.048192, loss flux t1 7.525505, binary loss 1.738187, binary loss t1 1.854470\n",
      "Epoch 4/10, Batch 891/1650, Loss 31.358061, Loss rec 7.985771, loss rec t1 7.845264, loss kl 0.211053, loss_trans 0.006660, loss flux 8.655405, loss flux t1 6.653906, binary loss 1.205741, binary loss t1 1.119484\n",
      "Epoch 4/10, Batch 901/1650, Loss 45.605965, Loss rec 14.684231, loss rec t1 15.277293, loss kl 0.156045, loss_trans 0.006951, loss flux 7.979558, loss flux t1 7.501888, binary loss 3.050100, binary loss t1 3.087742\n",
      "Epoch 4/10, Batch 911/1650, Loss 86.490974, Loss rec 47.956093, loss rec t1 19.297411, loss kl 0.177432, loss_trans 0.014069, loss flux 9.621573, loss flux t1 9.424403, binary loss 3.382307, binary loss t1 3.251668\n",
      "Epoch 4/10, Batch 921/1650, Loss 55.789406, Loss rec 15.816159, loss rec t1 16.504627, loss kl 0.285078, loss_trans 0.010232, loss flux 11.794315, loss flux t1 11.378997, binary loss 0.641725, binary loss t1 0.649474\n",
      "Epoch 4/10, Batch 931/1650, Loss 71.326355, Loss rec 29.646341, loss rec t1 18.471449, loss kl 0.294402, loss_trans 0.024113, loss flux 12.167922, loss flux t1 10.722127, binary loss 0.699148, binary loss t1 0.630714\n",
      "Epoch 4/10, Batch 941/1650, Loss 53.154888, Loss rec 16.091373, loss rec t1 16.622320, loss kl 0.180004, loss_trans 0.023806, loss flux 10.443742, loss flux t1 9.793645, binary loss 5.856612, binary loss t1 5.068398\n",
      "Epoch 4/10, Batch 951/1650, Loss 40.704552, Loss rec 9.939246, loss rec t1 11.962536, loss kl 0.193477, loss_trans 0.018670, loss flux 9.723604, loss flux t1 8.867019, binary loss 1.191312, binary loss t1 1.270087\n",
      "Epoch 4/10, Batch 961/1650, Loss 38.627312, Loss rec 9.497776, loss rec t1 12.125740, loss kl 0.261654, loss_trans 0.013600, loss flux 8.296310, loss flux t1 8.432232, binary loss 2.985900, binary loss t1 2.647161\n",
      "Epoch 4/10, Batch 971/1650, Loss 38.444786, Loss rec 12.645222, loss rec t1 9.578659, loss kl 0.200040, loss_trans 0.007507, loss flux 8.256703, loss flux t1 7.756653, binary loss 1.238917, binary loss t1 1.265671\n",
      "Epoch 4/10, Batch 981/1650, Loss 35.306530, Loss rec 9.132454, loss rec t1 9.599148, loss kl 0.203570, loss_trans 0.021993, loss flux 9.082741, loss flux t1 7.266627, binary loss 1.522667, binary loss t1 1.388548\n",
      "Epoch 4/10, Batch 991/1650, Loss 35.423927, Loss rec 8.973656, loss rec t1 10.555369, loss kl 0.198263, loss_trans 0.018616, loss flux 7.812071, loss flux t1 7.865953, binary loss 2.245305, binary loss t1 2.069360\n",
      "Epoch 4/10, Batch 1001/1650, Loss 28.270014, Loss rec 6.329544, loss rec t1 7.110511, loss kl 0.161081, loss_trans 0.008362, loss flux 7.270774, loss flux t1 7.389742, binary loss 1.303081, binary loss t1 1.327523\n",
      "Epoch 4/10, Batch 1011/1650, Loss 33.025444, Loss rec 8.647903, loss rec t1 9.423127, loss kl 0.172195, loss_trans 0.008714, loss flux 7.690300, loss flux t1 7.083205, binary loss 2.076963, binary loss t1 1.908682\n",
      "Epoch 4/10, Batch 1021/1650, Loss 43.905727, Loss rec 13.009815, loss rec t1 13.092880, loss kl 0.390385, loss_trans 0.011442, loss flux 8.818992, loss flux t1 8.582210, binary loss 0.768749, binary loss t1 0.617222\n",
      "Epoch 4/10, Batch 1031/1650, Loss 33.852974, Loss rec 9.411516, loss rec t1 10.635986, loss kl 0.186677, loss_trans 0.009290, loss flux 6.674561, loss flux t1 6.934943, binary loss 1.186130, binary loss t1 1.334873\n",
      "Epoch 4/10, Batch 1041/1650, Loss 31.345879, Loss rec 8.022058, loss rec t1 8.942088, loss kl 0.202880, loss_trans 0.013950, loss flux 7.034828, loss flux t1 7.130076, binary loss 1.359702, binary loss t1 1.347524\n",
      "Epoch 4/10, Batch 1051/1650, Loss 31.804047, Loss rec 7.284889, loss rec t1 8.774976, loss kl 0.346450, loss_trans 0.013909, loss flux 8.129003, loss flux t1 7.254821, binary loss 4.296694, binary loss t1 2.963783\n",
      "Epoch 4/10, Batch 1061/1650, Loss 27.329687, Loss rec 5.807955, loss rec t1 7.597337, loss kl 0.164189, loss_trans 0.010276, loss flux 7.097745, loss flux t1 6.652188, binary loss 2.302862, binary loss t1 2.320539\n",
      "Epoch 4/10, Batch 1071/1650, Loss 33.499203, Loss rec 8.058014, loss rec t1 9.432821, loss kl 0.478477, loss_trans 0.009407, loss flux 7.936722, loss flux t1 7.583760, binary loss 5.716107, binary loss t1 3.839568\n",
      "Epoch 4/10, Batch 1081/1650, Loss 33.987869, Loss rec 7.136982, loss rec t1 9.291935, loss kl 0.207369, loss_trans 0.015738, loss flux 9.810599, loss flux t1 7.525247, binary loss 1.386187, binary loss t1 1.447188\n",
      "Epoch 4/10, Batch 1091/1650, Loss 36.497356, Loss rec 9.191659, loss rec t1 9.800817, loss kl 0.311789, loss_trans 0.011591, loss flux 9.279393, loss flux t1 7.902107, binary loss 1.679706, binary loss t1 1.375311\n",
      "Epoch 4/10, Batch 1101/1650, Loss 35.245342, Loss rec 9.848893, loss rec t1 9.349068, loss kl 0.219784, loss_trans 0.010607, loss flux 8.481623, loss flux t1 7.335366, binary loss 1.985109, binary loss t1 1.824517\n",
      "Epoch 4/10, Batch 1111/1650, Loss 32.958435, Loss rec 9.001410, loss rec t1 10.246201, loss kl 0.247172, loss_trans 0.017444, loss flux 6.610460, loss flux t1 6.835747, binary loss 1.763626, binary loss t1 1.710485\n",
      "Epoch 4/10, Batch 1121/1650, Loss 36.817806, Loss rec 10.473676, loss rec t1 11.157908, loss kl 0.227840, loss_trans 0.012379, loss flux 7.954514, loss flux t1 6.991488, binary loss 2.383730, binary loss t1 2.090407\n",
      "Epoch 4/10, Batch 1131/1650, Loss 30.185802, Loss rec 7.618001, loss rec t1 9.271219, loss kl 0.203627, loss_trans 0.006519, loss flux 6.756971, loss flux t1 6.329464, binary loss 1.335333, binary loss t1 1.317803\n",
      "Epoch 4/10, Batch 1141/1650, Loss 27.672636, Loss rec 5.634670, loss rec t1 7.726147, loss kl 0.217145, loss_trans 0.017045, loss flux 7.628705, loss flux t1 6.448924, binary loss 1.488224, binary loss t1 1.334568\n",
      "Epoch 4/10, Batch 1151/1650, Loss 35.253086, Loss rec 8.988832, loss rec t1 10.923124, loss kl 0.231337, loss_trans 0.012576, loss flux 6.982186, loss flux t1 8.115028, binary loss 3.438696, binary loss t1 3.098838\n",
      "Epoch 4/10, Batch 1161/1650, Loss 32.937424, Loss rec 8.709502, loss rec t1 9.872574, loss kl 0.219867, loss_trans 0.012998, loss flux 7.345565, loss flux t1 6.776917, binary loss 3.465365, binary loss t1 2.940570\n",
      "Epoch 4/10, Batch 1171/1650, Loss 23.823980, Loss rec 5.193123, loss rec t1 6.230841, loss kl 0.141972, loss_trans 0.008352, loss flux 6.244872, loss flux t1 6.004823, binary loss 2.860870, binary loss t1 2.348266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Batch 1181/1650, Loss 35.425892, Loss rec 9.064428, loss rec t1 10.899305, loss kl 0.206647, loss_trans 0.010542, loss flux 8.268575, loss flux t1 6.976393, binary loss 0.735902, binary loss t1 0.689843\n",
      "Epoch 4/10, Batch 1191/1650, Loss 30.420753, Loss rec 7.783586, loss rec t1 8.925308, loss kl 0.189525, loss_trans 0.010861, loss flux 6.776690, loss flux t1 6.734783, binary loss 1.306658, binary loss t1 1.357512\n",
      "Epoch 4/10, Batch 1201/1650, Loss 45.674152, Loss rec 13.880911, loss rec t1 14.220129, loss kl 0.344503, loss_trans 0.013254, loss flux 8.894568, loss flux t1 8.320786, binary loss 2.171104, binary loss t1 1.909826\n",
      "Epoch 4/10, Batch 1211/1650, Loss 37.441120, Loss rec 10.890487, loss rec t1 10.543420, loss kl 0.300189, loss_trans 0.008388, loss flux 8.465096, loss flux t1 7.233540, binary loss 4.284541, binary loss t1 3.693356\n",
      "Epoch 4/10, Batch 1221/1650, Loss 28.419100, Loss rec 6.520029, loss rec t1 7.829703, loss kl 0.142025, loss_trans 0.009154, loss flux 7.203963, loss flux t1 6.714227, binary loss 4.700814, binary loss t1 4.076489\n",
      "Epoch 4/10, Batch 1231/1650, Loss 26.660252, Loss rec 5.517143, loss rec t1 8.070168, loss kl 0.190547, loss_trans 0.008838, loss flux 6.553422, loss flux t1 6.320135, binary loss 1.223430, binary loss t1 1.031924\n",
      "Epoch 4/10, Batch 1241/1650, Loss 33.079105, Loss rec 9.101772, loss rec t1 10.065042, loss kl 0.203707, loss_trans 0.017848, loss flux 7.136204, loss flux t1 6.554533, binary loss 0.635640, binary loss t1 0.632465\n",
      "Epoch 4/10, Batch 1251/1650, Loss 40.238289, Loss rec 11.077000, loss rec t1 15.477040, loss kl 0.217627, loss_trans 0.008972, loss flux 6.854234, loss flux t1 6.603418, binary loss 2.396128, binary loss t1 2.173794\n",
      "Epoch 4/10, Batch 1261/1650, Loss 34.373379, Loss rec 9.712994, loss rec t1 10.728102, loss kl 0.163423, loss_trans 0.008344, loss flux 7.374707, loss flux t1 6.385809, binary loss 2.343850, binary loss t1 2.101380\n",
      "Epoch 4/10, Batch 1271/1650, Loss 33.541363, Loss rec 7.218853, loss rec t1 11.834292, loss kl 0.175597, loss_trans 0.009974, loss flux 7.281209, loss flux t1 7.021435, binary loss 0.942322, binary loss t1 1.036780\n",
      "Epoch 4/10, Batch 1281/1650, Loss 30.455969, Loss rec 7.260740, loss rec t1 8.735668, loss kl 0.172806, loss_trans 0.007855, loss flux 7.358446, loss flux t1 6.920453, binary loss 1.379947, binary loss t1 1.387612\n",
      "Epoch 4/10, Batch 1291/1650, Loss 29.807213, Loss rec 7.504666, loss rec t1 8.019911, loss kl 0.245434, loss_trans 0.007895, loss flux 7.135419, loss flux t1 6.893888, binary loss 1.740536, binary loss t1 1.534662\n",
      "Epoch 4/10, Batch 1301/1650, Loss 33.682873, Loss rec 9.902521, loss rec t1 9.127398, loss kl 0.217776, loss_trans 0.007560, loss flux 7.578999, loss flux t1 6.848620, binary loss 0.932785, binary loss t1 0.890544\n",
      "Epoch 4/10, Batch 1311/1650, Loss 25.384075, Loss rec 5.178600, loss rec t1 6.740339, loss kl 0.379310, loss_trans 0.011932, loss flux 6.979364, loss flux t1 6.094528, binary loss 1.516863, binary loss t1 1.378486\n",
      "Epoch 4/10, Batch 1321/1650, Loss 31.538071, Loss rec 7.845443, loss rec t1 8.390810, loss kl 0.447702, loss_trans 0.011100, loss flux 7.631288, loss flux t1 7.211727, binary loss 4.726387, binary loss t1 1.996290\n",
      "Epoch 4/10, Batch 1331/1650, Loss 34.519234, Loss rec 9.395357, loss rec t1 12.093254, loss kl 0.171541, loss_trans 0.009181, loss flux 6.449633, loss flux t1 6.400267, binary loss 6.510915, binary loss t1 5.328533\n",
      "Epoch 4/10, Batch 1341/1650, Loss 39.480862, Loss rec 11.830143, loss rec t1 12.332373, loss kl 0.240119, loss_trans 0.009679, loss flux 8.105612, loss flux t1 6.962938, binary loss 2.363000, binary loss t1 2.018628\n",
      "Epoch 4/10, Batch 1351/1650, Loss 49.201172, Loss rec 15.302088, loss rec t1 19.269703, loss kl 0.213285, loss_trans 0.018303, loss flux 7.780164, loss flux t1 6.617628, binary loss 0.450100, binary loss t1 0.490176\n",
      "Epoch 4/10, Batch 1361/1650, Loss 69.994125, Loss rec 21.831436, loss rec t1 32.564186, loss kl 0.212621, loss_trans 0.010645, loss flux 7.451668, loss flux t1 7.923572, binary loss 6.426908, binary loss t1 5.978566\n",
      "Epoch 4/10, Batch 1371/1650, Loss 93.300835, Loss rec 33.855762, loss rec t1 42.930969, loss kl 0.190295, loss_trans 0.011531, loss flux 8.253281, loss flux t1 8.059003, binary loss 1.289137, binary loss t1 1.234880\n",
      "Epoch 4/10, Batch 1381/1650, Loss 87.672981, Loss rec 32.950172, loss rec t1 34.879135, loss kl 0.358238, loss_trans 0.013957, loss flux 10.410448, loss flux t1 9.061034, binary loss 3.953551, binary loss t1 3.335820\n",
      "Epoch 4/10, Batch 1391/1650, Loss 56.086285, Loss rec 22.670782, loss rec t1 15.926052, loss kl 0.203213, loss_trans 0.007854, loss flux 8.993645, loss flux t1 8.284740, binary loss 0.771717, binary loss t1 0.705461\n",
      "Epoch 4/10, Batch 1401/1650, Loss 45.930614, Loss rec 16.233288, loss rec t1 11.949931, loss kl 0.191542, loss_trans 0.011369, loss flux 9.170989, loss flux t1 8.373497, binary loss 2.775684, binary loss t1 2.652758\n",
      "Epoch 4/10, Batch 1411/1650, Loss 34.166199, Loss rec 8.818146, loss rec t1 8.460125, loss kl 0.163891, loss_trans 0.015499, loss flux 8.265635, loss flux t1 8.442903, binary loss 2.832012, binary loss t1 2.778968\n",
      "Epoch 4/10, Batch 1421/1650, Loss 34.878292, Loss rec 8.716902, loss rec t1 9.774219, loss kl 0.183343, loss_trans 0.009479, loss flux 8.359885, loss flux t1 7.834465, binary loss 3.856101, binary loss t1 3.415471\n",
      "Epoch 4/10, Batch 1431/1650, Loss 30.503695, Loss rec 5.711412, loss rec t1 8.983545, loss kl 0.652721, loss_trans 0.013735, loss flux 7.849676, loss flux t1 7.292604, binary loss 1.109410, binary loss t1 1.086246\n",
      "Epoch 4/10, Batch 1441/1650, Loss 33.152126, Loss rec 8.504135, loss rec t1 8.138088, loss kl 0.334453, loss_trans 0.013675, loss flux 8.410686, loss flux t1 7.751088, binary loss 2.683659, binary loss t1 2.155592\n",
      "Epoch 4/10, Batch 1451/1650, Loss 32.986912, Loss rec 9.095500, loss rec t1 8.603115, loss kl 0.217313, loss_trans 0.018807, loss flux 7.880269, loss flux t1 7.171905, binary loss 1.373000, binary loss t1 1.328703\n",
      "Epoch 4/10, Batch 1461/1650, Loss 28.624962, Loss rec 7.331494, loss rec t1 7.237149, loss kl 0.222257, loss_trans 0.009363, loss flux 7.492370, loss flux t1 6.332327, binary loss 5.081648, binary loss t1 3.479647\n",
      "Epoch 4/10, Batch 1471/1650, Loss 31.208736, Loss rec 8.372599, loss rec t1 7.895871, loss kl 0.241945, loss_trans 0.009310, loss flux 8.432776, loss flux t1 6.256235, binary loss 1.751607, binary loss t1 1.614252\n",
      "Epoch 4/10, Batch 1481/1650, Loss 29.048893, Loss rec 7.268066, loss rec t1 9.090289, loss kl 0.193003, loss_trans 0.009663, loss flux 6.391446, loss flux t1 6.096427, binary loss 0.933684, binary loss t1 0.949379\n",
      "Epoch 4/10, Batch 1491/1650, Loss 31.085939, Loss rec 7.560720, loss rec t1 8.498476, loss kl 0.263948, loss_trans 0.012902, loss flux 7.430940, loss flux t1 7.318950, binary loss 2.009478, binary loss t1 1.654035\n",
      "Epoch 4/10, Batch 1501/1650, Loss 31.635067, Loss rec 7.739076, loss rec t1 9.790930, loss kl 0.212790, loss_trans 0.017695, loss flux 6.749641, loss flux t1 7.124936, binary loss 0.756315, binary loss t1 0.799578\n",
      "Epoch 4/10, Batch 1511/1650, Loss 35.526375, Loss rec 10.013419, loss rec t1 11.439810, loss kl 0.217771, loss_trans 0.011447, loss flux 6.726887, loss flux t1 7.117039, binary loss 5.485742, binary loss t1 4.767216\n",
      "Epoch 4/10, Batch 1521/1650, Loss 26.380198, Loss rec 6.160449, loss rec t1 6.755318, loss kl 0.558960, loss_trans 0.008082, loss flux 6.811769, loss flux t1 6.085620, binary loss 9.136992, binary loss t1 4.685315\n",
      "Epoch 4/10, Batch 1531/1650, Loss 37.518875, Loss rec 9.896437, loss rec t1 11.876071, loss kl 0.363849, loss_trans 0.008662, loss flux 7.818186, loss flux t1 7.555670, binary loss 0.941263, binary loss t1 0.839507\n",
      "Epoch 4/10, Batch 1541/1650, Loss 33.017307, Loss rec 9.444275, loss rec t1 9.117126, loss kl 0.239457, loss_trans 0.012081, loss flux 7.186318, loss flux t1 7.018053, binary loss 3.764247, binary loss t1 3.358996\n",
      "Epoch 4/10, Batch 1551/1650, Loss 32.918148, Loss rec 9.670937, loss rec t1 7.504054, loss kl 0.429799, loss_trans 0.011720, loss flux 8.854219, loss flux t1 6.447418, binary loss 0.947759, binary loss t1 1.085102\n",
      "Epoch 4/10, Batch 1561/1650, Loss 25.628410, Loss rec 5.944303, loss rec t1 6.314203, loss kl 0.233321, loss_trans 0.008148, loss flux 7.339714, loss flux t1 5.788722, binary loss 1.898828, binary loss t1 1.362987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10, Batch 1571/1650, Loss 27.809956, Loss rec 6.772902, loss rec t1 6.244417, loss kl 0.397773, loss_trans 0.008514, loss flux 8.243435, loss flux t1 6.142915, binary loss 1.352937, binary loss t1 1.433793\n",
      "Epoch 4/10, Batch 1581/1650, Loss 38.767467, Loss rec 10.969306, loss rec t1 12.273540, loss kl 0.304295, loss_trans 0.011320, loss flux 7.600626, loss flux t1 7.608379, binary loss 3.737665, binary loss t1 3.263822\n",
      "Epoch 4/10, Batch 1591/1650, Loss 28.503946, Loss rec 5.894708, loss rec t1 8.383563, loss kl 0.261655, loss_trans 0.007318, loss flux 6.908041, loss flux t1 7.048660, binary loss 1.179145, binary loss t1 1.288749\n",
      "Epoch 4/10, Batch 1601/1650, Loss 28.688164, Loss rec 6.404073, loss rec t1 7.684092, loss kl 0.445922, loss_trans 0.008268, loss flux 7.901075, loss flux t1 6.244733, binary loss 1.974026, binary loss t1 1.619812\n",
      "Epoch 4/10, Batch 1611/1650, Loss 28.476830, Loss rec 7.578594, loss rec t1 7.628188, loss kl 0.197791, loss_trans 0.012621, loss flux 6.686942, loss flux t1 6.372694, binary loss 1.908768, binary loss t1 1.717201\n",
      "Epoch 4/10, Batch 1621/1650, Loss 30.667355, Loss rec 8.421144, loss rec t1 9.170872, loss kl 0.220460, loss_trans 0.007770, loss flux 6.836653, loss flux t1 6.010455, binary loss 0.980146, binary loss t1 0.977956\n",
      "Epoch 4/10, Batch 1631/1650, Loss 28.927906, Loss rec 7.322085, loss rec t1 7.289219, loss kl 0.292008, loss_trans 0.005588, loss flux 7.349589, loss flux t1 6.669415, binary loss 2.338363, binary loss t1 1.994039\n",
      "Epoch 4/10, Batch 1641/1650, Loss 34.658070, Loss rec 9.608893, loss rec t1 8.861444, loss kl 0.308238, loss_trans 0.009751, loss flux 8.135139, loss flux t1 7.734605, binary loss 0.909486, binary loss t1 0.825175\n",
      "Epoch 4/10, Train loss 27.889774, Eval loss 27.272158\n",
      "Epoch 5/10, Batch 1/1650, Loss 28.010746, Loss rec 6.466150, loss rec t1 7.250429, loss kl 0.227305, loss_trans 0.009490, loss flux 7.243286, loss flux t1 6.814087, binary loss 2.864191, binary loss t1 2.645069\n",
      "Epoch 5/10, Batch 11/1650, Loss 29.089653, Loss rec 6.960304, loss rec t1 8.035785, loss kl 0.171941, loss_trans 0.012340, loss flux 7.348612, loss flux t1 6.560670, binary loss 2.940496, binary loss t1 2.484416\n",
      "Epoch 5/10, Batch 21/1650, Loss 28.959761, Loss rec 7.558541, loss rec t1 8.181437, loss kl 0.275305, loss_trans 0.008119, loss flux 6.777991, loss flux t1 6.158369, binary loss 0.955643, binary loss t1 0.910289\n",
      "Epoch 5/10, Batch 31/1650, Loss 27.907290, Loss rec 6.921692, loss rec t1 7.639034, loss kl 0.170234, loss_trans 0.012517, loss flux 6.685121, loss flux t1 6.478693, binary loss 3.449767, binary loss t1 3.063484\n",
      "Epoch 5/10, Batch 41/1650, Loss 27.625435, Loss rec 7.244183, loss rec t1 7.150235, loss kl 0.208590, loss_trans 0.010514, loss flux 6.921630, loss flux t1 6.090281, binary loss 0.924827, binary loss t1 0.869484\n",
      "Epoch 5/10, Batch 51/1650, Loss 28.513275, Loss rec 6.351017, loss rec t1 7.287806, loss kl 0.224843, loss_trans 0.010904, loss flux 7.854817, loss flux t1 6.783887, binary loss 2.693672, binary loss t1 2.134594\n",
      "Epoch 5/10, Batch 61/1650, Loss 31.350574, Loss rec 7.347080, loss rec t1 8.618285, loss kl 0.209158, loss_trans 0.012376, loss flux 7.732604, loss flux t1 7.431071, binary loss 1.250122, binary loss t1 1.274772\n",
      "Epoch 5/10, Batch 71/1650, Loss 29.236895, Loss rec 8.258577, loss rec t1 6.933483, loss kl 0.222959, loss_trans 0.007074, loss flux 7.308762, loss flux t1 6.506038, binary loss 1.882368, binary loss t1 1.783615\n",
      "Epoch 5/10, Batch 81/1650, Loss 27.678652, Loss rec 7.488813, loss rec t1 7.411076, loss kl 0.197238, loss_trans 0.008625, loss flux 6.901473, loss flux t1 5.671427, binary loss 2.227579, binary loss t1 2.001704\n",
      "Epoch 5/10, Batch 91/1650, Loss 26.079052, Loss rec 6.570820, loss rec t1 6.705364, loss kl 0.276303, loss_trans 0.005080, loss flux 6.360337, loss flux t1 6.161146, binary loss 1.223479, binary loss t1 1.165933\n",
      "Epoch 5/10, Batch 101/1650, Loss 26.729654, Loss rec 6.452877, loss rec t1 7.558330, loss kl 0.175268, loss_trans 0.009635, loss flux 6.554756, loss flux t1 5.978791, binary loss 1.503724, binary loss t1 1.412782\n",
      "Epoch 5/10, Batch 111/1650, Loss 31.009163, Loss rec 8.247544, loss rec t1 8.603081, loss kl 0.250194, loss_trans 0.011165, loss flux 7.384870, loss flux t1 6.512309, binary loss 1.490329, binary loss t1 1.324262\n",
      "Epoch 5/10, Batch 121/1650, Loss 26.567135, Loss rec 6.665722, loss rec t1 7.246189, loss kl 0.256995, loss_trans 0.006255, loss flux 6.347899, loss flux t1 6.044074, binary loss 1.968503, binary loss t1 1.740475\n",
      "Epoch 5/10, Batch 131/1650, Loss 29.729006, Loss rec 7.576980, loss rec t1 8.991722, loss kl 0.231466, loss_trans 0.007154, loss flux 6.468407, loss flux t1 6.453276, binary loss 0.913537, binary loss t1 0.830735\n",
      "Epoch 5/10, Batch 141/1650, Loss 31.590343, Loss rec 8.569446, loss rec t1 8.185725, loss kl 0.326793, loss_trans 0.014102, loss flux 7.640379, loss flux t1 6.853897, binary loss 3.508432, binary loss t1 2.440071\n",
      "Epoch 5/10, Batch 151/1650, Loss 25.039513, Loss rec 5.686375, loss rec t1 6.912438, loss kl 0.161616, loss_trans 0.008296, loss flux 6.370494, loss flux t1 5.900293, binary loss 1.489173, binary loss t1 1.475863\n",
      "Epoch 5/10, Batch 161/1650, Loss 27.377089, Loss rec 6.370750, loss rec t1 7.059699, loss kl 0.242977, loss_trans 0.011365, loss flux 7.405138, loss flux t1 6.287158, binary loss 2.282922, binary loss t1 1.651967\n",
      "Epoch 5/10, Batch 171/1650, Loss 25.256382, Loss rec 6.390494, loss rec t1 6.786527, loss kl 0.172884, loss_trans 0.010367, loss flux 6.347461, loss flux t1 5.548649, binary loss 2.205449, binary loss t1 2.024990\n",
      "Epoch 5/10, Batch 181/1650, Loss 24.492189, Loss rec 6.088005, loss rec t1 6.219179, loss kl 0.212214, loss_trans 0.005310, loss flux 6.101027, loss flux t1 5.866456, binary loss 1.154813, binary loss t1 1.150568\n",
      "Epoch 5/10, Batch 191/1650, Loss 26.209127, Loss rec 6.707270, loss rec t1 6.838675, loss kl 0.236342, loss_trans 0.008267, loss flux 6.674994, loss flux t1 5.743579, binary loss 2.118060, binary loss t1 1.605444\n",
      "Epoch 5/10, Batch 201/1650, Loss 24.061451, Loss rec 6.298734, loss rec t1 6.069036, loss kl 0.180562, loss_trans 0.014879, loss flux 6.216013, loss flux t1 5.282227, binary loss 8.716290, binary loss t1 6.675885\n",
      "Epoch 5/10, Batch 211/1650, Loss 34.359127, Loss rec 10.153344, loss rec t1 11.135273, loss kl 0.169482, loss_trans 0.016153, loss flux 6.414623, loss flux t1 6.470254, binary loss 0.969295, binary loss t1 0.902783\n",
      "Epoch 5/10, Batch 221/1650, Loss 32.551231, Loss rec 8.715914, loss rec t1 8.792423, loss kl 0.278250, loss_trans 0.008546, loss flux 7.755349, loss flux t1 7.000751, binary loss 3.307036, binary loss t1 2.904059\n",
      "Epoch 5/10, Batch 231/1650, Loss 25.897064, Loss rec 6.814876, loss rec t1 6.427031, loss kl 0.154701, loss_trans 0.012355, loss flux 6.889447, loss flux t1 5.598654, binary loss 1.609836, binary loss t1 1.313045\n",
      "Epoch 5/10, Batch 241/1650, Loss 25.200594, Loss rec 4.921161, loss rec t1 6.703334, loss kl 0.329823, loss_trans 0.006771, loss flux 6.814976, loss flux t1 6.424529, binary loss 3.054565, binary loss t1 2.575309\n",
      "Epoch 5/10, Batch 251/1650, Loss 20.745213, Loss rec 4.153103, loss rec t1 5.399859, loss kl 0.155779, loss_trans 0.009461, loss flux 5.576555, loss flux t1 5.450457, binary loss 1.383912, binary loss t1 1.480255\n",
      "Epoch 5/10, Batch 261/1650, Loss 25.177671, Loss rec 4.889878, loss rec t1 6.915351, loss kl 0.333877, loss_trans 0.007635, loss flux 6.701917, loss flux t1 6.329011, binary loss 1.944098, binary loss t1 1.979537\n",
      "Epoch 5/10, Batch 271/1650, Loss 21.563644, Loss rec 4.646600, loss rec t1 5.974467, loss kl 0.137811, loss_trans 0.010196, loss flux 5.408527, loss flux t1 5.386044, binary loss 2.076938, binary loss t1 2.004977\n",
      "Epoch 5/10, Batch 281/1650, Loss 26.872509, Loss rec 6.899361, loss rec t1 7.249244, loss kl 0.224922, loss_trans 0.011164, loss flux 6.822487, loss flux t1 5.665330, binary loss 1.134898, binary loss t1 1.060807\n",
      "Epoch 5/10, Batch 291/1650, Loss 25.476738, Loss rec 5.792658, loss rec t1 7.046322, loss kl 0.211956, loss_trans 0.010918, loss flux 6.197490, loss flux t1 6.217394, binary loss 1.938684, binary loss t1 1.922090\n",
      "Epoch 5/10, Batch 301/1650, Loss 26.649586, Loss rec 6.349738, loss rec t1 7.607140, loss kl 0.233255, loss_trans 0.005332, loss flux 6.385422, loss flux t1 6.068699, binary loss 1.690691, binary loss t1 1.528032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Batch 311/1650, Loss 33.807564, Loss rec 9.438976, loss rec t1 10.012672, loss kl 0.245063, loss_trans 0.013848, loss flux 6.843603, loss flux t1 7.253399, binary loss 2.271790, binary loss t1 2.226435\n",
      "Epoch 5/10, Batch 321/1650, Loss 23.359901, Loss rec 5.644036, loss rec t1 5.610108, loss kl 0.195489, loss_trans 0.007889, loss flux 6.656746, loss flux t1 5.245633, binary loss 5.554371, binary loss t1 3.799614\n",
      "Epoch 5/10, Batch 331/1650, Loss 31.961727, Loss rec 8.372408, loss rec t1 9.698952, loss kl 0.232932, loss_trans 0.012132, loss flux 6.768309, loss flux t1 6.876997, binary loss 2.861904, binary loss t1 2.565199\n",
      "Epoch 5/10, Batch 341/1650, Loss 31.229633, Loss rec 8.079583, loss rec t1 8.953337, loss kl 0.176065, loss_trans 0.010231, loss flux 7.276507, loss flux t1 6.733910, binary loss 2.566489, binary loss t1 2.084920\n",
      "Epoch 5/10, Batch 351/1650, Loss 30.089809, Loss rec 7.727923, loss rec t1 9.609964, loss kl 0.208760, loss_trans 0.014986, loss flux 5.952814, loss flux t1 6.575363, binary loss 2.393755, binary loss t1 2.186640\n",
      "Epoch 5/10, Batch 361/1650, Loss 24.524012, Loss rec 5.729496, loss rec t1 6.314183, loss kl 0.312667, loss_trans 0.006410, loss flux 6.323695, loss flux t1 5.837561, binary loss 3.722177, binary loss t1 2.121235\n",
      "Epoch 5/10, Batch 371/1650, Loss 26.348864, Loss rec 6.594385, loss rec t1 6.687990, loss kl 0.223291, loss_trans 0.013511, loss flux 6.688113, loss flux t1 6.141572, binary loss 2.754807, binary loss t1 2.258700\n",
      "Epoch 5/10, Batch 381/1650, Loss 35.489460, Loss rec 8.933415, loss rec t1 11.485305, loss kl 0.326781, loss_trans 0.013995, loss flux 7.266096, loss flux t1 7.463866, binary loss 0.609081, binary loss t1 0.605858\n",
      "Epoch 5/10, Batch 391/1650, Loss 29.492409, Loss rec 7.586834, loss rec t1 8.764028, loss kl 0.288847, loss_trans 0.008828, loss flux 6.381677, loss flux t1 6.462194, binary loss 0.963393, binary loss t1 0.982190\n",
      "Epoch 5/10, Batch 401/1650, Loss 28.620569, Loss rec 7.129401, loss rec t1 7.712353, loss kl 0.388873, loss_trans 0.007717, loss flux 6.606195, loss flux t1 6.776030, binary loss 0.912430, binary loss t1 1.059675\n",
      "Epoch 5/10, Batch 411/1650, Loss 33.526985, Loss rec 8.720207, loss rec t1 10.050568, loss kl 0.261151, loss_trans 0.005829, loss flux 7.465847, loss flux t1 7.023384, binary loss 1.030088, binary loss t1 0.780040\n",
      "Epoch 5/10, Batch 421/1650, Loss 31.879650, Loss rec 6.960319, loss rec t1 10.666752, loss kl 0.171049, loss_trans 0.013207, loss flux 6.721971, loss flux t1 7.346351, binary loss 1.469306, binary loss t1 1.584653\n",
      "Epoch 5/10, Batch 431/1650, Loss 28.469332, Loss rec 7.165718, loss rec t1 7.860428, loss kl 0.184671, loss_trans 0.007161, loss flux 6.991099, loss flux t1 6.260255, binary loss 1.243407, binary loss t1 1.107232\n",
      "Epoch 5/10, Batch 441/1650, Loss 29.698153, Loss rec 7.450144, loss rec t1 8.310733, loss kl 0.259638, loss_trans 0.007792, loss flux 7.152029, loss flux t1 6.517817, binary loss 0.758651, binary loss t1 0.704525\n",
      "Epoch 5/10, Batch 451/1650, Loss 28.299751, Loss rec 7.279532, loss rec t1 6.841822, loss kl 0.330033, loss_trans 0.010595, loss flux 7.898063, loss flux t1 5.939707, binary loss 1.490182, binary loss t1 1.720510\n",
      "Epoch 5/10, Batch 461/1650, Loss 35.216660, Loss rec 9.556198, loss rec t1 10.008391, loss kl 0.269972, loss_trans 0.008750, loss flux 7.833220, loss flux t1 7.540125, binary loss 1.655410, binary loss t1 1.461605\n",
      "Epoch 5/10, Batch 471/1650, Loss 24.462585, Loss rec 5.907536, loss rec t1 6.344831, loss kl 0.185410, loss_trans 0.007648, loss flux 6.527978, loss flux t1 5.489181, binary loss 2.880713, binary loss t1 2.566306\n",
      "Epoch 5/10, Batch 481/1650, Loss 30.455305, Loss rec 7.343125, loss rec t1 9.345358, loss kl 0.204634, loss_trans 0.006407, loss flux 7.167067, loss flux t1 6.388715, binary loss 1.739355, binary loss t1 1.588996\n",
      "Epoch 5/10, Batch 491/1650, Loss 25.563942, Loss rec 6.957026, loss rec t1 6.046682, loss kl 0.195019, loss_trans 0.006209, loss flux 6.485472, loss flux t1 5.873533, binary loss 1.758140, binary loss t1 1.434900\n",
      "Epoch 5/10, Batch 501/1650, Loss 24.603605, Loss rec 5.376482, loss rec t1 6.058966, loss kl 0.225870, loss_trans 0.013576, loss flux 7.220326, loss flux t1 5.708386, binary loss 4.098607, binary loss t1 3.000293\n",
      "Epoch 5/10, Batch 511/1650, Loss 28.874281, Loss rec 8.062712, loss rec t1 7.268052, loss kl 0.376428, loss_trans 0.004937, loss flux 7.149819, loss flux t1 6.012334, binary loss 6.486570, binary loss t1 3.697747\n",
      "Epoch 5/10, Batch 521/1650, Loss 24.086018, Loss rec 5.920426, loss rec t1 5.889867, loss kl 0.154054, loss_trans 0.005368, loss flux 6.733058, loss flux t1 5.383246, binary loss 1.892088, binary loss t1 1.719403\n",
      "Epoch 5/10, Batch 531/1650, Loss 33.430023, Loss rec 9.101416, loss rec t1 10.870833, loss kl 0.219530, loss_trans 0.006798, loss flux 6.917199, loss flux t1 6.314250, binary loss 0.751633, binary loss t1 0.686509\n",
      "Epoch 5/10, Batch 541/1650, Loss 26.431479, Loss rec 6.642766, loss rec t1 7.084608, loss kl 0.362305, loss_trans 0.009992, loss flux 6.299553, loss flux t1 6.032256, binary loss 0.878134, binary loss t1 1.013103\n",
      "Epoch 5/10, Batch 551/1650, Loss 34.012707, Loss rec 10.867287, loss rec t1 8.394362, loss kl 0.375262, loss_trans 0.007911, loss flux 7.223086, loss flux t1 7.144798, binary loss 0.629995, binary loss t1 0.710875\n",
      "Epoch 5/10, Batch 561/1650, Loss 29.898115, Loss rec 7.574399, loss rec t1 8.735800, loss kl 0.207675, loss_trans 0.014574, loss flux 7.024989, loss flux t1 6.340678, binary loss 2.786621, binary loss t1 2.375870\n",
      "Epoch 5/10, Batch 571/1650, Loss 34.865364, Loss rec 9.646099, loss rec t1 12.129844, loss kl 0.146556, loss_trans 0.007150, loss flux 5.889399, loss flux t1 7.046317, binary loss 0.440837, binary loss t1 0.599227\n",
      "Epoch 5/10, Batch 581/1650, Loss 40.847832, Loss rec 12.115293, loss rec t1 13.222866, loss kl 0.310820, loss_trans 0.015711, loss flux 8.466071, loss flux t1 6.717072, binary loss 1.642088, binary loss t1 1.605627\n",
      "Epoch 5/10, Batch 591/1650, Loss 40.493855, Loss rec 11.086449, loss rec t1 13.468714, loss kl 0.186029, loss_trans 0.008653, loss flux 8.688100, loss flux t1 7.055913, binary loss 0.796366, binary loss t1 0.749358\n",
      "Epoch 5/10, Batch 601/1650, Loss 37.399410, Loss rec 11.356061, loss rec t1 10.911434, loss kl 0.177746, loss_trans 0.014042, loss flux 7.620250, loss flux t1 7.319876, binary loss 2.934949, binary loss t1 2.770112\n",
      "Epoch 5/10, Batch 611/1650, Loss 34.807426, Loss rec 8.824173, loss rec t1 9.388068, loss kl 0.379061, loss_trans 0.011462, loss flux 9.086499, loss flux t1 7.118159, binary loss 3.093339, binary loss t1 2.217676\n",
      "Epoch 5/10, Batch 621/1650, Loss 34.349659, Loss rec 9.628434, loss rec t1 10.128698, loss kl 0.227782, loss_trans 0.007359, loss flux 7.566511, loss flux t1 6.790874, binary loss 1.171603, binary loss t1 1.024467\n",
      "Epoch 5/10, Batch 631/1650, Loss 30.312922, Loss rec 7.727875, loss rec t1 8.394339, loss kl 0.227909, loss_trans 0.013433, loss flux 7.250403, loss flux t1 6.698964, binary loss 1.780306, binary loss t1 1.604300\n",
      "Epoch 5/10, Batch 641/1650, Loss 35.132801, Loss rec 11.030271, loss rec t1 9.621028, loss kl 0.209365, loss_trans 0.012987, loss flux 7.356166, loss flux t1 6.902983, binary loss 1.975438, binary loss t1 1.793653\n",
      "Epoch 5/10, Batch 651/1650, Loss 30.385847, Loss rec 7.178434, loss rec t1 9.121906, loss kl 0.185902, loss_trans 0.008353, loss flux 7.070195, loss flux t1 6.821059, binary loss 1.446118, binary loss t1 1.467128\n",
      "Epoch 5/10, Batch 661/1650, Loss 22.544111, Loss rec 4.820614, loss rec t1 6.074225, loss kl 0.145454, loss_trans 0.007314, loss flux 5.699685, loss flux t1 5.796819, binary loss 3.357926, binary loss t1 2.828715\n",
      "Epoch 5/10, Batch 671/1650, Loss 36.767807, Loss rec 11.137176, loss rec t1 10.171507, loss kl 0.237149, loss_trans 0.011404, loss flux 7.944226, loss flux t1 7.266350, binary loss 1.293263, binary loss t1 1.210450\n",
      "Epoch 5/10, Batch 681/1650, Loss 25.583160, Loss rec 5.643282, loss rec t1 7.660815, loss kl 0.158965, loss_trans 0.013898, loss flux 6.122196, loss flux t1 5.984004, binary loss 2.452286, binary loss t1 2.499952\n",
      "Epoch 5/10, Batch 691/1650, Loss 30.032845, Loss rec 7.671638, loss rec t1 8.491619, loss kl 0.232035, loss_trans 0.010426, loss flux 6.945040, loss flux t1 6.682087, binary loss 1.593229, binary loss t1 1.404959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Batch 701/1650, Loss 25.261295, Loss rec 6.346221, loss rec t1 6.718111, loss kl 0.178374, loss_trans 0.012713, loss flux 6.148814, loss flux t1 5.857063, binary loss 1.264356, binary loss t1 1.220145\n",
      "Epoch 5/10, Batch 711/1650, Loss 29.449450, Loss rec 7.547640, loss rec t1 8.149879, loss kl 0.340065, loss_trans 0.006602, loss flux 6.934541, loss flux t1 6.470722, binary loss 4.152831, binary loss t1 2.947151\n",
      "Epoch 5/10, Batch 721/1650, Loss 25.351894, Loss rec 6.378231, loss rec t1 6.392716, loss kl 0.188529, loss_trans 0.010780, loss flux 6.458548, loss flux t1 5.923089, binary loss 2.374812, binary loss t1 2.216471\n",
      "Epoch 5/10, Batch 731/1650, Loss 27.351866, Loss rec 6.282182, loss rec t1 7.390627, loss kl 0.250929, loss_trans 0.012771, loss flux 6.724977, loss flux t1 6.690379, binary loss 1.220072, binary loss t1 1.217846\n",
      "Epoch 5/10, Batch 741/1650, Loss 36.885315, Loss rec 10.170061, loss rec t1 13.292744, loss kl 0.199930, loss_trans 0.013020, loss flux 6.570883, loss flux t1 6.638679, binary loss 0.563946, binary loss t1 0.544213\n",
      "Epoch 5/10, Batch 751/1650, Loss 27.815948, Loss rec 6.645054, loss rec t1 8.045459, loss kl 0.175968, loss_trans 0.006455, loss flux 6.660580, loss flux t1 6.282432, binary loss 1.351818, binary loss t1 1.265549\n",
      "Epoch 5/10, Batch 761/1650, Loss 25.657791, Loss rec 5.842901, loss rec t1 7.433031, loss kl 0.146601, loss_trans 0.006342, loss flux 6.413487, loss flux t1 5.815427, binary loss 2.527569, binary loss t1 2.364811\n",
      "Epoch 5/10, Batch 771/1650, Loss 32.232616, Loss rec 8.002701, loss rec t1 9.126150, loss kl 0.295646, loss_trans 0.011121, loss flux 7.804560, loss flux t1 6.992440, binary loss 1.732835, binary loss t1 1.663172\n",
      "Epoch 5/10, Batch 781/1650, Loss 33.095116, Loss rec 9.640427, loss rec t1 8.800389, loss kl 0.244695, loss_trans 0.006375, loss flux 7.855505, loss flux t1 6.547725, binary loss 1.335773, binary loss t1 1.146249\n",
      "Epoch 5/10, Batch 791/1650, Loss 30.259323, Loss rec 8.663206, loss rec t1 8.400589, loss kl 0.201447, loss_trans 0.010999, loss flux 6.653770, loss flux t1 6.329311, binary loss 1.171664, binary loss t1 1.037826\n",
      "Epoch 5/10, Batch 801/1650, Loss 25.911627, Loss rec 5.989352, loss rec t1 7.626563, loss kl 0.187175, loss_trans 0.010761, loss flux 5.893946, loss flux t1 6.203828, binary loss 1.911018, binary loss t1 1.706240\n",
      "Epoch 5/10, Batch 811/1650, Loss 36.958717, Loss rec 8.221453, loss rec t1 12.668533, loss kl 0.338408, loss_trans 0.011771, loss flux 8.469182, loss flux t1 7.249370, binary loss 4.264905, binary loss t1 1.758957\n",
      "Epoch 5/10, Batch 821/1650, Loss 81.955765, Loss rec 30.950178, loss rec t1 34.748123, loss kl 0.209743, loss_trans 0.006077, loss flux 8.173514, loss flux t1 7.868129, binary loss 0.394263, binary loss t1 0.425140\n",
      "Epoch 5/10, Batch 831/1650, Loss 41.325382, Loss rec 12.263877, loss rec t1 14.221272, loss kl 0.152698, loss_trans 0.010615, loss flux 7.243886, loss flux t1 7.433033, binary loss 1.958408, binary loss t1 1.677446\n",
      "Epoch 5/10, Batch 841/1650, Loss 31.637251, Loss rec 9.160614, loss rec t1 8.407005, loss kl 0.179626, loss_trans 0.009280, loss flux 7.389895, loss flux t1 6.490829, binary loss 1.320819, binary loss t1 1.340942\n",
      "Epoch 5/10, Batch 851/1650, Loss 35.340874, Loss rec 10.840425, loss rec t1 9.968557, loss kl 0.162488, loss_trans 0.012528, loss flux 7.662815, loss flux t1 6.694060, binary loss 2.160216, binary loss t1 1.584763\n",
      "Epoch 5/10, Batch 861/1650, Loss 56.006393, Loss rec 14.715849, loss rec t1 19.818043, loss kl 0.359225, loss_trans 0.011511, loss flux 11.203112, loss flux t1 9.898649, binary loss 1.909610, binary loss t1 1.822929\n",
      "Epoch 5/10, Batch 871/1650, Loss 34.154167, Loss rec 8.778110, loss rec t1 9.006660, loss kl 0.229428, loss_trans 0.007323, loss flux 8.363838, loss flux t1 7.768807, binary loss 1.509040, binary loss t1 1.279856\n",
      "Epoch 5/10, Batch 881/1650, Loss 28.678291, Loss rec 6.587379, loss rec t1 9.094997, loss kl 0.155640, loss_trans 0.012775, loss flux 6.214448, loss flux t1 6.613053, binary loss 1.667344, binary loss t1 1.660714\n",
      "Epoch 5/10, Batch 891/1650, Loss 27.787830, Loss rec 7.212392, loss rec t1 6.813839, loss kl 0.193072, loss_trans 0.006710, loss flux 7.599269, loss flux t1 5.962548, binary loss 1.149290, binary loss t1 1.109471\n",
      "Epoch 5/10, Batch 901/1650, Loss 32.397457, Loss rec 9.132452, loss rec t1 10.735077, loss kl 0.148491, loss_trans 0.005789, loss flux 6.216665, loss flux t1 6.158981, binary loss 2.558556, binary loss t1 2.762301\n",
      "Epoch 5/10, Batch 911/1650, Loss 45.843533, Loss rec 20.371632, loss rec t1 10.639359, loss kl 0.182963, loss_trans 0.008321, loss flux 7.511220, loss flux t1 7.130041, binary loss 3.643719, binary loss t1 3.154303\n",
      "Epoch 5/10, Batch 921/1650, Loss 42.929676, Loss rec 11.526474, loss rec t1 12.807193, loss kl 0.256778, loss_trans 0.007411, loss flux 9.224012, loss flux t1 9.107804, binary loss 1.278179, binary loss t1 1.230573\n",
      "Epoch 5/10, Batch 931/1650, Loss 44.169712, Loss rec 13.031569, loss rec t1 15.187038, loss kl 0.250944, loss_trans 0.015493, loss flux 8.125251, loss flux t1 7.559418, binary loss 4.085285, binary loss t1 3.425460\n",
      "Epoch 5/10, Batch 941/1650, Loss 28.741308, Loss rec 5.272849, loss rec t1 8.094780, loss kl 0.185976, loss_trans 0.022447, loss flux 7.668630, loss flux t1 7.496626, binary loss 3.164218, binary loss t1 2.980597\n",
      "Epoch 5/10, Batch 951/1650, Loss 25.262793, Loss rec 5.568499, loss rec t1 7.116204, loss kl 0.157364, loss_trans 0.007494, loss flux 6.398603, loss flux t1 6.014629, binary loss 0.778481, binary loss t1 0.721095\n",
      "Epoch 5/10, Batch 961/1650, Loss 26.943323, Loss rec 6.391632, loss rec t1 7.544745, loss kl 0.225822, loss_trans 0.008155, loss flux 6.363766, loss flux t1 6.409204, binary loss 0.882721, binary loss t1 0.858291\n",
      "Epoch 5/10, Batch 971/1650, Loss 27.953472, Loss rec 7.576163, loss rec t1 7.627031, loss kl 0.170551, loss_trans 0.005147, loss flux 6.236833, loss flux t1 6.337750, binary loss 4.049809, binary loss t1 3.681153\n",
      "Epoch 5/10, Batch 981/1650, Loss 35.577435, Loss rec 10.593256, loss rec t1 10.636120, loss kl 0.178088, loss_trans 0.017996, loss flux 7.750185, loss flux t1 6.401790, binary loss 0.435826, binary loss t1 0.481072\n",
      "Epoch 5/10, Batch 991/1650, Loss 28.332384, Loss rec 6.842036, loss rec t1 7.859041, loss kl 0.176363, loss_trans 0.014750, loss flux 7.081248, loss flux t1 6.358948, binary loss 1.255560, binary loss t1 1.258979\n",
      "Epoch 5/10, Batch 1001/1650, Loss 25.554556, Loss rec 5.862366, loss rec t1 6.741013, loss kl 0.149131, loss_trans 0.006269, loss flux 6.468893, loss flux t1 6.326885, binary loss 4.252434, binary loss t1 3.497422\n",
      "Epoch 5/10, Batch 1011/1650, Loss 27.608521, Loss rec 7.102564, loss rec t1 7.821855, loss kl 0.158747, loss_trans 0.006345, loss flux 6.446705, loss flux t1 6.072306, binary loss 0.775197, binary loss t1 0.786365\n",
      "Epoch 5/10, Batch 1021/1650, Loss 35.077892, Loss rec 10.751205, loss rec t1 9.166779, loss kl 0.367557, loss_trans 0.010103, loss flux 7.627226, loss flux t1 7.155022, binary loss 2.371466, binary loss t1 1.995074\n",
      "Epoch 5/10, Batch 1031/1650, Loss 32.070301, Loss rec 8.682090, loss rec t1 10.806370, loss kl 0.188044, loss_trans 0.008352, loss flux 5.951119, loss flux t1 6.434327, binary loss 2.797740, binary loss t1 2.920727\n",
      "Epoch 5/10, Batch 1041/1650, Loss 27.696453, Loss rec 7.237508, loss rec t1 7.726611, loss kl 0.192518, loss_trans 0.012074, loss flux 6.175463, loss flux t1 6.352279, binary loss 2.405945, binary loss t1 2.275233\n",
      "Epoch 5/10, Batch 1051/1650, Loss 30.143059, Loss rec 7.434901, loss rec t1 8.622129, loss kl 0.284927, loss_trans 0.010618, loss flux 7.243933, loss flux t1 6.546551, binary loss 1.256753, binary loss t1 1.434122\n",
      "Epoch 5/10, Batch 1061/1650, Loss 24.826967, Loss rec 5.195707, loss rec t1 6.675950, loss kl 0.153780, loss_trans 0.009183, loss flux 6.510299, loss flux t1 6.282047, binary loss 1.096234, binary loss t1 1.046341\n",
      "Epoch 5/10, Batch 1071/1650, Loss 38.309608, Loss rec 10.425678, loss rec t1 12.749131, loss kl 0.410914, loss_trans 0.008222, loss flux 7.458677, loss flux t1 7.256989, binary loss 0.674840, binary loss t1 0.893136\n",
      "Epoch 5/10, Batch 1081/1650, Loss 32.800453, Loss rec 8.479139, loss rec t1 8.794737, loss kl 0.197072, loss_trans 0.012469, loss flux 8.617023, loss flux t1 6.700013, binary loss 1.862232, binary loss t1 1.640823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Batch 1091/1650, Loss 30.922304, Loss rec 7.695865, loss rec t1 7.843238, loss kl 0.286196, loss_trans 0.010366, loss flux 7.963824, loss flux t1 7.122817, binary loss 1.692954, binary loss t1 1.416152\n",
      "Epoch 5/10, Batch 1101/1650, Loss 30.294514, Loss rec 8.264591, loss rec t1 8.029938, loss kl 0.203443, loss_trans 0.009530, loss flux 7.406698, loss flux t1 6.380312, binary loss 1.188100, binary loss t1 1.156006\n",
      "Epoch 5/10, Batch 1111/1650, Loss 32.300602, Loss rec 9.274539, loss rec t1 10.401267, loss kl 0.216557, loss_trans 0.016314, loss flux 6.237295, loss flux t1 6.154627, binary loss 0.500597, binary loss t1 0.575844\n",
      "Epoch 5/10, Batch 1121/1650, Loss 31.007975, Loss rec 8.341952, loss rec t1 9.901325, loss kl 0.200397, loss_trans 0.011004, loss flux 6.688470, loss flux t1 5.864825, binary loss 2.116892, binary loss t1 1.878802\n",
      "Epoch 5/10, Batch 1131/1650, Loss 29.926306, Loss rec 7.886957, loss rec t1 8.873115, loss kl 0.181535, loss_trans 0.005163, loss flux 6.923580, loss flux t1 6.055955, binary loss 2.284005, binary loss t1 2.183270\n",
      "Epoch 5/10, Batch 1141/1650, Loss 22.953650, Loss rec 4.241490, loss rec t1 6.125513, loss kl 0.202947, loss_trans 0.014696, loss flux 6.656618, loss flux t1 5.712385, binary loss 2.075941, binary loss t1 1.719537\n",
      "Epoch 5/10, Batch 1151/1650, Loss 31.395433, Loss rec 7.708578, loss rec t1 9.699250, loss kl 0.208993, loss_trans 0.011178, loss flux 6.461490, loss flux t1 7.305942, binary loss 3.259393, binary loss t1 3.112294\n",
      "Epoch 5/10, Batch 1161/1650, Loss 26.358580, Loss rec 6.724526, loss rec t1 7.500289, loss kl 0.200426, loss_trans 0.010542, loss flux 6.319551, loss flux t1 5.603244, binary loss 1.158355, binary loss t1 0.982483\n",
      "Epoch 5/10, Batch 1171/1650, Loss 18.944742, Loss rec 3.701129, loss rec t1 4.759914, loss kl 0.126367, loss_trans 0.007208, loss flux 5.232940, loss flux t1 5.117184, binary loss 3.114362, binary loss t1 2.807643\n",
      "Epoch 5/10, Batch 1181/1650, Loss 27.243393, Loss rec 6.640402, loss rec t1 7.556881, loss kl 0.187079, loss_trans 0.008680, loss flux 6.942484, loss flux t1 5.907867, binary loss 2.380457, binary loss t1 2.143719\n",
      "Epoch 5/10, Batch 1191/1650, Loss 25.826132, Loss rec 6.404983, loss rec t1 7.013077, loss kl 0.169799, loss_trans 0.009274, loss flux 6.365093, loss flux t1 5.863904, binary loss 1.508018, binary loss t1 1.524637\n",
      "Epoch 5/10, Batch 1201/1650, Loss 30.976839, Loss rec 8.435124, loss rec t1 8.024589, loss kl 0.303521, loss_trans 0.011792, loss flux 7.578475, loss flux t1 6.623339, binary loss 1.096161, binary loss t1 0.906931\n",
      "Epoch 5/10, Batch 1211/1650, Loss 25.699083, Loss rec 6.686505, loss rec t1 6.416466, loss kl 0.255453, loss_trans 0.006218, loss flux 6.521652, loss flux t1 5.812788, binary loss 1.224586, binary loss t1 1.138207\n",
      "Epoch 5/10, Batch 1221/1650, Loss 22.304537, Loss rec 5.025391, loss rec t1 6.094909, loss kl 0.120255, loss_trans 0.007667, loss flux 5.693834, loss flux t1 5.362478, binary loss 1.699499, binary loss t1 1.608777\n",
      "Epoch 5/10, Batch 1231/1650, Loss 25.724630, Loss rec 5.829781, loss rec t1 8.077024, loss kl 0.172713, loss_trans 0.008108, loss flux 5.914633, loss flux t1 5.722373, binary loss 0.661116, binary loss t1 0.738760\n",
      "Epoch 5/10, Batch 1241/1650, Loss 27.227114, Loss rec 6.701233, loss rec t1 7.762214, loss kl 0.169431, loss_trans 0.015099, loss flux 6.385787, loss flux t1 6.193349, binary loss 2.734635, binary loss t1 2.534297\n",
      "Epoch 5/10, Batch 1251/1650, Loss 26.386520, Loss rec 6.636623, loss rec t1 7.636304, loss kl 0.199116, loss_trans 0.007822, loss flux 6.099329, loss flux t1 5.807325, binary loss 1.934475, binary loss t1 1.656554\n",
      "Epoch 5/10, Batch 1261/1650, Loss 23.489414, Loss rec 5.631760, loss rec t1 6.511755, loss kl 0.146876, loss_trans 0.006057, loss flux 5.713958, loss flux t1 5.479007, binary loss 0.922357, binary loss t1 0.950010\n",
      "Epoch 5/10, Batch 1271/1650, Loss 26.090429, Loss rec 5.692327, loss rec t1 7.727600, loss kl 0.158913, loss_trans 0.008801, loss flux 6.304440, loss flux t1 6.198348, binary loss 0.958879, binary loss t1 1.065333\n",
      "Epoch 5/10, Batch 1281/1650, Loss 26.820221, Loss rec 6.373652, loss rec t1 8.053869, loss kl 0.164477, loss_trans 0.008230, loss flux 6.423926, loss flux t1 5.796069, binary loss 1.579276, binary loss t1 1.693174\n",
      "Epoch 5/10, Batch 1291/1650, Loss 30.081423, Loss rec 9.013277, loss rec t1 9.540789, loss kl 0.222548, loss_trans 0.006885, loss flux 5.812473, loss flux t1 5.485451, binary loss 2.709184, binary loss t1 2.481082\n",
      "Epoch 5/10, Batch 1301/1650, Loss 31.187202, Loss rec 9.229050, loss rec t1 9.514805, loss kl 0.197553, loss_trans 0.006607, loss flux 6.471650, loss flux t1 5.767539, binary loss 2.139120, binary loss t1 1.976240\n",
      "Epoch 5/10, Batch 1311/1650, Loss 19.813763, Loss rec 4.280859, loss rec t1 4.563885, loss kl 0.324991, loss_trans 0.011097, loss flux 5.577723, loss flux t1 5.055207, binary loss 1.299869, binary loss t1 1.558848\n",
      "Epoch 5/10, Batch 1321/1650, Loss 25.635717, Loss rec 5.880349, loss rec t1 6.776565, loss kl 0.392666, loss_trans 0.009214, loss flux 6.683063, loss flux t1 5.893860, binary loss 1.097244, binary loss t1 0.998857\n",
      "Epoch 5/10, Batch 1331/1650, Loss 24.606628, Loss rec 5.853603, loss rec t1 7.649866, loss kl 0.154708, loss_trans 0.008422, loss flux 5.319195, loss flux t1 5.620835, binary loss 3.652356, binary loss t1 3.103266\n",
      "Epoch 5/10, Batch 1341/1650, Loss 29.789526, Loss rec 8.508180, loss rec t1 8.023795, loss kl 0.200626, loss_trans 0.006308, loss flux 7.115321, loss flux t1 5.935296, binary loss 1.520441, binary loss t1 1.314457\n",
      "Epoch 5/10, Batch 1351/1650, Loss 24.208883, Loss rec 6.327574, loss rec t1 6.625112, loss kl 0.194037, loss_trans 0.013705, loss flux 6.003732, loss flux t1 5.044722, binary loss 1.012558, binary loss t1 0.974684\n",
      "Epoch 5/10, Batch 1361/1650, Loss 29.593948, Loss rec 7.412855, loss rec t1 10.174495, loss kl 0.178999, loss_trans 0.007396, loss flux 5.823024, loss flux t1 5.997181, binary loss 3.429839, binary loss t1 3.419888\n",
      "Epoch 5/10, Batch 1371/1650, Loss 27.241594, Loss rec 6.929142, loss rec t1 8.178730, loss kl 0.153101, loss_trans 0.009465, loss flux 6.210777, loss flux t1 5.760380, binary loss 1.651006, binary loss t1 1.389936\n",
      "Epoch 5/10, Batch 1381/1650, Loss 28.342119, Loss rec 7.338192, loss rec t1 8.097844, loss kl 0.259334, loss_trans 0.007713, loss flux 6.518100, loss flux t1 6.120935, binary loss 1.804748, binary loss t1 1.617622\n",
      "Epoch 5/10, Batch 1391/1650, Loss 23.299974, Loss rec 5.474795, loss rec t1 5.902199, loss kl 0.179009, loss_trans 0.004606, loss flux 5.938492, loss flux t1 5.800872, binary loss 1.480231, binary loss t1 1.410519\n",
      "Epoch 5/10, Batch 1401/1650, Loss 25.880234, Loss rec 6.747341, loss rec t1 7.202655, loss kl 0.158755, loss_trans 0.007313, loss flux 6.210070, loss flux t1 5.554101, binary loss 2.135701, binary loss t1 2.049285\n",
      "Epoch 5/10, Batch 1411/1650, Loss 29.557730, Loss rec 8.090307, loss rec t1 8.404757, loss kl 0.128037, loss_trans 0.009274, loss flux 6.783607, loss flux t1 6.141749, binary loss 1.247774, binary loss t1 1.250062\n",
      "Epoch 5/10, Batch 1421/1650, Loss 28.088663, Loss rec 6.602295, loss rec t1 7.322558, loss kl 0.157494, loss_trans 0.006481, loss flux 7.342468, loss flux t1 6.657365, binary loss 2.322742, binary loss t1 2.026060\n",
      "Epoch 5/10, Batch 1431/1650, Loss 27.878586, Loss rec 8.384438, loss rec t1 7.648814, loss kl 0.503651, loss_trans 0.008868, loss flux 5.847154, loss flux t1 5.485661, binary loss 0.896881, binary loss t1 1.003139\n",
      "Epoch 5/10, Batch 1441/1650, Loss 35.911808, Loss rec 8.529909, loss rec t1 8.885704, loss kl 0.268555, loss_trans 0.008329, loss flux 9.401169, loss flux t1 8.818144, binary loss 1.050916, binary loss t1 0.930168\n",
      "Epoch 5/10, Batch 1451/1650, Loss 28.832445, Loss rec 7.711163, loss rec t1 7.901607, loss kl 0.179330, loss_trans 0.013572, loss flux 7.008081, loss flux t1 6.018694, binary loss 1.011060, binary loss t1 0.941202\n",
      "Epoch 5/10, Batch 1461/1650, Loss 25.786657, Loss rec 6.535238, loss rec t1 6.723737, loss kl 0.198916, loss_trans 0.007242, loss flux 6.616293, loss flux t1 5.705231, binary loss 2.188769, binary loss t1 1.701628\n",
      "Epoch 5/10, Batch 1471/1650, Loss 27.712711, Loss rec 6.833517, loss rec t1 6.717843, loss kl 0.210030, loss_trans 0.007396, loss flux 7.789840, loss flux t1 6.154085, binary loss 2.306184, binary loss t1 2.160021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10, Batch 1481/1650, Loss 32.665287, Loss rec 8.765015, loss rec t1 11.631454, loss kl 0.163730, loss_trans 0.007974, loss flux 6.163271, loss flux t1 5.933843, binary loss 0.848583, binary loss t1 0.879741\n",
      "Epoch 5/10, Batch 1491/1650, Loss 35.894016, Loss rec 11.596676, loss rec t1 10.345742, loss kl 0.213890, loss_trans 0.011847, loss flux 6.798960, loss flux t1 6.926902, binary loss 0.967761, binary loss t1 0.869179\n",
      "Epoch 5/10, Batch 1501/1650, Loss 33.800476, Loss rec 9.347090, loss rec t1 11.232605, loss kl 0.184511, loss_trans 0.015310, loss flux 6.466333, loss flux t1 6.554629, binary loss 0.393585, binary loss t1 0.478992\n",
      "Epoch 5/10, Batch 1511/1650, Loss 34.081276, Loss rec 10.274443, loss rec t1 11.317860, loss kl 0.180622, loss_trans 0.010039, loss flux 5.990743, loss flux t1 6.307567, binary loss 2.658195, binary loss t1 2.410203\n",
      "Epoch 5/10, Batch 1521/1650, Loss 40.052551, Loss rec 16.414694, loss rec t1 10.772027, loss kl 0.470893, loss_trans 0.007479, loss flux 6.763246, loss flux t1 5.624211, binary loss 11.293629, binary loss t1 8.715195\n",
      "Epoch 5/10, Batch 1531/1650, Loss 33.271267, Loss rec 8.635364, loss rec t1 11.012697, loss kl 0.306536, loss_trans 0.007219, loss flux 6.962649, loss flux t1 6.346806, binary loss 2.801099, binary loss t1 2.327243\n",
      "Epoch 5/10, Batch 1541/1650, Loss 28.815092, Loss rec 7.947354, loss rec t1 7.109083, loss kl 0.206095, loss_trans 0.011087, loss flux 6.938266, loss flux t1 6.603205, binary loss 0.949013, binary loss t1 0.844908\n",
      "Epoch 5/10, Batch 1551/1650, Loss 32.276279, Loss rec 10.310797, loss rec t1 8.234642, loss kl 0.367186, loss_trans 0.010297, loss flux 7.613918, loss flux t1 5.739439, binary loss 0.724184, binary loss t1 0.739720\n",
      "Epoch 5/10, Batch 1561/1650, Loss 29.007893, Loss rec 7.646681, loss rec t1 8.029720, loss kl 0.199157, loss_trans 0.006713, loss flux 7.357322, loss flux t1 5.768298, binary loss 1.058946, binary loss t1 0.952835\n",
      "Epoch 5/10, Batch 1571/1650, Loss 26.512888, Loss rec 6.325223, loss rec t1 6.457997, loss kl 0.357656, loss_trans 0.007098, loss flux 7.476084, loss flux t1 5.888830, binary loss 2.430156, binary loss t1 1.884374\n",
      "Epoch 5/10, Batch 1581/1650, Loss 30.748177, Loss rec 8.095709, loss rec t1 9.073528, loss kl 0.262108, loss_trans 0.010113, loss flux 6.858696, loss flux t1 6.448022, binary loss 3.210717, binary loss t1 2.874167\n",
      "Epoch 5/10, Batch 1591/1650, Loss 26.156488, Loss rec 5.518095, loss rec t1 6.896175, loss kl 0.236579, loss_trans 0.006189, loss flux 6.762531, loss flux t1 6.736920, binary loss 1.222347, binary loss t1 1.309723\n",
      "Epoch 5/10, Batch 1601/1650, Loss 37.317921, Loss rec 14.251944, loss rec t1 8.149120, loss kl 0.406845, loss_trans 0.006538, loss flux 8.380496, loss flux t1 6.122980, binary loss 1.914218, binary loss t1 1.303215\n",
      "Epoch 5/10, Batch 1611/1650, Loss 29.771336, Loss rec 8.670574, loss rec t1 7.480294, loss kl 0.168904, loss_trans 0.010992, loss flux 6.962412, loss flux t1 6.478161, binary loss 2.197736, binary loss t1 1.906761\n",
      "Epoch 5/10, Batch 1621/1650, Loss 34.054386, Loss rec 10.024029, loss rec t1 10.662262, loss kl 0.184170, loss_trans 0.006755, loss flux 6.711620, loss flux t1 6.465549, binary loss 1.413319, binary loss t1 1.295929\n",
      "Epoch 5/10, Batch 1631/1650, Loss 25.803131, Loss rec 6.461371, loss rec t1 6.419235, loss kl 0.250860, loss_trans 0.004619, loss flux 6.639921, loss flux t1 6.027123, binary loss 0.814967, binary loss t1 0.750901\n",
      "Epoch 5/10, Batch 1641/1650, Loss 55.304913, Loss rec 21.413761, loss rec t1 16.779333, loss kl 0.251217, loss_trans 0.008983, loss flux 8.508926, loss flux t1 8.342691, binary loss 2.188903, binary loss t1 2.065977\n",
      "Epoch 5/10, Train loss 29.068808, Eval loss 41.414085\n",
      "Epoch 6/10, Batch 1/1650, Loss 38.208927, Loss rec 10.054262, loss rec t1 9.803800, loss kl 0.207405, loss_trans 0.009374, loss flux 9.208290, loss flux t1 8.925796, binary loss 1.111722, binary loss t1 1.210364\n",
      "Epoch 6/10, Batch 11/1650, Loss 29.881025, Loss rec 8.137341, loss rec t1 8.408575, loss kl 0.152115, loss_trans 0.013345, loss flux 7.274846, loss flux t1 5.894801, binary loss 3.559469, binary loss t1 3.226350\n",
      "Epoch 6/10, Batch 21/1650, Loss 31.600498, Loss rec 10.491014, loss rec t1 7.504660, loss kl 0.228916, loss_trans 0.008305, loss flux 7.168747, loss flux t1 6.198856, binary loss 0.819445, binary loss t1 0.789650\n",
      "Epoch 6/10, Batch 31/1650, Loss 31.072412, Loss rec 9.442554, loss rec t1 8.976610, loss kl 0.159278, loss_trans 0.013075, loss flux 6.428187, loss flux t1 6.052710, binary loss 5.608693, binary loss t1 4.802814\n",
      "Epoch 6/10, Batch 41/1650, Loss 25.184551, Loss rec 6.791473, loss rec t1 6.622676, loss kl 0.176112, loss_trans 0.010834, loss flux 6.048726, loss flux t1 5.534730, binary loss 1.395264, binary loss t1 1.344386\n",
      "Epoch 6/10, Batch 51/1650, Loss 29.998739, Loss rec 8.323690, loss rec t1 8.351404, loss kl 0.221441, loss_trans 0.012595, loss flux 7.072360, loss flux t1 6.017249, binary loss 1.195837, binary loss t1 1.109520\n",
      "Epoch 6/10, Batch 61/1650, Loss 29.389055, Loss rec 7.038063, loss rec t1 7.648283, loss kl 0.193188, loss_trans 0.014788, loss flux 7.542593, loss flux t1 6.952142, binary loss 1.819104, binary loss t1 1.977701\n",
      "Epoch 6/10, Batch 71/1650, Loss 32.795044, Loss rec 10.739457, loss rec t1 7.794940, loss kl 0.193732, loss_trans 0.008109, loss flux 7.414065, loss flux t1 6.644737, binary loss 1.214927, binary loss t1 1.209245\n",
      "Epoch 6/10, Batch 81/1650, Loss 28.534559, Loss rec 7.794302, loss rec t1 6.671931, loss kl 0.177632, loss_trans 0.010523, loss flux 7.412486, loss flux t1 6.467687, binary loss 1.108412, binary loss t1 1.038762\n",
      "Epoch 6/10, Batch 91/1650, Loss 23.828299, Loss rec 5.875205, loss rec t1 6.250615, loss kl 0.245417, loss_trans 0.004888, loss flux 5.713231, loss flux t1 5.738942, binary loss 2.253018, binary loss t1 1.951945\n",
      "Epoch 6/10, Batch 101/1650, Loss 25.401009, Loss rec 5.951483, loss rec t1 7.859778, loss kl 0.159769, loss_trans 0.009445, loss flux 5.792972, loss flux t1 5.627561, binary loss 3.001583, binary loss t1 2.555332\n",
      "Epoch 6/10, Batch 111/1650, Loss 30.127310, Loss rec 8.488331, loss rec t1 8.366303, loss kl 0.224997, loss_trans 0.010832, loss flux 6.978205, loss flux t1 6.058644, binary loss 1.583424, binary loss t1 1.452626\n",
      "Epoch 6/10, Batch 121/1650, Loss 26.810720, Loss rec 6.890047, loss rec t1 7.871591, loss kl 0.234170, loss_trans 0.006041, loss flux 5.995443, loss flux t1 5.813428, binary loss 1.895665, binary loss t1 1.574616\n",
      "Epoch 6/10, Batch 131/1650, Loss 26.695080, Loss rec 7.507597, loss rec t1 7.848276, loss kl 0.214809, loss_trans 0.006657, loss flux 5.640582, loss flux t1 5.477160, binary loss 0.668926, binary loss t1 0.591673\n",
      "Epoch 6/10, Batch 141/1650, Loss 30.925110, Loss rec 9.289519, loss rec t1 7.967531, loss kl 0.293117, loss_trans 0.013633, loss flux 7.246500, loss flux t1 6.114809, binary loss 3.288129, binary loss t1 2.288421\n",
      "Epoch 6/10, Batch 151/1650, Loss 23.004137, Loss rec 5.342710, loss rec t1 6.675582, loss kl 0.148042, loss_trans 0.008290, loss flux 5.579768, loss flux t1 5.249743, binary loss 1.469342, binary loss t1 1.417394\n",
      "Epoch 6/10, Batch 161/1650, Loss 23.994202, Loss rec 5.529019, loss rec t1 6.129039, loss kl 0.223871, loss_trans 0.010717, loss flux 6.459040, loss flux t1 5.642515, binary loss 1.884411, binary loss t1 1.395154\n",
      "Epoch 6/10, Batch 171/1650, Loss 23.310530, Loss rec 5.954610, loss rec t1 6.470118, loss kl 0.160538, loss_trans 0.011079, loss flux 5.632893, loss flux t1 5.081290, binary loss 2.359410, binary loss t1 2.185533\n",
      "Epoch 6/10, Batch 181/1650, Loss 21.039633, Loss rec 5.140553, loss rec t1 5.423234, loss kl 0.192974, loss_trans 0.004770, loss flux 5.267817, loss flux t1 5.010285, binary loss 1.339664, binary loss t1 1.325394\n",
      "Epoch 6/10, Batch 191/1650, Loss 25.862225, Loss rec 7.041328, loss rec t1 7.201502, loss kl 0.219921, loss_trans 0.008083, loss flux 6.127049, loss flux t1 5.264342, binary loss 1.985158, binary loss t1 1.667369\n",
      "Epoch 6/10, Batch 201/1650, Loss 19.057932, Loss rec 4.494314, loss rec t1 4.478721, loss kl 0.169700, loss_trans 0.014239, loss flux 5.317877, loss flux t1 4.583082, binary loss 3.153062, binary loss t1 2.588448\n",
      "Epoch 6/10, Batch 211/1650, Loss 33.945358, Loss rec 10.126261, loss rec t1 11.827003, loss kl 0.154348, loss_trans 0.016190, loss flux 5.924124, loss flux t1 5.897436, binary loss 0.698224, binary loss t1 0.661445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Batch 221/1650, Loss 45.446526, Loss rec 14.881907, loss rec t1 15.053687, loss kl 0.248826, loss_trans 0.007673, loss flux 7.833829, loss flux t1 7.420603, binary loss 5.600943, binary loss t1 4.757313\n",
      "Epoch 6/10, Batch 231/1650, Loss 32.372952, Loss rec 9.416675, loss rec t1 10.002851, loss kl 0.138625, loss_trans 0.014854, loss flux 7.175573, loss flux t1 5.624375, binary loss 0.589788, binary loss t1 0.555285\n",
      "Epoch 6/10, Batch 241/1650, Loss 34.875034, Loss rec 10.402885, loss rec t1 10.172603, loss kl 0.313102, loss_trans 0.008304, loss flux 7.308859, loss flux t1 6.669278, binary loss 10.836417, binary loss t1 8.234696\n",
      "Epoch 6/10, Batch 251/1650, Loss 20.682598, Loss rec 4.660569, loss rec t1 5.275162, loss kl 0.141886, loss_trans 0.009830, loss flux 5.522234, loss flux t1 5.072916, binary loss 1.670751, binary loss t1 1.623096\n",
      "Epoch 6/10, Batch 261/1650, Loss 24.870794, Loss rec 5.190581, loss rec t1 6.537653, loss kl 0.331221, loss_trans 0.008836, loss flux 6.949015, loss flux t1 5.853485, binary loss 2.765585, binary loss t1 1.523432\n",
      "Epoch 6/10, Batch 271/1650, Loss 20.796432, Loss rec 4.288311, loss rec t1 6.090536, loss kl 0.133223, loss_trans 0.010442, loss flux 5.176414, loss flux t1 5.097504, binary loss 2.459998, binary loss t1 2.375858\n",
      "Epoch 6/10, Batch 281/1650, Loss 24.332321, Loss rec 6.174182, loss rec t1 6.110602, loss kl 0.210979, loss_trans 0.011234, loss flux 6.405692, loss flux t1 5.419631, binary loss 0.988796, binary loss t1 0.935752\n",
      "Epoch 6/10, Batch 291/1650, Loss 28.286314, Loss rec 7.398363, loss rec t1 7.999464, loss kl 0.198137, loss_trans 0.011931, loss flux 6.567234, loss flux t1 6.111185, binary loss 1.745062, binary loss t1 1.840261\n",
      "Epoch 6/10, Batch 301/1650, Loss 27.228601, Loss rec 6.546413, loss rec t1 7.261210, loss kl 0.216972, loss_trans 0.005529, loss flux 6.657404, loss flux t1 6.541073, binary loss 0.754271, binary loss t1 0.810746\n",
      "Epoch 6/10, Batch 311/1650, Loss 29.705523, Loss rec 7.669722, loss rec t1 8.115383, loss kl 0.220427, loss_trans 0.014301, loss flux 6.703516, loss flux t1 6.982174, binary loss 1.117123, binary loss t1 1.059773\n",
      "Epoch 6/10, Batch 321/1650, Loss 20.299053, Loss rec 4.452572, loss rec t1 4.763194, loss kl 0.183782, loss_trans 0.008428, loss flux 6.009865, loss flux t1 4.881212, binary loss 2.306147, binary loss t1 2.054796\n",
      "Epoch 6/10, Batch 331/1650, Loss 27.808649, Loss rec 7.098459, loss rec t1 8.366619, loss kl 0.217382, loss_trans 0.012400, loss flux 5.860029, loss flux t1 6.253758, binary loss 2.386990, binary loss t1 2.145628\n",
      "Epoch 6/10, Batch 341/1650, Loss 27.916891, Loss rec 6.833918, loss rec t1 7.767784, loss kl 0.166951, loss_trans 0.009679, loss flux 6.695653, loss flux t1 6.442904, binary loss 3.784297, binary loss t1 3.096806\n",
      "Epoch 6/10, Batch 351/1650, Loss 25.470936, Loss rec 6.636238, loss rec t1 7.293534, loss kl 0.192618, loss_trans 0.013734, loss flux 5.583943, loss flux t1 5.750870, binary loss 0.974635, binary loss t1 0.924693\n",
      "Epoch 6/10, Batch 361/1650, Loss 22.847046, Loss rec 5.221080, loss rec t1 5.672786, loss kl 0.303503, loss_trans 0.007006, loss flux 6.209757, loss flux t1 5.432915, binary loss 3.138706, binary loss t1 2.305064\n",
      "Epoch 6/10, Batch 371/1650, Loss 25.443016, Loss rec 6.530138, loss rec t1 6.578642, loss kl 0.208555, loss_trans 0.012938, loss flux 6.301497, loss flux t1 5.811246, binary loss 2.615165, binary loss t1 1.986314\n",
      "Epoch 6/10, Batch 381/1650, Loss 32.527679, Loss rec 8.106266, loss rec t1 10.324101, loss kl 0.301809, loss_trans 0.014789, loss flux 6.996947, loss flux t1 6.783767, binary loss 0.578131, binary loss t1 0.626795\n",
      "Epoch 6/10, Batch 391/1650, Loss 24.121933, Loss rec 5.860633, loss rec t1 6.739413, loss kl 0.267246, loss_trans 0.008390, loss flux 5.534729, loss flux t1 5.711521, binary loss 1.362002, binary loss t1 1.302120\n",
      "Epoch 6/10, Batch 401/1650, Loss 22.682871, Loss rec 4.824345, loss rec t1 5.573417, loss kl 0.361633, loss_trans 0.007150, loss flux 5.982313, loss flux t1 5.934012, binary loss 1.910945, binary loss t1 1.569955\n",
      "Epoch 6/10, Batch 411/1650, Loss 29.911180, Loss rec 7.977866, loss rec t1 8.141371, loss kl 0.233959, loss_trans 0.005690, loss flux 7.117656, loss flux t1 6.434638, binary loss 0.809871, binary loss t1 0.631529\n",
      "Epoch 6/10, Batch 421/1650, Loss 27.559393, Loss rec 6.200620, loss rec t1 8.883780, loss kl 0.162116, loss_trans 0.011827, loss flux 5.942800, loss flux t1 6.358251, binary loss 2.001765, binary loss t1 1.985317\n",
      "Epoch 6/10, Batch 431/1650, Loss 22.575720, Loss rec 5.419092, loss rec t1 5.988649, loss kl 0.168724, loss_trans 0.007720, loss flux 5.856919, loss flux t1 5.134617, binary loss 1.089579, binary loss t1 0.968941\n",
      "Epoch 6/10, Batch 441/1650, Loss 25.952538, Loss rec 6.625124, loss rec t1 7.724852, loss kl 0.234703, loss_trans 0.008215, loss flux 6.020943, loss flux t1 5.338702, binary loss 0.622550, binary loss t1 0.588388\n",
      "Epoch 6/10, Batch 451/1650, Loss 27.990955, Loss rec 8.023527, loss rec t1 6.134188, loss kl 0.316023, loss_trans 0.010497, loss flux 7.824598, loss flux t1 5.682120, binary loss 0.994234, binary loss t1 1.181360\n",
      "Epoch 6/10, Batch 461/1650, Loss 42.527008, Loss rec 13.627982, loss rec t1 13.889750, loss kl 0.263585, loss_trans 0.009856, loss flux 7.834587, loss flux t1 6.901247, binary loss 3.951337, binary loss t1 3.302558\n",
      "Epoch 6/10, Batch 471/1650, Loss 23.554167, Loss rec 6.215016, loss rec t1 6.127395, loss kl 0.171009, loss_trans 0.007589, loss flux 5.859876, loss flux t1 5.173280, binary loss 1.296450, binary loss t1 1.232299\n",
      "Epoch 6/10, Batch 481/1650, Loss 28.047810, Loss rec 7.718994, loss rec t1 7.564666, loss kl 0.194090, loss_trans 0.006839, loss flux 6.875801, loss flux t1 5.687419, binary loss 1.184754, binary loss t1 1.076331\n",
      "Epoch 6/10, Batch 491/1650, Loss 22.958902, Loss rec 5.790249, loss rec t1 5.732682, loss kl 0.182464, loss_trans 0.006687, loss flux 5.904475, loss flux t1 5.342344, binary loss 1.485766, binary loss t1 1.344093\n",
      "Epoch 6/10, Batch 501/1650, Loss 22.884630, Loss rec 5.905620, loss rec t1 5.406954, loss kl 0.210264, loss_trans 0.014468, loss flux 6.196074, loss flux t1 5.151251, binary loss 1.490243, binary loss t1 1.225632\n",
      "Epoch 6/10, Batch 511/1650, Loss 23.308987, Loss rec 5.306114, loss rec t1 6.091512, loss kl 0.343379, loss_trans 0.005162, loss flux 6.199088, loss flux t1 5.363731, binary loss 0.799358, binary loss t1 0.975413\n",
      "Epoch 6/10, Batch 521/1650, Loss 23.455584, Loss rec 5.257520, loss rec t1 6.705498, loss kl 0.143579, loss_trans 0.005831, loss flux 6.267791, loss flux t1 5.075366, binary loss 1.523383, binary loss t1 1.420422\n",
      "Epoch 6/10, Batch 531/1650, Loss 26.172161, Loss rec 7.024930, loss rec t1 7.617293, loss kl 0.210837, loss_trans 0.006725, loss flux 5.751569, loss flux t1 5.560807, binary loss 1.762861, binary loss t1 1.621248\n",
      "Epoch 6/10, Batch 541/1650, Loss 20.673214, Loss rec 3.743502, loss rec t1 5.423286, loss kl 0.350858, loss_trans 0.010519, loss flux 5.471871, loss flux t1 5.673178, binary loss 1.267666, binary loss t1 1.310879\n",
      "Epoch 6/10, Batch 551/1650, Loss 25.978592, Loss rec 7.792844, loss rec t1 5.661883, loss kl 0.353603, loss_trans 0.007149, loss flux 6.162088, loss flux t1 6.001025, binary loss 0.716374, binary loss t1 0.820466\n",
      "Epoch 6/10, Batch 561/1650, Loss 23.015137, Loss rec 4.943978, loss rec t1 6.634496, loss kl 0.188927, loss_trans 0.013634, loss flux 5.646878, loss flux t1 5.587223, binary loss 1.119362, binary loss t1 1.137197\n",
      "Epoch 6/10, Batch 571/1650, Loss 24.673979, Loss rec 5.850789, loss rec t1 6.788880, loss kl 0.134795, loss_trans 0.006072, loss flux 5.375149, loss flux t1 6.518293, binary loss 0.754064, binary loss t1 1.067340\n",
      "Epoch 6/10, Batch 581/1650, Loss 29.415003, Loss rec 6.999348, loss rec t1 8.112925, loss kl 0.312128, loss_trans 0.015131, loss flux 7.932274, loss flux t1 6.043198, binary loss 5.036329, binary loss t1 3.928051\n",
      "Epoch 6/10, Batch 591/1650, Loss 29.881308, Loss rec 8.002600, loss rec t1 9.026283, loss kl 0.171492, loss_trans 0.008246, loss flux 6.887809, loss flux t1 5.784877, binary loss 1.281134, binary loss t1 1.075480\n",
      "Epoch 6/10, Batch 601/1650, Loss 31.085466, Loss rec 7.323342, loss rec t1 10.529485, loss kl 0.158483, loss_trans 0.013222, loss flux 7.039204, loss flux t1 6.021731, binary loss 2.823241, binary loss t1 2.399364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Batch 611/1650, Loss 31.065035, Loss rec 8.892273, loss rec t1 7.617850, loss kl 0.332732, loss_trans 0.008758, loss flux 7.982454, loss flux t1 6.230966, binary loss 3.034625, binary loss t1 2.094762\n",
      "Epoch 6/10, Batch 621/1650, Loss 27.554331, Loss rec 6.832603, loss rec t1 7.456820, loss kl 0.209343, loss_trans 0.007008, loss flux 7.043294, loss flux t1 6.005262, binary loss 0.794164, binary loss t1 0.739940\n",
      "Epoch 6/10, Batch 631/1650, Loss 28.159052, Loss rec 6.767093, loss rec t1 8.938294, loss kl 0.203765, loss_trans 0.012554, loss flux 6.555167, loss flux t1 5.682179, binary loss 0.947906, binary loss t1 0.730986\n",
      "Epoch 6/10, Batch 641/1650, Loss 36.541561, Loss rec 10.732088, loss rec t1 12.433113, loss kl 0.200856, loss_trans 0.015465, loss flux 6.774176, loss flux t1 6.385866, binary loss 5.109447, binary loss t1 4.223661\n",
      "Epoch 6/10, Batch 651/1650, Loss 29.895123, Loss rec 7.664525, loss rec t1 8.360659, loss kl 0.169998, loss_trans 0.008867, loss flux 7.148702, loss flux t1 6.542371, binary loss 1.291134, binary loss t1 1.308751\n",
      "Epoch 6/10, Batch 661/1650, Loss 22.869827, Loss rec 4.748958, loss rec t1 6.606146, loss kl 0.144151, loss_trans 0.008552, loss flux 5.352339, loss flux t1 6.009681, binary loss 2.301694, binary loss t1 2.219756\n",
      "Epoch 6/10, Batch 671/1650, Loss 30.944479, Loss rec 8.063334, loss rec t1 8.861389, loss kl 0.211860, loss_trans 0.012026, loss flux 7.505129, loss flux t1 6.290740, binary loss 1.128511, binary loss t1 0.950328\n",
      "Epoch 6/10, Batch 681/1650, Loss 21.827759, Loss rec 4.664823, loss rec t1 6.881925, loss kl 0.142098, loss_trans 0.014184, loss flux 5.039174, loss flux t1 5.085555, binary loss 2.044930, binary loss t1 2.204439\n",
      "Epoch 6/10, Batch 691/1650, Loss 33.519585, Loss rec 10.096807, loss rec t1 11.916114, loss kl 0.213061, loss_trans 0.012007, loss flux 5.850197, loss flux t1 5.431397, binary loss 2.744562, binary loss t1 2.406882\n",
      "Epoch 6/10, Batch 701/1650, Loss 25.272915, Loss rec 6.845257, loss rec t1 7.637044, loss kl 0.162850, loss_trans 0.011165, loss flux 5.353455, loss flux t1 5.263144, binary loss 3.262702, binary loss t1 2.868620\n",
      "Epoch 6/10, Batch 711/1650, Loss 25.252563, Loss rec 5.499679, loss rec t1 7.150176, loss kl 0.316238, loss_trans 0.007198, loss flux 6.369623, loss flux t1 5.909648, binary loss 3.703503, binary loss t1 3.175399\n",
      "Epoch 6/10, Batch 721/1650, Loss 25.511961, Loss rec 6.410737, loss rec t1 7.908779, loss kl 0.176578, loss_trans 0.010955, loss flux 5.690981, loss flux t1 5.313930, binary loss 0.611564, binary loss t1 0.585238\n",
      "Epoch 6/10, Batch 731/1650, Loss 27.003216, Loss rec 7.779460, loss rec t1 7.879693, loss kl 0.223315, loss_trans 0.011974, loss flux 5.719638, loss flux t1 5.389135, binary loss 0.700011, binary loss t1 0.753238\n",
      "Epoch 6/10, Batch 741/1650, Loss 28.812757, Loss rec 7.442378, loss rec t1 8.962752, loss kl 0.182552, loss_trans 0.011976, loss flux 6.139845, loss flux t1 6.073254, binary loss 0.581599, binary loss t1 0.577305\n",
      "Epoch 6/10, Batch 751/1650, Loss 23.993345, Loss rec 5.721936, loss rec t1 6.993622, loss kl 0.159563, loss_trans 0.005718, loss flux 5.660230, loss flux t1 5.452276, binary loss 0.943343, binary loss t1 0.849422\n",
      "Epoch 6/10, Batch 761/1650, Loss 20.306503, Loss rec 4.218399, loss rec t1 5.472874, loss kl 0.139541, loss_trans 0.006408, loss flux 5.560277, loss flux t1 4.909004, binary loss 1.391747, binary loss t1 1.339615\n",
      "Epoch 6/10, Batch 771/1650, Loss 25.676178, Loss rec 6.642586, loss rec t1 7.034039, loss kl 0.264903, loss_trans 0.010314, loss flux 6.203843, loss flux t1 5.520494, binary loss 2.065965, binary loss t1 1.865590\n",
      "Epoch 6/10, Batch 781/1650, Loss 27.677528, Loss rec 7.918390, loss rec t1 8.214287, loss kl 0.222292, loss_trans 0.005949, loss flux 6.014630, loss flux t1 5.301980, binary loss 0.955948, binary loss t1 0.857477\n",
      "Epoch 6/10, Batch 791/1650, Loss 21.995497, Loss rec 5.707522, loss rec t1 5.892964, loss kl 0.183715, loss_trans 0.010222, loss flux 5.141079, loss flux t1 5.059993, binary loss 1.226971, binary loss t1 1.037655\n",
      "Epoch 6/10, Batch 801/1650, Loss 20.405312, Loss rec 4.525530, loss rec t1 5.680669, loss kl 0.166569, loss_trans 0.010294, loss flux 4.940361, loss flux t1 5.081888, binary loss 2.093667, binary loss t1 1.856794\n",
      "Epoch 6/10, Batch 811/1650, Loss 21.610937, Loss rec 4.381220, loss rec t1 6.172277, loss kl 0.314301, loss_trans 0.007505, loss flux 5.574797, loss flux t1 5.160836, binary loss 1.398512, binary loss t1 1.083278\n",
      "Epoch 6/10, Batch 821/1650, Loss 38.070580, Loss rec 12.850920, loss rec t1 13.228949, loss kl 0.190186, loss_trans 0.005251, loss flux 6.340189, loss flux t1 5.455086, binary loss 0.338681, binary loss t1 0.419500\n",
      "Epoch 6/10, Batch 831/1650, Loss 35.162563, Loss rec 11.941062, loss rec t1 10.783327, loss kl 0.138154, loss_trans 0.009493, loss flux 6.342212, loss flux t1 5.948317, binary loss 0.961814, binary loss t1 1.116845\n",
      "Epoch 6/10, Batch 841/1650, Loss 25.260366, Loss rec 5.619170, loss rec t1 7.364328, loss kl 0.168298, loss_trans 0.007982, loss flux 6.178676, loss flux t1 5.921913, binary loss 1.593436, binary loss t1 1.564786\n",
      "Epoch 6/10, Batch 851/1650, Loss 26.098425, Loss rec 5.200255, loss rec t1 6.415819, loss kl 0.149943, loss_trans 0.012861, loss flux 7.518824, loss flux t1 6.800721, binary loss 3.734307, binary loss t1 2.662709\n",
      "Epoch 6/10, Batch 861/1650, Loss 36.477535, Loss rec 11.761698, loss rec t1 9.302841, loss kl 0.349235, loss_trans 0.008972, loss flux 8.573048, loss flux t1 6.481741, binary loss 1.044981, binary loss t1 1.094035\n",
      "Epoch 6/10, Batch 871/1650, Loss 29.521240, Loss rec 6.789619, loss rec t1 9.124228, loss kl 0.207846, loss_trans 0.006406, loss flux 7.087843, loss flux t1 6.305299, binary loss 2.936080, binary loss t1 2.425727\n",
      "Epoch 6/10, Batch 881/1650, Loss 23.877697, Loss rec 5.194340, loss rec t1 6.708065, loss kl 0.136445, loss_trans 0.011863, loss flux 5.721171, loss flux t1 6.105812, binary loss 1.458174, binary loss t1 1.541183\n",
      "Epoch 6/10, Batch 891/1650, Loss 26.612053, Loss rec 7.352581, loss rec t1 6.741094, loss kl 0.182120, loss_trans 0.005636, loss flux 6.780986, loss flux t1 5.549635, binary loss 1.571050, binary loss t1 1.408342\n",
      "Epoch 6/10, Batch 901/1650, Loss 21.622913, Loss rec 4.841916, loss rec t1 5.847075, loss kl 0.133149, loss_trans 0.005375, loss flux 5.498500, loss flux t1 5.296899, binary loss 2.034905, binary loss t1 2.027216\n",
      "Epoch 6/10, Batch 911/1650, Loss 24.434334, Loss rec 6.389583, loss rec t1 6.903259, loss kl 0.187437, loss_trans 0.006233, loss flux 5.531440, loss flux t1 5.416381, binary loss 0.594835, binary loss t1 0.598181\n",
      "Epoch 6/10, Batch 921/1650, Loss 33.031437, Loss rec 9.723093, loss rec t1 11.009850, loss kl 0.225054, loss_trans 0.006024, loss flux 6.366202, loss flux t1 5.701212, binary loss 2.614644, binary loss t1 2.357550\n",
      "Epoch 6/10, Batch 931/1650, Loss 28.417206, Loss rec 7.322530, loss rec t1 7.884866, loss kl 0.227602, loss_trans 0.013340, loss flux 7.065047, loss flux t1 5.903823, binary loss 2.870834, binary loss t1 2.469051\n",
      "Epoch 6/10, Batch 941/1650, Loss 21.556095, Loss rec 4.061234, loss rec t1 6.239826, loss kl 0.168321, loss_trans 0.017523, loss flux 5.463729, loss flux t1 5.605463, binary loss 2.401395, binary loss t1 2.242191\n",
      "Epoch 6/10, Batch 951/1650, Loss 18.892336, Loss rec 4.256905, loss rec t1 4.868681, loss kl 0.138802, loss_trans 0.005703, loss flux 4.901108, loss flux t1 4.721137, binary loss 0.950035, binary loss t1 0.904668\n",
      "Epoch 6/10, Batch 961/1650, Loss 21.720747, Loss rec 5.231468, loss rec t1 6.371172, loss kl 0.200412, loss_trans 0.007082, loss flux 4.927740, loss flux t1 4.982874, binary loss 0.875993, binary loss t1 0.870506\n",
      "Epoch 6/10, Batch 971/1650, Loss 19.335148, Loss rec 4.350087, loss rec t1 5.563374, loss kl 0.154080, loss_trans 0.004666, loss flux 4.597538, loss flux t1 4.665402, binary loss 2.722408, binary loss t1 2.653779\n",
      "Epoch 6/10, Batch 981/1650, Loss 23.153355, Loss rec 6.265467, loss rec t1 5.181914, loss kl 0.159880, loss_trans 0.015133, loss flux 6.485493, loss flux t1 5.045467, binary loss 0.619228, binary loss t1 0.700984\n",
      "Epoch 6/10, Batch 991/1650, Loss 22.880243, Loss rec 5.533457, loss rec t1 5.697656, loss kl 0.155578, loss_trans 0.012546, loss flux 5.940863, loss flux t1 5.540142, binary loss 1.627537, binary loss t1 1.662977\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Batch 1001/1650, Loss 20.159649, Loss rec 4.375042, loss rec t1 4.955086, loss kl 0.137468, loss_trans 0.006085, loss flux 5.488017, loss flux t1 5.197951, binary loss 1.485754, binary loss t1 1.373985\n",
      "Epoch 6/10, Batch 1011/1650, Loss 22.747349, Loss rec 5.853632, loss rec t1 6.165932, loss kl 0.141634, loss_trans 0.005623, loss flux 5.503084, loss flux t1 5.077445, binary loss 1.672868, binary loss t1 1.507957\n",
      "Epoch 6/10, Batch 1021/1650, Loss 25.064028, Loss rec 6.388512, loss rec t1 6.400167, loss kl 0.321707, loss_trans 0.009736, loss flux 6.069588, loss flux t1 5.874318, binary loss 1.098363, binary loss t1 0.975535\n",
      "Epoch 6/10, Batch 1031/1650, Loss 21.303135, Loss rec 5.230841, loss rec t1 5.978901, loss kl 0.161816, loss_trans 0.006743, loss flux 4.931719, loss flux t1 4.993116, binary loss 1.665167, binary loss t1 1.908853\n",
      "Epoch 6/10, Batch 1041/1650, Loss 22.346443, Loss rec 5.310509, loss rec t1 6.671353, loss kl 0.162913, loss_trans 0.010475, loss flux 5.142144, loss flux t1 5.049050, binary loss 2.940497, binary loss t1 2.758931\n",
      "Epoch 6/10, Batch 1051/1650, Loss 24.007662, Loss rec 5.393122, loss rec t1 6.412716, loss kl 0.255864, loss_trans 0.009427, loss flux 6.536599, loss flux t1 5.399936, binary loss 1.691713, binary loss t1 1.679657\n",
      "Epoch 6/10, Batch 1061/1650, Loss 19.060177, Loss rec 4.100319, loss rec t1 4.608260, loss kl 0.134706, loss_trans 0.007773, loss flux 5.064407, loss flux t1 5.144713, binary loss 1.675204, binary loss t1 1.775902\n",
      "Epoch 6/10, Batch 1071/1650, Loss 25.034521, Loss rec 5.976236, loss rec t1 7.343916, loss kl 0.359333, loss_trans 0.007069, loss flux 5.659760, loss flux t1 5.688208, binary loss 1.040952, binary loss t1 1.099726\n",
      "Epoch 6/10, Batch 1081/1650, Loss 26.474371, Loss rec 5.654107, loss rec t1 7.482691, loss kl 0.177614, loss_trans 0.011196, loss flux 7.183708, loss flux t1 5.965058, binary loss 1.762544, binary loss t1 1.563276\n",
      "Epoch 6/10, Batch 1091/1650, Loss 27.002827, Loss rec 7.159796, loss rec t1 6.986336, loss kl 0.237271, loss_trans 0.008082, loss flux 6.661624, loss flux t1 5.949721, binary loss 1.250208, binary loss t1 1.098461\n",
      "Epoch 6/10, Batch 1101/1650, Loss 25.695885, Loss rec 6.617201, loss rec t1 6.519979, loss kl 0.189960, loss_trans 0.008192, loss flux 6.955376, loss flux t1 5.405179, binary loss 0.999781, binary loss t1 0.981070\n",
      "Epoch 6/10, Batch 1111/1650, Loss 25.272985, Loss rec 6.587811, loss rec t1 8.194287, loss kl 0.186576, loss_trans 0.013775, loss flux 5.243427, loss flux t1 5.047107, binary loss 0.833898, binary loss t1 0.904790\n",
      "Epoch 6/10, Batch 1121/1650, Loss 27.380465, Loss rec 6.951121, loss rec t1 8.739095, loss kl 0.174332, loss_trans 0.009895, loss flux 6.155638, loss flux t1 5.350384, binary loss 1.567827, binary loss t1 1.396286\n",
      "Epoch 6/10, Batch 1131/1650, Loss 23.304636, Loss rec 5.541666, loss rec t1 5.751072, loss kl 0.162216, loss_trans 0.004137, loss flux 6.134244, loss flux t1 5.711299, binary loss 1.482518, binary loss t1 1.481435\n",
      "Epoch 6/10, Batch 1141/1650, Loss 20.681253, Loss rec 4.407076, loss rec t1 5.028262, loss kl 0.182960, loss_trans 0.013626, loss flux 6.039417, loss flux t1 5.009912, binary loss 3.360299, binary loss t1 2.710401\n",
      "Epoch 6/10, Batch 1151/1650, Loss 24.929337, Loss rec 5.680592, loss rec t1 6.857381, loss kl 0.186509, loss_trans 0.010493, loss flux 5.735058, loss flux t1 6.459303, binary loss 2.788859, binary loss t1 2.698149\n",
      "Epoch 6/10, Batch 1161/1650, Loss 23.592424, Loss rec 6.568487, loss rec t1 6.676146, loss kl 0.169572, loss_trans 0.009730, loss flux 5.391199, loss flux t1 4.777293, binary loss 0.662467, binary loss t1 0.634887\n",
      "Epoch 6/10, Batch 1171/1650, Loss 16.335697, Loss rec 3.270543, loss rec t1 4.125690, loss kl 0.115264, loss_trans 0.006762, loss flux 4.387144, loss flux t1 4.430295, binary loss 2.970425, binary loss t1 2.877416\n",
      "Epoch 6/10, Batch 1181/1650, Loss 23.108593, Loss rec 5.542269, loss rec t1 6.226988, loss kl 0.162956, loss_trans 0.008061, loss flux 6.127842, loss flux t1 5.040477, binary loss 1.114204, binary loss t1 1.058959\n",
      "Epoch 6/10, Batch 1191/1650, Loss 23.290962, Loss rec 6.264198, loss rec t1 6.713409, loss kl 0.148189, loss_trans 0.009013, loss flux 5.296425, loss flux t1 4.859725, binary loss 1.206896, binary loss t1 1.227956\n",
      "Epoch 6/10, Batch 1201/1650, Loss 29.682936, Loss rec 8.625248, loss rec t1 7.780046, loss kl 0.272972, loss_trans 0.010967, loss flux 6.875732, loss flux t1 6.117972, binary loss 1.273286, binary loss t1 1.100590\n",
      "Epoch 6/10, Batch 1211/1650, Loss 21.997051, Loss rec 5.514939, loss rec t1 5.259263, loss kl 0.227385, loss_trans 0.005740, loss flux 5.738046, loss flux t1 5.251676, binary loss 1.974014, binary loss t1 1.804663\n",
      "Epoch 6/10, Batch 1221/1650, Loss 22.334116, Loss rec 5.548658, loss rec t1 6.381988, loss kl 0.111127, loss_trans 0.007333, loss flux 5.208230, loss flux t1 5.076780, binary loss 1.598911, binary loss t1 1.492677\n",
      "Epoch 6/10, Batch 1231/1650, Loss 20.343473, Loss rec 4.388629, loss rec t1 5.979747, loss kl 0.155152, loss_trans 0.007596, loss flux 4.957672, loss flux t1 4.854678, binary loss 0.743005, binary loss t1 0.867136\n",
      "Epoch 6/10, Batch 1241/1650, Loss 22.885469, Loss rec 5.531322, loss rec t1 6.665844, loss kl 0.156468, loss_trans 0.015184, loss flux 5.377936, loss flux t1 5.138714, binary loss 2.613936, binary loss t1 2.384825\n",
      "Epoch 6/10, Batch 1251/1650, Loss 20.872112, Loss rec 5.140656, loss rec t1 5.487681, loss kl 0.182925, loss_trans 0.007756, loss flux 5.066465, loss flux t1 4.986628, binary loss 1.445971, binary loss t1 1.267702\n",
      "Epoch 6/10, Batch 1261/1650, Loss 21.370321, Loss rec 4.996459, loss rec t1 5.942761, loss kl 0.133687, loss_trans 0.006365, loss flux 5.372811, loss flux t1 4.918239, binary loss 0.933477, binary loss t1 0.961191\n",
      "Epoch 6/10, Batch 1271/1650, Loss 19.126780, Loss rec 3.883723, loss rec t1 5.005736, loss kl 0.145682, loss_trans 0.008268, loss flux 5.051564, loss flux t1 5.031806, binary loss 1.067303, binary loss t1 1.232482\n",
      "Epoch 6/10, Batch 1281/1650, Loss 23.393442, Loss rec 5.457255, loss rec t1 6.909544, loss kl 0.143030, loss_trans 0.006994, loss flux 5.794596, loss flux t1 5.082024, binary loss 1.675533, binary loss t1 1.777278\n",
      "Epoch 6/10, Batch 1291/1650, Loss 25.907631, Loss rec 7.081463, loss rec t1 8.128119, loss kl 0.189595, loss_trans 0.006043, loss flux 5.317258, loss flux t1 5.185155, binary loss 2.291791, binary loss t1 2.142319\n",
      "Epoch 6/10, Batch 1301/1650, Loss 24.729498, Loss rec 6.943383, loss rec t1 6.783832, loss kl 0.173677, loss_trans 0.005728, loss flux 5.724001, loss flux t1 5.098877, binary loss 1.525817, binary loss t1 1.293275\n",
      "Epoch 6/10, Batch 1311/1650, Loss 17.897928, Loss rec 3.578154, loss rec t1 4.498137, loss kl 0.295709, loss_trans 0.010645, loss flux 5.106253, loss flux t1 4.409030, binary loss 1.971922, binary loss t1 2.195485\n",
      "Epoch 6/10, Batch 1321/1650, Loss 22.736719, Loss rec 5.275420, loss rec t1 5.771029, loss kl 0.355187, loss_trans 0.008001, loss flux 5.996586, loss flux t1 5.330496, binary loss 0.957736, binary loss t1 0.977773\n",
      "Epoch 6/10, Batch 1331/1650, Loss 18.145538, Loss rec 3.872837, loss rec t1 4.795555, loss kl 0.136114, loss_trans 0.008106, loss flux 4.650454, loss flux t1 4.682472, binary loss 1.894290, binary loss t1 1.907600\n",
      "Epoch 6/10, Batch 1341/1650, Loss 26.180195, Loss rec 7.164607, loss rec t1 7.458432, loss kl 0.181568, loss_trans 0.005673, loss flux 6.184614, loss flux t1 5.185301, binary loss 1.221582, binary loss t1 1.069981\n",
      "Epoch 6/10, Batch 1351/1650, Loss 24.001331, Loss rec 6.390197, loss rec t1 7.128483, loss kl 0.184658, loss_trans 0.013228, loss flux 5.523725, loss flux t1 4.761039, binary loss 1.368656, binary loss t1 1.447164\n",
      "Epoch 6/10, Batch 1361/1650, Loss 20.382074, Loss rec 3.904524, loss rec t1 5.800206, loss kl 0.158930, loss_trans 0.006657, loss flux 5.195667, loss flux t1 5.316089, binary loss 1.842292, binary loss t1 1.821330\n",
      "Epoch 6/10, Batch 1371/1650, Loss 22.417253, Loss rec 5.490773, loss rec t1 5.635447, loss kl 0.131657, loss_trans 0.009096, loss flux 6.012065, loss flux t1 5.138216, binary loss 1.813446, binary loss t1 1.603108\n",
      "Epoch 6/10, Batch 1381/1650, Loss 23.054943, Loss rec 5.855707, loss rec t1 6.111022, loss kl 0.226148, loss_trans 0.006895, loss flux 5.665781, loss flux t1 5.189390, binary loss 1.433769, binary loss t1 1.287618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10, Batch 1391/1650, Loss 26.805502, Loss rec 7.468678, loss rec t1 7.555504, loss kl 0.166430, loss_trans 0.005105, loss flux 6.017147, loss flux t1 5.592640, binary loss 5.547729, binary loss t1 4.455035\n",
      "Epoch 6/10, Batch 1401/1650, Loss 46.678635, Loss rec 13.458138, loss rec t1 14.881454, loss kl 0.145159, loss_trans 0.006196, loss flux 9.916357, loss flux t1 8.271334, binary loss 3.335735, binary loss t1 3.060052\n",
      "Epoch 6/10, Batch 1411/1650, Loss 33.322189, Loss rec 10.411001, loss rec t1 9.259684, loss kl 0.141560, loss_trans 0.010458, loss flux 6.974446, loss flux t1 6.525043, binary loss 0.978966, binary loss t1 0.914802\n",
      "Epoch 6/10, Batch 1421/1650, Loss 35.984486, Loss rec 9.465309, loss rec t1 12.210553, loss kl 0.128465, loss_trans 0.006952, loss flux 7.319781, loss flux t1 6.853429, binary loss 3.878304, binary loss t1 3.464294\n",
      "Epoch 6/10, Batch 1431/1650, Loss 36.804466, Loss rec 11.879717, loss rec t1 9.857464, loss kl 0.499695, loss_trans 0.011896, loss flux 7.591637, loss flux t1 6.964061, binary loss 8.009089, binary loss t1 3.098072\n",
      "Epoch 6/10, Batch 1441/1650, Loss 62.991962, Loss rec 22.971947, loss rec t1 25.885244, loss kl 0.251705, loss_trans 0.010409, loss flux 7.090703, loss flux t1 6.781950, binary loss 0.364365, binary loss t1 0.385485\n",
      "Epoch 6/10, Batch 1451/1650, Loss 35.716373, Loss rec 11.033834, loss rec t1 10.384186, loss kl 0.166492, loss_trans 0.014253, loss flux 7.547400, loss flux t1 6.570212, binary loss 3.304797, binary loss t1 2.675897\n",
      "Epoch 6/10, Batch 1461/1650, Loss 38.869553, Loss rec 12.893087, loss rec t1 12.734980, loss kl 0.197680, loss_trans 0.008516, loss flux 6.867815, loss flux t1 6.167472, binary loss 7.818435, binary loss t1 6.047048\n",
      "Epoch 6/10, Batch 1471/1650, Loss 38.283699, Loss rec 10.978125, loss rec t1 13.308903, loss kl 0.203202, loss_trans 0.009625, loss flux 7.810275, loss flux t1 5.973567, binary loss 3.557316, binary loss t1 3.361308\n",
      "Epoch 6/10, Batch 1481/1650, Loss 32.160503, Loss rec 9.995090, loss rec t1 10.486330, loss kl 0.174307, loss_trans 0.008225, loss flux 5.768729, loss flux t1 5.727824, binary loss 2.018603, binary loss t1 1.954257\n",
      "Epoch 6/10, Batch 1491/1650, Loss 32.336369, Loss rec 9.302635, loss rec t1 9.821327, loss kl 0.221702, loss_trans 0.012271, loss flux 6.627423, loss flux t1 6.351010, binary loss 1.325369, binary loss t1 1.247823\n",
      "Epoch 6/10, Batch 1501/1650, Loss 25.732613, Loss rec 5.953495, loss rec t1 7.829596, loss kl 0.184224, loss_trans 0.016279, loss flux 5.924139, loss flux t1 5.824881, binary loss 1.061816, binary loss t1 1.180436\n",
      "Epoch 6/10, Batch 1511/1650, Loss 27.062780, Loss rec 7.215755, loss rec t1 8.483891, loss kl 0.176233, loss_trans 0.010268, loss flux 5.541851, loss flux t1 5.634781, binary loss 3.520622, binary loss t1 3.319116\n",
      "Epoch 6/10, Batch 1521/1650, Loss 21.315109, Loss rec 4.420674, loss rec t1 5.560045, loss kl 0.453273, loss_trans 0.006366, loss flux 5.762918, loss flux t1 5.111833, binary loss 0.765159, binary loss t1 0.910264\n",
      "Epoch 6/10, Batch 1531/1650, Loss 28.207600, Loss rec 6.823794, loss rec t1 8.097046, loss kl 0.307481, loss_trans 0.008571, loss flux 6.796834, loss flux t1 6.173873, binary loss 0.811768, binary loss t1 0.726582\n",
      "Epoch 6/10, Batch 1541/1650, Loss 24.782383, Loss rec 6.214770, loss rec t1 6.535005, loss kl 0.191626, loss_trans 0.010600, loss flux 5.846802, loss flux t1 5.983578, binary loss 2.533263, binary loss t1 2.320771\n",
      "Epoch 6/10, Batch 1551/1650, Loss 29.060478, Loss rec 8.917144, loss rec t1 7.731440, loss kl 0.339099, loss_trans 0.009143, loss flux 6.978742, loss flux t1 5.084912, binary loss 0.748895, binary loss t1 0.764431\n",
      "Epoch 6/10, Batch 1561/1650, Loss 21.995609, Loss rec 5.359600, loss rec t1 5.077936, loss kl 0.203540, loss_trans 0.006547, loss flux 6.281115, loss flux t1 5.066871, binary loss 1.069664, binary loss t1 0.956629\n",
      "Epoch 6/10, Batch 1571/1650, Loss 23.172808, Loss rec 5.304438, loss rec t1 5.759896, loss kl 0.327929, loss_trans 0.006418, loss flux 6.684996, loss flux t1 5.089131, binary loss 0.889119, binary loss t1 0.954634\n",
      "Epoch 6/10, Batch 1581/1650, Loss 26.122986, Loss rec 6.515567, loss rec t1 7.821267, loss kl 0.239894, loss_trans 0.010249, loss flux 5.701326, loss flux t1 5.834684, binary loss 1.831221, binary loss t1 1.913172\n",
      "Epoch 6/10, Batch 1591/1650, Loss 20.720667, Loss rec 4.176470, loss rec t1 5.506406, loss kl 0.223570, loss_trans 0.005881, loss flux 5.271367, loss flux t1 5.536974, binary loss 1.226751, binary loss t1 1.306451\n",
      "Epoch 6/10, Batch 1601/1650, Loss 23.332504, Loss rec 6.945979, loss rec t1 5.636747, loss kl 0.341217, loss_trans 0.005386, loss flux 5.667521, loss flux t1 4.735656, binary loss 1.292034, binary loss t1 1.184730\n",
      "Epoch 6/10, Batch 1611/1650, Loss 22.310143, Loss rec 5.330061, loss rec t1 6.131728, loss kl 0.156369, loss_trans 0.010460, loss flux 5.456017, loss flux t1 5.225505, binary loss 1.941920, binary loss t1 1.740487\n",
      "Epoch 6/10, Batch 1621/1650, Loss 24.586067, Loss rec 6.840785, loss rec t1 7.705356, loss kl 0.180804, loss_trans 0.006942, loss flux 5.080487, loss flux t1 4.771692, binary loss 0.674706, binary loss t1 0.648209\n",
      "Epoch 6/10, Batch 1631/1650, Loss 23.466969, Loss rec 5.760378, loss rec t1 6.312173, loss kl 0.232027, loss_trans 0.004686, loss flux 5.843204, loss flux t1 5.314500, binary loss 2.012836, binary loss t1 1.740475\n",
      "Epoch 6/10, Batch 1641/1650, Loss 35.041550, Loss rec 11.001970, loss rec t1 10.584083, loss kl 0.243997, loss_trans 0.008347, loss flux 6.831572, loss flux t1 6.371582, binary loss 0.696702, binary loss t1 0.667770\n",
      "Epoch 6/10, Train loss 24.477489, Eval loss 23.758263\n",
      "Epoch 7/10, Batch 1/1650, Loss 23.275425, Loss rec 5.468706, loss rec t1 6.252831, loss kl 0.191822, loss_trans 0.008612, loss flux 5.750759, loss flux t1 5.602695, binary loss 2.475632, binary loss t1 2.339531\n",
      "Epoch 7/10, Batch 11/1650, Loss 23.691305, Loss rec 5.912321, loss rec t1 7.658074, loss kl 0.149022, loss_trans 0.010597, loss flux 5.230216, loss flux t1 4.731073, binary loss 2.377014, binary loss t1 2.224306\n",
      "Epoch 7/10, Batch 21/1650, Loss 20.796587, Loss rec 5.125953, loss rec t1 5.340431, loss kl 0.220996, loss_trans 0.006963, loss flux 5.440109, loss flux t1 4.662133, binary loss 1.875530, binary loss t1 1.733820\n",
      "Epoch 7/10, Batch 31/1650, Loss 21.186096, Loss rec 5.343920, loss rec t1 6.050742, loss kl 0.143155, loss_trans 0.012585, loss flux 4.935987, loss flux t1 4.699707, binary loss 3.851733, binary loss t1 3.282703\n",
      "Epoch 7/10, Batch 41/1650, Loss 22.267342, Loss rec 6.224068, loss rec t1 6.100531, loss kl 0.168587, loss_trans 0.009384, loss flux 5.079184, loss flux t1 4.685588, binary loss 0.703540, binary loss t1 0.623950\n",
      "Epoch 7/10, Batch 51/1650, Loss 22.339508, Loss rec 5.163775, loss rec t1 6.193700, loss kl 0.199927, loss_trans 0.009818, loss flux 5.916628, loss flux t1 4.855660, binary loss 0.959901, binary loss t1 0.924474\n",
      "Epoch 7/10, Batch 61/1650, Loss 29.627377, Loss rec 7.237620, loss rec t1 9.178233, loss kl 0.183991, loss_trans 0.010994, loss flux 6.274105, loss flux t1 6.742433, binary loss 2.921725, binary loss t1 2.913075\n",
      "Epoch 7/10, Batch 71/1650, Loss 25.520113, Loss rec 7.900576, loss rec t1 6.649567, loss kl 0.180320, loss_trans 0.006433, loss flux 5.812349, loss flux t1 4.970867, binary loss 1.467336, binary loss t1 1.368620\n",
      "Epoch 7/10, Batch 81/1650, Loss 32.828339, Loss rec 10.139387, loss rec t1 9.332629, loss kl 0.169648, loss_trans 0.010361, loss flux 7.189621, loss flux t1 5.986696, binary loss 0.529626, binary loss t1 0.529748\n",
      "Epoch 7/10, Batch 91/1650, Loss 21.306305, Loss rec 5.100404, loss rec t1 5.155834, loss kl 0.234875, loss_trans 0.005318, loss flux 5.555589, loss flux t1 5.254283, binary loss 2.068191, binary loss t1 1.821330\n",
      "Epoch 7/10, Batch 101/1650, Loss 26.396437, Loss rec 6.828360, loss rec t1 8.567904, loss kl 0.156912, loss_trans 0.008852, loss flux 5.636068, loss flux t1 5.198340, binary loss 4.768518, binary loss t1 3.919267\n",
      "Epoch 7/10, Batch 111/1650, Loss 29.072824, Loss rec 7.519808, loss rec t1 9.342064, loss kl 0.219448, loss_trans 0.010713, loss flux 6.349823, loss flux t1 5.630967, binary loss 1.335504, binary loss t1 1.159376\n",
      "Epoch 7/10, Batch 121/1650, Loss 27.355263, Loss rec 7.328226, loss rec t1 8.369571, loss kl 0.209468, loss_trans 0.004708, loss flux 5.814237, loss flux t1 5.629056, binary loss 2.102573, binary loss t1 1.795928\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Batch 131/1650, Loss 24.301805, Loss rec 6.413085, loss rec t1 7.334353, loss kl 0.202201, loss_trans 0.006569, loss flux 5.269162, loss flux t1 5.076437, binary loss 0.740986, binary loss t1 0.590663\n",
      "Epoch 7/10, Batch 141/1650, Loss 28.831432, Loss rec 7.746753, loss rec t1 8.165618, loss kl 0.292826, loss_trans 0.012635, loss flux 6.688684, loss flux t1 5.924918, binary loss 1.800295, binary loss t1 1.557826\n",
      "Epoch 7/10, Batch 151/1650, Loss 23.653240, Loss rec 4.993114, loss rec t1 8.129307, loss kl 0.139630, loss_trans 0.008808, loss flux 5.325049, loss flux t1 5.057332, binary loss 0.899278, binary loss t1 1.079823\n",
      "Epoch 7/10, Batch 161/1650, Loss 22.482473, Loss rec 5.988860, loss rec t1 5.360635, loss kl 0.212097, loss_trans 0.010270, loss flux 5.765287, loss flux t1 5.145327, binary loss 0.673489, binary loss t1 0.656943\n",
      "Epoch 7/10, Batch 171/1650, Loss 21.708084, Loss rec 5.475713, loss rec t1 6.067335, loss kl 0.156297, loss_trans 0.011443, loss flux 5.244776, loss flux t1 4.752518, binary loss 1.788202, binary loss t1 1.825734\n",
      "Epoch 7/10, Batch 181/1650, Loss 22.084318, Loss rec 5.595724, loss rec t1 5.592052, loss kl 0.194800, loss_trans 0.004691, loss flux 5.584176, loss flux t1 5.112874, binary loss 2.395799, binary loss t1 2.174438\n",
      "Epoch 7/10, Batch 191/1650, Loss 23.216091, Loss rec 6.354454, loss rec t1 6.708200, loss kl 0.204698, loss_trans 0.007243, loss flux 5.278531, loss flux t1 4.662963, binary loss 2.598497, binary loss t1 1.868863\n",
      "Epoch 7/10, Batch 201/1650, Loss 16.190710, Loss rec 3.391724, loss rec t1 4.058479, loss kl 0.159712, loss_trans 0.013973, loss flux 4.522176, loss flux t1 4.044647, binary loss 1.524552, binary loss t1 1.210108\n",
      "Epoch 7/10, Batch 211/1650, Loss 25.765429, Loss rec 6.894244, loss rec t1 8.474048, loss kl 0.142097, loss_trans 0.015005, loss flux 5.235664, loss flux t1 5.004372, binary loss 0.746656, binary loss t1 0.758761\n",
      "Epoch 7/10, Batch 221/1650, Loss 29.919310, Loss rec 8.871029, loss rec t1 8.153249, loss kl 0.231755, loss_trans 0.006752, loss flux 6.722827, loss flux t1 5.933698, binary loss 4.810467, binary loss t1 4.100784\n",
      "Epoch 7/10, Batch 231/1650, Loss 24.943993, Loss rec 6.780633, loss rec t1 7.315169, loss kl 0.134388, loss_trans 0.012965, loss flux 5.947121, loss flux t1 4.753717, binary loss 0.562998, binary loss t1 0.486375\n",
      "Epoch 7/10, Batch 241/1650, Loss 27.339865, Loss rec 7.038329, loss rec t1 8.073935, loss kl 0.278110, loss_trans 0.007419, loss flux 6.001765, loss flux t1 5.940306, binary loss 9.954051, binary loss t1 7.381127\n",
      "Epoch 7/10, Batch 251/1650, Loss 16.681068, Loss rec 3.518094, loss rec t1 4.231466, loss kl 0.136706, loss_trans 0.009791, loss flux 4.575571, loss flux t1 4.209441, binary loss 3.360177, binary loss t1 2.877428\n",
      "Epoch 7/10, Batch 261/1650, Loss 20.275497, Loss rec 4.151634, loss rec t1 5.048331, loss kl 0.288446, loss_trans 0.007210, loss flux 5.714117, loss flux t1 5.065763, binary loss 2.245256, binary loss t1 1.011984\n",
      "Epoch 7/10, Batch 271/1650, Loss 20.582172, Loss rec 4.452304, loss rec t1 6.445346, loss kl 0.129496, loss_trans 0.011438, loss flux 4.767203, loss flux t1 4.776384, binary loss 2.592852, binary loss t1 2.637136\n",
      "Epoch 7/10, Batch 281/1650, Loss 21.697380, Loss rec 5.645345, loss rec t1 5.432184, loss kl 0.201418, loss_trans 0.011108, loss flux 5.555291, loss flux t1 4.852033, binary loss 0.760902, binary loss t1 0.740974\n",
      "Epoch 7/10, Batch 291/1650, Loss 23.429886, Loss rec 5.380891, loss rec t1 6.609841, loss kl 0.192687, loss_trans 0.011253, loss flux 5.658765, loss flux t1 5.576447, binary loss 2.600785, binary loss t1 2.546646\n",
      "Epoch 7/10, Batch 301/1650, Loss 23.802874, Loss rec 5.786513, loss rec t1 6.553618, loss kl 0.207060, loss_trans 0.004667, loss flux 5.760588, loss flux t1 5.490427, binary loss 0.830906, binary loss t1 0.814348\n",
      "Epoch 7/10, Batch 311/1650, Loss 28.069227, Loss rec 7.212650, loss rec t1 7.870705, loss kl 0.199687, loss_trans 0.013644, loss flux 6.186998, loss flux t1 6.585542, binary loss 1.040781, binary loss t1 0.973491\n",
      "Epoch 7/10, Batch 321/1650, Loss 18.027922, Loss rec 3.770056, loss rec t1 3.993176, loss kl 0.175657, loss_trans 0.008452, loss flux 5.706689, loss flux t1 4.373892, binary loss 1.427089, binary loss t1 1.289820\n",
      "Epoch 7/10, Batch 331/1650, Loss 25.061094, Loss rec 6.472567, loss rec t1 7.321724, loss kl 0.205660, loss_trans 0.011539, loss flux 5.311538, loss flux t1 5.738066, binary loss 1.847779, binary loss t1 1.667381\n",
      "Epoch 7/10, Batch 341/1650, Loss 24.573414, Loss rec 6.049065, loss rec t1 7.103812, loss kl 0.158950, loss_trans 0.009305, loss flux 5.639477, loss flux t1 5.612804, binary loss 3.273932, binary loss t1 2.808921\n",
      "Epoch 7/10, Batch 351/1650, Loss 29.443266, Loss rec 9.057013, loss rec t1 9.618925, loss kl 0.180145, loss_trans 0.012779, loss flux 5.158782, loss flux t1 5.415623, binary loss 0.406215, binary loss t1 0.468555\n",
      "Epoch 7/10, Batch 361/1650, Loss 22.544788, Loss rec 5.078350, loss rec t1 5.761356, loss kl 0.285335, loss_trans 0.007122, loss flux 6.014236, loss flux t1 5.398389, binary loss 2.832073, binary loss t1 3.416603\n",
      "Epoch 7/10, Batch 371/1650, Loss 23.350105, Loss rec 6.227600, loss rec t1 5.714302, loss kl 0.195905, loss_trans 0.011467, loss flux 5.959156, loss flux t1 5.241677, binary loss 1.987519, binary loss t1 1.453953\n",
      "Epoch 7/10, Batch 381/1650, Loss 29.628969, Loss rec 7.845220, loss rec t1 9.659693, loss kl 0.283873, loss_trans 0.014492, loss flux 5.938034, loss flux t1 5.887658, binary loss 1.325247, binary loss t1 1.365091\n",
      "Epoch 7/10, Batch 391/1650, Loss 23.569086, Loss rec 6.037215, loss rec t1 6.129174, loss kl 0.255817, loss_trans 0.008116, loss flux 5.531267, loss flux t1 5.607497, binary loss 0.668112, binary loss t1 0.647977\n",
      "Epoch 7/10, Batch 401/1650, Loss 23.065035, Loss rec 5.236828, loss rec t1 6.316990, loss kl 0.337933, loss_trans 0.006803, loss flux 5.427223, loss flux t1 5.739258, binary loss 2.845395, binary loss t1 1.945315\n",
      "Epoch 7/10, Batch 411/1650, Loss 22.700329, Loss rec 5.634371, loss rec t1 5.737365, loss kl 0.225946, loss_trans 0.005471, loss flux 5.720526, loss flux t1 5.376650, binary loss 0.695595, binary loss t1 0.601478\n",
      "Epoch 7/10, Batch 421/1650, Loss 25.490364, Loss rec 5.901148, loss rec t1 8.319152, loss kl 0.152796, loss_trans 0.010866, loss flux 5.506896, loss flux t1 5.599506, binary loss 2.826513, binary loss t1 2.692626\n",
      "Epoch 7/10, Batch 431/1650, Loss 23.782248, Loss rec 6.238150, loss rec t1 7.303929, loss kl 0.155758, loss_trans 0.007517, loss flux 5.305134, loss flux t1 4.771759, binary loss 1.067523, binary loss t1 0.919243\n",
      "Epoch 7/10, Batch 441/1650, Loss 20.887390, Loss rec 4.619555, loss rec t1 5.177564, loss kl 0.226868, loss_trans 0.008067, loss flux 5.764936, loss flux t1 5.090401, binary loss 2.083740, binary loss t1 1.468345\n",
      "Epoch 7/10, Batch 451/1650, Loss 21.030666, Loss rec 4.793816, loss rec t1 4.408049, loss kl 0.289410, loss_trans 0.009411, loss flux 6.707269, loss flux t1 4.822713, binary loss 1.506874, binary loss t1 1.157028\n",
      "Epoch 7/10, Batch 461/1650, Loss 35.911114, Loss rec 10.278738, loss rec t1 11.649261, loss kl 0.250387, loss_trans 0.008400, loss flux 7.225399, loss flux t1 6.498929, binary loss 3.634667, binary loss t1 3.166335\n",
      "Epoch 7/10, Batch 471/1650, Loss 22.233551, Loss rec 6.299280, loss rec t1 6.491077, loss kl 0.167224, loss_trans 0.007672, loss flux 4.791815, loss flux t1 4.476483, binary loss 0.437809, binary loss t1 0.466557\n",
      "Epoch 7/10, Batch 481/1650, Loss 40.010029, Loss rec 13.917834, loss rec t1 13.245049, loss kl 0.186855, loss_trans 0.006584, loss flux 6.759656, loss flux t1 5.894051, binary loss 2.964926, binary loss t1 2.744599\n",
      "Epoch 7/10, Batch 491/1650, Loss 20.394625, Loss rec 4.748270, loss rec t1 5.540156, loss kl 0.171230, loss_trans 0.006529, loss flux 5.240333, loss flux t1 4.688107, binary loss 1.074141, binary loss t1 1.048824\n",
      "Epoch 7/10, Batch 501/1650, Loss 27.531603, Loss rec 6.896363, loss rec t1 8.935893, loss kl 0.208045, loss_trans 0.015068, loss flux 6.212706, loss flux t1 5.263529, binary loss 0.422834, binary loss t1 0.423102\n",
      "Epoch 7/10, Batch 511/1650, Loss 22.825880, Loss rec 5.669515, loss rec t1 5.490510, loss kl 0.316569, loss_trans 0.005346, loss flux 6.071322, loss flux t1 5.272618, binary loss 1.488005, binary loss t1 1.729452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Batch 521/1650, Loss 19.920570, Loss rec 4.422163, loss rec t1 5.169459, loss kl 0.144085, loss_trans 0.006837, loss flux 5.475913, loss flux t1 4.702117, binary loss 2.486582, binary loss t1 2.085881\n",
      "Epoch 7/10, Batch 531/1650, Loss 21.444061, Loss rec 5.386439, loss rec t1 5.790604, loss kl 0.199517, loss_trans 0.006091, loss flux 5.143281, loss flux t1 4.918131, binary loss 1.080942, binary loss t1 1.079908\n",
      "Epoch 7/10, Batch 541/1650, Loss 17.661917, Loss rec 3.517664, loss rec t1 4.369163, loss kl 0.322920, loss_trans 0.010835, loss flux 4.866631, loss flux t1 4.574702, binary loss 4.703064, binary loss t1 2.165605\n",
      "Epoch 7/10, Batch 551/1650, Loss 20.545490, Loss rec 4.589344, loss rec t1 4.297994, loss kl 0.333378, loss_trans 0.007063, loss flux 5.658113, loss flux t1 5.659597, binary loss 1.713880, binary loss t1 1.608704\n",
      "Epoch 7/10, Batch 561/1650, Loss 23.733843, Loss rec 5.844953, loss rec t1 6.657532, loss kl 0.182317, loss_trans 0.013086, loss flux 5.822094, loss flux t1 5.213861, binary loss 1.102828, binary loss t1 1.084093\n",
      "Epoch 7/10, Batch 571/1650, Loss 21.151205, Loss rec 4.286588, loss rec t1 6.220232, loss kl 0.130001, loss_trans 0.005714, loss flux 4.949403, loss flux t1 5.559267, binary loss 1.475875, binary loss t1 1.809152\n",
      "Epoch 7/10, Batch 581/1650, Loss 26.495958, Loss rec 6.668249, loss rec t1 6.994491, loss kl 0.287249, loss_trans 0.014374, loss flux 7.137298, loss flux t1 5.394297, binary loss 2.398257, binary loss t1 2.357208\n",
      "Epoch 7/10, Batch 591/1650, Loss 25.895624, Loss rec 6.699571, loss rec t1 6.903136, loss kl 0.160400, loss_trans 0.008002, loss flux 6.622983, loss flux t1 5.501531, binary loss 1.007592, binary loss t1 0.932528\n",
      "Epoch 7/10, Batch 601/1650, Loss 28.628975, Loss rec 6.163554, loss rec t1 10.056616, loss kl 0.152527, loss_trans 0.013873, loss flux 6.449253, loss flux t1 5.793152, binary loss 1.784796, binary loss t1 1.548130\n",
      "Epoch 7/10, Batch 611/1650, Loss 26.010252, Loss rec 6.062298, loss rec t1 6.809151, loss kl 0.323473, loss_trans 0.008606, loss flux 7.187236, loss flux t1 5.619489, binary loss 2.150105, binary loss t1 1.724975\n",
      "Epoch 7/10, Batch 621/1650, Loss 25.238903, Loss rec 6.530402, loss rec t1 7.080279, loss kl 0.203501, loss_trans 0.006736, loss flux 6.179032, loss flux t1 5.238952, binary loss 1.597780, binary loss t1 1.396334\n",
      "Epoch 7/10, Batch 631/1650, Loss 23.467691, Loss rec 5.583712, loss rec t1 7.006164, loss kl 0.193940, loss_trans 0.011886, loss flux 5.705541, loss flux t1 4.966447, binary loss 1.091769, binary loss t1 0.805040\n",
      "Epoch 7/10, Batch 641/1650, Loss 27.494967, Loss rec 7.575201, loss rec t1 8.122139, loss kl 0.179172, loss_trans 0.012923, loss flux 5.919988, loss flux t1 5.685545, binary loss 2.451435, binary loss t1 2.183343\n",
      "Epoch 7/10, Batch 651/1650, Loss 27.468119, Loss rec 6.191501, loss rec t1 7.575555, loss kl 0.167057, loss_trans 0.008857, loss flux 7.206818, loss flux t1 6.318333, binary loss 1.484976, binary loss t1 1.467287\n",
      "Epoch 7/10, Batch 661/1650, Loss 20.552946, Loss rec 4.067574, loss rec t1 5.818794, loss kl 0.136949, loss_trans 0.008782, loss flux 4.888036, loss flux t1 5.632811, binary loss 3.501838, binary loss t1 3.178513\n",
      "Epoch 7/10, Batch 671/1650, Loss 26.175898, Loss rec 6.011364, loss rec t1 6.643200, loss kl 0.201282, loss_trans 0.010992, loss flux 7.177511, loss flux t1 6.131549, binary loss 1.110663, binary loss t1 0.995475\n",
      "Epoch 7/10, Batch 681/1650, Loss 20.434162, Loss rec 4.938447, loss rec t1 6.365521, loss kl 0.137343, loss_trans 0.013374, loss flux 4.493817, loss flux t1 4.485660, binary loss 4.775039, binary loss t1 4.279102\n",
      "Epoch 7/10, Batch 691/1650, Loss 27.309765, Loss rec 7.687335, loss rec t1 9.206265, loss kl 0.202940, loss_trans 0.011711, loss flux 5.430061, loss flux t1 4.771452, binary loss 2.427929, binary loss t1 2.150020\n",
      "Epoch 7/10, Batch 701/1650, Loss 21.283558, Loss rec 5.246539, loss rec t1 5.832700, loss kl 0.154581, loss_trans 0.011028, loss flux 5.141968, loss flux t1 4.896741, binary loss 2.597317, binary loss t1 2.307278\n",
      "Epoch 7/10, Batch 711/1650, Loss 26.590179, Loss rec 6.903657, loss rec t1 8.096037, loss kl 0.286390, loss_trans 0.006130, loss flux 6.095299, loss flux t1 5.202665, binary loss 0.703381, binary loss t1 0.665910\n",
      "Epoch 7/10, Batch 721/1650, Loss 22.410559, Loss rec 5.480732, loss rec t1 6.539765, loss kl 0.166014, loss_trans 0.010717, loss flux 5.133419, loss flux t1 5.079911, binary loss 0.640154, binary loss t1 0.666724\n",
      "Epoch 7/10, Batch 731/1650, Loss 22.375231, Loss rec 5.404344, loss rec t1 6.344567, loss kl 0.218444, loss_trans 0.011178, loss flux 5.191267, loss flux t1 5.205428, binary loss 2.287350, binary loss t1 2.147830\n",
      "Epoch 7/10, Batch 741/1650, Loss 28.088856, Loss rec 7.881528, loss rec t1 9.201649, loss kl 0.177132, loss_trans 0.011762, loss flux 5.519215, loss flux t1 5.297570, binary loss 4.879095, binary loss t1 4.427418\n",
      "Epoch 7/10, Batch 751/1650, Loss 22.395145, Loss rec 4.685188, loss rec t1 6.644473, loss kl 0.157707, loss_trans 0.005538, loss flux 5.480062, loss flux t1 5.422178, binary loss 1.629825, binary loss t1 1.262618\n",
      "Epoch 7/10, Batch 761/1650, Loss 25.164446, Loss rec 7.892264, loss rec t1 6.531006, loss kl 0.130320, loss_trans 0.006831, loss flux 5.582880, loss flux t1 5.021146, binary loss 0.575469, binary loss t1 0.550722\n",
      "Epoch 7/10, Batch 771/1650, Loss 22.505657, Loss rec 5.075037, loss rec t1 6.184347, loss kl 0.262525, loss_trans 0.010560, loss flux 6.036726, loss flux t1 4.936462, binary loss 0.955595, binary loss t1 0.811634\n",
      "Epoch 7/10, Batch 781/1650, Loss 23.104046, Loss rec 6.078386, loss rec t1 6.203613, loss kl 0.221261, loss_trans 0.005995, loss flux 5.396202, loss flux t1 5.198587, binary loss 0.994746, binary loss t1 0.848449\n",
      "Epoch 7/10, Batch 791/1650, Loss 21.556526, Loss rec 5.018988, loss rec t1 6.450069, loss kl 0.178481, loss_trans 0.010194, loss flux 4.818875, loss flux t1 5.079917, binary loss 1.510232, binary loss t1 1.412782\n",
      "Epoch 7/10, Batch 801/1650, Loss 24.997038, Loss rec 7.230892, loss rec t1 8.259711, loss kl 0.162800, loss_trans 0.010181, loss flux 4.508326, loss flux t1 4.825129, binary loss 5.152490, binary loss t1 4.489356\n",
      "Epoch 7/10, Batch 811/1650, Loss 17.296906, Loss rec 3.203341, loss rec t1 4.005739, loss kl 0.284732, loss_trans 0.007087, loss flux 5.067701, loss flux t1 4.728305, binary loss 1.272179, binary loss t1 1.131711\n",
      "Epoch 7/10, Batch 821/1650, Loss 25.782444, Loss rec 7.435339, loss rec t1 8.273445, loss kl 0.187974, loss_trans 0.005006, loss flux 5.251286, loss flux t1 4.629393, binary loss 0.392210, binary loss t1 0.438709\n",
      "Epoch 7/10, Batch 831/1650, Loss 21.439753, Loss rec 4.808283, loss rec t1 6.233863, loss kl 0.136082, loss_trans 0.010130, loss flux 5.442325, loss flux t1 4.809071, binary loss 2.493248, binary loss t1 2.416846\n",
      "Epoch 7/10, Batch 841/1650, Loss 19.107426, Loss rec 4.090383, loss rec t1 5.242886, loss kl 0.156292, loss_trans 0.006577, loss flux 4.932679, loss flux t1 4.678608, binary loss 1.734878, binary loss t1 1.781499\n",
      "Epoch 7/10, Batch 851/1650, Loss 17.642389, Loss rec 3.755984, loss rec t1 4.471519, loss kl 0.140059, loss_trans 0.010291, loss flux 5.049019, loss flux t1 4.215517, binary loss 1.320831, binary loss t1 1.222359\n",
      "Epoch 7/10, Batch 861/1650, Loss 26.778601, Loss rec 7.155663, loss rec t1 7.268108, loss kl 0.308407, loss_trans 0.008347, loss flux 6.756649, loss flux t1 5.281427, binary loss 2.813533, binary loss t1 1.692274\n",
      "Epoch 7/10, Batch 871/1650, Loss 22.316069, Loss rec 5.099426, loss rec t1 6.145767, loss kl 0.192935, loss_trans 0.005521, loss flux 5.720089, loss flux t1 5.152329, binary loss 1.140421, binary loss t1 1.017520\n",
      "Epoch 7/10, Batch 881/1650, Loss 17.866529, Loss rec 3.722097, loss rec t1 4.263375, loss kl 0.132456, loss_trans 0.010534, loss flux 4.724646, loss flux t1 5.013421, binary loss 1.964086, binary loss t1 1.930910\n",
      "Epoch 7/10, Batch 891/1650, Loss 20.656746, Loss rec 5.493876, loss rec t1 5.149511, loss kl 0.163953, loss_trans 0.004476, loss flux 5.526095, loss flux t1 4.318834, binary loss 1.625311, binary loss t1 1.540124\n",
      "Epoch 7/10, Batch 901/1650, Loss 19.050488, Loss rec 4.179123, loss rec t1 5.329018, loss kl 0.131507, loss_trans 0.004915, loss flux 4.810436, loss flux t1 4.595489, binary loss 2.985986, binary loss t1 2.695996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Batch 911/1650, Loss 20.226254, Loss rec 5.823971, loss rec t1 4.851594, loss kl 0.162040, loss_trans 0.005000, loss flux 4.955934, loss flux t1 4.427714, binary loss 0.594970, binary loss t1 0.636747\n",
      "Epoch 7/10, Batch 921/1650, Loss 24.985460, Loss rec 6.328070, loss rec t1 6.942724, loss kl 0.211655, loss_trans 0.005930, loss flux 6.391736, loss flux t1 5.105344, binary loss 1.520636, binary loss t1 1.439682\n",
      "Epoch 7/10, Batch 931/1650, Loss 23.139736, Loss rec 5.442335, loss rec t1 6.117616, loss kl 0.206572, loss_trans 0.011505, loss flux 6.155738, loss flux t1 5.205971, binary loss 1.760537, binary loss t1 1.584592\n",
      "Epoch 7/10, Batch 941/1650, Loss 18.393188, Loss rec 3.546158, loss rec t1 4.619175, loss kl 0.157507, loss_trans 0.015342, loss flux 4.853068, loss flux t1 5.201938, binary loss 2.305040, binary loss t1 2.103814\n",
      "Epoch 7/10, Batch 951/1650, Loss 16.611280, Loss rec 3.613571, loss rec t1 4.096917, loss kl 0.131222, loss_trans 0.005070, loss flux 4.453432, loss flux t1 4.311069, binary loss 1.377379, binary loss t1 1.242300\n",
      "Epoch 7/10, Batch 961/1650, Loss 19.657282, Loss rec 4.288177, loss rec t1 5.478989, loss kl 0.182467, loss_trans 0.006399, loss flux 4.851936, loss flux t1 4.849315, binary loss 1.704998, binary loss t1 1.676262\n",
      "Epoch 7/10, Batch 971/1650, Loss 16.543135, Loss rec 3.376628, loss rec t1 4.247541, loss kl 0.144129, loss_trans 0.004539, loss flux 4.362580, loss flux t1 4.407719, binary loss 0.613437, binary loss t1 0.598120\n",
      "Epoch 7/10, Batch 981/1650, Loss 19.121258, Loss rec 4.504667, loss rec t1 4.539535, loss kl 0.151663, loss_trans 0.013749, loss flux 5.418947, loss flux t1 4.492699, binary loss 3.880543, binary loss t1 3.188538\n",
      "Epoch 7/10, Batch 991/1650, Loss 20.894369, Loss rec 5.190553, loss rec t1 5.485417, loss kl 0.144979, loss_trans 0.011070, loss flux 5.130809, loss flux t1 4.931540, binary loss 2.485499, binary loss t1 2.215388\n",
      "Epoch 7/10, Batch 1001/1650, Loss 18.192215, Loss rec 4.300846, loss rec t1 4.047179, loss kl 0.127106, loss_trans 0.006043, loss flux 4.853199, loss flux t1 4.857844, binary loss 1.046219, binary loss t1 0.932284\n",
      "Epoch 7/10, Batch 1011/1650, Loss 21.038692, Loss rec 5.639415, loss rec t1 5.455974, loss kl 0.130125, loss_trans 0.004867, loss flux 5.255276, loss flux t1 4.553035, binary loss 0.893816, binary loss t1 0.889339\n",
      "Epoch 7/10, Batch 1021/1650, Loss 22.818714, Loss rec 5.394942, loss rec t1 6.047409, loss kl 0.305938, loss_trans 0.007696, loss flux 5.605052, loss flux t1 5.457678, binary loss 1.210132, binary loss t1 1.026499\n",
      "Epoch 7/10, Batch 1031/1650, Loss 19.570004, Loss rec 4.509811, loss rec t1 5.715207, loss kl 0.142926, loss_trans 0.006672, loss flux 4.525564, loss flux t1 4.669826, binary loss 1.388499, binary loss t1 1.626674\n",
      "Epoch 7/10, Batch 1041/1650, Loss 19.618477, Loss rec 4.586064, loss rec t1 5.438940, loss kl 0.150669, loss_trans 0.009608, loss flux 4.597740, loss flux t1 4.835455, binary loss 1.175897, binary loss t1 1.162722\n",
      "Epoch 7/10, Batch 1051/1650, Loss 19.224663, Loss rec 3.729223, loss rec t1 4.909657, loss kl 0.245739, loss_trans 0.009453, loss flux 5.537624, loss flux t1 4.792967, binary loss 1.896516, binary loss t1 1.640908\n",
      "Epoch 7/10, Batch 1061/1650, Loss 16.146515, Loss rec 3.403007, loss rec t1 4.204236, loss kl 0.126868, loss_trans 0.007259, loss flux 4.140156, loss flux t1 4.264989, binary loss 1.919765, binary loss t1 2.077024\n",
      "Epoch 7/10, Batch 1071/1650, Loss 20.927151, Loss rec 4.650012, loss rec t1 5.140404, loss kl 0.333725, loss_trans 0.006481, loss flux 5.445290, loss flux t1 5.351241, binary loss 5.328667, binary loss t1 2.911907\n",
      "Epoch 7/10, Batch 1081/1650, Loss 23.106182, Loss rec 5.027128, loss rec t1 6.238113, loss kl 0.167678, loss_trans 0.010541, loss flux 6.504802, loss flux t1 5.157921, binary loss 0.903536, binary loss t1 0.885871\n",
      "Epoch 7/10, Batch 1091/1650, Loss 24.173882, Loss rec 6.484009, loss rec t1 6.150784, loss kl 0.227345, loss_trans 0.008144, loss flux 6.028293, loss flux t1 5.275307, binary loss 2.428051, binary loss t1 2.007215\n",
      "Epoch 7/10, Batch 1101/1650, Loss 22.944693, Loss rec 5.964013, loss rec t1 5.793058, loss kl 0.172716, loss_trans 0.007159, loss flux 6.218458, loss flux t1 4.789289, binary loss 2.362610, binary loss t1 2.112452\n",
      "Epoch 7/10, Batch 1111/1650, Loss 21.560534, Loss rec 5.365456, loss rec t1 6.677010, loss kl 0.185174, loss_trans 0.014093, loss flux 4.697387, loss flux t1 4.621413, binary loss 1.668427, binary loss t1 1.616393\n",
      "Epoch 7/10, Batch 1121/1650, Loss 24.605551, Loss rec 6.454334, loss rec t1 7.126580, loss kl 0.165479, loss_trans 0.008720, loss flux 5.762133, loss flux t1 5.088305, binary loss 1.961933, binary loss t1 1.740560\n",
      "Epoch 7/10, Batch 1131/1650, Loss 21.184326, Loss rec 5.234078, loss rec t1 5.996645, loss kl 0.148693, loss_trans 0.004383, loss flux 5.020822, loss flux t1 4.779704, binary loss 1.203624, binary loss t1 1.158196\n",
      "Epoch 7/10, Batch 1141/1650, Loss 17.413679, Loss rec 3.300264, loss rec t1 4.166782, loss kl 0.177813, loss_trans 0.013321, loss flux 5.194870, loss flux t1 4.560628, binary loss 1.015501, binary loss t1 0.930192\n",
      "Epoch 7/10, Batch 1151/1650, Loss 27.833969, Loss rec 7.349639, loss rec t1 9.050442, loss kl 0.178705, loss_trans 0.009522, loss flux 5.222530, loss flux t1 6.023131, binary loss 4.179365, binary loss t1 3.694438\n",
      "Epoch 7/10, Batch 1161/1650, Loss 20.082222, Loss rec 4.715344, loss rec t1 5.597785, loss kl 0.163014, loss_trans 0.009064, loss flux 4.981791, loss flux t1 4.615222, binary loss 1.367464, binary loss t1 1.252447\n",
      "Epoch 7/10, Batch 1171/1650, Loss 14.871966, Loss rec 2.949016, loss rec t1 3.901531, loss kl 0.110977, loss_trans 0.006408, loss flux 3.993747, loss flux t1 3.910288, binary loss 2.157831, binary loss t1 2.096927\n",
      "Epoch 7/10, Batch 1181/1650, Loss 20.919189, Loss rec 4.826228, loss rec t1 5.540603, loss kl 0.155385, loss_trans 0.007422, loss flux 5.702224, loss flux t1 4.687328, binary loss 1.487313, binary loss t1 1.318010\n",
      "Epoch 7/10, Batch 1191/1650, Loss 18.862709, Loss rec 4.807327, loss rec t1 5.233722, loss kl 0.142957, loss_trans 0.007761, loss flux 4.455400, loss flux t1 4.215542, binary loss 1.254514, binary loss t1 1.323167\n",
      "Epoch 7/10, Batch 1201/1650, Loss 26.136118, Loss rec 6.601466, loss rec t1 7.120543, loss kl 0.250783, loss_trans 0.009831, loss flux 6.608200, loss flux t1 5.545294, binary loss 0.749929, binary loss t1 0.680339\n",
      "Epoch 7/10, Batch 1211/1650, Loss 21.073154, Loss rec 5.436862, loss rec t1 5.341418, loss kl 0.217201, loss_trans 0.005577, loss flux 5.314370, loss flux t1 4.757727, binary loss 0.707834, binary loss t1 0.675618\n",
      "Epoch 7/10, Batch 1221/1650, Loss 17.668060, Loss rec 3.976936, loss rec t1 4.687053, loss kl 0.108951, loss_trans 0.007479, loss flux 4.554480, loss flux t1 4.333162, binary loss 0.948928, binary loss t1 0.995475\n",
      "Epoch 7/10, Batch 1231/1650, Loss 18.047153, Loss rec 3.629689, loss rec t1 4.824531, loss kl 0.153430, loss_trans 0.008146, loss flux 4.847418, loss flux t1 4.583939, binary loss 0.881418, binary loss t1 0.965668\n",
      "Epoch 7/10, Batch 1241/1650, Loss 21.863850, Loss rec 5.816300, loss rec t1 6.481404, loss kl 0.142873, loss_trans 0.013226, loss flux 4.909061, loss flux t1 4.500987, binary loss 1.485925, binary loss t1 1.502495\n",
      "Epoch 7/10, Batch 1251/1650, Loss 22.488922, Loss rec 5.249543, loss rec t1 7.042160, loss kl 0.173553, loss_trans 0.007669, loss flux 5.114248, loss flux t1 4.901749, binary loss 3.753188, binary loss t1 2.897417\n",
      "Epoch 7/10, Batch 1261/1650, Loss 26.071976, Loss rec 7.661750, loss rec t1 8.379289, loss kl 0.127903, loss_trans 0.006621, loss flux 5.027220, loss flux t1 4.869194, binary loss 0.480925, binary loss t1 0.539773\n",
      "Epoch 7/10, Batch 1271/1650, Loss 21.910583, Loss rec 4.910478, loss rec t1 7.129331, loss kl 0.145860, loss_trans 0.008534, loss flux 4.921587, loss flux t1 4.794795, binary loss 0.579312, binary loss t1 0.679744\n",
      "Epoch 7/10, Batch 1281/1650, Loss 22.891613, Loss rec 5.457734, loss rec t1 7.286890, loss kl 0.141734, loss_trans 0.007393, loss flux 5.294120, loss flux t1 4.703740, binary loss 1.580444, binary loss t1 1.565893\n",
      "Epoch 7/10, Batch 1291/1650, Loss 24.429201, Loss rec 6.664079, loss rec t1 6.813643, loss kl 0.192903, loss_trans 0.006501, loss flux 5.884649, loss flux t1 4.867427, binary loss 2.007349, binary loss t1 1.865651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10, Batch 1301/1650, Loss 25.625305, Loss rec 6.915058, loss rec t1 7.966034, loss kl 0.169945, loss_trans 0.005583, loss flux 5.685939, loss flux t1 4.882746, binary loss 1.675326, binary loss t1 1.505889\n",
      "Epoch 7/10, Batch 1311/1650, Loss 18.353062, Loss rec 3.978810, loss rec t1 4.716076, loss kl 0.294043, loss_trans 0.010888, loss flux 5.188653, loss flux t1 4.164591, binary loss 1.013238, binary loss t1 1.114033\n",
      "Epoch 7/10, Batch 1321/1650, Loss 21.499083, Loss rec 4.816691, loss rec t1 5.237829, loss kl 0.339826, loss_trans 0.007734, loss flux 6.019822, loss flux t1 5.077179, binary loss 0.701191, binary loss t1 0.614861\n",
      "Epoch 7/10, Batch 1331/1650, Loss 18.697258, Loss rec 4.166776, loss rec t1 5.449354, loss kl 0.137890, loss_trans 0.008482, loss flux 4.456089, loss flux t1 4.478668, binary loss 2.840844, binary loss t1 2.540866\n",
      "Epoch 7/10, Batch 1341/1650, Loss 22.216362, Loss rec 5.471627, loss rec t1 5.773714, loss kl 0.176308, loss_trans 0.005212, loss flux 5.765304, loss flux t1 5.024197, binary loss 1.447273, binary loss t1 1.274418\n",
      "Epoch 7/10, Batch 1351/1650, Loss 24.013832, Loss rec 6.452225, loss rec t1 7.952881, loss kl 0.169437, loss_trans 0.012463, loss flux 5.123854, loss flux t1 4.302972, binary loss 0.423978, binary loss t1 0.431666\n",
      "Epoch 7/10, Batch 1361/1650, Loss 35.252613, Loss rec 10.606232, loss rec t1 14.293098, loss kl 0.167058, loss_trans 0.006638, loss flux 4.923316, loss flux t1 5.256270, binary loss 3.576002, binary loss t1 3.525050\n",
      "Epoch 7/10, Batch 1371/1650, Loss 33.382851, Loss rec 9.777966, loss rec t1 12.801504, loss kl 0.134993, loss_trans 0.008303, loss flux 5.489412, loss flux t1 5.170668, binary loss 1.217230, binary loss t1 1.111508\n",
      "Epoch 7/10, Batch 1381/1650, Loss 30.270775, Loss rec 9.186052, loss rec t1 10.077982, loss kl 0.227505, loss_trans 0.007054, loss flux 5.633728, loss flux t1 5.138454, binary loss 2.739295, binary loss t1 2.286402\n",
      "Epoch 7/10, Batch 1391/1650, Loss 20.883024, Loss rec 5.410793, loss rec t1 5.587916, loss kl 0.154843, loss_trans 0.004109, loss flux 4.846674, loss flux t1 4.878689, binary loss 1.263493, binary loss t1 1.126468\n",
      "Epoch 7/10, Batch 1401/1650, Loss 34.823029, Loss rec 9.919491, loss rec t1 10.605595, loss kl 0.145577, loss_trans 0.008509, loss flux 7.943011, loss flux t1 6.200843, binary loss 1.542424, binary loss t1 1.450607\n",
      "Epoch 7/10, Batch 1411/1650, Loss 26.999741, Loss rec 6.921503, loss rec t1 7.616646, loss kl 0.113193, loss_trans 0.009285, loss flux 6.785284, loss flux t1 5.553830, binary loss 1.484744, binary loss t1 1.466009\n",
      "Epoch 7/10, Batch 1421/1650, Loss 23.842009, Loss rec 5.498424, loss rec t1 6.042532, loss kl 0.141896, loss_trans 0.006153, loss flux 6.623990, loss flux t1 5.529014, binary loss 1.884436, binary loss t1 1.699524\n",
      "Epoch 7/10, Batch 1431/1650, Loss 32.747684, Loss rec 14.361876, loss rec t1 6.639653, loss kl 0.428063, loss_trans 0.009090, loss flux 6.058891, loss flux t1 5.250112, binary loss 0.686579, binary loss t1 0.916797\n",
      "Epoch 7/10, Batch 1441/1650, Loss 32.702633, Loss rec 6.298567, loss rec t1 9.823753, loss kl 0.241550, loss_trans 0.008065, loss flux 8.167297, loss flux t1 8.163401, binary loss 1.605517, binary loss t1 1.511303\n",
      "Epoch 7/10, Batch 1451/1650, Loss 24.345303, Loss rec 5.856600, loss rec t1 6.312775, loss kl 0.170989, loss_trans 0.012820, loss flux 6.458428, loss flux t1 5.533692, binary loss 1.034309, binary loss t1 0.989988\n",
      "Epoch 7/10, Batch 1461/1650, Loss 18.726734, Loss rec 3.688196, loss rec t1 4.337038, loss kl 0.174887, loss_trans 0.006871, loss flux 5.619257, loss flux t1 4.900486, binary loss 1.837839, binary loss t1 1.444986\n",
      "Epoch 7/10, Batch 1471/1650, Loss 22.257338, Loss rec 5.056279, loss rec t1 5.717276, loss kl 0.185739, loss_trans 0.007486, loss flux 6.184521, loss flux t1 5.106036, binary loss 0.884874, binary loss t1 0.857330\n",
      "Epoch 7/10, Batch 1481/1650, Loss 29.064997, Loss rec 8.492775, loss rec t1 10.743710, loss kl 0.146797, loss_trans 0.007113, loss flux 4.985446, loss flux t1 4.689156, binary loss 0.361943, binary loss t1 0.457289\n",
      "Epoch 7/10, Batch 1491/1650, Loss 26.255705, Loss rec 6.475963, loss rec t1 7.942301, loss kl 0.197163, loss_trans 0.010931, loss flux 5.838579, loss flux t1 5.790767, binary loss 1.150592, binary loss t1 0.967895\n",
      "Epoch 7/10, Batch 1501/1650, Loss 20.758135, Loss rec 4.820266, loss rec t1 5.563013, loss kl 0.166375, loss_trans 0.015887, loss flux 5.136463, loss flux t1 5.056130, binary loss 0.494076, binary loss t1 0.629192\n",
      "Epoch 7/10, Batch 1511/1650, Loss 20.234602, Loss rec 4.853274, loss rec t1 5.581186, loss kl 0.165931, loss_trans 0.009825, loss flux 4.655372, loss flux t1 4.969012, binary loss 1.002008, binary loss t1 1.000998\n",
      "Epoch 7/10, Batch 1521/1650, Loss 19.301592, Loss rec 4.609639, loss rec t1 4.873491, loss kl 0.418687, loss_trans 0.006758, loss flux 5.105278, loss flux t1 4.287739, binary loss 7.571550, binary loss t1 3.021401\n",
      "Epoch 7/10, Batch 1531/1650, Loss 22.710270, Loss rec 5.308471, loss rec t1 6.196123, loss kl 0.275628, loss_trans 0.006272, loss flux 5.648970, loss flux t1 5.274808, binary loss 1.033117, binary loss t1 0.963357\n",
      "Epoch 7/10, Batch 1541/1650, Loss 23.708206, Loss rec 6.468946, loss rec t1 6.478884, loss kl 0.175845, loss_trans 0.009960, loss flux 5.408260, loss flux t1 5.166311, binary loss 3.933672, binary loss t1 3.465316\n",
      "Epoch 7/10, Batch 1551/1650, Loss 22.633501, Loss rec 5.921980, loss rec t1 5.173236, loss kl 0.318734, loss_trans 0.008066, loss flux 6.642171, loss flux t1 4.569314, binary loss 0.973309, binary loss t1 1.173708\n",
      "Epoch 7/10, Batch 1561/1650, Loss 19.014626, Loss rec 4.085253, loss rec t1 4.802910, loss kl 0.186479, loss_trans 0.006234, loss flux 5.634029, loss flux t1 4.299719, binary loss 0.756595, binary loss t1 0.696726\n",
      "Epoch 7/10, Batch 1571/1650, Loss 18.923763, Loss rec 4.445692, loss rec t1 4.253416, loss kl 0.301884, loss_trans 0.005428, loss flux 5.491177, loss flux t1 4.426166, binary loss 1.056281, binary loss t1 1.138158\n",
      "Epoch 7/10, Batch 1581/1650, Loss 23.880987, Loss rec 5.768491, loss rec t1 7.030124, loss kl 0.218533, loss_trans 0.009789, loss flux 5.545079, loss flux t1 5.308972, binary loss 1.023189, binary loss t1 1.106296\n",
      "Epoch 7/10, Batch 1591/1650, Loss 19.113306, Loss rec 3.793380, loss rec t1 4.756032, loss kl 0.205371, loss_trans 0.005901, loss flux 4.964664, loss flux t1 5.387957, binary loss 0.724270, binary loss t1 0.791791\n",
      "Epoch 7/10, Batch 1601/1650, Loss 20.046312, Loss rec 3.698017, loss rec t1 5.328766, loss kl 0.331608, loss_trans 0.005256, loss flux 5.884495, loss flux t1 4.798173, binary loss 4.118498, binary loss t1 2.005013\n",
      "Epoch 7/10, Batch 1611/1650, Loss 20.878813, Loss rec 4.699093, loss rec t1 5.579194, loss kl 0.140347, loss_trans 0.009423, loss flux 5.298096, loss flux t1 5.152660, binary loss 1.390774, binary loss t1 1.221399\n",
      "Epoch 7/10, Batch 1621/1650, Loss 19.234375, Loss rec 4.982664, loss rec t1 5.337625, loss kl 0.167879, loss_trans 0.006233, loss flux 4.407259, loss flux t1 4.332714, binary loss 1.432942, binary loss t1 1.296768\n",
      "Epoch 7/10, Batch 1631/1650, Loss 19.493294, Loss rec 4.750978, loss rec t1 4.851281, loss kl 0.214811, loss_trans 0.003991, loss flux 5.065501, loss flux t1 4.606734, binary loss 1.090613, binary loss t1 0.941068\n",
      "Epoch 7/10, Batch 1641/1650, Loss 22.903376, Loss rec 5.459927, loss rec t1 5.663205, loss kl 0.235815, loss_trans 0.007755, loss flux 6.055275, loss flux t1 5.481397, binary loss 1.473807, binary loss t1 1.342037\n",
      "Epoch 7/10, Train loss 19.277702, Eval loss 20.017437\n",
      "Epoch 8/10, Batch 1/1650, Loss 19.307285, Loss rec 4.112062, loss rec t1 4.669818, loss kl 0.176046, loss_trans 0.008381, loss flux 5.182498, loss flux t1 5.158481, binary loss 2.163427, binary loss t1 2.010756\n",
      "Epoch 8/10, Batch 11/1650, Loss 18.282188, Loss rec 4.044229, loss rec t1 4.263986, loss kl 0.142384, loss_trans 0.011539, loss flux 5.329252, loss flux t1 4.490800, binary loss 1.766972, binary loss t1 1.610870\n",
      "Epoch 8/10, Batch 21/1650, Loss 19.900558, Loss rec 5.109427, loss rec t1 4.931285, loss kl 0.211766, loss_trans 0.006076, loss flux 5.165479, loss flux t1 4.476525, binary loss 0.710948, binary loss t1 0.710972\n",
      "Epoch 8/10, Batch 31/1650, Loss 17.940348, Loss rec 4.099617, loss rec t1 4.611244, loss kl 0.132230, loss_trans 0.010901, loss flux 4.646047, loss flux t1 4.440310, binary loss 3.433160, binary loss t1 2.921700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Batch 41/1650, Loss 19.660061, Loss rec 5.119111, loss rec t1 5.099163, loss kl 0.158697, loss_trans 0.008737, loss flux 5.016962, loss flux t1 4.257393, binary loss 1.505938, binary loss t1 1.416140\n",
      "Epoch 8/10, Batch 51/1650, Loss 20.224113, Loss rec 4.567098, loss rec t1 5.688072, loss kl 0.179756, loss_trans 0.009269, loss flux 5.243893, loss flux t1 4.536025, binary loss 3.877172, binary loss t1 2.824286\n",
      "Epoch 8/10, Batch 61/1650, Loss 27.709999, Loss rec 6.994487, loss rec t1 9.160056, loss kl 0.162036, loss_trans 0.010216, loss flux 5.752674, loss flux t1 5.630528, binary loss 0.784627, binary loss t1 0.893514\n",
      "Epoch 8/10, Batch 71/1650, Loss 25.280989, Loss rec 7.849191, loss rec t1 6.632216, loss kl 0.171906, loss_trans 0.005968, loss flux 5.730947, loss flux t1 4.890758, binary loss 0.481438, binary loss t1 0.513471\n",
      "Epoch 8/10, Batch 81/1650, Loss 20.584122, Loss rec 5.320549, loss rec t1 5.591137, loss kl 0.151974, loss_trans 0.009103, loss flux 5.126084, loss flux t1 4.385277, binary loss 1.001206, binary loss t1 0.895009\n",
      "Epoch 8/10, Batch 91/1650, Loss 21.495068, Loss rec 5.661045, loss rec t1 6.054608, loss kl 0.212082, loss_trans 0.004945, loss flux 4.815300, loss flux t1 4.747089, binary loss 2.549699, binary loss t1 2.138973\n",
      "Epoch 8/10, Batch 101/1650, Loss 19.308767, Loss rec 4.415468, loss rec t1 4.811689, loss kl 0.142598, loss_trans 0.008699, loss flux 5.250937, loss flux t1 4.679375, binary loss 2.274175, binary loss t1 1.953040\n",
      "Epoch 8/10, Batch 111/1650, Loss 23.287977, Loss rec 6.242974, loss rec t1 6.485015, loss kl 0.188138, loss_trans 0.008739, loss flux 5.556725, loss flux t1 4.806385, binary loss 1.028774, binary loss t1 0.935679\n",
      "Epoch 8/10, Batch 121/1650, Loss 22.105997, Loss rec 5.799879, loss rec t1 6.230667, loss kl 0.204927, loss_trans 0.005092, loss flux 5.228071, loss flux t1 4.637360, binary loss 1.038579, binary loss t1 0.945606\n",
      "Epoch 8/10, Batch 131/1650, Loss 22.475077, Loss rec 6.071980, loss rec t1 6.636601, loss kl 0.180278, loss_trans 0.005637, loss flux 4.875547, loss flux t1 4.705032, binary loss 1.068703, binary loss t1 0.965949\n",
      "Epoch 8/10, Batch 141/1650, Loss 30.644770, Loss rec 12.688894, loss rec t1 5.870112, loss kl 0.252753, loss_trans 0.011514, loss flux 6.526043, loss flux t1 5.295454, binary loss 1.511254, binary loss t1 1.300940\n",
      "Epoch 8/10, Batch 151/1650, Loss 19.468649, Loss rec 4.117361, loss rec t1 5.317295, loss kl 0.131226, loss_trans 0.008379, loss flux 5.234518, loss flux t1 4.659871, binary loss 1.603376, binary loss t1 1.638852\n",
      "Epoch 8/10, Batch 161/1650, Loss 20.260286, Loss rec 4.794632, loss rec t1 4.733006, loss kl 0.196268, loss_trans 0.011714, loss flux 5.869900, loss flux t1 4.654768, binary loss 1.232470, binary loss t1 1.078545\n",
      "Epoch 8/10, Batch 171/1650, Loss 18.800634, Loss rec 4.177364, loss rec t1 4.539214, loss kl 0.149969, loss_trans 0.012203, loss flux 5.400139, loss flux t1 4.521744, binary loss 2.148998, binary loss t1 2.175642\n",
      "Epoch 8/10, Batch 181/1650, Loss 16.747864, Loss rec 3.891937, loss rec t1 4.089158, loss kl 0.170376, loss_trans 0.004478, loss flux 4.458208, loss flux t1 4.133707, binary loss 1.438246, binary loss t1 1.427297\n",
      "Epoch 8/10, Batch 191/1650, Loss 19.612808, Loss rec 5.047646, loss rec t1 4.997102, loss kl 0.187471, loss_trans 0.006970, loss flux 5.115737, loss flux t1 4.257883, binary loss 2.407028, binary loss t1 1.573313\n",
      "Epoch 8/10, Batch 201/1650, Loss 14.985759, Loss rec 3.173503, loss rec t1 3.387558, loss kl 0.153521, loss_trans 0.013480, loss flux 4.452385, loss flux t1 3.805311, binary loss 1.546730, binary loss t1 1.213478\n",
      "Epoch 8/10, Batch 211/1650, Loss 20.313648, Loss rec 5.231188, loss rec t1 5.715737, loss kl 0.130183, loss_trans 0.014489, loss flux 4.797903, loss flux t1 4.424150, binary loss 0.894972, binary loss t1 0.933574\n",
      "Epoch 8/10, Batch 221/1650, Loss 20.704363, Loss rec 4.933461, loss rec t1 5.282216, loss kl 0.207680, loss_trans 0.005742, loss flux 5.396999, loss flux t1 4.878266, binary loss 2.543240, binary loss t1 2.394813\n",
      "Epoch 8/10, Batch 231/1650, Loss 17.331530, Loss rec 3.974728, loss rec t1 4.178419, loss kl 0.127639, loss_trans 0.012529, loss flux 4.998611, loss flux t1 4.039602, binary loss 1.474854, binary loss t1 1.302083\n",
      "Epoch 8/10, Batch 241/1650, Loss 18.002811, Loss rec 3.556945, loss rec t1 4.291878, loss kl 0.261664, loss_trans 0.006238, loss flux 5.412395, loss flux t1 4.473692, binary loss 4.617805, binary loss t1 2.836501\n",
      "Epoch 8/10, Batch 251/1650, Loss 13.967758, Loss rec 2.515647, loss rec t1 3.844236, loss kl 0.124642, loss_trans 0.009277, loss flux 3.795118, loss flux t1 3.678838, binary loss 1.090650, binary loss t1 1.130616\n",
      "Epoch 8/10, Batch 261/1650, Loss 17.899136, Loss rec 3.991561, loss rec t1 4.589163, loss kl 0.273782, loss_trans 0.005786, loss flux 4.685938, loss flux t1 4.352904, binary loss 1.465912, binary loss t1 1.591112\n",
      "Epoch 8/10, Batch 271/1650, Loss 15.011234, Loss rec 2.855284, loss rec t1 3.728441, loss kl 0.119031, loss_trans 0.010097, loss flux 4.156322, loss flux t1 4.142059, binary loss 1.819079, binary loss t1 1.706118\n",
      "Epoch 8/10, Batch 281/1650, Loss 17.786257, Loss rec 4.217415, loss rec t1 4.640993, loss kl 0.177119, loss_trans 0.009342, loss flux 4.726281, loss flux t1 4.015106, binary loss 1.313313, binary loss t1 1.109581\n",
      "Epoch 8/10, Batch 291/1650, Loss 17.974894, Loss rec 4.306490, loss rec t1 4.886767, loss kl 0.171821, loss_trans 0.011284, loss flux 4.209670, loss flux t1 4.388863, binary loss 0.898001, binary loss t1 1.026499\n",
      "Epoch 8/10, Batch 301/1650, Loss 21.989613, Loss rec 5.583014, loss rec t1 5.992338, loss kl 0.184417, loss_trans 0.004005, loss flux 5.323062, loss flux t1 4.902776, binary loss 0.548459, binary loss t1 0.601746\n",
      "Epoch 8/10, Batch 311/1650, Loss 23.576893, Loss rec 6.204135, loss rec t1 6.714861, loss kl 0.179161, loss_trans 0.011713, loss flux 5.184341, loss flux t1 5.282681, binary loss 0.606989, binary loss t1 0.602793\n",
      "Epoch 8/10, Batch 321/1650, Loss 15.548098, Loss rec 3.308626, loss rec t1 3.590174, loss kl 0.167819, loss_trans 0.007492, loss flux 4.669379, loss flux t1 3.804607, binary loss 1.281000, binary loss t1 1.184754\n",
      "Epoch 8/10, Batch 331/1650, Loss 20.565378, Loss rec 4.977491, loss rec t1 5.567197, loss kl 0.182925, loss_trans 0.010238, loss flux 4.780425, loss flux t1 5.047101, binary loss 1.506935, binary loss t1 1.386260\n",
      "Epoch 8/10, Batch 341/1650, Loss 21.803009, Loss rec 5.002683, loss rec t1 6.226684, loss kl 0.143429, loss_trans 0.009011, loss flux 5.291084, loss flux t1 5.130119, binary loss 2.573156, binary loss t1 2.120445\n",
      "Epoch 8/10, Batch 351/1650, Loss 19.502012, Loss rec 5.065662, loss rec t1 5.339555, loss kl 0.165429, loss_trans 0.010515, loss flux 4.464449, loss flux t1 4.456403, binary loss 0.689013, binary loss t1 0.681202\n",
      "Epoch 8/10, Batch 361/1650, Loss 17.573711, Loss rec 3.790177, loss rec t1 4.189941, loss kl 0.264389, loss_trans 0.005786, loss flux 4.854735, loss flux t1 4.468681, binary loss 1.746047, binary loss t1 1.579968\n",
      "Epoch 8/10, Batch 371/1650, Loss 18.365313, Loss rec 4.504045, loss rec t1 4.596790, loss kl 0.175313, loss_trans 0.010612, loss flux 4.670846, loss flux t1 4.407706, binary loss 1.830419, binary loss t1 1.362148\n",
      "Epoch 8/10, Batch 381/1650, Loss 26.005638, Loss rec 6.679082, loss rec t1 8.163531, loss kl 0.253439, loss_trans 0.011969, loss flux 5.410958, loss flux t1 5.486659, binary loss 0.604665, binary loss t1 0.632282\n",
      "Epoch 8/10, Batch 391/1650, Loss 20.807533, Loss rec 5.384274, loss rec t1 6.143626, loss kl 0.224314, loss_trans 0.006394, loss flux 4.554088, loss flux t1 4.494838, binary loss 0.440304, binary loss t1 0.479977\n",
      "Epoch 8/10, Batch 401/1650, Loss 24.620821, Loss rec 6.196565, loss rec t1 7.676905, loss kl 0.312272, loss_trans 0.006295, loss flux 5.265489, loss flux t1 5.163295, binary loss 0.399121, binary loss t1 0.482752\n",
      "Epoch 8/10, Batch 411/1650, Loss 26.341713, Loss rec 7.673401, loss rec t1 8.613842, loss kl 0.205429, loss_trans 0.005280, loss flux 5.085186, loss flux t1 4.758575, binary loss 0.793447, binary loss t1 0.603949\n",
      "Epoch 8/10, Batch 421/1650, Loss 26.731485, Loss rec 6.476221, loss rec t1 9.735866, loss kl 0.146399, loss_trans 0.011032, loss flux 4.894319, loss flux t1 5.467649, binary loss 2.617294, binary loss t1 2.630689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Batch 431/1650, Loss 21.987394, Loss rec 5.390249, loss rec t1 7.305764, loss kl 0.146062, loss_trans 0.007180, loss flux 4.876445, loss flux t1 4.261696, binary loss 1.419449, binary loss t1 1.293385\n",
      "Epoch 8/10, Batch 441/1650, Loss 30.654219, Loss rec 8.822576, loss rec t1 11.283159, loss kl 0.213374, loss_trans 0.008203, loss flux 5.378874, loss flux t1 4.948031, binary loss 0.346321, binary loss t1 0.355581\n",
      "Epoch 8/10, Batch 451/1650, Loss 24.296522, Loss rec 7.697705, loss rec t1 5.276381, loss kl 0.271292, loss_trans 0.009812, loss flux 6.346161, loss flux t1 4.695168, binary loss 0.520525, binary loss t1 0.634533\n",
      "Epoch 8/10, Batch 461/1650, Loss 26.454655, Loss rec 7.002382, loss rec t1 7.222526, loss kl 0.223611, loss_trans 0.007767, loss flux 6.348382, loss flux t1 5.649987, binary loss 1.032278, binary loss t1 0.936847\n",
      "Epoch 8/10, Batch 471/1650, Loss 18.842215, Loss rec 4.438117, loss rec t1 4.946487, loss kl 0.161806, loss_trans 0.007056, loss flux 4.924435, loss flux t1 4.364314, binary loss 4.521462, binary loss t1 3.528384\n",
      "Epoch 8/10, Batch 481/1650, Loss 21.836233, Loss rec 5.130803, loss rec t1 5.977832, loss kl 0.170090, loss_trans 0.006246, loss flux 5.668654, loss flux t1 4.882606, binary loss 1.392879, binary loss t1 1.322109\n",
      "Epoch 8/10, Batch 491/1650, Loss 18.088873, Loss rec 4.511329, loss rec t1 4.376074, loss kl 0.160940, loss_trans 0.005628, loss flux 4.775108, loss flux t1 4.259793, binary loss 0.845893, binary loss t1 0.772885\n",
      "Epoch 8/10, Batch 501/1650, Loss 17.022736, Loss rec 3.465608, loss rec t1 3.741045, loss kl 0.187892, loss_trans 0.013402, loss flux 5.365924, loss flux t1 4.248864, binary loss 1.646334, binary loss t1 1.344068\n",
      "Epoch 8/10, Batch 511/1650, Loss 16.710266, Loss rec 3.292733, loss rec t1 3.562351, loss kl 0.303220, loss_trans 0.003765, loss flux 5.134771, loss flux t1 4.413425, binary loss 2.385932, binary loss t1 1.718357\n",
      "Epoch 8/10, Batch 521/1650, Loss 14.970869, Loss rec 3.000176, loss rec t1 3.549741, loss kl 0.134081, loss_trans 0.005978, loss flux 4.499704, loss flux t1 3.781189, binary loss 3.151031, binary loss t1 2.505598\n",
      "Epoch 8/10, Batch 531/1650, Loss 22.133934, Loss rec 6.036953, loss rec t1 7.199676, loss kl 0.172077, loss_trans 0.005346, loss flux 4.400778, loss flux t1 4.319103, binary loss 0.645375, binary loss t1 0.646690\n",
      "Epoch 8/10, Batch 541/1650, Loss 17.552059, Loss rec 4.033238, loss rec t1 4.135181, loss kl 0.303732, loss_trans 0.010649, loss flux 4.770734, loss flux t1 4.298525, binary loss 0.677734, binary loss t1 0.766291\n",
      "Epoch 8/10, Batch 551/1650, Loss 20.246344, Loss rec 4.574755, loss rec t1 5.240089, loss kl 0.318433, loss_trans 0.006529, loss flux 5.068110, loss flux t1 5.038429, binary loss 0.576951, binary loss t1 0.646809\n",
      "Epoch 8/10, Batch 561/1650, Loss 21.634295, Loss rec 5.352204, loss rec t1 6.772661, loss kl 0.175686, loss_trans 0.013362, loss flux 4.795981, loss flux t1 4.524400, binary loss 1.294285, binary loss t1 1.193538\n",
      "Epoch 8/10, Batch 571/1650, Loss 24.153748, Loss rec 6.090808, loss rec t1 8.552435, loss kl 0.127762, loss_trans 0.006092, loss flux 4.465847, loss flux t1 4.910804, binary loss 0.416688, binary loss t1 0.611747\n",
      "Epoch 8/10, Batch 581/1650, Loss 23.655214, Loss rec 6.106540, loss rec t1 6.433805, loss kl 0.263487, loss_trans 0.014679, loss flux 6.052073, loss flux t1 4.784629, binary loss 0.739794, binary loss t1 0.833898\n",
      "Epoch 8/10, Batch 591/1650, Loss 24.356852, Loss rec 6.177740, loss rec t1 7.360386, loss kl 0.156353, loss_trans 0.007589, loss flux 5.778561, loss flux t1 4.876222, binary loss 0.691008, binary loss t1 0.654802\n",
      "Epoch 8/10, Batch 601/1650, Loss 26.763664, Loss rec 8.312395, loss rec t1 7.325528, loss kl 0.153537, loss_trans 0.012698, loss flux 5.857522, loss flux t1 5.101985, binary loss 1.541109, binary loss t1 1.444901\n",
      "Epoch 8/10, Batch 611/1650, Loss 24.195007, Loss rec 6.104553, loss rec t1 6.123290, loss kl 0.312183, loss_trans 0.009592, loss flux 6.598532, loss flux t1 5.046858, binary loss 3.630275, binary loss t1 2.837706\n",
      "Epoch 8/10, Batch 621/1650, Loss 28.749226, Loss rec 8.188210, loss rec t1 8.845870, loss kl 0.191647, loss_trans 0.006537, loss flux 6.143402, loss flux t1 5.373560, binary loss 0.691435, binary loss t1 0.688223\n",
      "Epoch 8/10, Batch 631/1650, Loss 23.302580, Loss rec 5.706071, loss rec t1 6.293322, loss kl 0.191998, loss_trans 0.012017, loss flux 5.801476, loss flux t1 5.297696, binary loss 1.561184, binary loss t1 1.212456\n",
      "Epoch 8/10, Batch 641/1650, Loss 23.971981, Loss rec 6.637599, loss rec t1 7.112022, loss kl 0.169256, loss_trans 0.011063, loss flux 5.189147, loss flux t1 4.852895, binary loss 1.823789, binary loss t1 1.720632\n",
      "Epoch 8/10, Batch 651/1650, Loss 20.839289, Loss rec 4.664828, loss rec t1 5.807028, loss kl 0.159590, loss_trans 0.008170, loss flux 5.311821, loss flux t1 4.887851, binary loss 1.665191, binary loss t1 1.695205\n",
      "Epoch 8/10, Batch 661/1650, Loss 17.717791, Loss rec 3.688743, loss rec t1 4.986935, loss kl 0.132276, loss_trans 0.008177, loss flux 4.442378, loss flux t1 4.459280, binary loss 3.659023, binary loss t1 3.382258\n",
      "Epoch 8/10, Batch 671/1650, Loss 21.267405, Loss rec 5.269490, loss rec t1 4.992963, loss kl 0.194537, loss_trans 0.009948, loss flux 5.753279, loss flux t1 5.047185, binary loss 1.123875, binary loss t1 1.047656\n",
      "Epoch 8/10, Batch 681/1650, Loss 17.646389, Loss rec 3.485482, loss rec t1 5.498989, loss kl 0.133196, loss_trans 0.013264, loss flux 4.226888, loss flux t1 4.288571, binary loss 1.533433, binary loss t1 1.674085\n",
      "Epoch 8/10, Batch 691/1650, Loss 20.802286, Loss rec 5.541909, loss rec t1 6.358126, loss kl 0.180102, loss_trans 0.009767, loss flux 4.487473, loss flux t1 4.224909, binary loss 0.907089, binary loss t1 0.836222\n",
      "Epoch 8/10, Batch 701/1650, Loss 17.459301, Loss rec 4.568100, loss rec t1 4.807128, loss kl 0.143693, loss_trans 0.010869, loss flux 4.023684, loss flux t1 3.905828, binary loss 0.667929, binary loss t1 0.640142\n",
      "Epoch 8/10, Batch 711/1650, Loss 18.324081, Loss rec 3.867423, loss rec t1 4.725354, loss kl 0.267798, loss_trans 0.005611, loss flux 4.870853, loss flux t1 4.587042, binary loss 0.937869, binary loss t1 0.756278\n",
      "Epoch 8/10, Batch 721/1650, Loss 20.758728, Loss rec 4.983921, loss rec t1 5.704439, loss kl 0.154606, loss_trans 0.010337, loss flux 4.980649, loss flux t1 4.924776, binary loss 2.935022, binary loss t1 2.592901\n",
      "Epoch 8/10, Batch 731/1650, Loss 19.150082, Loss rec 4.455588, loss rec t1 5.166940, loss kl 0.200258, loss_trans 0.009606, loss flux 4.715568, loss flux t1 4.602123, binary loss 1.507969, binary loss t1 1.349665\n",
      "Epoch 8/10, Batch 741/1650, Loss 19.775452, Loss rec 4.570809, loss rec t1 5.805598, loss kl 0.164628, loss_trans 0.010686, loss flux 4.631720, loss flux t1 4.592010, binary loss 1.782630, binary loss t1 1.658756\n",
      "Epoch 8/10, Batch 751/1650, Loss 19.677851, Loss rec 4.721450, loss rec t1 5.177252, loss kl 0.145758, loss_trans 0.004410, loss flux 4.971576, loss flux t1 4.657404, binary loss 2.013882, binary loss t1 1.771449\n",
      "Epoch 8/10, Batch 761/1650, Loss 16.561867, Loss rec 3.285613, loss rec t1 4.246474, loss kl 0.125629, loss_trans 0.005397, loss flux 4.682299, loss flux t1 4.216454, binary loss 1.701726, binary loss t1 1.544419\n",
      "Epoch 8/10, Batch 771/1650, Loss 21.300112, Loss rec 4.900825, loss rec t1 5.983443, loss kl 0.231956, loss_trans 0.009190, loss flux 5.391379, loss flux t1 4.783319, binary loss 1.610955, binary loss t1 1.360736\n",
      "Epoch 8/10, Batch 781/1650, Loss 21.960447, Loss rec 6.034004, loss rec t1 6.106092, loss kl 0.193822, loss_trans 0.005208, loss flux 5.047355, loss flux t1 4.573966, binary loss 0.980305, binary loss t1 0.894935\n",
      "Epoch 8/10, Batch 791/1650, Loss 17.655710, Loss rec 4.626087, loss rec t1 4.116759, loss kl 0.164591, loss_trans 0.008813, loss flux 4.405422, loss flux t1 4.334038, binary loss 1.156116, binary loss t1 0.936798\n",
      "Epoch 8/10, Batch 801/1650, Loss 16.480040, Loss rec 3.593539, loss rec t1 4.310681, loss kl 0.149642, loss_trans 0.009183, loss flux 4.260018, loss flux t1 4.156978, binary loss 1.290076, binary loss t1 1.187103\n",
      "Epoch 8/10, Batch 811/1650, Loss 20.637375, Loss rec 4.437370, loss rec t1 6.552457, loss kl 0.278693, loss_trans 0.007132, loss flux 4.965366, loss flux t1 4.396357, binary loss 0.457822, binary loss t1 0.482740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Batch 821/1650, Loss 44.902695, Loss rec 17.146048, loss rec t1 17.781675, loss kl 0.167002, loss_trans 0.004411, loss flux 5.091097, loss flux t1 4.712465, binary loss 0.286956, binary loss t1 0.264215\n",
      "Epoch 8/10, Batch 831/1650, Loss 25.263668, Loss rec 7.350395, loss rec t1 8.450851, loss kl 0.129356, loss_trans 0.009778, loss flux 4.801074, loss flux t1 4.522215, binary loss 1.082574, binary loss t1 1.303984\n",
      "Epoch 8/10, Batch 841/1650, Loss 18.388130, Loss rec 4.407837, loss rec t1 4.895665, loss kl 0.143291, loss_trans 0.007079, loss flux 4.680902, loss flux t1 4.253356, binary loss 1.991825, binary loss t1 1.923233\n",
      "Epoch 8/10, Batch 851/1650, Loss 19.881786, Loss rec 5.250779, loss rec t1 5.239128, loss kl 0.139580, loss_trans 0.011449, loss flux 5.021149, loss flux t1 4.219701, binary loss 3.087791, binary loss t1 2.015026\n",
      "Epoch 8/10, Batch 861/1650, Loss 29.504267, Loss rec 7.672158, loss rec t1 10.047570, loss kl 0.299986, loss_trans 0.009476, loss flux 6.119540, loss flux t1 5.355537, binary loss 2.314616, binary loss t1 2.540116\n",
      "Epoch 8/10, Batch 871/1650, Loss 24.258373, Loss rec 5.543654, loss rec t1 7.912044, loss kl 0.184319, loss_trans 0.005555, loss flux 5.512302, loss flux t1 5.100497, binary loss 0.456508, binary loss t1 0.480986\n",
      "Epoch 8/10, Batch 881/1650, Loss 19.716518, Loss rec 4.339136, loss rec t1 5.755694, loss kl 0.135345, loss_trans 0.010384, loss flux 4.491288, loss flux t1 4.984672, binary loss 1.947516, binary loss t1 1.904437\n",
      "Epoch 8/10, Batch 891/1650, Loss 20.096952, Loss rec 4.880223, loss rec t1 5.269194, loss kl 0.156504, loss_trans 0.005276, loss flux 5.410799, loss flux t1 4.374958, binary loss 1.232384, binary loss t1 1.241546\n",
      "Epoch 8/10, Batch 901/1650, Loss 21.541706, Loss rec 5.903707, loss rec t1 6.295578, loss kl 0.132855, loss_trans 0.005178, loss flux 4.718780, loss flux t1 4.485609, binary loss 1.648682, binary loss t1 1.715182\n",
      "Epoch 8/10, Batch 911/1650, Loss 31.042513, Loss rec 12.346949, loss rec t1 7.781337, loss kl 0.147973, loss_trans 0.005339, loss flux 5.556462, loss flux t1 5.204453, binary loss 5.070808, binary loss t1 4.377586\n",
      "Epoch 8/10, Batch 921/1650, Loss 36.189835, Loss rec 9.496103, loss rec t1 13.209549, loss kl 0.212871, loss_trans 0.006049, loss flux 6.871836, loss flux t1 6.393426, binary loss 1.138451, binary loss t1 1.137368\n",
      "Epoch 8/10, Batch 931/1650, Loss 29.489367, Loss rec 6.867596, loss rec t1 8.232497, loss kl 0.193477, loss_trans 0.011218, loss flux 7.386793, loss flux t1 6.797786, binary loss 1.536876, binary loss t1 1.391942\n",
      "Epoch 8/10, Batch 941/1650, Loss 19.714149, Loss rec 4.368790, loss rec t1 4.577664, loss kl 0.162353, loss_trans 0.018271, loss flux 5.236342, loss flux t1 5.350731, binary loss 2.227542, binary loss t1 2.557583\n",
      "Epoch 8/10, Batch 951/1650, Loss 17.880735, Loss rec 3.504831, loss rec t1 4.214266, loss kl 0.133580, loss_trans 0.005648, loss flux 5.067151, loss flux t1 4.955261, binary loss 1.093935, binary loss t1 0.940107\n",
      "Epoch 8/10, Batch 961/1650, Loss 18.129982, Loss rec 4.021708, loss rec t1 4.818960, loss kl 0.178419, loss_trans 0.006891, loss flux 4.605412, loss flux t1 4.498593, binary loss 1.761546, binary loss t1 1.809140\n",
      "Epoch 8/10, Batch 971/1650, Loss 17.015375, Loss rec 3.438173, loss rec t1 4.819551, loss kl 0.138358, loss_trans 0.005122, loss flux 4.477393, loss flux t1 4.136780, binary loss 0.497227, binary loss t1 0.468857\n",
      "Epoch 8/10, Batch 981/1650, Loss 18.439697, Loss rec 4.115471, loss rec t1 4.205170, loss kl 0.147104, loss_trans 0.014945, loss flux 5.404254, loss flux t1 4.552753, binary loss 2.865421, binary loss t1 2.382611\n",
      "Epoch 8/10, Batch 991/1650, Loss 21.811451, Loss rec 5.452518, loss rec t1 5.733897, loss kl 0.139737, loss_trans 0.011967, loss flux 5.546858, loss flux t1 4.926476, binary loss 2.486606, binary loss t1 2.109094\n",
      "Epoch 8/10, Batch 1001/1650, Loss 17.648783, Loss rec 4.139660, loss rec t1 3.683820, loss kl 0.127125, loss_trans 0.007318, loss flux 5.015274, loss flux t1 4.675585, binary loss 0.987554, binary loss t1 0.959974\n",
      "Epoch 8/10, Batch 1011/1650, Loss 18.033255, Loss rec 4.100322, loss rec t1 4.413268, loss kl 0.127219, loss_trans 0.005477, loss flux 4.828174, loss flux t1 4.558794, binary loss 1.654328, binary loss t1 1.525891\n",
      "Epoch 8/10, Batch 1021/1650, Loss 22.020483, Loss rec 4.633607, loss rec t1 6.222443, loss kl 0.295860, loss_trans 0.008519, loss flux 5.280792, loss flux t1 5.579263, binary loss 0.671141, binary loss t1 0.613778\n",
      "Epoch 8/10, Batch 1031/1650, Loss 21.150414, Loss rec 4.186562, loss rec t1 6.681843, loss kl 0.134545, loss_trans 0.006996, loss flux 5.172307, loss flux t1 4.968161, binary loss 1.476132, binary loss t1 1.590359\n",
      "Epoch 8/10, Batch 1041/1650, Loss 18.653702, Loss rec 4.141809, loss rec t1 5.296517, loss kl 0.144621, loss_trans 0.010110, loss flux 4.483200, loss flux t1 4.577444, binary loss 1.162722, binary loss t1 1.194901\n",
      "Epoch 8/10, Batch 1051/1650, Loss 18.653742, Loss rec 3.912249, loss rec t1 4.910154, loss kl 0.240884, loss_trans 0.010561, loss flux 5.040318, loss flux t1 4.539575, binary loss 1.112743, binary loss t1 1.200486\n",
      "Epoch 8/10, Batch 1061/1650, Loss 15.346532, Loss rec 3.067469, loss rec t1 3.842378, loss kl 0.132437, loss_trans 0.007921, loss flux 4.161448, loss flux t1 4.134880, binary loss 1.203563, binary loss t1 1.237993\n",
      "Epoch 8/10, Batch 1071/1650, Loss 20.682808, Loss rec 5.093873, loss rec t1 5.650760, loss kl 0.322949, loss_trans 0.007126, loss flux 4.998749, loss flux t1 4.609352, binary loss 0.478918, binary loss t1 0.590846\n",
      "Epoch 8/10, Batch 1081/1650, Loss 20.384550, Loss rec 4.904874, loss rec t1 4.533289, loss kl 0.162235, loss_trans 0.010213, loss flux 6.085852, loss flux t1 4.688087, binary loss 2.133474, binary loss t1 1.820260\n",
      "Epoch 8/10, Batch 1091/1650, Loss 21.968140, Loss rec 5.232855, loss rec t1 5.227535, loss kl 0.220146, loss_trans 0.008415, loss flux 5.986879, loss flux t1 5.292308, binary loss 1.366430, binary loss t1 1.202505\n",
      "Epoch 8/10, Batch 1101/1650, Loss 20.565231, Loss rec 4.901508, loss rec t1 5.181837, loss kl 0.168313, loss_trans 0.006837, loss flux 5.786582, loss flux t1 4.520153, binary loss 2.005074, binary loss t1 1.837913\n",
      "Epoch 8/10, Batch 1111/1650, Loss 19.911287, Loss rec 4.830876, loss rec t1 6.059117, loss kl 0.169298, loss_trans 0.012686, loss flux 4.431919, loss flux t1 4.407391, binary loss 1.295380, binary loss t1 1.341854\n",
      "Epoch 8/10, Batch 1121/1650, Loss 19.332310, Loss rec 4.786540, loss rec t1 5.121010, loss kl 0.156538, loss_trans 0.008467, loss flux 5.058695, loss flux t1 4.201059, binary loss 1.497008, binary loss t1 1.390677\n",
      "Epoch 8/10, Batch 1131/1650, Loss 23.115135, Loss rec 6.219609, loss rec t1 7.294086, loss kl 0.143557, loss_trans 0.004017, loss flux 4.757723, loss flux t1 4.696145, binary loss 0.559310, binary loss t1 0.540538\n",
      "Epoch 8/10, Batch 1141/1650, Loss 15.118069, Loss rec 2.629702, loss rec t1 3.775057, loss kl 0.173122, loss_trans 0.012505, loss flux 4.553929, loss flux t1 3.973753, binary loss 0.967748, binary loss t1 0.872720\n",
      "Epoch 8/10, Batch 1151/1650, Loss 22.166136, Loss rec 5.685021, loss rec t1 6.416383, loss kl 0.166618, loss_trans 0.009073, loss flux 4.661853, loss flux t1 5.227189, binary loss 3.114337, binary loss t1 2.853108\n",
      "Epoch 8/10, Batch 1161/1650, Loss 17.725985, Loss rec 4.497104, loss rec t1 4.667656, loss kl 0.152502, loss_trans 0.008843, loss flux 4.382939, loss flux t1 4.016941, binary loss 2.305064, binary loss t1 2.054955\n",
      "Epoch 8/10, Batch 1171/1650, Loss 13.545517, Loss rec 2.736758, loss rec t1 3.475898, loss kl 0.110446, loss_trans 0.006666, loss flux 3.591005, loss flux t1 3.624744, binary loss 1.443794, binary loss t1 1.479172\n",
      "Epoch 8/10, Batch 1181/1650, Loss 19.425365, Loss rec 4.570551, loss rec t1 5.280158, loss kl 0.147825, loss_trans 0.007272, loss flux 5.201921, loss flux t1 4.217638, binary loss 1.501729, binary loss t1 1.343583\n",
      "Epoch 8/10, Batch 1191/1650, Loss 17.772434, Loss rec 4.372783, loss rec t1 5.263375, loss kl 0.135799, loss_trans 0.007854, loss flux 4.022700, loss flux t1 3.969922, binary loss 0.925837, binary loss t1 0.983431\n",
      "Epoch 8/10, Batch 1201/1650, Loss 24.050592, Loss rec 6.184836, loss rec t1 6.314595, loss kl 0.235569, loss_trans 0.009712, loss flux 6.056236, loss flux t1 5.249645, binary loss 0.814214, binary loss t1 0.690462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Batch 1211/1650, Loss 18.882975, Loss rec 4.417554, loss rec t1 4.601692, loss kl 0.204342, loss_trans 0.005536, loss flux 5.073377, loss flux t1 4.580472, binary loss 0.837268, binary loss t1 0.795186\n",
      "Epoch 8/10, Batch 1221/1650, Loss 15.313682, Loss rec 3.156711, loss rec t1 3.725945, loss kl 0.107829, loss_trans 0.007759, loss flux 4.201476, loss flux t1 4.113962, binary loss 1.224549, binary loss t1 1.296536\n",
      "Epoch 8/10, Batch 1231/1650, Loss 14.791578, Loss rec 2.971267, loss rec t1 3.888231, loss kl 0.146328, loss_trans 0.007657, loss flux 3.964282, loss flux t1 3.813811, binary loss 0.769527, binary loss t1 0.872635\n",
      "Epoch 8/10, Batch 1241/1650, Loss 18.240164, Loss rec 4.650638, loss rec t1 5.298991, loss kl 0.142881, loss_trans 0.013361, loss flux 4.280360, loss flux t1 3.853931, binary loss 0.859191, binary loss t1 0.812851\n",
      "Epoch 8/10, Batch 1251/1650, Loss 16.052029, Loss rec 3.735558, loss rec t1 4.099460, loss kl 0.166105, loss_trans 0.007545, loss flux 4.199467, loss flux t1 3.843895, binary loss 1.092901, binary loss t1 0.921335\n",
      "Epoch 8/10, Batch 1261/1650, Loss 15.726547, Loss rec 3.358352, loss rec t1 4.060658, loss kl 0.127673, loss_trans 0.006121, loss flux 4.173587, loss flux t1 4.000154, binary loss 1.579956, binary loss t1 1.538993\n",
      "Epoch 8/10, Batch 1271/1650, Loss 14.934530, Loss rec 2.699636, loss rec t1 4.133878, loss kl 0.131167, loss_trans 0.007353, loss flux 4.018373, loss flux t1 3.944123, binary loss 2.450108, binary loss t1 2.253030\n",
      "Epoch 8/10, Batch 1281/1650, Loss 17.096607, Loss rec 3.702804, loss rec t1 4.884905, loss kl 0.140754, loss_trans 0.007285, loss flux 4.306781, loss flux t1 4.054076, binary loss 2.725852, binary loss t1 2.098108\n",
      "Epoch 8/10, Batch 1291/1650, Loss 16.600700, Loss rec 3.926704, loss rec t1 4.311687, loss kl 0.171676, loss_trans 0.005347, loss flux 4.188942, loss flux t1 3.996344, binary loss 1.844628, binary loss t1 1.643073\n",
      "Epoch 8/10, Batch 1301/1650, Loss 18.536366, Loss rec 4.907318, loss rec t1 4.908475, loss kl 0.155424, loss_trans 0.005259, loss flux 4.493258, loss flux t1 4.066633, binary loss 1.039845, binary loss t1 0.902649\n",
      "Epoch 8/10, Batch 1311/1650, Loss 14.787199, Loss rec 3.001280, loss rec t1 3.186166, loss kl 0.265662, loss_trans 0.010724, loss flux 4.557056, loss flux t1 3.766311, binary loss 1.185849, binary loss t1 1.417186\n",
      "Epoch 8/10, Batch 1321/1650, Loss 18.634706, Loss rec 3.936378, loss rec t1 4.678032, loss kl 0.314732, loss_trans 0.007844, loss flux 5.038795, loss flux t1 4.658924, binary loss 0.735353, binary loss t1 0.780793\n",
      "Epoch 8/10, Batch 1331/1650, Loss 14.519506, Loss rec 3.187038, loss rec t1 3.774176, loss kl 0.130514, loss_trans 0.008259, loss flux 3.694621, loss flux t1 3.724898, binary loss 1.275537, binary loss t1 1.335407\n",
      "Epoch 8/10, Batch 1341/1650, Loss 24.906446, Loss rec 7.101077, loss rec t1 7.855023, loss kl 0.150713, loss_trans 0.005199, loss flux 5.336449, loss flux t1 4.457985, binary loss 0.648318, binary loss t1 0.636409\n",
      "Epoch 8/10, Batch 1351/1650, Loss 31.313917, Loss rec 9.385176, loss rec t1 11.455039, loss kl 0.167087, loss_trans 0.012510, loss flux 5.545194, loss flux t1 4.748913, binary loss 0.309619, binary loss t1 0.342091\n",
      "Epoch 8/10, Batch 1361/1650, Loss 21.075233, Loss rec 4.888418, loss rec t1 6.713143, loss kl 0.151329, loss_trans 0.005727, loss flux 4.540713, loss flux t1 4.775904, binary loss 1.499088, binary loss t1 1.485827\n",
      "Epoch 8/10, Batch 1371/1650, Loss 37.891201, Loss rec 11.729223, loss rec t1 14.527119, loss kl 0.120741, loss_trans 0.008518, loss flux 6.111894, loss flux t1 5.393707, binary loss 1.261197, binary loss t1 1.193093\n",
      "Epoch 8/10, Batch 1381/1650, Loss 24.431808, Loss rec 6.548184, loss rec t1 6.894603, loss kl 0.208959, loss_trans 0.007128, loss flux 5.781751, loss flux t1 4.991184, binary loss 1.798288, binary loss t1 1.517009\n",
      "Epoch 8/10, Batch 1391/1650, Loss 19.718172, Loss rec 5.495034, loss rec t1 4.454154, loss kl 0.146399, loss_trans 0.004638, loss flux 4.835514, loss flux t1 4.782432, binary loss 2.108035, binary loss t1 1.883389\n",
      "Epoch 8/10, Batch 1401/1650, Loss 28.780294, Loss rec 8.255742, loss rec t1 5.906782, loss kl 0.139224, loss_trans 0.009837, loss flux 8.640008, loss flux t1 5.828702, binary loss 1.231509, binary loss t1 1.207079\n",
      "Epoch 8/10, Batch 1411/1650, Loss 27.912922, Loss rec 7.686539, loss rec t1 8.794977, loss kl 0.109676, loss_trans 0.009488, loss flux 6.127871, loss flux t1 5.184372, binary loss 1.049797, binary loss t1 1.073156\n",
      "Epoch 8/10, Batch 1421/1650, Loss 22.710363, Loss rec 5.415916, loss rec t1 5.684803, loss kl 0.138589, loss_trans 0.005616, loss flux 5.892925, loss flux t1 5.572515, binary loss 1.489112, binary loss t1 1.352974\n",
      "Epoch 8/10, Batch 1431/1650, Loss 29.307549, Loss rec 13.487762, loss rec t1 5.624477, loss kl 0.431636, loss_trans 0.010563, loss flux 4.952612, loss flux t1 4.800498, binary loss 1.578873, binary loss t1 1.768177\n",
      "Epoch 8/10, Batch 1441/1650, Loss 30.846607, Loss rec 6.500028, loss rec t1 9.456078, loss kl 0.230105, loss_trans 0.007498, loss flux 7.409473, loss flux t1 7.243425, binary loss 0.811902, binary loss t1 0.780732\n",
      "Epoch 8/10, Batch 1451/1650, Loss 22.187756, Loss rec 5.339337, loss rec t1 5.668458, loss kl 0.165303, loss_trans 0.012605, loss flux 5.947540, loss flux t1 5.054512, binary loss 1.072936, binary loss t1 1.024309\n",
      "Epoch 8/10, Batch 1461/1650, Loss 16.756565, Loss rec 3.441080, loss rec t1 3.791781, loss kl 0.173198, loss_trans 0.006575, loss flux 4.954216, loss flux t1 4.389715, binary loss 1.534467, binary loss t1 1.194608\n",
      "Epoch 8/10, Batch 1471/1650, Loss 18.237114, Loss rec 3.962302, loss rec t1 4.027156, loss kl 0.178622, loss_trans 0.007178, loss flux 5.468759, loss flux t1 4.593098, binary loss 2.030623, binary loss t1 1.627586\n",
      "Epoch 8/10, Batch 1481/1650, Loss 18.173698, Loss rec 3.851641, loss rec t1 5.649073, loss kl 0.138320, loss_trans 0.007344, loss flux 4.400428, loss flux t1 4.126892, binary loss 2.127902, binary loss t1 2.025014\n",
      "Epoch 8/10, Batch 1491/1650, Loss 23.216854, Loss rec 6.228001, loss rec t1 6.211788, loss kl 0.196498, loss_trans 0.009534, loss flux 5.146292, loss flux t1 5.424743, binary loss 1.565563, binary loss t1 1.364094\n",
      "Epoch 8/10, Batch 1501/1650, Loss 20.379244, Loss rec 4.811810, loss rec t1 5.337265, loss kl 0.159489, loss_trans 0.015618, loss flux 5.319078, loss flux t1 4.735984, binary loss 1.528956, binary loss t1 1.545538\n",
      "Epoch 8/10, Batch 1511/1650, Loss 19.445417, Loss rec 4.476645, loss rec t1 5.746652, loss kl 0.162440, loss_trans 0.009379, loss flux 4.323362, loss flux t1 4.726938, binary loss 4.373085, binary loss t1 4.162831\n",
      "Epoch 8/10, Batch 1521/1650, Loss 19.499456, Loss rec 4.912066, loss rec t1 4.816402, loss kl 0.398003, loss_trans 0.007034, loss flux 5.031577, loss flux t1 4.334373, binary loss 0.442030, binary loss t1 0.553885\n",
      "Epoch 8/10, Batch 1531/1650, Loss 21.047287, Loss rec 4.861295, loss rec t1 5.750379, loss kl 0.260717, loss_trans 0.006136, loss flux 5.249124, loss flux t1 4.919636, binary loss 0.681031, binary loss t1 0.671141\n",
      "Epoch 8/10, Batch 1541/1650, Loss 20.845041, Loss rec 5.654283, loss rec t1 5.419057, loss kl 0.164154, loss_trans 0.009450, loss flux 4.875536, loss flux t1 4.722561, binary loss 4.198271, binary loss t1 3.659133\n",
      "Epoch 8/10, Batch 1551/1650, Loss 22.903236, Loss rec 6.386756, loss rec t1 5.686216, loss kl 0.304533, loss_trans 0.007911, loss flux 6.225897, loss flux t1 4.291924, binary loss 0.949135, binary loss t1 1.078826\n",
      "Epoch 8/10, Batch 1561/1650, Loss 19.522272, Loss rec 4.552835, loss rec t1 5.414121, loss kl 0.188926, loss_trans 0.006065, loss flux 5.177815, loss flux t1 4.182510, binary loss 2.977178, binary loss t1 1.896553\n",
      "Epoch 8/10, Batch 1571/1650, Loss 18.329332, Loss rec 4.394657, loss rec t1 4.146479, loss kl 0.288504, loss_trans 0.005449, loss flux 5.326063, loss flux t1 4.168180, binary loss 0.806086, binary loss t1 0.945570\n",
      "Epoch 8/10, Batch 1581/1650, Loss 35.449234, Loss rec 11.376885, loss rec t1 12.587587, loss kl 0.213191, loss_trans 0.010096, loss flux 5.918726, loss flux t1 5.342744, binary loss 0.284262, binary loss t1 0.319702\n",
      "Epoch 8/10, Batch 1591/1650, Loss 29.568634, Loss rec 8.712059, loss rec t1 10.266109, loss kl 0.196549, loss_trans 0.006351, loss flux 5.106058, loss flux t1 5.281507, binary loss 0.421361, binary loss t1 0.496742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10, Batch 1601/1650, Loss 27.305429, Loss rec 10.959380, loss rec t1 5.190165, loss kl 0.301596, loss_trans 0.005232, loss flux 5.891029, loss flux t1 4.958027, binary loss 3.966836, binary loss t1 1.415058\n",
      "Epoch 8/10, Batch 1611/1650, Loss 22.204655, Loss rec 5.263751, loss rec t1 6.514860, loss kl 0.137468, loss_trans 0.009862, loss flux 5.244872, loss flux t1 5.033844, binary loss 1.053069, binary loss t1 0.964647\n",
      "Epoch 8/10, Batch 1621/1650, Loss 21.561155, Loss rec 5.731791, loss rec t1 6.516985, loss kl 0.165813, loss_trans 0.007037, loss flux 4.632368, loss flux t1 4.507161, binary loss 0.912796, binary loss t1 0.812146\n",
      "Epoch 8/10, Batch 1631/1650, Loss 23.019491, Loss rec 6.043153, loss rec t1 7.393491, loss kl 0.216289, loss_trans 0.004161, loss flux 4.885357, loss flux t1 4.477041, binary loss 1.210157, binary loss t1 1.127038\n",
      "Epoch 8/10, Batch 1641/1650, Loss 27.947517, Loss rec 6.738535, loss rec t1 8.889130, loss kl 0.224490, loss_trans 0.007709, loss flux 6.381727, loss flux t1 5.705928, binary loss 1.079786, binary loss t1 0.973430\n",
      "Epoch 8/10, Train loss 20.714567, Eval loss 24.839520\n",
      "Epoch 9/10, Batch 1/1650, Loss 24.849159, Loss rec 5.015086, loss rec t1 6.468041, loss kl 0.176976, loss_trans 0.009521, loss flux 6.538019, loss flux t1 6.641515, binary loss 1.834884, binary loss t1 1.723249\n",
      "Epoch 9/10, Batch 11/1650, Loss 23.120239, Loss rec 4.678346, loss rec t1 6.232352, loss kl 0.141238, loss_trans 0.013407, loss flux 6.810888, loss flux t1 5.244009, binary loss 0.855906, binary loss t1 0.765123\n",
      "Epoch 9/10, Batch 21/1650, Loss 18.526045, Loss rec 4.371994, loss rec t1 5.044403, loss kl 0.200907, loss_trans 0.007115, loss flux 4.774398, loss flux t1 4.127229, binary loss 1.902052, binary loss t1 1.769211\n",
      "Epoch 9/10, Batch 31/1650, Loss 18.346838, Loss rec 4.450373, loss rec t1 4.705137, loss kl 0.131807, loss_trans 0.013477, loss flux 4.693404, loss flux t1 4.352641, binary loss 2.483272, binary loss t1 2.110225\n",
      "Epoch 9/10, Batch 41/1650, Loss 20.609066, Loss rec 5.668880, loss rec t1 6.217326, loss kl 0.152944, loss_trans 0.009420, loss flux 4.526773, loss flux t1 4.033722, binary loss 0.439331, binary loss t1 0.452750\n",
      "Epoch 9/10, Batch 51/1650, Loss 22.140530, Loss rec 5.667894, loss rec t1 6.153391, loss kl 0.176346, loss_trans 0.010412, loss flux 5.508326, loss flux t1 4.624160, binary loss 3.031280, binary loss t1 2.281790\n",
      "Epoch 9/10, Batch 61/1650, Loss 24.578621, Loss rec 5.545018, loss rec t1 7.356486, loss kl 0.171372, loss_trans 0.011159, loss flux 5.702391, loss flux t1 5.792195, binary loss 1.211300, binary loss t1 1.312267\n",
      "Epoch 9/10, Batch 71/1650, Loss 22.825750, Loss rec 6.912355, loss rec t1 6.112805, loss kl 0.167311, loss_trans 0.005857, loss flux 5.169465, loss flux t1 4.457957, binary loss 0.883974, binary loss t1 0.943502\n",
      "Epoch 9/10, Batch 81/1650, Loss 23.380699, Loss rec 6.999993, loss rec t1 7.125038, loss kl 0.161644, loss_trans 0.009895, loss flux 4.811165, loss flux t1 4.272965, binary loss 0.510927, binary loss t1 0.481023\n",
      "Epoch 9/10, Batch 91/1650, Loss 20.180548, Loss rec 5.342720, loss rec t1 5.868213, loss kl 0.217283, loss_trans 0.005218, loss flux 4.351949, loss flux t1 4.395165, binary loss 4.014418, binary loss t1 3.321379\n",
      "Epoch 9/10, Batch 101/1650, Loss 20.030378, Loss rec 5.447745, loss rec t1 5.901655, loss kl 0.145541, loss_trans 0.008440, loss flux 4.416677, loss flux t1 4.110322, binary loss 4.612343, binary loss t1 3.630251\n",
      "Epoch 9/10, Batch 111/1650, Loss 23.186600, Loss rec 5.888160, loss rec t1 7.316700, loss kl 0.193299, loss_trans 0.009677, loss flux 5.144397, loss flux t1 4.634367, binary loss 0.924925, binary loss t1 0.855079\n",
      "Epoch 9/10, Batch 121/1650, Loss 21.913980, Loss rec 5.425941, loss rec t1 7.063921, loss kl 0.195744, loss_trans 0.004501, loss flux 4.598129, loss flux t1 4.625744, binary loss 1.487056, binary loss t1 1.398512\n",
      "Epoch 9/10, Batch 131/1650, Loss 18.097660, Loss rec 4.342831, loss rec t1 5.096494, loss kl 0.182176, loss_trans 0.005410, loss flux 4.364832, loss flux t1 4.105918, binary loss 0.808398, binary loss t1 0.695741\n",
      "Epoch 9/10, Batch 141/1650, Loss 20.081772, Loss rec 4.624996, loss rec t1 5.085189, loss kl 0.265767, loss_trans 0.012187, loss flux 5.331808, loss flux t1 4.761824, binary loss 1.531292, binary loss t1 1.316439\n",
      "Epoch 9/10, Batch 151/1650, Loss 16.101301, Loss rec 3.364312, loss rec t1 4.458259, loss kl 0.130896, loss_trans 0.007616, loss flux 4.156708, loss flux t1 3.983509, binary loss 1.468284, binary loss t1 1.526998\n",
      "Epoch 9/10, Batch 161/1650, Loss 15.905612, Loss rec 3.474148, loss rec t1 3.622209, loss kl 0.191386, loss_trans 0.009848, loss flux 4.534777, loss flux t1 4.073245, binary loss 1.199281, binary loss t1 0.988869\n",
      "Epoch 9/10, Batch 171/1650, Loss 16.325344, Loss rec 3.788188, loss rec t1 4.496225, loss kl 0.144318, loss_trans 0.011815, loss flux 4.079854, loss flux t1 3.804942, binary loss 2.641601, binary loss t1 2.354860\n",
      "Epoch 9/10, Batch 181/1650, Loss 16.078276, Loss rec 3.956162, loss rec t1 3.913028, loss kl 0.171550, loss_trans 0.004378, loss flux 4.096892, loss flux t1 3.936266, binary loss 1.959695, binary loss t1 1.836805\n",
      "Epoch 9/10, Batch 191/1650, Loss 16.749464, Loss rec 4.162112, loss rec t1 4.210108, loss kl 0.179059, loss_trans 0.006355, loss flux 4.461219, loss flux t1 3.730610, binary loss 1.979745, binary loss t1 1.350943\n",
      "Epoch 9/10, Batch 201/1650, Loss 12.863539, Loss rec 2.690839, loss rec t1 2.786392, loss kl 0.154703, loss_trans 0.014490, loss flux 3.928360, loss flux t1 3.288755, binary loss 1.717250, binary loss t1 1.396176\n",
      "Epoch 9/10, Batch 211/1650, Loss 17.918762, Loss rec 4.426775, loss rec t1 5.255993, loss kl 0.124117, loss_trans 0.014674, loss flux 4.147701, loss flux t1 3.949501, binary loss 0.983492, binary loss t1 1.002215\n",
      "Epoch 9/10, Batch 221/1650, Loss 19.001762, Loss rec 4.676982, loss rec t1 4.471942, loss kl 0.209043, loss_trans 0.005789, loss flux 5.102873, loss flux t1 4.535135, binary loss 1.706228, binary loss t1 1.541195\n",
      "Epoch 9/10, Batch 231/1650, Loss 15.102653, Loss rec 3.399637, loss rec t1 3.437268, loss kl 0.129943, loss_trans 0.012358, loss flux 4.553575, loss flux t1 3.569871, binary loss 0.865992, binary loss t1 0.733090\n",
      "Epoch 9/10, Batch 241/1650, Loss 16.220663, Loss rec 3.280291, loss rec t1 4.197614, loss kl 0.251165, loss_trans 0.006320, loss flux 4.258625, loss flux t1 4.226649, binary loss 6.279565, binary loss t1 3.776413\n",
      "Epoch 9/10, Batch 251/1650, Loss 13.213000, Loss rec 2.601314, loss rec t1 3.426128, loss kl 0.121842, loss_trans 0.009918, loss flux 3.633157, loss flux t1 3.420641, binary loss 1.636431, binary loss t1 1.696178\n",
      "Epoch 9/10, Batch 261/1650, Loss 16.235909, Loss rec 3.107812, loss rec t1 4.136587, loss kl 0.255747, loss_trans 0.005623, loss flux 4.440746, loss flux t1 4.289393, binary loss 1.733917, binary loss t1 1.247908\n",
      "Epoch 9/10, Batch 271/1650, Loss 13.584563, Loss rec 2.425262, loss rec t1 3.586089, loss kl 0.118520, loss_trans 0.010463, loss flux 3.775671, loss flux t1 3.668557, binary loss 1.458113, binary loss t1 1.576537\n",
      "Epoch 9/10, Batch 281/1650, Loss 16.428484, Loss rec 3.870483, loss rec t1 3.952864, loss kl 0.175166, loss_trans 0.009809, loss flux 4.536184, loss flux t1 3.883978, binary loss 0.697882, binary loss t1 0.642478\n",
      "Epoch 9/10, Batch 291/1650, Loss 17.714455, Loss rec 4.291734, loss rec t1 4.491066, loss kl 0.173082, loss_trans 0.011113, loss flux 4.459863, loss flux t1 4.287601, binary loss 0.651298, binary loss t1 0.871662\n",
      "Epoch 9/10, Batch 301/1650, Loss 16.993826, Loss rec 3.792306, loss rec t1 4.335641, loss kl 0.189974, loss_trans 0.004023, loss flux 4.524385, loss flux t1 4.147497, binary loss 1.099629, binary loss t1 1.067632\n",
      "Epoch 9/10, Batch 311/1650, Loss 21.720457, Loss rec 5.791562, loss rec t1 6.691545, loss kl 0.175981, loss_trans 0.011634, loss flux 4.498561, loss flux t1 4.551175, binary loss 1.904254, binary loss t1 1.796937\n",
      "Epoch 9/10, Batch 321/1650, Loss 13.910441, Loss rec 2.765942, loss rec t1 3.095554, loss kl 0.160206, loss_trans 0.007999, loss flux 4.397255, loss flux t1 3.483484, binary loss 1.295404, binary loss t1 0.977737\n",
      "Epoch 9/10, Batch 331/1650, Loss 17.268173, Loss rec 4.118165, loss rec t1 4.379408, loss kl 0.177978, loss_trans 0.009441, loss flux 4.198264, loss flux t1 4.384915, binary loss 1.459220, binary loss t1 1.439353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Batch 341/1650, Loss 19.048265, Loss rec 4.513577, loss rec t1 5.377577, loss kl 0.142404, loss_trans 0.008669, loss flux 4.540318, loss flux t1 4.465720, binary loss 1.851247, binary loss t1 1.604422\n",
      "Epoch 9/10, Batch 351/1650, Loss 18.179487, Loss rec 4.489349, loss rec t1 5.144223, loss kl 0.162319, loss_trans 0.010503, loss flux 4.068410, loss flux t1 4.304685, binary loss 0.997714, binary loss t1 1.019941\n",
      "Epoch 9/10, Batch 361/1650, Loss 17.237978, Loss rec 4.541016, loss rec t1 3.808289, loss kl 0.255405, loss_trans 0.005743, loss flux 4.432776, loss flux t1 4.194750, binary loss 4.770610, binary loss t1 2.575187\n",
      "Epoch 9/10, Batch 371/1650, Loss 19.758522, Loss rec 4.748286, loss rec t1 4.905710, loss kl 0.169909, loss_trans 0.009884, loss flux 5.251268, loss flux t1 4.673466, binary loss 2.159060, binary loss t1 1.641018\n",
      "Epoch 9/10, Batch 381/1650, Loss 22.132217, Loss rec 5.586080, loss rec t1 6.621815, loss kl 0.250083, loss_trans 0.012444, loss flux 4.898450, loss flux t1 4.763346, binary loss 0.488480, binary loss t1 0.530501\n",
      "Epoch 9/10, Batch 391/1650, Loss 17.447212, Loss rec 3.887979, loss rec t1 4.816826, loss kl 0.223318, loss_trans 0.006598, loss flux 4.340427, loss flux t1 4.172064, binary loss 1.123037, binary loss t1 1.105274\n",
      "Epoch 9/10, Batch 401/1650, Loss 18.595760, Loss rec 4.373854, loss rec t1 4.398279, loss kl 0.305565, loss_trans 0.006489, loss flux 4.971350, loss flux t1 4.540224, binary loss 1.665289, binary loss t1 1.656456\n",
      "Epoch 9/10, Batch 411/1650, Loss 19.730743, Loss rec 4.931991, loss rec t1 5.344610, loss kl 0.198265, loss_trans 0.005085, loss flux 4.827553, loss flux t1 4.423243, binary loss 0.743286, binary loss t1 0.651396\n",
      "Epoch 9/10, Batch 421/1650, Loss 17.994831, Loss rec 3.417676, loss rec t1 5.678616, loss kl 0.139678, loss_trans 0.009614, loss flux 4.313447, loss flux t1 4.435801, binary loss 1.293312, binary loss t1 1.354337\n",
      "Epoch 9/10, Batch 431/1650, Loss 17.234411, Loss rec 4.145741, loss rec t1 4.708052, loss kl 0.141914, loss_trans 0.006747, loss flux 4.459425, loss flux t1 3.772534, binary loss 0.812936, binary loss t1 0.768664\n",
      "Epoch 9/10, Batch 441/1650, Loss 18.813238, Loss rec 4.681911, loss rec t1 5.186151, loss kl 0.207405, loss_trans 0.007543, loss flux 4.557289, loss flux t1 4.172937, binary loss 0.492118, binary loss t1 0.436885\n",
      "Epoch 9/10, Batch 451/1650, Loss 22.146414, Loss rec 6.046734, loss rec t1 5.916674, loss kl 0.266485, loss_trans 0.008484, loss flux 5.648985, loss flux t1 4.259052, binary loss 0.360116, binary loss t1 0.447675\n",
      "Epoch 9/10, Batch 461/1650, Loss 28.107548, Loss rec 7.144608, loss rec t1 9.034576, loss kl 0.213436, loss_trans 0.007693, loss flux 6.126303, loss flux t1 5.580932, binary loss 2.486691, binary loss t1 2.208697\n",
      "Epoch 9/10, Batch 471/1650, Loss 19.798672, Loss rec 5.524222, loss rec t1 5.426425, loss kl 0.149689, loss_trans 0.007060, loss flux 4.511162, loss flux t1 4.180115, binary loss 7.189572, binary loss t1 5.631906\n",
      "Epoch 9/10, Batch 481/1650, Loss 23.200798, Loss rec 5.990759, loss rec t1 6.147015, loss kl 0.162433, loss_trans 0.006115, loss flux 5.866787, loss flux t1 5.027689, binary loss 1.384181, binary loss t1 1.249101\n",
      "Epoch 9/10, Batch 491/1650, Loss 16.403162, Loss rec 3.368179, loss rec t1 4.282823, loss kl 0.153100, loss_trans 0.006113, loss flux 4.689406, loss flux t1 3.903542, binary loss 1.122671, binary loss t1 1.048665\n",
      "Epoch 9/10, Batch 501/1650, Loss 21.199469, Loss rec 6.469530, loss rec t1 4.999853, loss kl 0.180667, loss_trans 0.013588, loss flux 5.293547, loss flux t1 4.242283, binary loss 0.825065, binary loss t1 0.684389\n",
      "Epoch 9/10, Batch 511/1650, Loss 25.546791, Loss rec 7.962140, loss rec t1 6.171174, loss kl 0.288415, loss_trans 0.004485, loss flux 6.120233, loss flux t1 5.000346, binary loss 0.371053, binary loss t1 0.449853\n",
      "Epoch 9/10, Batch 521/1650, Loss 19.066666, Loss rec 4.099260, loss rec t1 5.039554, loss kl 0.131766, loss_trans 0.006828, loss flux 5.333682, loss flux t1 4.455575, binary loss 1.498091, binary loss t1 1.273299\n",
      "Epoch 9/10, Batch 531/1650, Loss 20.799385, Loss rec 5.066869, loss rec t1 5.420193, loss kl 0.174831, loss_trans 0.006158, loss flux 5.399937, loss flux t1 4.731395, binary loss 2.016292, binary loss t1 1.983090\n",
      "Epoch 9/10, Batch 541/1650, Loss 17.724251, Loss rec 3.589771, loss rec t1 4.663497, loss kl 0.299636, loss_trans 0.010692, loss flux 4.700269, loss flux t1 4.460386, binary loss 5.060649, binary loss t1 2.551925\n",
      "Epoch 9/10, Batch 551/1650, Loss 19.328440, Loss rec 4.596969, loss rec t1 4.665974, loss kl 0.314423, loss_trans 0.007291, loss flux 4.933040, loss flux t1 4.810742, binary loss 3.866065, binary loss t1 2.145640\n",
      "Epoch 9/10, Batch 561/1650, Loss 18.104979, Loss rec 4.243100, loss rec t1 4.825511, loss kl 0.162172, loss_trans 0.012453, loss flux 4.656871, loss flux t1 4.204869, binary loss 1.232360, binary loss t1 1.224561\n",
      "Epoch 9/10, Batch 571/1650, Loss 20.070192, Loss rec 3.385783, loss rec t1 6.660101, loss kl 0.121024, loss_trans 0.005898, loss flux 4.736662, loss flux t1 5.160725, binary loss 1.552193, binary loss t1 1.827875\n",
      "Epoch 9/10, Batch 581/1650, Loss 22.422066, Loss rec 5.420506, loss rec t1 5.352216, loss kl 0.267995, loss_trans 0.012753, loss flux 6.829573, loss flux t1 4.539022, binary loss 3.259503, binary loss t1 2.658208\n",
      "Epoch 9/10, Batch 591/1650, Loss 27.071991, Loss rec 7.004554, loss rec t1 8.104342, loss kl 0.153810, loss_trans 0.008348, loss flux 6.445952, loss flux t1 5.354987, binary loss 0.792764, binary loss t1 0.692225\n",
      "Epoch 9/10, Batch 601/1650, Loss 28.826193, Loss rec 7.176916, loss rec t1 10.307407, loss kl 0.150248, loss_trans 0.014163, loss flux 6.120531, loss flux t1 5.056928, binary loss 3.790818, binary loss t1 3.538446\n",
      "Epoch 9/10, Batch 611/1650, Loss 25.460592, Loss rec 6.304057, loss rec t1 7.208192, loss kl 0.303276, loss_trans 0.009532, loss flux 6.528168, loss flux t1 5.107368, binary loss 6.619423, binary loss t1 4.637770\n",
      "Epoch 9/10, Batch 621/1650, Loss 30.274986, Loss rec 9.219481, loss rec t1 10.765440, loss kl 0.190726, loss_trans 0.006949, loss flux 5.429820, loss flux t1 4.662572, binary loss 0.352830, binary loss t1 0.420778\n",
      "Epoch 9/10, Batch 631/1650, Loss 21.742201, Loss rec 5.271857, loss rec t1 6.929897, loss kl 0.185244, loss_trans 0.013191, loss flux 4.984232, loss flux t1 4.357779, binary loss 1.357451, binary loss t1 1.119496\n",
      "Epoch 9/10, Batch 641/1650, Loss 19.252825, Loss rec 5.081846, loss rec t1 4.994090, loss kl 0.171184, loss_trans 0.012669, loss flux 4.725605, loss flux t1 4.267432, binary loss 2.522143, binary loss t1 2.287387\n",
      "Epoch 9/10, Batch 651/1650, Loss 21.519258, Loss rec 4.794018, loss rec t1 6.534094, loss kl 0.155680, loss_trans 0.008485, loss flux 5.240697, loss flux t1 4.786285, binary loss 3.331355, binary loss t1 3.279382\n",
      "Epoch 9/10, Batch 661/1650, Loss 15.791078, Loss rec 3.055187, loss rec t1 4.437669, loss kl 0.136288, loss_trans 0.008794, loss flux 3.935792, loss flux t1 4.217347, binary loss 1.968466, binary loss t1 1.813459\n",
      "Epoch 9/10, Batch 671/1650, Loss 23.231987, Loss rec 5.835196, loss rec t1 6.228631, loss kl 0.187545, loss_trans 0.009477, loss flux 5.666896, loss flux t1 5.304241, binary loss 0.882721, binary loss t1 0.765404\n",
      "Epoch 9/10, Batch 681/1650, Loss 16.592512, Loss rec 3.646856, loss rec t1 5.021248, loss kl 0.131125, loss_trans 0.014084, loss flux 3.762053, loss flux t1 4.017147, binary loss 3.541718, binary loss t1 3.321379\n",
      "Epoch 9/10, Batch 691/1650, Loss 21.643301, Loss rec 6.145310, loss rec t1 7.175838, loss kl 0.183113, loss_trans 0.010627, loss flux 4.169642, loss flux t1 3.958771, binary loss 2.460084, binary loss t1 2.091416\n",
      "Epoch 9/10, Batch 701/1650, Loss 18.390295, Loss rec 4.743403, loss rec t1 5.123852, loss kl 0.144407, loss_trans 0.011154, loss flux 4.321050, loss flux t1 4.046429, binary loss 3.825114, binary loss t1 3.241679\n",
      "Epoch 9/10, Batch 711/1650, Loss 18.532324, Loss rec 3.819147, loss rec t1 5.131472, loss kl 0.266308, loss_trans 0.006291, loss flux 4.992756, loss flux t1 4.316349, binary loss 2.596344, binary loss t1 2.125944\n",
      "Epoch 9/10, Batch 721/1650, Loss 19.879854, Loss rec 4.672121, loss rec t1 5.949987, loss kl 0.156056, loss_trans 0.010265, loss flux 4.650561, loss flux t1 4.440863, binary loss 0.590651, binary loss t1 0.611857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Batch 731/1650, Loss 18.054861, Loss rec 4.322114, loss rec t1 4.573793, loss kl 0.193591, loss_trans 0.010084, loss flux 4.709559, loss flux t1 4.245719, binary loss 0.654558, binary loss t1 0.638098\n",
      "Epoch 9/10, Batch 741/1650, Loss 19.021851, Loss rec 4.175471, loss rec t1 5.403237, loss kl 0.164939, loss_trans 0.010846, loss flux 4.746094, loss flux t1 4.521263, binary loss 0.753201, binary loss t1 0.703515\n",
      "Epoch 9/10, Batch 751/1650, Loss 18.126137, Loss rec 4.496790, loss rec t1 4.707569, loss kl 0.141129, loss_trans 0.004247, loss flux 4.452554, loss flux t1 4.323848, binary loss 1.072924, binary loss t1 0.972226\n",
      "Epoch 9/10, Batch 761/1650, Loss 15.067138, Loss rec 3.129820, loss rec t1 3.726185, loss kl 0.123754, loss_trans 0.005861, loss flux 4.333785, loss flux t1 3.747735, binary loss 0.861600, binary loss t1 0.848205\n",
      "Epoch 9/10, Batch 771/1650, Loss 20.639524, Loss rec 5.127494, loss rec t1 5.839401, loss kl 0.228901, loss_trans 0.009284, loss flux 5.083311, loss flux t1 4.351133, binary loss 2.234295, binary loss t1 1.679596\n",
      "Epoch 9/10, Batch 781/1650, Loss 25.086905, Loss rec 7.328217, loss rec t1 7.793480, loss kl 0.189948, loss_trans 0.005292, loss flux 5.288191, loss flux t1 4.481775, binary loss 0.768094, binary loss t1 0.673770\n",
      "Epoch 9/10, Batch 791/1650, Loss 17.161823, Loss rec 4.457026, loss rec t1 4.232506, loss kl 0.164748, loss_trans 0.008467, loss flux 4.127855, loss flux t1 4.171221, binary loss 0.973674, binary loss t1 0.764187\n",
      "Epoch 9/10, Batch 801/1650, Loss 16.938251, Loss rec 3.605621, loss rec t1 4.636722, loss kl 0.150743, loss_trans 0.009414, loss flux 4.431216, loss flux t1 4.104535, binary loss 1.399655, binary loss t1 1.276693\n",
      "Epoch 9/10, Batch 811/1650, Loss 18.004768, Loss rec 3.614473, loss rec t1 5.393337, loss kl 0.272721, loss_trans 0.006944, loss flux 4.522602, loss flux t1 4.194691, binary loss 0.834057, binary loss t1 0.720415\n",
      "Epoch 9/10, Batch 821/1650, Loss 41.477184, Loss rec 15.042233, loss rec t1 15.708265, loss kl 0.166349, loss_trans 0.004718, loss flux 5.516456, loss flux t1 5.039161, binary loss 0.291469, binary loss t1 0.290082\n",
      "Epoch 9/10, Batch 831/1650, Loss 26.764248, Loss rec 6.811998, loss rec t1 7.754312, loss kl 0.131991, loss_trans 0.010299, loss flux 6.084598, loss flux t1 5.971049, binary loss 1.104741, binary loss t1 1.166678\n",
      "Epoch 9/10, Batch 841/1650, Loss 23.336573, Loss rec 7.086592, loss rec t1 5.433606, loss kl 0.135602, loss_trans 0.007993, loss flux 5.553073, loss flux t1 5.119704, binary loss 1.325308, binary loss t1 1.371868\n",
      "Epoch 9/10, Batch 851/1650, Loss 26.602777, Loss rec 7.368796, loss rec t1 7.542559, loss kl 0.141480, loss_trans 0.012152, loss flux 6.095750, loss flux t1 5.442039, binary loss 0.497312, binary loss t1 0.457566\n",
      "Epoch 9/10, Batch 861/1650, Loss 41.033798, Loss rec 12.778986, loss rec t1 10.903862, loss kl 0.292308, loss_trans 0.010771, loss flux 9.144755, loss flux t1 7.903114, binary loss 5.082172, binary loss t1 1.330176\n",
      "Epoch 9/10, Batch 871/1650, Loss 23.562399, Loss rec 4.774009, loss rec t1 5.210823, loss kl 0.178629, loss_trans 0.008127, loss flux 7.124656, loss flux t1 6.266156, binary loss 2.159996, binary loss t1 1.913172\n",
      "Epoch 9/10, Batch 881/1650, Loss 22.245445, Loss rec 5.164608, loss rec t1 5.927840, loss kl 0.122176, loss_trans 0.013014, loss flux 5.067338, loss flux t1 5.950469, binary loss 0.900361, binary loss t1 0.780696\n",
      "Epoch 9/10, Batch 891/1650, Loss 22.231518, Loss rec 5.245976, loss rec t1 5.645556, loss kl 0.153046, loss_trans 0.008172, loss flux 6.530543, loss flux t1 4.648222, binary loss 1.158342, binary loss t1 1.093047\n",
      "Epoch 9/10, Batch 901/1650, Loss 19.479944, Loss rec 4.274377, loss rec t1 5.894599, loss kl 0.123977, loss_trans 0.007103, loss flux 4.445014, loss flux t1 4.734875, binary loss 2.141212, binary loss t1 2.090322\n",
      "Epoch 9/10, Batch 911/1650, Loss 19.656178, Loss rec 4.624904, loss rec t1 5.873346, loss kl 0.158935, loss_trans 0.005105, loss flux 4.675117, loss flux t1 4.318769, binary loss 0.889473, binary loss t1 0.804287\n",
      "Epoch 9/10, Batch 921/1650, Loss 24.401981, Loss rec 7.046338, loss rec t1 7.818183, loss kl 0.191268, loss_trans 0.005359, loss flux 4.831786, loss flux t1 4.509047, binary loss 1.421240, binary loss t1 1.360276\n",
      "Epoch 9/10, Batch 931/1650, Loss 23.521946, Loss rec 5.898445, loss rec t1 7.165819, loss kl 0.198550, loss_trans 0.012249, loss flux 5.672275, loss flux t1 4.574607, binary loss 3.619229, binary loss t1 3.082329\n",
      "Epoch 9/10, Batch 941/1650, Loss 18.474976, Loss rec 4.279653, loss rec t1 5.216313, loss kl 0.155057, loss_trans 0.018216, loss flux 4.247929, loss flux t1 4.557807, binary loss 4.037655, binary loss t1 2.873060\n",
      "Epoch 9/10, Batch 951/1650, Loss 17.542730, Loss rec 4.301205, loss rec t1 5.067761, loss kl 0.128581, loss_trans 0.006469, loss flux 4.169631, loss flux t1 3.869082, binary loss 0.269528, binary loss t1 0.290868\n",
      "Epoch 9/10, Batch 961/1650, Loss 17.413048, Loss rec 3.936347, loss rec t1 4.911778, loss kl 0.178021, loss_trans 0.006503, loss flux 4.210442, loss flux t1 4.169956, binary loss 0.770015, binary loss t1 0.712506\n",
      "Epoch 9/10, Batch 971/1650, Loss 18.620752, Loss rec 4.630131, loss rec t1 6.257853, loss kl 0.140870, loss_trans 0.005297, loss flux 3.701561, loss flux t1 3.885042, binary loss 7.647916, binary loss t1 6.332718\n",
      "Epoch 9/10, Batch 981/1650, Loss 23.308462, Loss rec 7.292260, loss rec t1 6.409343, loss kl 0.146935, loss_trans 0.017203, loss flux 5.283383, loss flux t1 4.159338, binary loss 0.250369, binary loss t1 0.302293\n",
      "Epoch 9/10, Batch 991/1650, Loss 17.677114, Loss rec 3.999242, loss rec t1 4.400809, loss kl 0.137860, loss_trans 0.012842, loss flux 4.805489, loss flux t1 4.320874, binary loss 1.036316, binary loss t1 1.048641\n",
      "Epoch 9/10, Batch 1001/1650, Loss 16.522299, Loss rec 3.548162, loss rec t1 4.187613, loss kl 0.128905, loss_trans 0.006565, loss flux 4.479245, loss flux t1 4.171808, binary loss 4.685302, binary loss t1 3.850700\n",
      "Epoch 9/10, Batch 1011/1650, Loss 18.082270, Loss rec 4.324423, loss rec t1 5.254928, loss kl 0.134372, loss_trans 0.005846, loss flux 4.399528, loss flux t1 3.963172, binary loss 0.636979, binary loss t1 0.654912\n",
      "Epoch 9/10, Batch 1021/1650, Loss 22.610336, Loss rec 5.381229, loss rec t1 6.600543, loss kl 0.302389, loss_trans 0.010126, loss flux 5.171545, loss flux t1 5.144504, binary loss 2.692565, binary loss t1 2.271900\n",
      "Epoch 9/10, Batch 1031/1650, Loss 22.135578, Loss rec 5.613773, loss rec t1 7.737054, loss kl 0.149814, loss_trans 0.006321, loss flux 4.339241, loss flux t1 4.289373, binary loss 1.962967, binary loss t1 2.154766\n",
      "Epoch 9/10, Batch 1041/1650, Loss 19.103956, Loss rec 4.717655, loss rec t1 5.644815, loss kl 0.148462, loss_trans 0.010213, loss flux 4.282135, loss flux t1 4.300676, binary loss 2.010671, binary loss t1 1.958685\n",
      "Epoch 9/10, Batch 1051/1650, Loss 19.659653, Loss rec 4.843965, loss rec t1 5.563279, loss kl 0.241581, loss_trans 0.010701, loss flux 4.791530, loss flux t1 4.208599, binary loss 1.216995, binary loss t1 1.182882\n",
      "Epoch 9/10, Batch 1061/1650, Loss 15.384819, Loss rec 3.260073, loss rec t1 3.660573, loss kl 0.128169, loss_trans 0.008234, loss flux 4.142920, loss flux t1 4.184849, binary loss 1.127307, binary loss t1 1.267812\n",
      "Epoch 9/10, Batch 1071/1650, Loss 18.986568, Loss rec 4.295806, loss rec t1 5.293865, loss kl 0.325335, loss_trans 0.007946, loss flux 4.691577, loss flux t1 4.372038, binary loss 0.985523, binary loss t1 1.146140\n",
      "Epoch 9/10, Batch 1081/1650, Loss 22.462721, Loss rec 5.209813, loss rec t1 6.432452, loss kl 0.166997, loss_trans 0.011348, loss flux 5.987422, loss flux t1 4.654688, binary loss 1.112768, binary loss t1 0.861539\n",
      "Epoch 9/10, Batch 1091/1650, Loss 21.540743, Loss rec 5.419871, loss rec t1 5.313847, loss kl 0.218896, loss_trans 0.008254, loss flux 5.566935, loss flux t1 5.012940, binary loss 1.231350, binary loss t1 1.075089\n",
      "Epoch 9/10, Batch 1101/1650, Loss 19.592892, Loss rec 4.793175, loss rec t1 4.556009, loss kl 0.173159, loss_trans 0.007883, loss flux 5.781603, loss flux t1 4.281063, binary loss 0.813897, binary loss t1 0.827170\n",
      "Epoch 9/10, Batch 1111/1650, Loss 22.630949, Loss rec 5.306855, loss rec t1 7.944687, loss kl 0.175095, loss_trans 0.013327, loss flux 4.680187, loss flux t1 4.510800, binary loss 0.834859, binary loss t1 0.876929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Batch 1121/1650, Loss 25.301756, Loss rec 6.255198, loss rec t1 8.680117, loss kl 0.156082, loss_trans 0.009573, loss flux 5.572148, loss flux t1 4.628640, binary loss 1.164948, binary loss t1 1.114168\n",
      "Epoch 9/10, Batch 1131/1650, Loss 19.269325, Loss rec 4.563846, loss rec t1 5.250217, loss kl 0.148654, loss_trans 0.004211, loss flux 4.817736, loss flux t1 4.484662, binary loss 2.333886, binary loss t1 2.121296\n",
      "Epoch 9/10, Batch 1141/1650, Loss 17.528023, Loss rec 3.629781, loss rec t1 4.331922, loss kl 0.174561, loss_trans 0.014900, loss flux 4.877687, loss flux t1 4.499172, binary loss 7.085590, binary loss t1 5.046293\n",
      "Epoch 9/10, Batch 1151/1650, Loss 19.280315, Loss rec 4.288468, loss rec t1 5.030904, loss kl 0.166578, loss_trans 0.009807, loss flux 4.649011, loss flux t1 5.135546, binary loss 1.049687, binary loss t1 1.146066\n",
      "Epoch 9/10, Batch 1161/1650, Loss 17.075544, Loss rec 4.510695, loss rec t1 4.375309, loss kl 0.149133, loss_trans 0.009786, loss flux 4.295529, loss flux t1 3.735090, binary loss 0.804274, binary loss t1 0.816489\n",
      "Epoch 9/10, Batch 1171/1650, Loss 12.366304, Loss rec 2.338828, loss rec t1 3.018316, loss kl 0.113509, loss_trans 0.007313, loss flux 3.473285, loss flux t1 3.415055, binary loss 2.228674, binary loss t1 2.217664\n",
      "Epoch 9/10, Batch 1181/1650, Loss 18.101555, Loss rec 4.487138, loss rec t1 4.838585, loss kl 0.152508, loss_trans 0.007816, loss flux 4.629468, loss flux t1 3.986040, binary loss 1.166031, binary loss t1 1.073156\n",
      "Epoch 9/10, Batch 1191/1650, Loss 17.727301, Loss rec 4.495142, loss rec t1 5.012002, loss kl 0.136440, loss_trans 0.009568, loss flux 4.140246, loss flux t1 3.933902, binary loss 1.118401, binary loss t1 1.212517\n",
      "Epoch 9/10, Batch 1201/1650, Loss 23.202961, Loss rec 6.378222, loss rec t1 5.959470, loss kl 0.240793, loss_trans 0.009710, loss flux 5.678145, loss flux t1 4.936621, binary loss 1.159291, binary loss t1 1.054103\n",
      "Epoch 9/10, Batch 1211/1650, Loss 19.279533, Loss rec 4.372538, loss rec t1 4.725481, loss kl 0.201142, loss_trans 0.005577, loss flux 5.223054, loss flux t1 4.751741, binary loss 0.883718, binary loss t1 0.780683\n",
      "Epoch 9/10, Batch 1221/1650, Loss 16.152838, Loss rec 3.641955, loss rec t1 4.190939, loss kl 0.107859, loss_trans 0.009073, loss flux 4.248696, loss flux t1 3.954315, binary loss 0.909243, binary loss t1 1.070942\n",
      "Epoch 9/10, Batch 1231/1650, Loss 14.167378, Loss rec 2.731913, loss rec t1 3.459548, loss kl 0.144337, loss_trans 0.009225, loss flux 3.990414, loss flux t1 3.831942, binary loss 0.912369, binary loss t1 0.921335\n",
      "Epoch 9/10, Batch 1241/1650, Loss 22.913027, Loss rec 7.146583, loss rec t1 7.142754, loss kl 0.136837, loss_trans 0.014791, loss flux 4.386894, loss flux t1 4.085167, binary loss 0.518738, binary loss t1 0.519650\n",
      "Epoch 9/10, Batch 1251/1650, Loss 33.309856, Loss rec 10.403811, loss rec t1 13.087989, loss kl 0.154939, loss_trans 0.008211, loss flux 4.810904, loss flux t1 4.844006, binary loss 3.118061, binary loss t1 2.668041\n",
      "Epoch 9/10, Batch 1261/1650, Loss 27.395609, Loss rec 9.021317, loss rec t1 8.938301, loss kl 0.134624, loss_trans 0.007923, loss flux 5.006421, loss flux t1 4.287024, binary loss 1.019371, binary loss t1 0.926227\n",
      "Epoch 9/10, Batch 1271/1650, Loss 22.004313, Loss rec 5.149102, loss rec t1 6.748567, loss kl 0.136361, loss_trans 0.009395, loss flux 5.102495, loss flux t1 4.858393, binary loss 0.526646, binary loss t1 0.560177\n",
      "Epoch 9/10, Batch 1281/1650, Loss 20.059649, Loss rec 4.615632, loss rec t1 6.061746, loss kl 0.147331, loss_trans 0.008515, loss flux 4.851861, loss flux t1 4.374565, binary loss 2.065236, binary loss t1 1.556963\n",
      "Epoch 9/10, Batch 1291/1650, Loss 19.205967, Loss rec 5.122637, loss rec t1 5.168756, loss kl 0.188826, loss_trans 0.005880, loss flux 4.662157, loss flux t1 4.057710, binary loss 1.861296, binary loss t1 1.692055\n",
      "Epoch 9/10, Batch 1301/1650, Loss 19.045012, Loss rec 5.125583, loss rec t1 5.152251, loss kl 0.168727, loss_trans 0.006029, loss flux 4.374538, loss flux t1 4.217883, binary loss 1.160666, binary loss t1 1.007885\n",
      "Epoch 9/10, Batch 1311/1650, Loss 13.985455, Loss rec 2.441045, loss rec t1 3.223265, loss kl 0.278849, loss_trans 0.012759, loss flux 4.374242, loss flux t1 3.655293, binary loss 1.012082, binary loss t1 1.119435\n",
      "Epoch 9/10, Batch 1321/1650, Loss 17.694689, Loss rec 3.856208, loss rec t1 4.271208, loss kl 0.322409, loss_trans 0.008451, loss flux 5.003527, loss flux t1 4.232883, binary loss 0.608121, binary loss t1 0.592768\n",
      "Epoch 9/10, Batch 1331/1650, Loss 19.639078, Loss rec 4.970973, loss rec t1 6.422423, loss kl 0.140436, loss_trans 0.009196, loss flux 4.112935, loss flux t1 3.983114, binary loss 5.255488, binary loss t1 4.397575\n",
      "Epoch 9/10, Batch 1341/1650, Loss 21.317343, Loss rec 5.663999, loss rec t1 5.493814, loss kl 0.169072, loss_trans 0.005944, loss flux 5.371539, loss flux t1 4.612975, binary loss 2.266633, binary loss t1 1.952140\n",
      "Epoch 9/10, Batch 1351/1650, Loss 20.836075, Loss rec 4.965707, loss rec t1 5.669977, loss kl 0.174850, loss_trans 0.013749, loss flux 5.236388, loss flux t1 4.775404, binary loss 0.613135, binary loss t1 0.563449\n",
      "Epoch 9/10, Batch 1361/1650, Loss 28.908710, Loss rec 8.587021, loss rec t1 10.873499, loss kl 0.159705, loss_trans 0.006897, loss flux 4.718245, loss flux t1 4.563343, binary loss 7.001413, binary loss t1 6.374776\n",
      "Epoch 9/10, Batch 1371/1650, Loss 30.657322, Loss rec 10.378979, loss rec t1 11.424547, loss kl 0.135035, loss_trans 0.008285, loss flux 4.496223, loss flux t1 4.214252, binary loss 0.632761, binary loss t1 0.571968\n",
      "Epoch 9/10, Batch 1381/1650, Loss 30.827486, Loss rec 9.468242, loss rec t1 11.094494, loss kl 0.220201, loss_trans 0.007638, loss flux 5.046822, loss flux t1 4.990087, binary loss 3.605979, binary loss t1 2.960522\n",
      "Epoch 9/10, Batch 1391/1650, Loss 19.446203, Loss rec 5.065260, loss rec t1 5.111471, loss kl 0.146287, loss_trans 0.004813, loss flux 4.666786, loss flux t1 4.451588, binary loss 0.580187, binary loss t1 0.594726\n",
      "Epoch 9/10, Batch 1401/1650, Loss 20.523951, Loss rec 4.938634, loss rec t1 5.334414, loss kl 0.143383, loss_trans 0.009131, loss flux 5.632818, loss flux t1 4.465572, binary loss 3.229587, binary loss t1 2.938429\n",
      "Epoch 9/10, Batch 1411/1650, Loss 22.744095, Loss rec 5.434650, loss rec t1 7.229834, loss kl 0.117857, loss_trans 0.009698, loss flux 5.172050, loss flux t1 4.780004, binary loss 0.914717, binary loss t1 0.985767\n",
      "Epoch 9/10, Batch 1421/1650, Loss 19.630545, Loss rec 4.738981, loss rec t1 4.788552, loss kl 0.137012, loss_trans 0.005570, loss flux 4.996767, loss flux t1 4.963663, binary loss 3.087877, binary loss t1 2.856527\n",
      "Epoch 9/10, Batch 1431/1650, Loss 19.481632, Loss rec 5.982147, loss rec t1 4.545903, loss kl 0.434151, loss_trans 0.011441, loss flux 4.419968, loss flux t1 4.088025, binary loss 0.387867, binary loss t1 0.544942\n",
      "Epoch 9/10, Batch 1441/1650, Loss 18.376165, Loss rec 4.042824, loss rec t1 4.430381, loss kl 0.229382, loss_trans 0.006956, loss flux 4.890041, loss flux t1 4.776581, binary loss 1.306707, binary loss t1 1.136090\n",
      "Epoch 9/10, Batch 1451/1650, Loss 17.920626, Loss rec 4.223035, loss rec t1 4.220349, loss kl 0.159435, loss_trans 0.011923, loss flux 5.039315, loss flux t1 4.266569, binary loss 1.221362, binary loss t1 1.287679\n",
      "Epoch 9/10, Batch 1461/1650, Loss 13.857177, Loss rec 2.709504, loss rec t1 2.962657, loss kl 0.169649, loss_trans 0.006583, loss flux 4.260142, loss flux t1 3.748642, binary loss 1.315344, binary loss t1 1.143925\n",
      "Epoch 9/10, Batch 1471/1650, Loss 16.401203, Loss rec 3.614566, loss rec t1 3.468514, loss kl 0.179503, loss_trans 0.008136, loss flux 5.096225, loss flux t1 4.034260, binary loss 0.942553, binary loss t1 0.924827\n",
      "Epoch 9/10, Batch 1481/1650, Loss 15.048481, Loss rec 3.190598, loss rec t1 4.006519, loss kl 0.144740, loss_trans 0.008059, loss flux 3.866745, loss flux t1 3.831821, binary loss 0.708831, binary loss t1 0.757715\n",
      "Epoch 9/10, Batch 1491/1650, Loss 19.265900, Loss rec 5.083489, loss rec t1 4.157425, loss kl 0.199206, loss_trans 0.010828, loss flux 4.865873, loss flux t1 4.949077, binary loss 1.873365, binary loss t1 1.606527\n",
      "Epoch 9/10, Batch 1501/1650, Loss 15.096577, Loss rec 2.995271, loss rec t1 3.544632, loss kl 0.159791, loss_trans 0.015344, loss flux 4.179691, loss flux t1 4.201848, binary loss 1.000998, binary loss t1 0.961155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10, Batch 1511/1650, Loss 14.844603, Loss rec 2.766738, loss rec t1 4.037202, loss kl 0.156932, loss_trans 0.010226, loss flux 3.766701, loss flux t1 4.106804, binary loss 1.014198, binary loss t1 1.153792\n",
      "Epoch 9/10, Batch 1521/1650, Loss 16.909208, Loss rec 4.363952, loss rec t1 4.584667, loss kl 0.396694, loss_trans 0.005930, loss flux 4.155772, loss flux t1 3.402192, binary loss 0.218406, binary loss t1 0.322889\n",
      "Epoch 9/10, Batch 1531/1650, Loss 18.912626, Loss rec 4.150436, loss rec t1 5.142422, loss kl 0.261559, loss_trans 0.006319, loss flux 4.929763, loss flux t1 4.422128, binary loss 0.637842, binary loss t1 0.637793\n",
      "Epoch 9/10, Batch 1541/1650, Loss 17.847744, Loss rec 4.394987, loss rec t1 4.464650, loss kl 0.163737, loss_trans 0.009399, loss flux 4.426507, loss flux t1 4.388463, binary loss 3.809773, binary loss t1 3.259539\n",
      "Epoch 9/10, Batch 1551/1650, Loss 19.835453, Loss rec 5.259523, loss rec t1 5.038309, loss kl 0.299519, loss_trans 0.008076, loss flux 5.442053, loss flux t1 3.787974, binary loss 0.830674, binary loss t1 0.974904\n",
      "Epoch 9/10, Batch 1561/1650, Loss 17.635645, Loss rec 4.331858, loss rec t1 4.754380, loss kl 0.183461, loss_trans 0.006282, loss flux 4.655041, loss flux t1 3.704623, binary loss 4.383122, binary loss t1 2.310539\n",
      "Epoch 9/10, Batch 1571/1650, Loss 17.056112, Loss rec 4.551098, loss rec t1 3.413095, loss kl 0.281343, loss_trans 0.005742, loss flux 4.881357, loss flux t1 3.923476, binary loss 0.658889, binary loss t1 0.750743\n",
      "Epoch 9/10, Batch 1581/1650, Loss 25.597111, Loss rec 6.764690, loss rec t1 7.892146, loss kl 0.219960, loss_trans 0.011878, loss flux 5.871077, loss flux t1 4.837360, binary loss 0.383573, binary loss t1 0.389108\n",
      "Epoch 9/10, Batch 1591/1650, Loss 17.786776, Loss rec 3.583739, loss rec t1 5.010380, loss kl 0.194680, loss_trans 0.006263, loss flux 4.392938, loss flux t1 4.598777, binary loss 2.677139, binary loss t1 2.203296\n",
      "Epoch 9/10, Batch 1601/1650, Loss 25.982962, Loss rec 11.557656, loss rec t1 4.073351, loss kl 0.297753, loss_trans 0.005210, loss flux 5.420666, loss flux t1 4.628325, binary loss 0.831488, binary loss t1 0.830442\n",
      "Epoch 9/10, Batch 1611/1650, Loss 18.699537, Loss rec 4.544249, loss rec t1 5.112586, loss kl 0.142086, loss_trans 0.010873, loss flux 4.505160, loss flux t1 4.384586, binary loss 1.025465, binary loss t1 0.914766\n",
      "Epoch 9/10, Batch 1621/1650, Loss 19.563107, Loss rec 5.334564, loss rec t1 5.637586, loss kl 0.166154, loss_trans 0.007614, loss flux 4.342366, loss flux t1 4.074821, binary loss 1.490280, binary loss t1 1.317620\n",
      "Epoch 9/10, Batch 1631/1650, Loss 18.623909, Loss rec 4.196609, loss rec t1 4.392941, loss kl 0.214282, loss_trans 0.004719, loss flux 5.282218, loss flux t1 4.533140, binary loss 1.051913, binary loss t1 1.063969\n",
      "Epoch 9/10, Batch 1641/1650, Loss 32.543610, Loss rec 9.577295, loss rec t1 12.068190, loss kl 0.216020, loss_trans 0.007944, loss flux 5.520369, loss flux t1 5.153792, binary loss 0.922979, binary loss t1 0.913964\n",
      "Epoch 9/10, Train loss 18.062704, Eval loss 19.766457\n",
      "Epoch 10/10, Batch 1/1650, Loss 19.533041, Loss rec 4.664946, loss rec t1 5.107370, loss kl 0.176406, loss_trans 0.008792, loss flux 4.985532, loss flux t1 4.589996, binary loss 1.238164, binary loss t1 1.178624\n",
      "Epoch 10/10, Batch 11/1650, Loss 14.863908, Loss rec 3.101097, loss rec t1 3.772976, loss kl 0.140940, loss_trans 0.012319, loss flux 4.174764, loss flux t1 3.661813, binary loss 1.310953, binary loss t1 1.217992\n",
      "Epoch 10/10, Batch 21/1650, Loss 14.942274, Loss rec 3.374347, loss rec t1 3.752920, loss kl 0.203490, loss_trans 0.006740, loss flux 3.966549, loss flux t1 3.638227, binary loss 1.358570, binary loss t1 1.282192\n",
      "Epoch 10/10, Batch 31/1650, Loss 16.443960, Loss rec 4.103254, loss rec t1 4.648102, loss kl 0.134253, loss_trans 0.013920, loss flux 3.884368, loss flux t1 3.660063, binary loss 1.723978, binary loss t1 1.553605\n",
      "Epoch 10/10, Batch 41/1650, Loss 15.445844, Loss rec 4.021447, loss rec t1 3.961472, loss kl 0.149084, loss_trans 0.009084, loss flux 3.765542, loss flux t1 3.539215, binary loss 1.133037, binary loss t1 1.076599\n",
      "Epoch 10/10, Batch 51/1650, Loss 17.590189, Loss rec 4.017128, loss rec t1 4.751907, loss kl 0.178118, loss_trans 0.010282, loss flux 4.506621, loss flux t1 4.126131, binary loss 1.896528, binary loss t1 1.369507\n",
      "Epoch 10/10, Batch 61/1650, Loss 20.980156, Loss rec 4.864989, loss rec t1 5.778974, loss kl 0.160816, loss_trans 0.010509, loss flux 5.208931, loss flux t1 4.955935, binary loss 0.707944, binary loss t1 0.811015\n",
      "Epoch 10/10, Batch 71/1650, Loss 17.348623, Loss rec 4.574561, loss rec t1 3.867665, loss kl 0.167568, loss_trans 0.005998, loss flux 4.731351, loss flux t1 4.001479, binary loss 1.574689, binary loss t1 1.560089\n",
      "Epoch 10/10, Batch 81/1650, Loss 17.188103, Loss rec 3.923847, loss rec t1 4.653583, loss kl 0.155579, loss_trans 0.010633, loss flux 4.564704, loss flux t1 3.879756, binary loss 1.407271, binary loss t1 1.351891\n",
      "Epoch 10/10, Batch 91/1650, Loss 15.766519, Loss rec 3.399537, loss rec t1 3.820430, loss kl 0.205007, loss_trans 0.005628, loss flux 4.306733, loss flux t1 4.029185, binary loss 1.029820, binary loss t1 0.979963\n",
      "Epoch 10/10, Batch 101/1650, Loss 15.261789, Loss rec 3.304511, loss rec t1 3.830030, loss kl 0.140964, loss_trans 0.007986, loss flux 4.218633, loss flux t1 3.759664, binary loss 0.923623, binary loss t1 0.904704\n",
      "Epoch 10/10, Batch 111/1650, Loss 18.431789, Loss rec 4.337620, loss rec t1 5.008536, loss kl 0.184742, loss_trans 0.009250, loss flux 4.845431, loss flux t1 4.046208, binary loss 1.101684, binary loss t1 1.051828\n",
      "Epoch 10/10, Batch 121/1650, Loss 16.697044, Loss rec 3.831996, loss rec t1 4.563302, loss kl 0.190976, loss_trans 0.004308, loss flux 4.121080, loss flux t1 3.985383, binary loss 1.868912, binary loss t1 1.665240\n",
      "Epoch 10/10, Batch 131/1650, Loss 15.419833, Loss rec 3.530897, loss rec t1 4.157559, loss kl 0.173312, loss_trans 0.004922, loss flux 3.822439, loss flux t1 3.730704, binary loss 0.690035, binary loss t1 0.606126\n",
      "Epoch 10/10, Batch 141/1650, Loss 18.993483, Loss rec 4.556374, loss rec t1 5.288535, loss kl 0.255576, loss_trans 0.011922, loss flux 4.668307, loss flux t1 4.212770, binary loss 3.470839, binary loss t1 2.275172\n",
      "Epoch 10/10, Batch 151/1650, Loss 14.697937, Loss rec 3.140327, loss rec t1 3.983206, loss kl 0.132687, loss_trans 0.007414, loss flux 3.856596, loss flux t1 3.577707, binary loss 1.627635, binary loss t1 1.532521\n",
      "Epoch 10/10, Batch 161/1650, Loss 14.665181, Loss rec 3.353482, loss rec t1 3.265945, loss kl 0.190052, loss_trans 0.009096, loss flux 4.244236, loss flux t1 3.602369, binary loss 1.303447, binary loss t1 0.972275\n",
      "Epoch 10/10, Batch 171/1650, Loss 13.678323, Loss rec 3.027047, loss rec t1 3.225049, loss kl 0.142064, loss_trans 0.011244, loss flux 3.776850, loss flux t1 3.496068, binary loss 1.465875, binary loss t1 1.338557\n",
      "Epoch 10/10, Batch 181/1650, Loss 13.995719, Loss rec 3.339897, loss rec t1 3.489698, loss kl 0.166767, loss_trans 0.004488, loss flux 3.614684, loss flux t1 3.380185, binary loss 1.495852, binary loss t1 1.472664\n",
      "Epoch 10/10, Batch 191/1650, Loss 14.100003, Loss rec 3.194331, loss rec t1 3.305962, loss kl 0.175555, loss_trans 0.006615, loss flux 4.030080, loss flux t1 3.387461, binary loss 1.712955, binary loss t1 1.173769\n",
      "Epoch 10/10, Batch 201/1650, Loss 11.936035, Loss rec 2.353141, loss rec t1 2.472455, loss kl 0.150203, loss_trans 0.015285, loss flux 3.800154, loss flux t1 3.144797, binary loss 2.478905, binary loss t1 1.789151\n",
      "Epoch 10/10, Batch 211/1650, Loss 17.152433, Loss rec 4.145500, loss rec t1 5.060076, loss kl 0.123929, loss_trans 0.015632, loss flux 4.055749, loss flux t1 3.751546, binary loss 0.910679, binary loss t1 0.910520\n",
      "Epoch 10/10, Batch 221/1650, Loss 17.449724, Loss rec 4.123163, loss rec t1 4.224143, loss kl 0.197441, loss_trans 0.005961, loss flux 4.783543, loss flux t1 4.115474, binary loss 1.345358, binary loss t1 1.289954\n",
      "Epoch 10/10, Batch 231/1650, Loss 13.264524, Loss rec 2.855606, loss rec t1 3.044500, loss kl 0.130458, loss_trans 0.012520, loss flux 3.964391, loss flux t1 3.257046, binary loss 0.715413, binary loss t1 0.697638\n",
      "Epoch 10/10, Batch 241/1650, Loss 14.038933, Loss rec 2.475454, loss rec t1 3.178483, loss kl 0.245642, loss_trans 0.006455, loss flux 4.385082, loss flux t1 3.747815, binary loss 1.747081, binary loss t1 1.901042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Batch 251/1650, Loss 11.341094, Loss rec 2.017873, loss rec t1 2.743089, loss kl 0.123195, loss_trans 0.010316, loss flux 3.286902, loss flux t1 3.159719, binary loss 0.905799, binary loss t1 1.018724\n",
      "Epoch 10/10, Batch 261/1650, Loss 13.991951, Loss rec 2.488505, loss rec t1 3.547738, loss kl 0.248376, loss_trans 0.005531, loss flux 3.910929, loss flux t1 3.790871, binary loss 1.485888, binary loss t1 1.457091\n",
      "Epoch 10/10, Batch 271/1650, Loss 12.150495, Loss rec 2.331918, loss rec t1 2.883193, loss kl 0.115738, loss_trans 0.010750, loss flux 3.462430, loss flux t1 3.346464, binary loss 1.705084, binary loss t1 1.718308\n",
      "Epoch 10/10, Batch 281/1650, Loss 14.963619, Loss rec 3.588295, loss rec t1 3.680867, loss kl 0.167710, loss_trans 0.009716, loss flux 4.028155, loss flux t1 3.488876, binary loss 0.782096, binary loss t1 0.639339\n",
      "Epoch 10/10, Batch 291/1650, Loss 13.957087, Loss rec 2.879535, loss rec t1 3.374602, loss kl 0.165200, loss_trans 0.011481, loss flux 3.702626, loss flux t1 3.823643, binary loss 1.112804, binary loss t1 1.132732\n",
      "Epoch 10/10, Batch 301/1650, Loss 14.963007, Loss rec 3.131604, loss rec t1 3.515102, loss kl 0.178721, loss_trans 0.003814, loss flux 4.154540, loss flux t1 3.979226, binary loss 1.034273, binary loss t1 1.013323\n",
      "Epoch 10/10, Batch 311/1650, Loss 17.560057, Loss rec 4.346728, loss rec t1 4.679737, loss kl 0.173262, loss_trans 0.011607, loss flux 4.151656, loss flux t1 4.197066, binary loss 1.588752, binary loss t1 1.542339\n",
      "Epoch 10/10, Batch 321/1650, Loss 12.815739, Loss rec 2.494004, loss rec t1 3.056866, loss kl 0.161708, loss_trans 0.008236, loss flux 3.924337, loss flux t1 3.170588, binary loss 1.172539, binary loss t1 0.819579\n",
      "Epoch 10/10, Batch 331/1650, Loss 15.780273, Loss rec 3.682286, loss rec t1 4.022831, loss kl 0.168195, loss_trans 0.009423, loss flux 3.811636, loss flux t1 4.085903, binary loss 1.368522, binary loss t1 1.388426\n",
      "Epoch 10/10, Batch 341/1650, Loss 17.720848, Loss rec 3.983360, loss rec t1 5.025299, loss kl 0.138726, loss_trans 0.008626, loss flux 4.417146, loss flux t1 4.147694, binary loss 1.262484, binary loss t1 1.157320\n",
      "Epoch 10/10, Batch 351/1650, Loss 16.976746, Loss rec 4.315651, loss rec t1 4.756202, loss kl 0.159321, loss_trans 0.010231, loss flux 3.886430, loss flux t1 3.848912, binary loss 0.475402, binary loss t1 0.510976\n",
      "Epoch 10/10, Batch 361/1650, Loss 14.475467, Loss rec 3.158669, loss rec t1 3.133916, loss kl 0.248441, loss_trans 0.005842, loss flux 4.166748, loss flux t1 3.761852, binary loss 1.170398, binary loss t1 1.472542\n",
      "Epoch 10/10, Batch 371/1650, Loss 15.639713, Loss rec 3.957146, loss rec t1 3.984505, loss kl 0.162782, loss_trans 0.009583, loss flux 3.922650, loss flux t1 3.603047, binary loss 0.996912, binary loss t1 0.748846\n",
      "Epoch 10/10, Batch 381/1650, Loss 20.862041, Loss rec 5.599701, loss rec t1 6.564465, loss kl 0.238534, loss_trans 0.012042, loss flux 4.182940, loss flux t1 4.264358, binary loss 1.055088, binary loss t1 1.102706\n",
      "Epoch 10/10, Batch 391/1650, Loss 16.569895, Loss rec 3.659590, loss rec t1 4.226657, loss kl 0.218093, loss_trans 0.006239, loss flux 4.330619, loss flux t1 4.128696, binary loss 0.917151, binary loss t1 0.916980\n",
      "Epoch 10/10, Batch 401/1650, Loss 16.738560, Loss rec 3.676909, loss rec t1 4.113617, loss kl 0.295392, loss_trans 0.006226, loss flux 4.427141, loss flux t1 4.219274, binary loss 3.270525, binary loss t1 2.787849\n",
      "Epoch 10/10, Batch 411/1650, Loss 18.032974, Loss rec 4.623692, loss rec t1 4.914310, loss kl 0.196303, loss_trans 0.005042, loss flux 4.310704, loss flux t1 3.982924, binary loss 0.769710, binary loss t1 0.705461\n",
      "Epoch 10/10, Batch 421/1650, Loss 18.955936, Loss rec 4.543968, loss rec t1 5.248497, loss kl 0.138565, loss_trans 0.009540, loss flux 4.612362, loss flux t1 4.403005, binary loss 2.557473, binary loss t1 2.377038\n",
      "Epoch 10/10, Batch 431/1650, Loss 15.790028, Loss rec 3.637977, loss rec t1 4.229043, loss kl 0.138721, loss_trans 0.007257, loss flux 4.174735, loss flux t1 3.602296, binary loss 1.440546, binary loss t1 1.179243\n",
      "Epoch 10/10, Batch 441/1650, Loss 16.167864, Loss rec 3.151507, loss rec t1 3.963443, loss kl 0.197860, loss_trans 0.008168, loss flux 4.663878, loss flux t1 4.183008, binary loss 0.899303, binary loss t1 0.736716\n",
      "Epoch 10/10, Batch 451/1650, Loss 17.258556, Loss rec 3.628404, loss rec t1 3.754032, loss kl 0.261746, loss_trans 0.008410, loss flux 5.327136, loss flux t1 4.278830, binary loss 0.750840, binary loss t1 0.825224\n",
      "Epoch 10/10, Batch 461/1650, Loss 32.707340, Loss rec 10.028732, loss rec t1 10.669844, loss kl 0.219096, loss_trans 0.007832, loss flux 6.272746, loss flux t1 5.509089, binary loss 4.252434, binary loss t1 3.660118\n",
      "Epoch 10/10, Batch 471/1650, Loss 17.063814, Loss rec 4.549866, loss rec t1 4.258677, loss kl 0.149520, loss_trans 0.007625, loss flux 4.071125, loss flux t1 4.027001, binary loss 3.034796, binary loss t1 2.461301\n",
      "Epoch 10/10, Batch 481/1650, Loss 28.391712, Loss rec 9.312513, loss rec t1 7.430751, loss kl 0.161642, loss_trans 0.006439, loss flux 6.310907, loss flux t1 5.169461, binary loss 0.824007, binary loss t1 0.803045\n",
      "Epoch 10/10, Batch 491/1650, Loss 17.931026, Loss rec 3.864387, loss rec t1 4.743611, loss kl 0.150969, loss_trans 0.006905, loss flux 4.911176, loss flux t1 4.253979, binary loss 0.786158, binary loss t1 0.725365\n",
      "Epoch 10/10, Batch 501/1650, Loss 18.930639, Loss rec 5.662536, loss rec t1 4.175943, loss kl 0.180786, loss_trans 0.013822, loss flux 5.044200, loss flux t1 3.853352, binary loss 0.744124, binary loss t1 0.613498\n",
      "Epoch 10/10, Batch 511/1650, Loss 26.951773, Loss rec 10.146572, loss rec t1 5.909024, loss kl 0.276118, loss_trans 0.004682, loss flux 5.696484, loss flux t1 4.918896, binary loss 0.561439, binary loss t1 0.692273\n",
      "Epoch 10/10, Batch 521/1650, Loss 16.400309, Loss rec 2.937037, loss rec t1 3.817304, loss kl 0.130652, loss_trans 0.007799, loss flux 5.168529, loss flux t1 4.338988, binary loss 1.689523, binary loss t1 1.371770\n",
      "Epoch 10/10, Batch 531/1650, Loss 21.127596, Loss rec 4.861677, loss rec t1 5.379355, loss kl 0.170389, loss_trans 0.006128, loss flux 5.817151, loss flux t1 4.892895, binary loss 1.633183, binary loss t1 1.503663\n",
      "Epoch 10/10, Batch 541/1650, Loss 15.722345, Loss rec 2.948244, loss rec t1 3.689232, loss kl 0.302224, loss_trans 0.012032, loss flux 4.608660, loss flux t1 4.161953, binary loss 3.062315, binary loss t1 1.426080\n",
      "Epoch 10/10, Batch 551/1650, Loss 17.491570, Loss rec 3.571154, loss rec t1 3.912015, loss kl 0.318216, loss_trans 0.007564, loss flux 4.821883, loss flux t1 4.860737, binary loss 0.593594, binary loss t1 0.665642\n",
      "Epoch 10/10, Batch 561/1650, Loss 18.955183, Loss rec 4.712635, loss rec t1 5.069522, loss kl 0.157746, loss_trans 0.012998, loss flux 4.815694, loss flux t1 4.186587, binary loss 0.616041, binary loss t1 0.587208\n",
      "Epoch 10/10, Batch 571/1650, Loss 18.126247, Loss rec 4.461761, loss rec t1 4.874290, loss kl 0.123631, loss_trans 0.006433, loss flux 4.037493, loss flux t1 4.622641, binary loss 0.626018, binary loss t1 0.866248\n",
      "Epoch 10/10, Batch 581/1650, Loss 20.278675, Loss rec 4.179845, loss rec t1 5.241022, loss kl 0.278444, loss_trans 0.014273, loss flux 6.000367, loss flux t1 4.564723, binary loss 5.631930, binary loss t1 4.571330\n",
      "Epoch 10/10, Batch 591/1650, Loss 23.040398, Loss rec 6.239221, loss rec t1 6.981454, loss kl 0.144242, loss_trans 0.007907, loss flux 5.374938, loss flux t1 4.292637, binary loss 1.218150, binary loss t1 1.152941\n",
      "Epoch 10/10, Batch 601/1650, Loss 25.230385, Loss rec 6.408803, loss rec t1 8.012931, loss kl 0.146660, loss_trans 0.014453, loss flux 5.780116, loss flux t1 4.867422, binary loss 1.860079, binary loss t1 1.877028\n",
      "Epoch 10/10, Batch 611/1650, Loss 25.647110, Loss rec 8.703786, loss rec t1 5.803661, loss kl 0.287655, loss_trans 0.009917, loss flux 6.050438, loss flux t1 4.791650, binary loss 3.291731, binary loss t1 1.768348\n",
      "Epoch 10/10, Batch 621/1650, Loss 16.686571, Loss rec 3.674559, loss rec t1 3.885043, loss kl 0.191193, loss_trans 0.007638, loss flux 4.894626, loss flux t1 4.033511, binary loss 1.032156, binary loss t1 0.916032\n",
      "Epoch 10/10, Batch 631/1650, Loss 20.803547, Loss rec 4.658369, loss rec t1 6.480927, loss kl 0.183864, loss_trans 0.013657, loss flux 5.093992, loss flux t1 4.372737, binary loss 1.320917, binary loss t1 0.843764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Batch 641/1650, Loss 24.128126, Loss rec 7.291988, loss rec t1 6.656064, loss kl 0.165045, loss_trans 0.014396, loss flux 5.298948, loss flux t1 4.701685, binary loss 2.445850, binary loss t1 2.150154\n",
      "Epoch 10/10, Batch 651/1650, Loss 23.507538, Loss rec 5.162746, loss rec t1 5.848024, loss kl 0.145300, loss_trans 0.010244, loss flux 6.892759, loss flux t1 5.448463, binary loss 0.937954, binary loss t1 1.012082\n",
      "Epoch 10/10, Batch 661/1650, Loss 18.617565, Loss rec 3.716326, loss rec t1 5.639498, loss kl 0.133613, loss_trans 0.013559, loss flux 4.516153, loss flux t1 4.598414, binary loss 2.984915, binary loss t1 2.702553\n",
      "Epoch 10/10, Batch 671/1650, Loss 27.430681, Loss rec 7.788765, loss rec t1 8.094218, loss kl 0.191173, loss_trans 0.012785, loss flux 6.254247, loss flux t1 5.089493, binary loss 1.420617, binary loss t1 1.177102\n",
      "Epoch 10/10, Batch 681/1650, Loss 19.041945, Loss rec 5.017280, loss rec t1 5.598642, loss kl 0.127844, loss_trans 0.015830, loss flux 4.115578, loss flux t1 4.166770, binary loss 0.815419, binary loss t1 0.922747\n",
      "Epoch 10/10, Batch 691/1650, Loss 20.906328, Loss rec 5.948380, loss rec t1 6.537476, loss kl 0.171765, loss_trans 0.011987, loss flux 4.233608, loss flux t1 4.003114, binary loss 1.557231, binary loss t1 1.348997\n",
      "Epoch 10/10, Batch 701/1650, Loss 16.426456, Loss rec 4.611690, loss rec t1 3.897964, loss kl 0.142210, loss_trans 0.015668, loss flux 3.854119, loss flux t1 3.904805, binary loss 1.116126, binary loss t1 1.050831\n",
      "Epoch 10/10, Batch 711/1650, Loss 19.482710, Loss rec 3.916749, loss rec t1 5.443934, loss kl 0.259716, loss_trans 0.007587, loss flux 4.970062, loss flux t1 4.884661, binary loss 0.924730, binary loss t1 0.813168\n",
      "Epoch 10/10, Batch 721/1650, Loss 17.087727, Loss rec 4.036493, loss rec t1 4.552650, loss kl 0.156228, loss_trans 0.011974, loss flux 4.181715, loss flux t1 4.148666, binary loss 0.774224, binary loss t1 0.754369\n",
      "Epoch 10/10, Batch 731/1650, Loss 20.524572, Loss rec 6.203260, loss rec t1 5.781640, loss kl 0.185262, loss_trans 0.013354, loss flux 4.375835, loss flux t1 3.965223, binary loss 0.662418, binary loss t1 0.658075\n",
      "Epoch 10/10, Batch 741/1650, Loss 23.145962, Loss rec 6.038123, loss rec t1 7.988342, loss kl 0.159633, loss_trans 0.011007, loss flux 4.709733, loss flux t1 4.239124, binary loss 0.430413, binary loss t1 0.380922\n",
      "Epoch 10/10, Batch 751/1650, Loss 17.512039, Loss rec 3.974981, loss rec t1 5.052266, loss kl 0.138691, loss_trans 0.004356, loss flux 4.339302, loss flux t1 4.002443, binary loss 0.713174, binary loss t1 0.759673\n",
      "Epoch 10/10, Batch 761/1650, Loss 14.628707, Loss rec 2.939639, loss rec t1 3.778841, loss kl 0.126465, loss_trans 0.006115, loss flux 4.088754, loss flux t1 3.688892, binary loss 0.982153, binary loss t1 0.962225\n",
      "Epoch 10/10, Batch 771/1650, Loss 18.284407, Loss rec 4.388973, loss rec t1 5.176763, loss kl 0.227398, loss_trans 0.009862, loss flux 4.494305, loss flux t1 3.987104, binary loss 1.402843, binary loss t1 1.321026\n",
      "Epoch 10/10, Batch 781/1650, Loss 20.913431, Loss rec 6.482330, loss rec t1 5.520407, loss kl 0.187388, loss_trans 0.005690, loss flux 4.980659, loss flux t1 3.736958, binary loss 1.149754, binary loss t1 1.044566\n",
      "Epoch 10/10, Batch 791/1650, Loss 16.401327, Loss rec 3.658911, loss rec t1 4.718210, loss kl 0.160254, loss_trans 0.008413, loss flux 3.968100, loss flux t1 3.887440, binary loss 1.002252, binary loss t1 0.807425\n",
      "Epoch 10/10, Batch 801/1650, Loss 13.928058, Loss rec 2.990907, loss rec t1 3.649655, loss kl 0.144063, loss_trans 0.010309, loss flux 3.604440, loss flux t1 3.528684, binary loss 1.245780, binary loss t1 1.192541\n",
      "Epoch 10/10, Batch 811/1650, Loss 14.528509, Loss rec 2.739357, loss rec t1 3.262809, loss kl 0.283840, loss_trans 0.007153, loss flux 4.330083, loss flux t1 3.905268, binary loss 2.091563, binary loss t1 0.950352\n",
      "Epoch 10/10, Batch 821/1650, Loss 21.642954, Loss rec 6.632504, loss rec t1 7.053530, loss kl 0.160799, loss_trans 0.004617, loss flux 4.131948, loss flux t1 3.659555, binary loss 0.293290, binary loss t1 0.365325\n",
      "Epoch 10/10, Batch 831/1650, Loss 22.122349, Loss rec 6.422256, loss rec t1 6.844933, loss kl 0.130228, loss_trans 0.012196, loss flux 4.504541, loss flux t1 4.208196, binary loss 0.619024, binary loss t1 0.783801\n",
      "Epoch 10/10, Batch 841/1650, Loss 15.375105, Loss rec 3.173282, loss rec t1 4.053578, loss kl 0.143021, loss_trans 0.006862, loss flux 4.158850, loss flux t1 3.839512, binary loss 1.406262, binary loss t1 1.382988\n",
      "Epoch 10/10, Batch 851/1650, Loss 14.740980, Loss rec 2.832907, loss rec t1 4.120486, loss kl 0.135261, loss_trans 0.012365, loss flux 4.123311, loss flux t1 3.516650, binary loss 0.982190, binary loss t1 0.820747\n",
      "Epoch 10/10, Batch 861/1650, Loss 19.945786, Loss rec 4.896641, loss rec t1 5.205141, loss kl 0.288870, loss_trans 0.007145, loss flux 5.188259, loss flux t1 4.359731, binary loss 0.778884, binary loss t1 0.810323\n",
      "Epoch 10/10, Batch 871/1650, Loss 17.741909, Loss rec 4.049807, loss rec t1 4.841730, loss kl 0.178378, loss_trans 0.005815, loss flux 4.549859, loss flux t1 4.116321, binary loss 2.853084, binary loss t1 2.639411\n",
      "Epoch 10/10, Batch 881/1650, Loss 14.581087, Loss rec 2.987462, loss rec t1 3.611176, loss kl 0.125327, loss_trans 0.010336, loss flux 3.775049, loss flux t1 4.071737, binary loss 0.595955, binary loss t1 0.674462\n",
      "Epoch 10/10, Batch 891/1650, Loss 16.067331, Loss rec 3.974885, loss rec t1 3.796872, loss kl 0.147368, loss_trans 0.005164, loss flux 4.626952, loss flux t1 3.516088, binary loss 0.772861, binary loss t1 0.728735\n",
      "Epoch 10/10, Batch 901/1650, Loss 13.929992, Loss rec 2.904308, loss rec t1 3.737357, loss kl 0.124111, loss_trans 0.005279, loss flux 3.632675, loss flux t1 3.526260, binary loss 2.401359, binary loss t1 2.322875\n",
      "Epoch 10/10, Batch 911/1650, Loss 14.589762, Loss rec 3.634039, loss rec t1 3.309018, loss kl 0.154105, loss_trans 0.004129, loss flux 3.906959, loss flux t1 3.581511, binary loss 0.861771, binary loss t1 0.837134\n",
      "Epoch 10/10, Batch 921/1650, Loss 21.882103, Loss rec 6.043141, loss rec t1 6.868139, loss kl 0.189531, loss_trans 0.004633, loss flux 4.643144, loss flux t1 4.133517, binary loss 0.878186, binary loss t1 0.824813\n",
      "Epoch 10/10, Batch 931/1650, Loss 19.356413, Loss rec 4.593654, loss rec t1 5.625668, loss kl 0.187267, loss_trans 0.011173, loss flux 5.057850, loss flux t1 3.880800, binary loss 2.909644, binary loss t1 2.585297\n",
      "Epoch 10/10, Batch 941/1650, Loss 15.501694, Loss rec 3.036622, loss rec t1 4.442228, loss kl 0.152158, loss_trans 0.016232, loss flux 3.700627, loss flux t1 4.153827, binary loss 3.398865, binary loss t1 2.548702\n",
      "Epoch 10/10, Batch 951/1650, Loss 13.062716, Loss rec 2.784349, loss rec t1 3.280879, loss kl 0.124776, loss_trans 0.005959, loss flux 3.568451, loss flux t1 3.298301, binary loss 0.467481, binary loss t1 0.438879\n",
      "Epoch 10/10, Batch 961/1650, Loss 14.469356, Loss rec 3.054383, loss rec t1 3.708493, loss kl 0.166745, loss_trans 0.005937, loss flux 3.677630, loss flux t1 3.856169, binary loss 0.859532, binary loss t1 0.835066\n",
      "Epoch 10/10, Batch 971/1650, Loss 12.842854, Loss rec 2.667241, loss rec t1 3.342221, loss kl 0.136923, loss_trans 0.004822, loss flux 3.338831, loss flux t1 3.352814, binary loss 2.700266, binary loss t1 2.371515\n",
      "Epoch 10/10, Batch 981/1650, Loss 14.600469, Loss rec 3.328797, loss rec t1 3.002813, loss kl 0.141928, loss_trans 0.015111, loss flux 4.479519, loss flux t1 3.632300, binary loss 0.696824, binary loss t1 0.792923\n",
      "Epoch 10/10, Batch 991/1650, Loss 15.992033, Loss rec 3.570018, loss rec t1 3.768327, loss kl 0.132826, loss_trans 0.012038, loss flux 4.585068, loss flux t1 3.923757, binary loss 1.406079, binary loss t1 1.330844\n",
      "Epoch 10/10, Batch 1001/1650, Loss 13.634363, Loss rec 2.743927, loss rec t1 3.256757, loss kl 0.121821, loss_trans 0.006480, loss flux 3.781112, loss flux t1 3.724265, binary loss 2.006145, binary loss t1 1.695144\n",
      "Epoch 10/10, Batch 1011/1650, Loss 14.632459, Loss rec 3.262542, loss rec t1 3.801383, loss kl 0.125064, loss_trans 0.005360, loss flux 3.914706, loss flux t1 3.523403, binary loss 0.854957, binary loss t1 0.845091\n",
      "Epoch 10/10, Batch 1021/1650, Loss 17.042324, Loss rec 3.561572, loss rec t1 4.200528, loss kl 0.280281, loss_trans 0.008529, loss flux 4.645978, loss flux t1 4.345436, binary loss 1.264417, binary loss t1 1.092901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Batch 1031/1650, Loss 16.460220, Loss rec 3.999763, loss rec t1 4.813927, loss kl 0.138003, loss_trans 0.005887, loss flux 3.725510, loss flux t1 3.777129, binary loss 1.244453, binary loss t1 1.433915\n",
      "Epoch 10/10, Batch 1041/1650, Loss 15.608537, Loss rec 3.396394, loss rec t1 4.580492, loss kl 0.141935, loss_trans 0.009841, loss flux 3.701117, loss flux t1 3.778757, binary loss 2.142295, binary loss t1 2.054869\n",
      "Epoch 10/10, Batch 1051/1650, Loss 17.443575, Loss rec 4.609339, loss rec t1 4.253437, loss kl 0.226899, loss_trans 0.010941, loss flux 4.604427, loss flux t1 3.738533, binary loss 1.490390, binary loss t1 1.285696\n",
      "Epoch 10/10, Batch 1061/1650, Loss 12.800418, Loss rec 2.750073, loss rec t1 3.021726, loss kl 0.124929, loss_trans 0.008127, loss flux 3.500449, loss flux t1 3.395114, binary loss 1.670885, binary loss t1 1.740633\n",
      "Epoch 10/10, Batch 1071/1650, Loss 16.199741, Loss rec 3.183048, loss rec t1 4.365814, loss kl 0.309115, loss_trans 0.007310, loss flux 4.186884, loss flux t1 4.147572, binary loss 2.487908, binary loss t1 1.633439\n",
      "Epoch 10/10, Batch 1081/1650, Loss 19.390976, Loss rec 4.138921, loss rec t1 5.465932, loss kl 0.163654, loss_trans 0.010722, loss flux 5.318752, loss flux t1 4.292995, binary loss 1.173622, binary loss t1 1.051889\n",
      "Epoch 10/10, Batch 1091/1650, Loss 18.652163, Loss rec 4.741257, loss rec t1 4.314268, loss kl 0.208374, loss_trans 0.008581, loss flux 5.018403, loss flux t1 4.361280, binary loss 1.479282, binary loss t1 1.313069\n",
      "Epoch 10/10, Batch 1101/1650, Loss 16.744097, Loss rec 4.085310, loss rec t1 3.832560, loss kl 0.161089, loss_trans 0.007154, loss flux 4.863880, loss flux t1 3.794104, binary loss 1.076172, binary loss t1 1.003139\n",
      "Epoch 10/10, Batch 1111/1650, Loss 15.636559, Loss rec 3.479840, loss rec t1 4.294786, loss kl 0.162329, loss_trans 0.012831, loss flux 3.947424, loss flux t1 3.739349, binary loss 0.683233, binary loss t1 0.703149\n",
      "Epoch 10/10, Batch 1121/1650, Loss 16.376827, Loss rec 3.579615, loss rec t1 4.571838, loss kl 0.149340, loss_trans 0.008354, loss flux 4.410120, loss flux t1 3.657560, binary loss 1.239112, binary loss t1 1.121783\n",
      "Epoch 10/10, Batch 1131/1650, Loss 15.220843, Loss rec 3.795073, loss rec t1 3.944093, loss kl 0.137804, loss_trans 0.003922, loss flux 3.761616, loss flux t1 3.578335, binary loss 1.277825, binary loss t1 1.138304\n",
      "Epoch 10/10, Batch 1141/1650, Loss 12.470493, Loss rec 2.086339, loss rec t1 2.749971, loss kl 0.167580, loss_trans 0.014274, loss flux 3.939826, loss flux t1 3.512504, binary loss 2.482263, binary loss t1 1.795867\n",
      "Epoch 10/10, Batch 1151/1650, Loss 16.647461, Loss rec 3.805434, loss rec t1 4.218516, loss kl 0.160462, loss_trans 0.008793, loss flux 3.900139, loss flux t1 4.554118, binary loss 2.191105, binary loss t1 2.146931\n",
      "Epoch 10/10, Batch 1161/1650, Loss 15.369930, Loss rec 3.657882, loss rec t1 3.764701, loss kl 0.139361, loss_trans 0.009360, loss flux 4.159661, loss flux t1 3.638964, binary loss 0.677869, binary loss t1 0.688003\n",
      "Epoch 10/10, Batch 1171/1650, Loss 11.140545, Loss rec 1.983196, loss rec t1 2.573368, loss kl 0.107895, loss_trans 0.006840, loss flux 3.256752, loss flux t1 3.212495, binary loss 1.605383, binary loss t1 1.671846\n",
      "Epoch 10/10, Batch 1181/1650, Loss 16.147593, Loss rec 3.659197, loss rec t1 4.240897, loss kl 0.140970, loss_trans 0.007574, loss flux 4.385433, loss flux t1 3.713523, binary loss 1.136334, binary loss t1 1.047753\n",
      "Epoch 10/10, Batch 1191/1650, Loss 15.695334, Loss rec 3.654403, loss rec t1 4.381519, loss kl 0.128962, loss_trans 0.008683, loss flux 3.836109, loss flux t1 3.685659, binary loss 0.903548, binary loss t1 0.978905\n",
      "Epoch 10/10, Batch 1201/1650, Loss 20.398830, Loss rec 5.359427, loss rec t1 5.081207, loss kl 0.227768, loss_trans 0.009547, loss flux 5.138183, loss flux t1 4.582699, binary loss 1.168160, binary loss t1 1.069542\n",
      "Epoch 10/10, Batch 1211/1650, Loss 15.358988, Loss rec 3.340892, loss rec t1 3.389980, loss kl 0.197159, loss_trans 0.005443, loss flux 4.423956, loss flux t1 4.001557, binary loss 1.614301, binary loss t1 1.439365\n",
      "Epoch 10/10, Batch 1221/1650, Loss 14.984539, Loss rec 3.763706, loss rec t1 4.136602, loss kl 0.104811, loss_trans 0.008530, loss flux 3.502299, loss flux t1 3.468590, binary loss 1.399802, binary loss t1 1.517253\n",
      "Epoch 10/10, Batch 1231/1650, Loss 12.295883, Loss rec 2.212149, loss rec t1 2.931350, loss kl 0.140942, loss_trans 0.008455, loss flux 3.548150, loss flux t1 3.454836, binary loss 1.484720, binary loss t1 1.389606\n",
      "Epoch 10/10, Batch 1241/1650, Loss 16.944036, Loss rec 4.271311, loss rec t1 4.901048, loss kl 0.135254, loss_trans 0.013948, loss flux 3.930913, loss flux t1 3.691562, binary loss 1.299869, binary loss t1 1.341891\n",
      "Epoch 10/10, Batch 1251/1650, Loss 17.804102, Loss rec 4.035572, loss rec t1 5.436970, loss kl 0.154665, loss_trans 0.007326, loss flux 4.163939, loss flux t1 4.005630, binary loss 2.255403, binary loss t1 1.949926\n",
      "Epoch 10/10, Batch 1261/1650, Loss 20.270136, Loss rec 5.491549, loss rec t1 6.636839, loss kl 0.123959, loss_trans 0.006887, loss flux 4.136611, loss flux t1 3.874291, binary loss 0.342939, binary loss t1 0.359643\n",
      "Epoch 10/10, Batch 1271/1650, Loss 16.301855, Loss rec 3.173700, loss rec t1 4.832150, loss kl 0.130539, loss_trans 0.008718, loss flux 4.155473, loss flux t1 4.001276, binary loss 0.593911, binary loss t1 0.733859\n",
      "Epoch 10/10, Batch 1281/1650, Loss 17.876635, Loss rec 4.178498, loss rec t1 5.554926, loss kl 0.137467, loss_trans 0.007472, loss flux 4.082052, loss flux t1 3.916220, binary loss 0.991657, binary loss t1 0.900813\n",
      "Epoch 10/10, Batch 1291/1650, Loss 19.635229, Loss rec 5.496178, loss rec t1 6.291432, loss kl 0.172434, loss_trans 0.005546, loss flux 4.057168, loss flux t1 3.612473, binary loss 1.597694, binary loss t1 1.539005\n",
      "Epoch 10/10, Batch 1301/1650, Loss 19.064856, Loss rec 4.974591, loss rec t1 5.682190, loss kl 0.155788, loss_trans 0.005678, loss flux 4.405644, loss flux t1 3.840965, binary loss 1.968625, binary loss t1 1.769308\n",
      "Epoch 10/10, Batch 1311/1650, Loss 12.720236, Loss rec 2.302230, loss rec t1 2.881874, loss kl 0.268871, loss_trans 0.012428, loss flux 3.981284, loss flux t1 3.273549, binary loss 2.482263, binary loss t1 2.160008\n",
      "Epoch 10/10, Batch 1321/1650, Loss 15.523162, Loss rec 3.477169, loss rec t1 3.516662, loss kl 0.314161, loss_trans 0.007595, loss flux 4.280648, loss flux t1 3.926927, binary loss 0.579202, binary loss t1 0.600298\n",
      "Epoch 10/10, Batch 1331/1650, Loss 13.253188, Loss rec 2.665551, loss rec t1 3.330485, loss kl 0.127971, loss_trans 0.009191, loss flux 3.594850, loss flux t1 3.525139, binary loss 2.001789, binary loss t1 1.960887\n",
      "Epoch 10/10, Batch 1341/1650, Loss 18.558214, Loss rec 4.846257, loss rec t1 5.394969, loss kl 0.154974, loss_trans 0.005281, loss flux 4.356458, loss flux t1 3.800275, binary loss 0.854387, binary loss t1 0.780308\n",
      "Epoch 10/10, Batch 1351/1650, Loss 19.619329, Loss rec 5.294692, loss rec t1 6.027180, loss kl 0.165124, loss_trans 0.013269, loss flux 4.339667, loss flux t1 3.779395, binary loss 0.338706, binary loss t1 0.358719\n",
      "Epoch 10/10, Batch 1361/1650, Loss 20.442371, Loss rec 5.195915, loss rec t1 6.867126, loss kl 0.145757, loss_trans 0.005716, loss flux 4.076456, loss flux t1 4.151401, binary loss 4.039857, binary loss t1 3.797436\n",
      "Epoch 10/10, Batch 1371/1650, Loss 20.080305, Loss rec 5.366054, loss rec t1 5.933799, loss kl 0.123753, loss_trans 0.008067, loss flux 4.590145, loss flux t1 4.058488, binary loss 0.878622, binary loss t1 0.801063\n",
      "Epoch 10/10, Batch 1381/1650, Loss 22.685213, Loss rec 6.485703, loss rec t1 6.839057, loss kl 0.198529, loss_trans 0.006326, loss flux 4.824983, loss flux t1 4.330616, binary loss 3.395555, binary loss t1 2.832012\n",
      "Epoch 10/10, Batch 1391/1650, Loss 19.919058, Loss rec 6.301933, loss rec t1 5.000732, loss kl 0.140377, loss_trans 0.004948, loss flux 4.311503, loss flux t1 4.159565, binary loss 3.736582, binary loss t1 3.205218\n",
      "Epoch 10/10, Batch 1401/1650, Loss 20.531256, Loss rec 5.107404, loss rec t1 4.291698, loss kl 0.133802, loss_trans 0.009509, loss flux 6.545684, loss flux t1 4.443161, binary loss 0.843825, binary loss t1 0.913561\n",
      "Epoch 10/10, Batch 1411/1650, Loss 24.634382, Loss rec 6.858699, loss rec t1 8.215303, loss kl 0.110920, loss_trans 0.009355, loss flux 5.093048, loss flux t1 4.347057, binary loss 0.564068, binary loss t1 0.546598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10, Batch 1421/1650, Loss 18.618324, Loss rec 4.098661, loss rec t1 4.385388, loss kl 0.136104, loss_trans 0.005512, loss flux 5.191366, loss flux t1 4.801292, binary loss 1.887794, binary loss t1 1.655398\n",
      "Epoch 10/10, Batch 1431/1650, Loss 19.370661, Loss rec 6.191673, loss rec t1 4.429347, loss kl 0.422994, loss_trans 0.011117, loss flux 4.363784, loss flux t1 3.951748, binary loss 4.074263, binary loss t1 2.387027\n",
      "Epoch 10/10, Batch 1441/1650, Loss 18.902538, Loss rec 3.659836, loss rec t1 4.272242, loss kl 0.231114, loss_trans 0.007240, loss flux 5.422732, loss flux t1 5.309373, binary loss 1.170398, binary loss t1 0.982202\n",
      "Epoch 10/10, Batch 1451/1650, Loss 16.928625, Loss rec 3.639842, loss rec t1 4.148340, loss kl 0.155167, loss_trans 0.011930, loss flux 4.817894, loss flux t1 4.155452, binary loss 1.093947, binary loss t1 1.097353\n",
      "Epoch 10/10, Batch 1461/1650, Loss 13.251588, Loss rec 2.639066, loss rec t1 2.515431, loss kl 0.164861, loss_trans 0.006304, loss flux 4.133265, loss flux t1 3.792660, binary loss 1.733808, binary loss t1 1.302132\n",
      "Epoch 10/10, Batch 1471/1650, Loss 15.954797, Loss rec 3.645770, loss rec t1 3.541809, loss kl 0.170375, loss_trans 0.006905, loss flux 4.837419, loss flux t1 3.752518, binary loss 2.366065, binary loss t1 1.834542\n",
      "Epoch 10/10, Batch 1481/1650, Loss 14.817488, Loss rec 3.192857, loss rec t1 4.066999, loss kl 0.136085, loss_trans 0.007839, loss flux 3.757701, loss flux t1 3.656008, binary loss 4.731862, binary loss t1 4.013348\n",
      "Epoch 10/10, Batch 1491/1650, Loss 20.669144, Loss rec 7.002090, loss rec t1 4.707116, loss kl 0.188553, loss_trans 0.010849, loss flux 4.424617, loss flux t1 4.335918, binary loss 1.840115, binary loss t1 1.643061\n",
      "Epoch 10/10, Batch 1501/1650, Loss 15.385182, Loss rec 3.116692, loss rec t1 3.810601, loss kl 0.153866, loss_trans 0.014939, loss flux 4.376850, loss flux t1 3.912234, binary loss 2.167843, binary loss t1 2.051548\n",
      "Epoch 10/10, Batch 1511/1650, Loss 17.865898, Loss rec 3.861422, loss rec t1 5.853670, loss kl 0.151861, loss_trans 0.009276, loss flux 3.928182, loss flux t1 4.061484, binary loss 2.663731, binary loss t1 2.691433\n",
      "Epoch 10/10, Batch 1521/1650, Loss 12.495471, Loss rec 2.024788, loss rec t1 2.917394, loss kl 0.387772, loss_trans 0.005902, loss flux 3.876060, loss flux t1 3.283554, binary loss 2.115822, binary loss t1 1.296536\n",
      "Epoch 10/10, Batch 1531/1650, Loss 18.084066, Loss rec 3.965494, loss rec t1 5.149408, loss kl 0.245672, loss_trans 0.005675, loss flux 4.679854, loss flux t1 4.037964, binary loss 1.408403, binary loss t1 1.260160\n",
      "Epoch 10/10, Batch 1541/1650, Loss 15.631346, Loss rec 3.694093, loss rec t1 3.741293, loss kl 0.157166, loss_trans 0.009470, loss flux 4.234896, loss flux t1 3.794427, binary loss 0.620360, binary loss t1 0.629302\n",
      "Epoch 10/10, Batch 1551/1650, Loss 19.547873, Loss rec 5.534648, loss rec t1 5.147380, loss kl 0.291738, loss_trans 0.007827, loss flux 4.842279, loss flux t1 3.724001, binary loss 0.668124, binary loss t1 0.697324\n",
      "Epoch 10/10, Batch 1561/1650, Loss 13.461897, Loss rec 2.723738, loss rec t1 3.055439, loss kl 0.175591, loss_trans 0.005885, loss flux 4.090155, loss flux t1 3.411088, binary loss 2.594130, binary loss t1 1.650787\n",
      "Epoch 10/10, Batch 1571/1650, Loss 14.582707, Loss rec 3.164242, loss rec t1 3.118564, loss kl 0.277385, loss_trans 0.005225, loss flux 4.413769, loss flux t1 3.603523, binary loss 1.444888, binary loss t1 1.318763\n",
      "Epoch 10/10, Batch 1581/1650, Loss 25.360285, Loss rec 7.085478, loss rec t1 8.935232, loss kl 0.202761, loss_trans 0.009634, loss flux 4.800608, loss flux t1 4.326571, binary loss 0.296440, binary loss t1 0.290929\n",
      "Epoch 10/10, Batch 1591/1650, Loss 21.700844, Loss rec 5.586457, loss rec t1 7.138850, loss kl 0.192234, loss_trans 0.005966, loss flux 4.389426, loss flux t1 4.387910, binary loss 0.415837, binary loss t1 0.533435\n",
      "Epoch 10/10, Batch 1601/1650, Loss 19.597506, Loss rec 7.604002, loss rec t1 3.557757, loss kl 0.291815, loss_trans 0.004857, loss flux 4.239060, loss flux t1 3.900017, binary loss 0.912405, binary loss t1 0.782983\n",
      "Epoch 10/10, Batch 1611/1650, Loss 21.278606, Loss rec 5.483763, loss rec t1 7.167750, loss kl 0.129426, loss_trans 0.010143, loss flux 4.449533, loss flux t1 4.037991, binary loss 1.011475, binary loss t1 0.961923\n",
      "Epoch 10/10, Batch 1621/1650, Loss 21.911705, Loss rec 6.014654, loss rec t1 7.328136, loss kl 0.156820, loss_trans 0.007003, loss flux 4.162619, loss flux t1 4.242473, binary loss 0.784664, binary loss t1 0.717276\n",
      "Epoch 10/10, Batch 1631/1650, Loss 23.485567, Loss rec 6.657321, loss rec t1 7.952362, loss kl 0.211001, loss_trans 0.004628, loss flux 4.516795, loss flux t1 4.143461, binary loss 2.104653, binary loss t1 1.680617\n",
      "Epoch 10/10, Batch 1641/1650, Loss 27.818153, Loss rec 8.053144, loss rec t1 9.827784, loss kl 0.218165, loss_trans 0.007664, loss flux 5.102565, loss flux t1 4.608829, binary loss 0.570833, binary loss t1 0.613888\n",
      "Epoch 10/10, Train loss 19.014183, Eval loss 19.364065\n"
     ]
    }
   ],
   "source": [
    "# Optimization\n",
    "opt = Adam(lr=learning_rate)\n",
    "\n",
    "trainable_weights = encoder.trainable_weights + decoder.trainable_weights + transition.trainable_weights\n",
    "\n",
    "updates = opt.get_updates(loss, trainable_weights)\n",
    "\n",
    "iterate = K.function([xt, ut, xt1, m_tf], [loss, loss_rec_t, loss_rec_t1, loss_kl, loss_trans, loss_flux_t, loss_flux_t1, binary_sat_loss_t, binary_sat_loss_t1], updates=updates)\n",
    "\n",
    "eval_loss = K.function([xt, ut, xt1, m_tf], [loss])\n",
    "\n",
    "num_batch = int(num_train/batch_size)\n",
    "\n",
    "for e in range(epoch):\n",
    "    for ib in range(num_batch):\n",
    "        ind0 = ib * batch_size\n",
    "        state_t_batch = state_t_train[ind0:ind0+batch_size, ...]\n",
    "        state_t1_batch = state_t1_train[ind0:ind0 + batch_size, ...]\n",
    "        bhp_batch = bhp_train[ind0:ind0 + batch_size, ...]\n",
    "        m_batch = m[ind0:ind0 + batch_size, ...]\n",
    "\n",
    "        output = iterate([state_t_batch, bhp_batch, state_t1_batch, m_batch])\n",
    "\n",
    "        # tf.session.run(feed_dict={xt: sat_t_batch, ut: bhp_batch, xt1: sat_t1_batch}, ...\n",
    "        #                fetches= [loss, loss_rec_t, loss_rec_t1, loss_kl, loss_trans, updates])\n",
    "        # But output tensor for the updates operation is not returned\n",
    "\n",
    "        if ib % 10 == 0:\n",
    "            print('Epoch %d/%d, Batch %d/%d, Loss %f, Loss rec %f, loss rec t1 %f, loss kl %f, loss_trans %f, loss flux %f, loss flux t1 %f, binary loss %f, binary loss t1 %f'\n",
    "                  % (e+1, epoch, ib+1, num_batch, output[0], output[1], output[2], output[3], output[4], output[5], output[6], output[7], output[8]))\n",
    "    eval_loss_val = eval_loss([state_t_eval, bhp_eval, state_t1_eval, m_eval])\n",
    "\n",
    "    print('Epoch %d/%d, Train loss %f, Eval loss %f' % (e + 1, epoch, output[0], eval_loss_val[0]))\n",
    "\n",
    "\n",
    "encoder.save_weights(output_dir + 'e2c_encoder_' + case_name + case_suffix + train_suffix + model_suffix + '_nt%d_l%d_lr%.0e_ep%d.h5' \\\n",
    "                     % (num_train, latent_dim, learning_rate, epoch))\n",
    "decoder.save_weights(output_dir + 'e2c_decoder_' + case_name + case_suffix + train_suffix + model_suffix + '_nt%d_l%d_lr%.0e_ep%d.h5' \\\n",
    "                     % (num_train, latent_dim, learning_rate, epoch))\n",
    "transition.save_weights(output_dir + 'e2c_transition_' + case_name + case_suffix + train_suffix + model_suffix + '_nt%d_l%d_lr%.0e_ep%d.h5' \\\n",
    "                        % (num_train, latent_dim, learning_rate, epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
